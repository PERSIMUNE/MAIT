
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>MAIT 1.0.0 - Tutorial: Dementia prediction &#8212; How to use medical artificial intelligence toolbox (MAIT)</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!-- 
    this give us a css class that will be invisible only if js is disabled 
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- So that users can add custom icons -->
  <script src="_static/scripts/fontawesome.js?digest=26a4bc78f4c0ddb94549"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549" />

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'MAIT_Tutorial_Dementia_pub';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="MAIT 1.0.0 - Tutorial: Azithromycin antibiotic resistance prediction based on unitigs representing DNA variation in bacteria" href="MAIT_Tutorial_Azithromycin_pub.html" />
    <link rel="prev" title="MAIT 1.0.0 - Tutorial: Breast cancer prediction" href="MAIT_Tutorial_BreastCancer_pub.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="How to use medical artificial intelligence toolbox (MAIT) - Home"/>
    <img src="_static/logo.png" class="logo__image only-dark pst-js-only" alt="How to use medical artificial intelligence toolbox (MAIT) - Home"/>
  
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    How to use medical artificial intelligence toolbox (MAIT)
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="QuickStart.html">QuickStart - minimal configuration guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="MANUAL.html">MAIT 1.0.0 Manual</a></li>
<li class="toctree-l1"><a class="reference internal" href="MAIT_Tutorial_BreastCancer_pub.html">MAIT 1.0.0 - Tutorial: Breast cancer prediction</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">MAIT 1.0.0 - Tutorial: Dementia prediction</a></li>
<li class="toctree-l1"><a class="reference internal" href="MAIT_Tutorial_Azithromycin_pub.html">MAIT 1.0.0 - Tutorial: Azithromycin antibiotic resistance prediction based on unitigs representing DNA variation in bacteria</a></li>
<li class="toctree-l1"><a class="reference internal" href="MAIT_Tutorial_Ciprofloxacin_pub.html">MAIT 1.0.0 - Tutorial: Ciprofloxacin antibiotic resistance prediction based on unitigs representing DNA variation in bacteria</a></li>
<li class="toctree-l1"><a class="reference internal" href="Executed_tutorials.html">Executed tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="function_reference.html">Function Reference</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/PERSIMUNE/MAIT" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/PERSIMUNE/MAIT/issues/new?title=Issue%20on%20page%20%2FMAIT_Tutorial_Dementia_pub.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/MAIT_Tutorial_Dementia_pub.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>MAIT 1.0.0 - Tutorial: Dementia prediction</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dataset-summary">Dataset Summary</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#load-data-libraries-and-set-parameters">Load Data, Libraries, and Set Parameters.</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#most-important-settings">Most important settings</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#less-important-settings">Less important settings</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#data-preparation">Data preparation</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#specify-data-types-for-numerical-features-optional">Specify data types for numerical features (optional)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#defined-missingness">Defined missingness</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#rare-categories-in-categorical-variables-and-data-harmonization-for-missing-values">Rare categories in categorical variables and data harmonization for missing values</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#shorten-the-name-of-features-optional">Shorten the name of features (optional)</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-split-prediction-vs-discovery">Data split (prediction vs. discovery)</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#checking-the-availability-of-all-categories">Checking the availability of all categories</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#filter-highly-missing-data">Filter highly missing data</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#feature-selection-optional-but-recommended-if-the-dataset-is-high-dimensional-e-g-100-features">Feature selection (optional but recommended if the dataset is high dimensional, e.g &gt;100 features)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#cross-correlation-of-variables">Cross correlation of variables</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sample-size-assessment">Sample size assessment</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#statistical-comparision-of-the-training-and-test-sets">Statistical comparision of the training and test sets</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-overview">Data overview</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#display-the-type-of-the-variables-columns">Display the type of the variables (columns)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#check-missing-values">Check missing values</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-imputation">Data imputation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#correlation-analysis">Correlation analysis</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#checking-the-outcome-variable-and-its-categories-binary">Checking the outcome variable and its categories (binary)</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-visualization">Data visualization</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#function-to-evaluate-models-and-generate-roc-curve-pr-curve-and-confusion-matrix">Function to evaluate models and generate ROC curve, PR curve and confusion matrix</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#initiate-machine-learning-models">Initiate machine learning models</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#variable-type-encoding-for-qlattice-model-only-required-for-qlattice">Variable type encoding for QLattice model (only required for QLattice)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#set-model-weights-based-on-class-balance-from-the-training-development-set">Set model weights based on class balance from the training (development) set</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#define-the-parameter-grid-for-random-search">Define the parameter grid for random search</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#set-parameters-for-models-when-the-datset-is-small">Set parameters for models (when the datset is small)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#k-fold-stratified-cross-validation-of-binary-classification-models">K-fold stratified cross validation of binary classification models</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#shap-summary-plot-for-when-the-model-uses-categorical-features">SHAP summary plot for when the model uses categorical features</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#qlattice-model">QLattice model</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#gaussian-naive-bayes">Gaussian Naive Bayes</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#random-forest-classifier-rf">Random Forest Classifier (RF)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#histogram-based-gradient-boosting-classification-tree-hgbc">Histogram-based Gradient Boosting Classification Tree (HGBC)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#light-gradient-boosting-machine-lightgbm">Light gradient-boosting machine (LightGBM)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#categorical-boosting-catboost">Categorical boosting (CATBoost)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#summary-of-the-cross-validation-results">summary of the cross validation results</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#statistical-test-to-compare-the-performance-of-the-models-on-cross-validation">Statistical test to compare the performance of the models on cross validation</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#model-uncertainty-reduction-mur-optional">Model Uncertainty Reduction (MUR) - optional</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#stopping-if-there-is-no-data-split">Stopping if there is no data split</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#prediction-block-for-binary-classification-models">Prediction block for binary classification models</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">QLattice model</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#test-dummy-models">Test dummy models</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">Gaussian Naive Bayes</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#logistic-regression">Logistic Regression</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#histgbc">HistGBC</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#random-forest-rf">Random Forest (RF)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#lightgbm">LightGBM</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#catboost">CatBoost</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#model-interpretation-for-the-best-performing-model">Model interpretation for the best performing model</a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#shap-values-association-with-predicted-probabilities">SHAP values association with predicted probabilities</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#interpret-the-model-based-on-shap-analysis">Interpret the model based on SHAP analysis</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#shap-summary-plot">SHAP summary plot</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#significance-of-features">Significance of features</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#model-interpretation-only-based-on-correctly-classified-samples">Model interpretation only based on correctly classified samples</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#feature-interactions-based-on-shap-method">Feature interactions based on SHAP method</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#additional-analyses-on-model-interpretation-and-evaluation">Additional analyses on model interpretation and evaluation:</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#feature-interactions-based-on-feature-permutation-method-for-feature-pairs">Feature interactions based on feature permutation method for feature pairs</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#shap-decision-plot">SHAP decision plot</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#shap-dependence-plots">SHAP dependence plots</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#shap-clustering">SHAP clustering</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#shap-force-plot-for-individuals-e-g-one-patient">SHAP force plot for individuals (e.g., one patient)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#decision-curve-analysis">Decision curve analysis</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#cost-sensitive-model-evaluation">Cost-sensitive model evaluation</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#model-calibration-and-conformal-predictions-optional">Model calibration and conformal predictions (optional)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#export-the-selected-model-to-deploy">Export the selected model to deploy</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#survival-models">Survival models</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#training-and-evaluation-of-the-survival-models">Training and evaluation of the survival models</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#concordance-index-ci-and-integrated-brier-score-ibs">Concordance Index (CI) and Integrated Brier Score (IBS)</a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#concordance-index-ci">Concordance Index (CI)</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#integrated-brier-score-ibs">Integrated Brier Score (IBS)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#k-fold-cross-validation-of-survival-models">K-fold cross validation of survival models</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#feature-importance-for-the-survival-model">feature importance for the survival model</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#predicted-survival-and-cumulative-hazard">Predicted survival and cumulative hazard</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#regression-models">Regression models</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#interpreting-regression-model-performance-metrics">Interpreting Regression Model Performance Metrics</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#model-interpretation">Model interpretation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#report-the-environment">Report the environment</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#save-the-pipeline-logs-in-html-format">Save the pipeline logs in HTML format</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#references">References</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="mait-1-0-0-tutorial-dementia-prediction">
<h1>MAIT 1.0.0 - Tutorial: Dementia prediction<a class="headerlink" href="#mait-1-0-0-tutorial-dementia-prediction" title="Link to this heading">#</a></h1>
<p>MAIT (medical artificial intelligence toolbox) is designed to streamline studies involving machine learning, with a particular focus on binary classification, while also extending its utility to precision medicine. It also allows the development of survival and regression models, alongside facilitating comparisons between machine learning and statistical models.</p>
<p>MAIT performs model evaluation and interpretation and presents the results in formats suitable for publication, including figures and tables. Moreover, MAIT offers essential data processing functionalities such as quality checks, imputation, scaling, exploration through association plots, and data splitting.</p>
<p>The data splitting feature is particularly advantageous for projects aiming to create prognostic or diagnostic tools, ensuring a portion of the dataset is reserved for external validation. Without data splitting, MAIT remains valuable for exploring associations, such as predictive feature discovery.</p>
<p>MAIT has many unique functionalities compared to existing pipelines and framwework that are explained in details in its documentation files (e.g., MANUAL) on GitHub and its upcoming paper.</p>
<p>For further details and practical examples, visit the MAIT repository on GitHub: <a class="github reference external" href="https://github.com/PERSIMUNE/MAIT">PERSIMUNE/MAIT</a>.</p>
<p>The development of MAIT is a result of extensive research and programming to provide a reliable open-access software for research. If you choose to utilize MAIT in your research, we kindly request that you cite it, enabling other researchers to discover and benefit from its capabilities.</p>
<p>Citation information is available on <a class="github reference external" href="https://github.com/PERSIMUNE/MAIT">PERSIMUNE/MAIT</a></p>
<p>MAIT is developed by Ramtin Zargari Marandi, PhD (Postdoc researcher), at PERSIMUNE - CHIP Center of excellence for health, immunity and infections - Rigshospitalet, Copenhagen University Hospital, to conduct several machine learning studies. Affiliated researchers are Anne Svane Frahm, PhD, Maja Milojevic, PhD, and Daniel Murray, PhD.</p>
<p>The pipeline is based on well-stablished Python packages and frameworks such as scikit-learn. All the packages and their versions that are used in the pipeline are reported as part of the pipeline documentation.</p>
<p>To utilize MAIT effectively, it is recommended to familiarize yourself with concepts and techniques in machine learning and statistical analyses. This foundational knowledge will enable you to understand MAIT’s functionalities and leverage them optimally for your research objectives.</p>
<p>Please note that the provided tutorials serve solely as guides for using MAIT and should not be relied upon for any scientific or clinical implications.</p>
<p><img alt="Logo" src="_images/MAITlogo_v4.png" /></p>
<section id="dataset-summary">
<h2>Dataset Summary<a class="headerlink" href="#dataset-summary" title="Link to this heading">#</a></h2>
<p>Dementia, typically a chronic or progressive syndrome, entails a decline in cognitive function surpassing normal aging effects. It impacts various cognitive abilities including memory, thinking, orientation, comprehension, calculation, learning capacity, language, and judgment. Consciousness remains unaffected. Cognitive decline is often accompanied or preceded by changes in emotional control, social behavior, or motivation. Dementia stems from diverse brain-affecting diseases and injuries such as Alzheimer’s disease or stroke. It stands as a leading cause of disability and dependency among older individuals globally. The ramifications extend beyond the affected individuals to their caregivers and families, compounded by a lack of awareness and understanding, leading to stigma and barriers to diagnosis and care. The repercussions of dementia encompass physical, psychological, social, and economic dimensions.</p>
<p>This dataset comprises a longitudinal collection of 150 subjects aged 60 to 96. Each subject underwent multiple scans, separated by at least one year, resulting in 373 imaging sessions. Each subject’s data includes 3 or 4 individual T1-weighted MRI scans from single scan sessions. The subjects are all right-handed and encompass both genders. Of the total subjects, 72 remained nondemented throughout the study, while 64 were initially characterized as demented and continued to be so in subsequent scans, including 51 individuals with mild to moderate Alzheimer’s disease. Additionally, 14 subjects initially classified as nondemented were later identified as demented in subsequent visits.</p>
<p>See also Battineni, Gopi; Amenta, Francesco; Chintalapudi, Nalini (2019), “Data for: MACHINE LEARNING IN MEDICINE: CLASSIFICATION AND PREDICTION OF DEMENTIA BY SUPPORT VECTOR MACHINES (SVM)”, Mendeley Data, V1, doi: 10.17632/tsy6rbc5d4.1</p>
<p><a class="reference external" href="https://www.kaggle.com/datasets/shashwatwork/dementia-prediction-dataset">Dataset is available here.</a></p>
<p><em>source: <a class="reference external" href="https://www.kaggle.com/datasets/shashwatwork/dementia-prediction-dataset">Kaggle</a></em></p>
</section>
<section id="load-data-libraries-and-set-parameters">
<h2>Load Data, Libraries, and Set Parameters.<a class="headerlink" href="#load-data-libraries-and-set-parameters" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Here we load dataset and required libraries </span>
<span class="c1"># Remove Future Warnings</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">simplefilter</span><span class="p">(</span><span class="n">action</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="ne">FutureWarning</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">numpy.random</span> <span class="kn">import</span> <span class="n">uniform</span><span class="p">,</span> <span class="n">randint</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span><span class="p">,</span> <span class="n">RandomizedSearchCV</span><span class="p">,</span> <span class="n">StratifiedKFold</span><span class="p">,</span> <span class="n">KFold</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">make_scorer</span><span class="p">,</span> <span class="n">matthews_corrcoef</span><span class="p">,</span> <span class="n">average_precision_score</span><span class="p">,</span> <span class="n">balanced_accuracy_score</span><span class="p">,</span> <span class="n">f1_score</span><span class="p">,</span> <span class="n">confusion_matrix</span><span class="p">,</span> <span class="n">roc_auc_score</span><span class="p">,</span> <span class="n">brier_score_loss</span><span class="p">,</span> <span class="n">precision_recall_curve</span><span class="p">,</span> <span class="n">roc_curve</span><span class="p">,</span> <span class="n">auc</span><span class="p">,</span> <span class="n">matthews_corrcoef</span><span class="p">,</span> <span class="n">ConfusionMatrixDisplay</span>
<span class="kn">from</span> <span class="nn">sklearn.utils.class_weight</span> <span class="kn">import</span> <span class="n">compute_sample_weight</span>
<span class="kn">from</span> <span class="nn">sklearn.inspection</span> <span class="kn">import</span> <span class="n">permutation_importance</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">RobustScaler</span><span class="p">,</span> <span class="n">LabelEncoder</span><span class="p">,</span> <span class="n">MinMaxScaler</span>
<span class="kn">import</span> <span class="nn">shap</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">ensemble</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">pointbiserialr</span><span class="p">,</span> <span class="n">wilcoxon</span><span class="p">,</span> <span class="n">mannwhitneyu</span><span class="p">,</span> <span class="n">chi2_contingency</span><span class="p">,</span> <span class="n">norm</span><span class="p">,</span> <span class="n">iqr</span><span class="p">,</span> <span class="n">kruskal</span><span class="p">,</span> <span class="n">spearmanr</span><span class="p">,</span> <span class="n">ttest_rel</span><span class="p">,</span> <span class="n">linregress</span>
<span class="kn">from</span> <span class="nn">joblib</span> <span class="kn">import</span> <span class="n">Parallel</span><span class="p">,</span> <span class="n">delayed</span>
<span class="kn">from</span> <span class="nn">mrmr</span> <span class="kn">import</span> <span class="n">mrmr_classif</span> <span class="c1"># for feature selection (optional)</span>
<span class="kn">from</span> <span class="nn">imblearn.over_sampling</span> <span class="kn">import</span> <span class="n">RandomOverSampler</span> <span class="c1"># for oversampling (optional)</span>
<span class="c1"># loading models (libraries or packages for base models)</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">import</span> <span class="nn">lightgbm</span> <span class="k">as</span> <span class="nn">lgb</span>
<span class="kn">import</span> <span class="nn">catboost</span> <span class="k">as</span> <span class="nn">cb</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">import</span> <span class="nn">feyn</span>
<span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">GaussianNB</span>
<span class="kn">from</span> <span class="nn">sklearn.impute</span> <span class="kn">import</span> <span class="n">KNNImputer</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">mutual_info_classif</span>
<span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">AgglomerativeClustering</span>
<span class="kn">from</span> <span class="nn">sksurv.util</span> <span class="kn">import</span> <span class="n">Surv</span>
<span class="kn">from</span> <span class="nn">sksurv.ensemble</span> <span class="kn">import</span> <span class="n">RandomSurvivalForest</span>
<span class="kn">from</span> <span class="nn">sksurv.metrics</span> <span class="kn">import</span> <span class="n">integrated_brier_score</span><span class="p">,</span> <span class="n">cumulative_dynamic_auc</span><span class="p">,</span> <span class="n">concordance_index_censored</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">IsolationForest</span><span class="p">,</span> <span class="n">RandomForestRegressor</span><span class="p">,</span> <span class="n">HistGradientBoostingClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">OneHotEncoder</span><span class="p">,</span> <span class="n">QuantileTransformer</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span><span class="p">,</span> <span class="n">mean_absolute_error</span><span class="p">,</span> <span class="n">r2_score</span><span class="p">,</span> <span class="n">silhouette_score</span>
<span class="kn">from</span> <span class="nn">joblib</span> <span class="kn">import</span> <span class="n">dump</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_classification</span>
<span class="kn">from</span> <span class="nn">sklearn.calibration</span> <span class="kn">import</span> <span class="n">CalibratedClassifierCV</span>
<span class="kn">from</span> <span class="nn">sklearn.isotonic</span> <span class="kn">import</span> <span class="n">IsotonicRegression</span>
<span class="kn">import</span> <span class="nn">joblib</span>
<span class="kn">from</span> <span class="nn">sksurv.linear_model</span> <span class="kn">import</span> <span class="n">CoxPHSurvivalAnalysis</span>
<span class="kn">from</span> <span class="nn">sklearn.semi_supervised</span> <span class="kn">import</span> <span class="n">LabelPropagation</span>
<span class="kn">from</span> <span class="nn">survshap</span> <span class="kn">import</span> <span class="n">SurvivalModelExplainer</span><span class="p">,</span> <span class="n">PredictSurvSHAP</span><span class="p">,</span> <span class="n">ModelSurvSHAP</span>
<span class="kn">from</span> <span class="nn">sksurv.compare</span> <span class="kn">import</span> <span class="n">compare_survival</span>
<span class="kn">from</span> <span class="nn">sklearn.dummy</span> <span class="kn">import</span> <span class="n">DummyClassifier</span>
<span class="kn">from</span> <span class="nn">scipy.integrate</span> <span class="kn">import</span> <span class="n">trapezoid</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">cm</span>
<span class="kn">from</span> <span class="nn">matplotlib.table</span> <span class="kn">import</span> <span class="n">table</span>
<span class="kn">from</span> <span class="nn">sympy</span> <span class="kn">import</span> <span class="n">init_printing</span>
<span class="kn">import</span> <span class="nn">itertools</span>
<span class="kn">from</span> <span class="nn">io</span> <span class="kn">import</span> <span class="n">StringIO</span>
<span class="kn">from</span> <span class="nn">IPython</span> <span class="kn">import</span> <span class="n">get_ipython</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">display</span><span class="p">,</span> <span class="n">Javascript</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">platform</span>
<span class="kn">import</span> <span class="nn">subprocess</span>
<span class="kn">import</span> <span class="nn">psutil</span>
<span class="o">%</span><span class="k">matplotlib</span> inline

<span class="c1"># Initialize MinMaxScaler for normalization</span>
<span class="n">minmax_scaler</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<section id="most-important-settings">
<h3>Most important settings<a class="headerlink" href="#most-important-settings" title="Link to this heading">#</a></h3>
<p>Below you can find parameters and configurations to set and complete like an entry form that are critical and important, so please make sure that you have an understanding on the parameters by reading the comments and the documentation of the pipeline (the MANUAL page on GitHub).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># settings for categorical variables</span>
<span class="c1"># specify the names of categorical features (variables) - if no categorical feature leave it empty as []</span>
<span class="n">cat_features</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;M/F&quot;</span><span class="p">,</span><span class="s2">&quot;Hand&quot;</span><span class="p">]</span>
<span class="n">merged_rare_categories</span> <span class="o">=</span> <span class="kc">True</span> <span class="c1"># merge rare categories and unify missing categories (recommended)</span>
<span class="n">rarity_threshold</span> <span class="o">=</span> <span class="mf">0.05</span>  <span class="c1"># Define a threshold for rarity (e.g., 0.05 means 5%) this is used to merge rare categories in categorical features (optional)</span>

<span class="c1">###################################################################################</span>
<span class="c1"># specify columns that must be removed</span>
<span class="n">columns_to_drop</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Subject ID&quot;</span><span class="p">,</span> <span class="s2">&quot;MRI ID&quot;</span><span class="p">]</span>
<span class="c1">###################################################################################</span>
<span class="c1"># import data</span>
<span class="n">mydata</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;dementia_dataset.csv&quot;</span><span class="p">)</span>
<span class="n">external_val</span> <span class="o">=</span> <span class="kc">False</span> <span class="c1"># True if you have a dataset that can be used as an external validation data</span>
<span class="c1"># load any external data</span>
<span class="c1"># extval_data = pd.read_excel(&#39;external_validation_data.xlsx&#39;)</span>
<span class="n">ext_val_demo</span> <span class="o">=</span> <span class="kc">True</span> <span class="c1"># only used to run a demo for external validation - this creates external validation dataset for simulation </span>

<span class="c1">###################################################################################</span>
<span class="c1"># random data split</span>
<span class="n">data_split</span> <span class="o">=</span> <span class="kc">True</span> <span class="c1"># True to apply stratified data split by outcome variable (e.g., 80% training or development data and 20% test data) </span>
<span class="c1"># if data_split = False, all the dataset will be used for cross validation (can be used when there is no enough data to set aside for the test set)</span>
<span class="n">train_size_perc</span> <span class="o">=</span> <span class="mf">0.8</span> <span class="c1"># percentage of the samples to be used for training (e.g. 0.8 means 80% of samples for training)</span>
<span class="c1"># see the following conditions to check if you need to do any custom data split based on your data</span>
<span class="c1"># below can be used in the case where multiple samples (instances) are available from same patients</span>
<span class="n">data_split_by_patients</span> <span class="o">=</span> <span class="kc">False</span> <span class="c1"># True to apply data split by patient ID (the column name that contains patient ID should then be specified)</span>
<span class="k">if</span> <span class="n">data_split_by_patients</span><span class="p">:</span>
    <span class="n">patient_id_col</span> <span class="o">=</span> <span class="s2">&quot;patient_ID&quot;</span> <span class="c1"># the column name that contains patient ID should then be specified (if not patients, it could be any individual identification number for example)</span>
<span class="n">data_split_multi_strats</span> <span class="o">=</span> <span class="kc">False</span> <span class="c1"># True if you need to use more than one variable for stratification</span>
<span class="k">if</span> <span class="n">data_split_multi_strats</span><span class="p">:</span> <span class="c1"># the names of the columns used for multiple stratification should be specified by user</span>
    <span class="n">strat_var1</span> <span class="o">=</span> <span class="s2">&quot;stratification variable 1&quot;</span>
<span class="n">already_split</span> <span class="o">=</span> <span class="kc">False</span> <span class="c1"># indicate if the data is already split to train and test sets</span>
<span class="k">if</span> <span class="n">already_split</span><span class="p">:</span> <span class="c1"># specify the names of the train (development) and test sets</span>
    <span class="c1"># Splitting based on values</span>
    <span class="n">testset</span> <span class="o">=</span> <span class="n">mydata</span><span class="p">[</span><span class="n">mydata</span><span class="p">[</span><span class="s1">&#39;subset&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;Test&#39;</span><span class="p">]</span>
    <span class="n">mydata</span> <span class="o">=</span> <span class="n">mydata</span><span class="p">[</span><span class="n">mydata</span><span class="p">[</span><span class="s1">&#39;subset&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;Train&#39;</span><span class="p">]</span>
<span class="c1"># so data_split = True is used for MAIT Discovery and Prediciton whereas data_split = False is used for MAIT Discovery pipeline (only cross validation is done)</span>
<span class="c1">###################################################################################</span>

<span class="c1"># available binary classification models in the pipeline to use (7 in total) - you can delete the name of any algorithms/models from the list to exclude them from the pipeline</span>
<span class="c1"># models_to_include = [&quot;NaiveBayes_mdl&quot;, &quot;LogisticRegression_mdl&quot;]</span>
<span class="n">models_to_include</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;QLattice_mdl&quot;</span><span class="p">,</span> <span class="s2">&quot;NaiveBayes_mdl&quot;</span><span class="p">,</span> <span class="s2">&quot;RandomForest_mdl&quot;</span><span class="p">,</span> <span class="s2">&quot;LightGBM_mdl&quot;</span><span class="p">,</span> <span class="s2">&quot;CatBoost_mdl&quot;</span><span class="p">,</span> <span class="s2">&quot;LogisticRegression_mdl&quot;</span><span class="p">,</span> <span class="s2">&quot;HistGBC_mdl&quot;</span><span class="p">]</span>

<span class="c1"># outcome variable (e.g., class 1 indicated as &quot;0&quot; and class 2 as &quot;1&quot;)</span>
<span class="n">outcome_var</span> <span class="o">=</span> <span class="s2">&quot;Group&quot;</span> <span class="c1"># specify the name of the column for the binary outcome variable (note: it should not contain any missingness)</span>

<span class="c1">###################################################################################</span>
<span class="c1"># set a directory to save the results</span>
<span class="n">main_folder_name</span> <span class="o">=</span> <span class="s1">&#39;results_dementia&#39;</span>
<span class="c1"># Define class labels for display</span>
<span class="n">class_labels_display</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Nondemented&#39;</span><span class="p">,</span> <span class="s1">&#39;Demented&#39;</span><span class="p">]</span>    <span class="c1"># Specify the labels for the two classes to display in figures</span>

<span class="c1"># Specify the class labels</span>
<span class="n">class_0</span> <span class="o">=</span> <span class="n">class_labels_display</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">class_1</span> <span class="o">=</span> <span class="n">class_labels_display</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

<span class="c1"># Create a mapping dictionary for class labels</span>
<span class="n">class_label_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;Nondemented&quot;</span><span class="p">:</span><span class="n">class_0</span><span class="p">,</span> <span class="s1">&#39;Demented&#39;</span><span class="p">:</span><span class="n">class_1</span><span class="p">}</span> <span class="c1"># this has to be set by user based on class labels in the outcome variable</span>

<span class="c1">###################################################################################</span>
<span class="c1"># feature selection</span>
<span class="n">feat_sel</span> <span class="o">=</span> <span class="kc">False</span> <span class="c1"># feature selection based on minimum Redundancy - Maximum Relevance (mRMR) algorithm</span>
<span class="n">num_features_sel</span> <span class="o">=</span> <span class="mi">10</span> <span class="c1"># number of features to select using mRMR algorithm within each fold (common selected features are then used for machine learning). </span>
<span class="c1"># If there was no common selected features, increase num_features_sel.</span>
<span class="n">top_n_f</span> <span class="o">=</span> <span class="mi">10</span> <span class="c1"># number of top features (most impactful features) based on SHAP values to be displayed for SHAP plots</span>

<span class="c1">###################################################################################</span>
<span class="c1"># survival analysis</span>
<span class="c1"># Two models are included: random survival forest (RSF) as main model and Cox proportional hazard (CPH) model as a baseline model to compare against the RSF</span>
<span class="n">survival_analysis</span> <span class="o">=</span> <span class="kc">False</span> <span class="c1"># True to conduct survival analyses. To do this you should provide a backup data that contains a column for time-to-event</span>
<span class="k">if</span> <span class="n">survival_analysis</span><span class="p">:</span>
    <span class="n">survival_demo</span> <span class="o">=</span> <span class="kc">True</span> <span class="c1"># only used to create a column for time to event just to showcase how the results would look like if survival models are used</span>
    <span class="n">time_to_event_column</span> <span class="o">=</span> <span class="s2">&quot;max_time_difference_days&quot;</span> <span class="c1"># use the column name for time-to-event in your data</span>
    <span class="k">if</span> <span class="n">survival_demo</span><span class="p">:</span> 
        <span class="c1"># Adding a new column with random integers between 90 to 365 (only for demonstration purpose - not to be used when the data is available)</span>
        <span class="n">mydata</span><span class="p">[</span><span class="n">time_to_event_column</span><span class="p">]</span> <span class="o">=</span> <span class="n">randint</span><span class="p">(</span><span class="mi">90</span><span class="p">,</span> <span class="mi">366</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">mydata</span><span class="p">))</span>
        
    <span class="n">mydata_copy_survival</span> <span class="o">=</span> <span class="n">mydata</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span> <span class="c1"># get a copy of your data as back up for the time-to-event column</span>
    
    <span class="k">if</span> <span class="n">external_val</span><span class="p">:</span>
        <span class="n">extval_data_copy</span> <span class="o">=</span> <span class="n">extval_data</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span> <span class="c1"># get a copy of extval_data that contains time_to_event_column</span>
    
    <span class="c1"># mydata.drop(columns = [time_to_event_column], inplace = True) # remove the time-to-event column for the data that&#39;s going to be used for binary classification</span>

<span class="c1">###################################################################################</span>
<span class="c1"># regression analysis</span>
<span class="c1"># Two models are included: random forest regressor (RFR) as main model and linear regression model as a baseline model to be compared against the RFR</span>
<span class="n">regression_analysis</span> <span class="o">=</span> <span class="kc">False</span>
<span class="k">if</span> <span class="n">regression_analysis</span><span class="p">:</span>
    <span class="n">regression_outcome</span> <span class="o">=</span> <span class="s2">&quot;regression_outcome_var&quot;</span>
    <span class="n">demo_regression_analysis</span> <span class="o">=</span> <span class="kc">True</span> <span class="c1"># only used for demonstration (simulation) purpose when the data is not available - not to be used otherwise</span>
    <span class="k">if</span> <span class="n">demo_regression_analysis</span><span class="p">:</span>
        <span class="n">mydata_copy_regression</span> <span class="o">=</span> <span class="n">mydata</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="c1"># Generate random features</span>
        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">123</span><span class="p">)</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">mydata_copy_regression</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">mydata_copy_regression</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="c1"># Define coefficients for each feature</span>
        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">123</span><span class="p">)</span>
        <span class="n">true_calculate</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">mydata_copy_regression</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="c1"># Generate outcome variable (target) based on features and calculate</span>
        <span class="c1"># Adding some noise for randomness</span>
        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">123</span><span class="p">)</span>
        <span class="n">noise</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">mydata_copy_regression</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">*</span> <span class="mf">0.5</span>  <span class="c1"># Adjust the magnitude of noise</span>
        <span class="n">mydata_copy_regression</span><span class="p">[</span><span class="n">regression_outcome</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">true_calculate</span><span class="p">)</span> <span class="o">+</span> <span class="n">noise</span>

<span class="c1">###################################################################################</span>
<span class="c1"># settings for processing resouces</span>
<span class="n">GPU_avail</span> <span class="o">=</span> <span class="kc">True</span> <span class="c1"># True if GPU is available in your machine otherwise set to False</span>
<span class="n">hp_tuning</span> <span class="o">=</span> <span class="kc">True</span> <span class="c1"># True if you want to conduct hyperparameter tuning otherwise set to False</span>
<span class="n">n_cpu_for_tuning</span> <span class="o">=</span> <span class="mi">20</span> <span class="c1"># number of CPUs to be available for hyperparameter tuning</span>
<span class="n">n_cpu_model_training</span> <span class="o">=</span> <span class="mi">20</span> <span class="c1"># number of CPUs to be available for model training</span>
<span class="n">n_rep_feature_permutation</span> <span class="o">=</span> <span class="mi">100</span> <span class="c1"># number of repetitions for feature permutation</span>
<span class="n">n_iter_hptuning</span> <span class="o">=</span> <span class="mi">10</span> <span class="c1"># number of iterations in repeated cross validation for hyperparameter tuning</span>
<span class="n">SEED</span> <span class="o">=</span> <span class="mi">123</span> <span class="c1"># arbitrarily chosen, this modifies computer randomization, if there are significant differences between train and test sets due to the random data split, this can be modified for example</span>

<span class="c1">###################################################################################</span>

<span class="c1">###################################################################################</span>
<span class="n">cv_folds</span> <span class="o">=</span> <span class="mi">5</span> <span class="c1"># number of folds for the outer loop in cross validation</span>
<span class="n">cv_folds_hptuning</span> <span class="o">=</span> <span class="mi">5</span> <span class="c1"># number of folds for hyperparameter tuning (inner loop - nested cross validation)</span>
<span class="n">use_default_threshold</span> <span class="o">=</span> <span class="kc">True</span> <span class="c1"># use default threshold of 0.5 bor binary classification, otherwise it optimize the threshold based on the development set</span>
<span class="n">test_only_best_cvmodel</span> <span class="o">=</span> <span class="kc">True</span> <span class="c1"># True to test only the best performing model from cross validation, this option speeds up the process</span>
<span class="c1">###################################################################################</span>

<span class="c1">###################################################################################</span>
<span class="c1"># handle missingness</span>
<span class="n">exclude_highly_missing_columns</span> <span class="o">=</span> <span class="kc">True</span> <span class="c1"># True to exclude features with high missingness</span>
<span class="n">exclude_highly_missing_rows</span> <span class="o">=</span> <span class="kc">True</span> <span class="c1"># True to exclude rows (samples) with high missingness</span>
<span class="n">column_threshold</span> <span class="o">=</span> <span class="mf">0.99</span>  <span class="c1"># Threshold for variables - columns (e.g., 99% missingness)</span>
<span class="n">row_threshold</span> <span class="o">=</span> <span class="mf">0.90</span>     <span class="c1"># Threshold for samples - rows (e.g., 90% missingness)</span>

<span class="c1">###################################################################################</span>
<span class="n">remove_outliers</span> <span class="o">=</span> <span class="kc">False</span> <span class="c1"># True to enable outlier detection and removal using Isolation Forest algorithm</span>
<span class="c1">###################################################################################</span>
<span class="c1"># Specify the filename of this Jupyter notebook so that it can be saved after execution</span>
<span class="n">JupyterNotebook_filename</span> <span class="o">=</span> <span class="s2">&quot;MAIT_Tutorial_Dementia_pub.ipynb&quot;</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="less-important-settings">
<h3>Less important settings<a class="headerlink" href="#less-important-settings" title="Link to this heading">#</a></h3>
<p>Here you have configurations that can be set but they are usually fine to be set as it is (default settings).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">###################################################################################</span>
<span class="c1"># continuous variables</span>
<span class="n">specify_continuous_variables</span> <span class="o">=</span> <span class="kc">False</span>  <span class="c1"># optional but recommended in case there are continuous variables that may have entries that could be recognized as categorical variables</span>
<span class="n">continuous_features</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1">###################################################################################</span>
<span class="n">export_missclassified</span> <span class="o">=</span> <span class="kc">False</span>
<span class="k">if</span> <span class="n">export_missclassified</span><span class="p">:</span>
    <span class="n">mydata_backup</span> <span class="o">=</span> <span class="n">mydata</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">mydata_backup</span><span class="p">[</span><span class="s1">&#39;ID&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">mydata</span><span class="p">[</span><span class="s2">&quot;Subject ID&quot;</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">already_split</span><span class="p">:</span>
        <span class="n">testset_backup</span> <span class="o">=</span> <span class="n">testset</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">testset_backup</span><span class="p">[</span><span class="s1">&#39;ID&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">testset</span><span class="p">[</span><span class="s2">&quot;Subject ID&quot;</span><span class="p">]</span>
        <span class="n">mydata_backup</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">mydata_backup</span><span class="p">,</span> <span class="n">testset_backup</span><span class="p">])</span>
    <span class="c1"># Generate random IDs in the format &quot;ID_randomnumber&quot;</span>
    <span class="c1"># mydata_backup[&#39;ID&#39;] = mydata[&quot;ID&quot;]</span>

<span class="c1">###################################################################################</span>
<span class="c1"># data manipulation settings</span>
<span class="n">oversampling</span> <span class="o">=</span> <span class="kc">False</span> <span class="c1"># apply oversampling using random oversampling only on train set to increase the number of samples of the minority class</span>
<span class="n">scale_data</span> <span class="o">=</span> <span class="kc">False</span> <span class="c1"># data scale using robust scaling (see scikit-learn)</span>
<span class="n">semi_supervised</span> <span class="o">=</span> <span class="kc">False</span> <span class="c1"># if True it applies a method to impute missingness in the outcome variable using label propagation method otherwise they are excluded</span>

<span class="c1">###################################################################################</span>
<span class="c1"># supplementary analyses</span>
<span class="n">model_uncertainty_reduction</span> <span class="o">=</span> <span class="kc">False</span> <span class="c1"># True to use model uncertainty reduction (MUR) approach to build more robust models (filtering samples based on SHAP values and predicted probabilities being close to the chance level)</span>
<span class="n">do_decision_curve_analysis</span> <span class="o">=</span> <span class="kc">True</span> <span class="c1"># True to conduct decision curve analysis</span>
<span class="n">calibration_and_conformal_predictions</span> <span class="o">=</span> <span class="kc">True</span> <span class="c1"># True to conduct model calibration and conformal predictions for the best performing binary classification model (recommended only if a large dataset is available)</span>
<span class="n">find_interacting_feature_permutation</span> <span class="o">=</span> <span class="kc">False</span> <span class="c1"># True to enable the analysis based on feature permutation on the final model to inspect potential interactions among pairs of features</span>

<span class="c1">###################################################################################</span>
<span class="c1"># settings for displaying feature names</span>
<span class="n">shorten_feature_names</span> <span class="o">=</span> <span class="kc">True</span> <span class="c1"># True to shorten feature names (for visualization purposes if your data has features with too long names)</span>
<span class="k">if</span> <span class="n">shorten_feature_names</span><span class="p">:</span>
    <span class="n">fname_max_length</span> <span class="o">=</span> <span class="mi">30</span> <span class="c1"># Specify max length (number of characters for the feature names to appear)</span>
<span class="n">data_dictionary</span> <span class="o">=</span> <span class="p">{</span>
<span class="p">}</span>
<span class="c1"># optional, using the data dictionary the name of the variables are displayed in figures and tables to facilitate reporting.</span>
<span class="c1">###################################################################################</span>

<span class="c1">###################################################################################</span>
<span class="n">demo_configs</span> <span class="o">=</span> <span class="kc">False</span> <span class="c1"># True only if using the Breast Cancer dataset to add missingness and a categorical feature to the data for demonstration - not to be used otherwise</span>

<span class="c1">###################################################################################</span>
<span class="c1"># following is the default custom metric (Mean of ROCAUC and PRAUC) used for hyperparameter tuning</span>
<span class="k">def</span> <span class="nf">combined_metric</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred_proba</span><span class="p">):</span>
    <span class="n">roc_auc</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred_proba</span><span class="p">)</span>
    <span class="n">pr_auc</span> <span class="o">=</span> <span class="n">average_precision_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred_proba</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">roc_auc</span> <span class="o">+</span> <span class="n">pr_auc</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>  <span class="c1"># Mean of ROCAUC and PRAUC</span>

<span class="n">custom_scorer</span> <span class="o">=</span> <span class="n">make_scorer</span><span class="p">(</span><span class="n">combined_metric</span><span class="p">,</span> <span class="n">needs_proba</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">use_single_metric</span> <span class="o">=</span> <span class="kc">False</span> <span class="c1"># in case you want to use a single metric for training and hyperparameter tuninig</span>
<span class="k">if</span> <span class="n">use_single_metric</span><span class="p">:</span>
    <span class="n">single_score</span> <span class="o">=</span> <span class="s2">&quot;ROCAUC&quot;</span> <span class="c1"># choose between ROCAUC and PRAUC</span>
    <span class="k">if</span> <span class="n">single_score</span> <span class="o">==</span> <span class="s2">&quot;ROCAUC&quot;</span><span class="p">:</span>
        <span class="n">custom_scorer</span> <span class="o">=</span> <span class="n">make_scorer</span><span class="p">(</span><span class="n">roc_auc_score</span><span class="p">,</span> <span class="n">needs_proba</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">single_score</span> <span class="o">==</span> <span class="s2">&quot;PRAUC&quot;</span><span class="p">:</span>
        <span class="n">custom_scorer</span> <span class="o">=</span> <span class="n">make_scorer</span><span class="p">(</span><span class="n">average_precision_score</span><span class="p">,</span> <span class="n">needs_proba</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1">###################################################################################</span>
<span class="c1"># Check if the main folder exists, and create it if not</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">main_folder_name</span><span class="p">):</span>
    <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">main_folder_name</span><span class="p">)</span>

<span class="c1"># Change the current working directory to the main folder</span>
<span class="n">os</span><span class="o">.</span><span class="n">chdir</span><span class="p">(</span><span class="n">main_folder_name</span><span class="p">)</span>

<span class="c1"># reporting file formats</span>
<span class="n">fig_file_format</span> <span class="o">=</span> <span class="s2">&quot;tif&quot;</span> <span class="c1"># specify desired file format for figures (e.g. tif, svg)</span>

<span class="c1"># limit the number of lines to display</span>
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;display.max_rows&#39;</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;display.max_columns&#39;</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;display.width&#39;</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span>

<span class="n">skip_block</span> <span class="o">=</span> <span class="kc">False</span> <span class="c1"># should not be changed</span>
<span class="c1">###################################################################################</span>
<span class="c1"># Record start time</span>
<span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<section id="data-preparation">
<h4>Data preparation<a class="headerlink" href="#data-preparation" title="Link to this heading">#</a></h4>
<p>The data may require some preparation before feeding them to machine learning models (algorithms).
The most important things to check are:
data types (feature types: categorical, numerical, etc.)
missingness
if there are more than one dataset, all variables must have the same definition and type across datasets
redundant features</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Ensure the outcome variable exists in the dataset</span>
<span class="k">if</span> <span class="n">outcome_var</span> <span class="ow">in</span> <span class="n">mydata</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
    <span class="c1"># Map the class labels in the outcome variable</span>
    <span class="n">mydata</span><span class="p">[</span><span class="n">outcome_var</span><span class="p">]</span> <span class="o">=</span> <span class="n">mydata</span><span class="p">[</span><span class="n">outcome_var</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">class_label_dict</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">already_split</span><span class="p">:</span> 
        <span class="n">testset</span><span class="p">[</span><span class="n">outcome_var</span><span class="p">]</span> <span class="o">=</span> <span class="n">testset</span><span class="p">[</span><span class="n">outcome_var</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">class_label_dict</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">external_val</span><span class="p">:</span>
        <span class="n">extval_data</span><span class="p">[</span><span class="n">outcome_var</span><span class="p">]</span> <span class="o">=</span> <span class="n">extval_data</span><span class="p">[</span><span class="n">outcome_var</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">class_label_dict</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;&#39;</span><span class="si">{</span><span class="n">outcome_var</span><span class="si">}</span><span class="s2">&#39; column not found in the dataset&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># add missingness</span>
<span class="c1"># empty entries replaced by NaN</span>
<span class="n">mydata</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># If there are lost to follow ups (missing endpoint/event) in the data, one option is to use semi-supervised learning methods to impute missing target labels (outcome variable)</span>
<span class="c1"># LabelPropagation assigns the labels based on similarity of samples (instances)</span>
<span class="k">if</span> <span class="n">semi_supervised</span><span class="p">:</span>
    <span class="c1"># Replace NaN values in the outcome variable with -1</span>
    <span class="n">mydata</span><span class="p">[</span><span class="n">outcome_var</span><span class="p">]</span> <span class="o">=</span> <span class="n">mydata</span><span class="p">[</span><span class="n">outcome_var</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># Create a LabelPropagation model</span>
    <span class="n">label_prop_model</span> <span class="o">=</span> <span class="n">LabelPropagation</span><span class="p">()</span>

    <span class="c1"># Separate the features (X) and labels (y)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">mydata</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="n">outcome_var</span><span class="p">])</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">mydata</span><span class="p">[</span><span class="n">outcome_var</span><span class="p">]</span>

    <span class="c1"># Fit the model on the dataset (X: features, y: labels including -1 for missing labels)</span>
    <span class="n">label_prop_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

    <span class="c1"># Get the predicted labels (transduction_ includes predictions for both labeled and unlabeled)</span>
    <span class="n">predicted_labels</span> <span class="o">=</span> <span class="n">label_prop_model</span><span class="o">.</span><span class="n">transduction_</span>

    <span class="c1"># Update the original DataFrame with predicted labels where labels were missing (-1)</span>
    <span class="n">mydata</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">mydata</span><span class="p">[</span><span class="n">outcome_var</span><span class="p">]</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">outcome_var</span><span class="p">]</span> <span class="o">=</span> <span class="n">predicted_labels</span><span class="p">[</span><span class="n">mydata</span><span class="p">[</span><span class="n">outcome_var</span><span class="p">]</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>

<span class="k">else</span><span class="p">:</span>
    <span class="c1"># Remove rows where outcome_var column contains NaN (missing) values</span>
    <span class="n">mydata</span> <span class="o">=</span> <span class="n">mydata</span><span class="o">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="p">[</span><span class="n">outcome_var</span><span class="p">])</span>

<span class="k">if</span> <span class="n">demo_configs</span><span class="p">:</span> <span class="c1"># used only for the Breast Cancer dataset</span>
    <span class="c1"># Randomly selecting some indices to set as missing values</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">SEED</span><span class="p">)</span>
    <span class="n">rows_to_change</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">mydata</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">SEED</span><span class="p">)</span>
    <span class="n">cols_to_change</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">mydata</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">outcome_var_backup</span> <span class="o">=</span> <span class="n">mydata</span><span class="p">[</span><span class="n">outcome_var</span><span class="p">]</span>
    <span class="c1"># Setting these selected entries to NaN</span>
    <span class="n">mydata</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">rows_to_change</span><span class="p">,</span> <span class="n">cols_to_change</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
    <span class="n">mydata</span><span class="p">[</span><span class="n">outcome_var</span><span class="p">]</span> <span class="o">=</span> <span class="n">outcome_var_backup</span>

    <span class="c1"># Adding a column for race with three categories</span>
    <span class="n">races</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;White&#39;</span><span class="p">,</span> <span class="s1">&#39;Black&#39;</span><span class="p">,</span> <span class="s1">&#39;Asian&#39;</span><span class="p">]</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">SEED</span><span class="p">)</span>
    <span class="n">mydata</span><span class="p">[</span><span class="s1">&#39;Race&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">races</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">mydata</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="n">mydata</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="n">columns_to_drop</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    
<span class="n">mydata</span><span class="p">[</span><span class="n">cat_features</span><span class="p">]</span> <span class="o">=</span> <span class="n">mydata</span><span class="p">[</span><span class="n">cat_features</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;category&#39;</span><span class="p">)</span>

<span class="c1"># Convert categories to strings for each categorical column</span>
<span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">cat_features</span><span class="p">:</span>
    <span class="n">mydata</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="n">mydata</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;category&#39;</span><span class="p">)</span>

<span class="k">if</span> <span class="n">ext_val_demo</span><span class="p">:</span>
    <span class="c1"># Randomly select a few samples from the dataframe</span>
    <span class="n">num_samples</span> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># Change this number to select different number of samples</span>
    <span class="n">extval_data</span> <span class="o">=</span> <span class="n">mydata</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="n">num_samples</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    
<span class="k">if</span> <span class="n">external_val</span><span class="p">:</span>
    <span class="n">columns_present</span> <span class="o">=</span> <span class="p">[</span><span class="n">col</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">columns_to_drop</span> <span class="k">if</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">extval_data</span><span class="o">.</span><span class="n">columns</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">columns_present</span><span class="p">:</span>
        <span class="n">extval_data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="n">columns_present</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">extval_data</span><span class="p">[</span><span class="n">cat_features</span><span class="p">]</span> <span class="o">=</span> <span class="n">extval_data</span><span class="p">[</span><span class="n">cat_features</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;category&#39;</span><span class="p">)</span>

    <span class="c1"># Convert categories to strings for each categorical column</span>
    <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">cat_features</span><span class="p">:</span>
        <span class="n">extval_data</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="n">extval_data</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;category&#39;</span><span class="p">)</span>
    <span class="n">extval_data</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="k">if</span> <span class="n">already_split</span><span class="p">:</span>
    <span class="n">columns_present</span> <span class="o">=</span> <span class="p">[</span><span class="n">col</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">columns_to_drop</span> <span class="k">if</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">testset</span><span class="o">.</span><span class="n">columns</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">columns_present</span><span class="p">:</span>
        <span class="n">testset</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="n">columns_present</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">testset</span><span class="p">[</span><span class="n">cat_features</span><span class="p">]</span> <span class="o">=</span> <span class="n">testset</span><span class="p">[</span><span class="n">cat_features</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;category&#39;</span><span class="p">)</span>

    <span class="c1"># Convert categories to strings for each categorical column</span>
    <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">cat_features</span><span class="p">:</span>
        <span class="n">testset</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="n">testset</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;category&#39;</span><span class="p">)</span>
    <span class="n">testset</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="specify-data-types-for-numerical-features-optional">
<h4>Specify data types for numerical features (optional)<a class="headerlink" href="#specify-data-types-for-numerical-features-optional" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">specify_continuous_variables</span><span class="p">:</span>

    <span class="c1"># Replace non-numeric values (including empty strings) with NaN</span>
    <span class="n">mydata</span><span class="p">[</span><span class="n">continuous_features</span><span class="p">]</span> <span class="o">=</span> <span class="n">mydata</span><span class="p">[</span><span class="n">continuous_features</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">to_numeric</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s1">&#39;coerce&#39;</span><span class="p">)</span>

    <span class="c1"># Convert to float64 after replacing non-numeric values with NaN</span>
    <span class="n">mydata</span><span class="p">[</span><span class="n">continuous_features</span><span class="p">]</span> <span class="o">=</span> <span class="n">mydata</span><span class="p">[</span><span class="n">continuous_features</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float64&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="defined-missingness">
<h4>Defined missingness<a class="headerlink" href="#defined-missingness" title="Link to this heading">#</a></h4>
<p>make sure all missing values are defined. For categorical features, missing values should be encoded as “missing”</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># empty entries replaced by NaN (if NaN occurs after the previous code chunk)</span>
<span class="n">mydata</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="rare-categories-in-categorical-variables-and-data-harmonization-for-missing-values">
<h4>Rare categories in categorical variables and data harmonization for missing values<a class="headerlink" href="#rare-categories-in-categorical-variables-and-data-harmonization-for-missing-values" title="Link to this heading">#</a></h4>
<p>If there are rare categories in categorical features, they can have negativae effect on learning process and thus the following code can handle merging such rare categories. It is however more favorable to be done by the data engineer or the researcher who knows the context of the data to merge rare categories in a meaningful way rather than automated merging.
The code also ensures that all values similar to “missing” are treated as “missing” for unification.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># sometimes there are rare categories that can be merged in the data</span>
<span class="k">if</span> <span class="n">merged_rare_categories</span><span class="p">:</span>
    <span class="k">if</span> <span class="s1">&#39;mydata_backup&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="nb">locals</span><span class="p">():</span>
        <span class="n">mydata_backup</span> <span class="o">=</span> <span class="n">mydata</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">external_val</span><span class="p">:</span>
        <span class="n">mydata</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">mydata</span><span class="p">,</span><span class="n">extval_data</span><span class="p">])</span>
    <span class="n">categorical_columns</span> <span class="o">=</span> <span class="n">mydata</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;category&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">columns</span>
    <span class="n">category_frequencies</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">categorical_columns</span><span class="p">:</span>
        <span class="n">category_counts</span> <span class="o">=</span> <span class="n">mydata</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
        <span class="n">category_frequencies</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="n">category_counts</span>

    <span class="nb">print</span><span class="p">(</span><span class="n">category_frequencies</span><span class="p">)</span>

    <span class="c1"># Categorical columns</span>
    <span class="n">categorical_columns</span> <span class="o">=</span> <span class="n">mydata</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;category&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">columns</span>

    <span class="c1"># Dictionary to store category frequencies</span>
    <span class="n">category_frequencies</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="c1"># Loop through categorical columns</span>
    <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">categorical_columns</span><span class="p">:</span>
        <span class="c1"># Calculate category frequencies</span>
        <span class="n">category_counts</span> <span class="o">=</span> <span class="n">mydata</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
        
        <span class="c1"># Identify rare categories</span>
        <span class="n">rare_categories</span> <span class="o">=</span> <span class="n">category_counts</span><span class="p">[</span><span class="n">category_counts</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">mydata</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">rarity_threshold</span><span class="p">]</span><span class="o">.</span><span class="n">index</span>
        
        <span class="c1"># Group rare categories into a single category and eliminate individual rare categories</span>
        <span class="n">grouped_category_name</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
        <span class="k">for</span> <span class="n">cat</span> <span class="ow">in</span> <span class="n">rare_categories</span><span class="p">:</span>
            <span class="n">grouped_category_name</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot; or </span><span class="si">{</span><span class="n">cat</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="c1"># Replace individual rare category with an empty string</span>
            <span class="n">mydata</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="n">mydata</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">({</span><span class="n">cat</span><span class="p">:</span> <span class="s2">&quot;&quot;</span><span class="p">})</span>
        
        <span class="c1"># Replace the empty strings with the grouped category name</span>
        <span class="n">mydata</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="n">mydata</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">({</span><span class="s2">&quot;&quot;</span><span class="p">:</span> <span class="n">grouped_category_name</span><span class="o">.</span><span class="n">lstrip</span><span class="p">(</span><span class="s2">&quot; or &quot;</span><span class="p">)})</span>
        
        <span class="c1"># Store updated category frequencies</span>
        <span class="n">category_frequencies</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="n">mydata</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>

        <span class="c1"># Create a new categorical Series with only used categories</span>
        <span class="n">used_categories</span> <span class="o">=</span> <span class="n">mydata</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">cat</span><span class="o">.</span><span class="n">categories</span>
        <span class="n">mydata</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Categorical</span><span class="p">(</span><span class="n">mydata</span><span class="p">[</span><span class="n">col</span><span class="p">],</span> <span class="n">categories</span><span class="o">=</span><span class="n">used_categories</span><span class="p">)</span>

    <span class="c1"># Print updated categories with the original category index</span>
    <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">categorical_columns</span><span class="p">:</span>
        <span class="n">updated_categories</span> <span class="o">=</span> <span class="n">mydata</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">cat</span><span class="o">.</span><span class="n">categories</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Categories for </span><span class="si">{</span><span class="n">col</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">updated_categories</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1">#########################################################################</span>
        <span class="c1"># Define a list of values similar to &quot;missing&quot; that should be unified</span>
        <span class="n">missing_values</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;missing&quot;</span><span class="p">,</span> <span class="s2">&quot;unknown&quot;</span><span class="p">,</span> <span class="s2">&quot;not available&quot;</span><span class="p">,</span> <span class="s2">&quot;na&quot;</span><span class="p">,</span> <span class="s2">&quot;n/a&quot;</span><span class="p">,</span> <span class="s2">&quot;none&quot;</span><span class="p">,</span> <span class="s2">&quot;Missing&quot;</span><span class="p">]</span>

        <span class="c1"># Iterate through each categorical column</span>
        <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">categorical_columns</span><span class="p">:</span>
            <span class="c1"># Check if &quot;missing&quot; is not already in the categories</span>
            <span class="k">if</span> <span class="s2">&quot;missing&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">mydata</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">cat</span><span class="o">.</span><span class="n">categories</span><span class="p">:</span>
                <span class="c1"># Add &quot;missing&quot; as a category</span>
                <span class="n">mydata</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="n">mydata</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">cat</span><span class="o">.</span><span class="n">add_categories</span><span class="p">(</span><span class="s2">&quot;missing&quot;</span><span class="p">)</span>
            
            <span class="c1"># Replace values in the column (case-insensitive)</span>
            <span class="n">mydata</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="n">mydata</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="n">x</span><span class="p">)</span>

            <span class="c1"># Replace any &quot;missing&quot; related values (now lowercase) with &quot;missing&quot;</span>
            <span class="n">mydata</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="n">mydata</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">([</span><span class="n">val</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">for</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">missing_values</span><span class="p">],</span> <span class="s2">&quot;missing&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="s2">&quot;missing&quot;</span><span class="p">)</span>
    <span class="c1">#########################################################################</span>


    <span class="c1"># Find features with mixed category data types</span>
    <span class="n">mixed_category_features</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">mydata</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">mydata</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="s1">&#39;category&#39;</span><span class="p">:</span>
            <span class="n">unique_categories</span> <span class="o">=</span> <span class="n">mydata</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">cat</span><span class="o">.</span><span class="n">categories</span>
            <span class="n">unique_dtypes</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">cat</span><span class="p">)</span> <span class="k">for</span> <span class="n">cat</span> <span class="ow">in</span> <span class="n">unique_categories</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">unique_dtypes</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">mixed_category_features</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">col</span><span class="p">)</span>

    <span class="c1"># Convert categories to strings for mixed category features</span>
    <span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="n">mixed_category_features</span><span class="p">:</span>
        <span class="n">mydata</span><span class="p">[</span><span class="n">feature</span><span class="p">]</span> <span class="o">=</span> <span class="n">mydata</span><span class="p">[</span><span class="n">feature</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;str&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;category&#39;</span><span class="p">)</span>


    <span class="c1"># Identify categorical columns</span>
    <span class="n">categorical_columns</span> <span class="o">=</span> <span class="n">mydata</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;category&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">columns</span>

    <span class="c1"># Convert categories to strings for each categorical column</span>
    <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">categorical_columns</span><span class="p">:</span>
        <span class="n">mydata</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="n">mydata</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;category&#39;</span><span class="p">)</span>

    <span class="n">category_frequencies</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">categorical_columns</span><span class="p">:</span>
        <span class="n">category_counts</span> <span class="o">=</span> <span class="n">mydata</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
        <span class="n">category_frequencies</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="n">category_counts</span>

    <span class="nb">print</span><span class="p">(</span><span class="n">category_frequencies</span><span class="p">)</span>
    
    <span class="c1"># Restore original index for mydata</span>
    <span class="n">mydata</span> <span class="o">=</span> <span class="n">mydata</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">mydata_backup</span><span class="o">.</span><span class="n">index</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">external_val</span><span class="p">:</span>
        <span class="c1"># Restore original index for extval_data</span>
        <span class="n">extval_data</span> <span class="o">=</span> <span class="n">extval_data</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">extval_data</span><span class="o">.</span><span class="n">index</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mydata</span><span class="o">.</span><span class="n">dtypes</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="shorten-the-name-of-features-optional">
<h4>Shorten the name of features (optional)<a class="headerlink" href="#shorten-the-name-of-features-optional" title="Link to this heading">#</a></h4>
<p>If feature names are longer than a specific number of characters specified by user, it cuts it down to that so when the feature names appear on the plots they’re shortened for visualization purposes.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">shorten_feature_names</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">shorten_column_names</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">max_length</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Shortens column names in a pandas DataFrame to fit within a maximum length.</span>

<span class="sd">        Parameters:</span>
<span class="sd">            df (pandas.DataFrame): The input DataFrame containing the columns to be shortened.</span>
<span class="sd">            max_length (int): The maximum allowed length for each column name.</span>

<span class="sd">        ## Returns</span>
<span class="sd">            list: A list of shortened column names.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">new_columns</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">used_names</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>  <span class="c1"># Keep track of used names to avoid duplicates</span>
        <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
            <span class="c1"># Check if column name is longer than max_length</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">col</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">max_length</span><span class="p">:</span>
                <span class="c1"># Shorten column name by keeping only the beginning part and adding ...</span>
                <span class="n">new_col</span> <span class="o">=</span> <span class="n">col</span><span class="p">[:</span><span class="n">max_length</span><span class="p">]</span> <span class="o">+</span> <span class="s1">&#39;...&#39;</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">new_col</span> <span class="o">=</span> <span class="n">col</span>
            
            <span class="c1"># If the shortened name already exists, add a numeric suffix</span>
            <span class="n">suffix</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="n">base_name</span> <span class="o">=</span> <span class="n">new_col</span>
            <span class="k">while</span> <span class="n">new_col</span> <span class="ow">in</span> <span class="n">used_names</span><span class="p">:</span>
                <span class="n">new_col</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">base_name</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">suffix</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="n">suffix</span> <span class="o">+=</span> <span class="mi">1</span>
            
            <span class="n">used_names</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">new_col</span><span class="p">)</span>
            <span class="n">new_columns</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">new_col</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">new_columns</span>

    <span class="c1"># Shorten column names</span>
    <span class="n">mydata</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="n">shorten_column_names</span><span class="p">(</span><span class="n">mydata</span><span class="p">,</span> <span class="n">fname_max_length</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">external_val</span><span class="p">:</span>
        <span class="n">extval_data</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="n">shorten_column_names</span><span class="p">(</span><span class="n">extval_data</span><span class="p">,</span> <span class="n">fname_max_length</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">shorten_data_dictionary</span><span class="p">(</span><span class="n">data_dict</span><span class="p">,</span> <span class="n">max_length</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Shortens values in a dictionary to fit within a specified maximum length.</span>

<span class="sd">        This function replaces long values with shorter versions by truncating them and adding an ellipsis (&#39;...&#39;) if necessary.</span>
<span class="sd">        If two values have the same length after truncation, it appends a numeric suffix (e.g., &#39;value_1&#39;, &#39;value_2&#39;) to make them unique.</span>

<span class="sd">        ## Parameters:</span>
<span class="sd">            data_dict (dict): The input dictionary containing the keys and values to be shortened.</span>
<span class="sd">            max_length (int): The maximum allowed length for each value in the dictionary.</span>

<span class="sd">        ## Returns</span>
<span class="sd">            dict: A new dictionary with shortened values.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">new_data_dict</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">used_values</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>  <span class="c1"># Keep track of used values to avoid duplicates</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">data_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="c1"># Check if column name is longer than max_length</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">max_length</span><span class="p">:</span>
                <span class="c1"># Shorten column name by keeping only the beginning part and adding ...</span>
                <span class="n">new_value</span> <span class="o">=</span> <span class="n">value</span><span class="p">[:</span><span class="n">max_length</span><span class="p">]</span> <span class="o">+</span> <span class="s1">&#39;...&#39;</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">new_value</span> <span class="o">=</span> <span class="n">value</span>
            
            <span class="c1"># If the shortened value already exists, add a numeric suffix</span>
            <span class="n">suffix</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="n">base_value</span> <span class="o">=</span> <span class="n">new_value</span>
            <span class="k">while</span> <span class="n">new_value</span> <span class="ow">in</span> <span class="n">used_values</span><span class="p">:</span>
                <span class="n">new_value</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">base_value</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">suffix</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="n">suffix</span> <span class="o">+=</span> <span class="mi">1</span>
            
            <span class="n">used_values</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">new_value</span><span class="p">)</span>
            <span class="n">new_data_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_value</span>
        <span class="k">return</span> <span class="n">new_data_dict</span>

    <span class="c1"># Shorten data dictionary</span>
    <span class="n">data_dictionary</span> <span class="o">=</span> <span class="n">shorten_data_dictionary</span><span class="p">(</span><span class="n">data_dictionary</span><span class="p">,</span> <span class="n">fname_max_length</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The code chunk below applies outlier (anomaly) detection and removal based on isolation forest algorithm. It’s optional and is done if chosen by the user (remove_outliers = True). It follows these steps:</p>
<ol class="arabic simple">
<li><p>Data Preparation:</p></li>
</ol>
<p>Separates the input features (X) and the target variable (y) from the original dataset (mydata).
Encodes categorical features using one-hot encoding to convert them into numerical format, avoiding multicollinearity by dropping the first category.</p>
<ol class="arabic simple" start="2">
<li><p>Handling Missing Values:</p></li>
</ol>
<p>Imputes missing values in the combined dataset (X_combined), which includes both numerical and encoded categorical features, using the K-Nearest Neighbors (KNN) imputation method. The number of neighbors used for imputation is calculated based on the size of the dataset.</p>
<ol class="arabic simple" start="3">
<li><p>Outlier Detection:</p></li>
</ol>
<p>Initializes an IsolationForest model to detect outliers.
Fits the model to the data and predicts outliers, labeling them as -1.</p>
<ol class="arabic simple" start="4">
<li><p>Filtering Outliers:</p></li>
</ol>
<p>Filters out rows marked as outliers from both the features (X) and the target variable (y).
Combines the cleaned features and target variable back into a single DataFrame (mydata).</p>
<ol class="arabic simple" start="5">
<li><p>Final Cleanup:</p></li>
</ol>
<p>Removes the ‘outlier’ column from the final DataFrame.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># to remove outliers automatically detected using isolation forest</span>
<span class="k">if</span> <span class="n">remove_outliers</span><span class="p">:</span>
 
    <span class="c1"># Separate features and outcome</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">mydata</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="n">outcome_var</span><span class="p">])</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">mydata</span><span class="p">[</span><span class="n">outcome_var</span><span class="p">]</span>
    
    <span class="c1"># One-Hot Encode categorical features</span>
    <span class="n">encoder</span> <span class="o">=</span> <span class="n">OneHotEncoder</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="s1">&#39;first&#39;</span><span class="p">,</span> <span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>  <span class="c1"># drop=&#39;first&#39; to avoid multicollinearity, sparse=False to get a dense output</span>
    <span class="n">X_encoded</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">cat_features</span><span class="p">])</span>

    <span class="c1"># Convert encoded features into a DataFrame with preserved index</span>
    <span class="n">encoded_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X_encoded</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">encoder</span><span class="o">.</span><span class="n">get_feature_names_out</span><span class="p">(</span><span class="n">cat_features</span><span class="p">),</span> <span class="n">index</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>

    <span class="c1"># Combine encoded features with numerical features</span>
    <span class="n">X_combined</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">X</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="n">cat_features</span><span class="p">),</span> <span class="n">encoded_df</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># Impute missing values in continuous features of X_train using KNN</span>
    <span class="n">nn</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">X_combined</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span> <span class="c1"># from Devroye, L., Györfi, L., &amp; Lugosi, G. (1996). A Probabilistic Theory of Pattern Recognition. Springer. https://doi.org/10.1007/978-1-4612-0711-5.</span>
    <span class="n">cont_imputer</span> <span class="o">=</span> <span class="n">KNNImputer</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">nn</span><span class="p">,</span> <span class="n">weights</span> <span class="o">=</span> <span class="s1">&#39;distance&#39;</span><span class="p">,</span> <span class="n">keep_empty_features</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>  
    
    <span class="n">X_combined</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">cont_imputer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_combined</span><span class="p">),</span> <span class="n">index</span><span class="o">=</span><span class="n">X_combined</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
    
    <span class="c1"># Step 1: Initialize the IsolationForest model</span>
    <span class="n">iso_forest</span> <span class="o">=</span> <span class="n">IsolationForest</span><span class="p">(</span><span class="n">contamination</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>

    <span class="c1"># Step 2: Fit the model to the DataFrame</span>
    <span class="n">iso_forest</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_combined</span><span class="p">)</span>

    <span class="c1"># Step 3: Predict the outliers (-1 indicates an outlier)</span>
    <span class="n">X</span><span class="p">[</span><span class="s1">&#39;outlier&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">iso_forest</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_combined</span><span class="p">)</span>

    <span class="c1"># Step 4: Filter out the outliers using the original index</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="s1">&#39;outlier&#39;</span><span class="p">]</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span>  <span class="c1"># Filter y using the same mask</span>
    
    <span class="n">mydata</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># Drop the &#39;outlier&#39; column if you don&#39;t need it anymore</span>
    <span class="n">mydata</span> <span class="o">=</span> <span class="n">mydata</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;outlier&#39;</span><span class="p">])</span>
    
    <span class="k">if</span> <span class="n">already_split</span><span class="p">:</span>
        <span class="c1"># Separate features and outcome</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">testset</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="n">outcome_var</span><span class="p">])</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">testset</span><span class="p">[</span><span class="n">outcome_var</span><span class="p">]</span>
        
        <span class="c1"># One-Hot Encode categorical features</span>
        <span class="n">encoder</span> <span class="o">=</span> <span class="n">OneHotEncoder</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="s1">&#39;first&#39;</span><span class="p">,</span> <span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>  <span class="c1"># drop=&#39;first&#39; to avoid multicollinearity, sparse=False to get a dense output</span>
        <span class="n">X_encoded</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">cat_features</span><span class="p">])</span>

        <span class="c1"># Convert encoded features into a DataFrame with preserved index</span>
        <span class="n">encoded_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X_encoded</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">encoder</span><span class="o">.</span><span class="n">get_feature_names_out</span><span class="p">(</span><span class="n">cat_features</span><span class="p">),</span> <span class="n">index</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>

        <span class="c1"># Combine encoded features with numerical features</span>
        <span class="n">X_combined</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">X</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="n">cat_features</span><span class="p">),</span> <span class="n">encoded_df</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Impute missing values in continuous features of X_train using KNN</span>
        <span class="n">nn</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">X_combined</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span> <span class="c1"># from Devroye, L., Györfi, L., &amp; Lugosi, G. (1996). A Probabilistic Theory of Pattern Recognition. Springer. https://doi.org/10.1007/978-1-4612-0711-5.</span>
        <span class="n">cont_imputer</span> <span class="o">=</span> <span class="n">KNNImputer</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">nn</span><span class="p">,</span> <span class="n">weights</span> <span class="o">=</span> <span class="s1">&#39;distance&#39;</span><span class="p">,</span> <span class="n">keep_empty_features</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>  
        
        <span class="n">X_combined</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">cont_imputer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_combined</span><span class="p">),</span> <span class="n">index</span><span class="o">=</span><span class="n">X_combined</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
        
        <span class="c1"># Step 1: Initialize the IsolationForest model</span>
        <span class="n">iso_forest</span> <span class="o">=</span> <span class="n">IsolationForest</span><span class="p">(</span><span class="n">contamination</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>

        <span class="c1"># Step 2: Fit the model to the DataFrame</span>
        <span class="n">iso_forest</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_combined</span><span class="p">)</span>

        <span class="c1"># Step 3: Predict the outliers (-1 indicates an outlier)</span>
        <span class="n">X</span><span class="p">[</span><span class="s1">&#39;outlier&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">iso_forest</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_combined</span><span class="p">)</span>

        <span class="c1"># Step 4: Filter out the outliers using the original index</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="s1">&#39;outlier&#39;</span><span class="p">]</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span>  <span class="c1"># Filter y using the same mask</span>
        
        <span class="n">testset</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Drop the &#39;outlier&#39; column if you don&#39;t need it anymore</span>
        <span class="n">testset</span> <span class="o">=</span> <span class="n">testset</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;outlier&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mydata</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="data-split-prediction-vs-discovery">
<h3>Data split (prediction vs. discovery)<a class="headerlink" href="#data-split-prediction-vs-discovery" title="Link to this heading">#</a></h3>
<p>This section covers performing a random data split. It’s important to note that the default data split may not always be the optimal approach. In certain cases, a custom data split, such as one stratified by multiple variables (data_split_multi_strats) or by patient ID (or other individual identifiers), may be more appropriate. The following code can be adjusted to accommodate these specific data splitting needs.</p>
<p>Additionally, if the primary aim of a study is to explore relationships between independent variables (features) and the outcome variable using cross-validation of machine learning models, it is recommended to use the entire dataset for cross-validation. This approach is particularly useful when the dataset is too small to be divided into a training (development) set and a test set.</p>
<p>However, if the study’s goal is both to investigate associations and to develop a model for prognostic or diagnostic purposes, then data splitting becomes relevant. The first approach is considered a discovery phase, while the second approach is aimed at prediction.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mydata</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mydata</span><span class="p">[</span><span class="n">outcome_var</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">dropna</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mydata</span><span class="p">[</span><span class="n">outcome_var</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">test_size_perc</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">train_size_perc</span>
<span class="k">if</span> <span class="n">data_split</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">data_split_by_patients</span><span class="p">:</span> 
        <span class="c1"># If there are more than one sample per patient, this split is suggested</span>
        <span class="c1"># to avoid having the same patient data in both training and test sets.</span>
        <span class="c1"># In this case, the column that specifies patient ID is also used in the data split.</span>
        <span class="n">unique_patients</span> <span class="o">=</span> <span class="n">mydata</span><span class="p">[</span><span class="n">patient_id_col</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span>
        <span class="n">train_patients</span><span class="p">,</span> <span class="n">test_patients</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">unique_patients</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="n">test_size_perc</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
        <span class="n">trainset</span> <span class="o">=</span> <span class="n">mydata</span><span class="p">[</span><span class="n">mydata</span><span class="p">[</span><span class="n">patient_id_col</span><span class="p">]</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">train_patients</span><span class="p">)]</span>
        <span class="n">testset</span> <span class="o">=</span> <span class="n">mydata</span><span class="p">[</span><span class="n">mydata</span><span class="p">[</span><span class="n">patient_id_col</span><span class="p">]</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">test_patients</span><span class="p">)]</span>

    <span class="k">elif</span> <span class="n">data_split_multi_strats</span><span class="p">:</span>
        <span class="c1"># If the data split must be stratified by more than one variable.</span>
        <span class="c1"># In this case, if there are two variables specified by the user,</span>
        <span class="c1"># they should be combined to create a combined variable.</span>
        <span class="c1"># Then the combined variable is used for the stratification so that</span>
        <span class="c1"># the same portion of categories exist in both train and test sets.</span>
        <span class="c1"># this is defined for two variables, if you need more then you should modify the following code</span>
        <span class="n">combined_strats</span> <span class="o">=</span> <span class="n">mydata</span><span class="p">[</span><span class="n">strat_var1</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;_&#39;</span> <span class="o">+</span> <span class="n">mydata</span><span class="p">[</span><span class="n">outcome_var</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span>
        <span class="n">mydata</span><span class="p">[</span><span class="s1">&#39;combined_strats&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">combined_strats</span>
        <span class="n">mydata</span><span class="p">,</span> <span class="n">testset</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">mydata</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="n">test_size_perc</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">mydata</span><span class="p">[</span><span class="s1">&#39;combined_strats&#39;</span><span class="p">])</span>
        <span class="n">mydata</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;combined_strats&#39;</span><span class="p">,</span><span class="n">strat_var1</span><span class="p">],</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">testset</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;combined_strats&#39;</span><span class="p">,</span><span class="n">strat_var1</span><span class="p">],</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="c1"># mydata.drop(columns = [&#39;combined_strats&#39;,strat_var1], inplace=True)</span>
        <span class="k">if</span> <span class="n">external_val</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">extval_data</span><span class="o">.</span><span class="n">empty</span> <span class="ow">and</span> <span class="n">strat_var1</span> <span class="ow">in</span> <span class="n">extval_data</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
                <span class="n">extval_data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="n">strat_var1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">already_split</span><span class="p">:</span>
        <span class="c1"># If you have done data split already using a different approach,</span>
        <span class="c1"># here just check if trainset and testset are comparable</span>
        <span class="c1"># (have the same variables and datatype).</span>
        <span class="k">if</span> <span class="nb">set</span><span class="p">(</span><span class="n">mydata</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">set</span><span class="p">(</span><span class="n">testset</span><span class="o">.</span><span class="n">columns</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Trainset and testset have different columns.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">all</span><span class="p">(</span><span class="n">mydata</span><span class="o">.</span><span class="n">dtypes</span> <span class="o">==</span> <span class="n">testset</span><span class="o">.</span><span class="n">dtypes</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Trainset and testset have different data types for columns.&quot;</span><span class="p">)</span>
        <span class="c1"># Optionally, you can check for other comparability metrics as needed.</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># stratified data split based on outcome variable (see also the other conditions if they may be relevant for your dataset)</span>
        <span class="n">mydata</span><span class="p">,</span> <span class="n">testset</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">mydata</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span> <span class="n">test_size_perc</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span> <span class="n">mydata</span><span class="p">[</span><span class="n">outcome_var</span><span class="p">])</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">testset</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">mydata</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="n">test_size_perc</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span> <span class="n">mydata</span><span class="p">[</span><span class="n">outcome_var</span><span class="p">])</span> <span class="c1"># this way we keep a dummy testset just to avoid including too many conditions in the pipeline</span>
</pre></div>
</div>
</div>
</div>
<section id="checking-the-availability-of-all-categories">
<h4>Checking the availability of all categories<a class="headerlink" href="#checking-the-availability-of-all-categories" title="Link to this heading">#</a></h4>
<p>make sure both train and test sets have all categorical levels</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">data_split</span><span class="p">:</span>
    <span class="c1"># Get list of categorical variable names</span>
    <span class="n">categorical_vars</span> <span class="o">=</span> <span class="n">mydata</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;category&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

    <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">categorical_vars</span><span class="p">:</span>
        <span class="n">unique_categories</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">mydata</span><span class="p">[</span><span class="n">var</span><span class="p">])</span><span class="o">.</span><span class="n">union</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">testset</span><span class="p">[</span><span class="n">var</span><span class="p">]))</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">var</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">unique_categories</span><span class="p">)</span>
        
        <span class="c1"># Exclude old categories before adding new categories to the train set</span>
        <span class="n">new_categories_train</span> <span class="o">=</span> <span class="n">unique_categories</span><span class="o">.</span><span class="n">difference</span><span class="p">(</span><span class="n">mydata</span><span class="p">[</span><span class="n">var</span><span class="p">]</span><span class="o">.</span><span class="n">cat</span><span class="o">.</span><span class="n">categories</span><span class="p">)</span>
        <span class="n">mydata</span><span class="p">[</span><span class="n">var</span><span class="p">]</span> <span class="o">=</span> <span class="n">mydata</span><span class="p">[</span><span class="n">var</span><span class="p">]</span><span class="o">.</span><span class="n">cat</span><span class="o">.</span><span class="n">add_categories</span><span class="p">(</span><span class="n">new_categories_train</span><span class="p">)</span>
        
        <span class="c1"># Exclude old categories before adding new categories to the test set</span>
        <span class="n">new_categories_test</span> <span class="o">=</span> <span class="n">unique_categories</span><span class="o">.</span><span class="n">difference</span><span class="p">(</span><span class="n">testset</span><span class="p">[</span><span class="n">var</span><span class="p">]</span><span class="o">.</span><span class="n">cat</span><span class="o">.</span><span class="n">categories</span><span class="p">)</span>
        <span class="n">testset</span><span class="p">[</span><span class="n">var</span><span class="p">]</span> <span class="o">=</span> <span class="n">testset</span><span class="p">[</span><span class="n">var</span><span class="p">]</span><span class="o">.</span><span class="n">cat</span><span class="o">.</span><span class="n">add_categories</span><span class="p">(</span><span class="n">new_categories_test</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">external_val</span><span class="p">:</span>
            <span class="c1"># Exclude old categories before adding new categories to the extval_data set</span>
            <span class="n">new_categories_test</span> <span class="o">=</span> <span class="n">unique_categories</span><span class="o">.</span><span class="n">difference</span><span class="p">(</span><span class="n">extval_data</span><span class="p">[</span><span class="n">var</span><span class="p">]</span><span class="o">.</span><span class="n">cat</span><span class="o">.</span><span class="n">categories</span><span class="p">)</span>
            <span class="n">extval_data</span><span class="p">[</span><span class="n">var</span><span class="p">]</span> <span class="o">=</span> <span class="n">extval_data</span><span class="p">[</span><span class="n">var</span><span class="p">]</span><span class="o">.</span><span class="n">cat</span><span class="o">.</span><span class="n">add_categories</span><span class="p">(</span><span class="n">new_categories_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mydata</span><span class="o">.</span><span class="n">dtypes</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="filter-highly-missing-data">
<h4>Filter highly missing data<a class="headerlink" href="#filter-highly-missing-data" title="Link to this heading">#</a></h4>
<p>Missing data can significantly impact model performance and introduce bias, making consistent preprocessing crucial.</p>
<p>To address this, the following steps are undertaken:</p>
<ol class="arabic simple">
<li><p><strong>Filter Columns in <code class="docutils literal notranslate"><span class="pre">mydata</span></code>:</strong> Identify and retain columns in <code class="docutils literal notranslate"><span class="pre">mydata</span></code> where the proportion of missing values is below a specified threshold. This step removes columns with excessive missing data that could skew analysis or model training.</p></li>
<li><p><strong>Apply Identified Columns to Other Datasets:</strong> Ensure that <code class="docutils literal notranslate"><span class="pre">testset</span></code> and <code class="docutils literal notranslate"><span class="pre">extval_data</span></code> are aligned with <code class="docutils literal notranslate"><span class="pre">mydata</span></code> by selecting only the columns present in the filtered <code class="docutils literal notranslate"><span class="pre">mydata</span></code>. This maintains consistency across datasets, which is essential for reliable model evaluation and comparison.</p></li>
<li><p><strong>Filter Rows in All Datasets:</strong> After aligning columns, filter out rows from all datasets where the proportion of missing values exceeds the threshold. This step ensures that all datasets have comparable completeness, supporting fair and accurate modeling.</p></li>
</ol>
<p>By following this approach, all datasets are harmonized with respect to both columns and rows, ensuring consistency and reducing potential bias from missing data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">filter_columns</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">0.90</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Filter out columns with missingness greater than the threshold.</span>
<span class="sd">    </span>
<span class="sd">    The `filter_columns` function filters out columns in a DataFrame based on the presence of missing values. It calculates the mean missingness ratio for each column, sets a threshold to determine which columns to keep, and returns a new DataFrame with only the specified columns.</span>

<span class="sd">    1. Calculate the mean number of missing values per column.</span>
<span class="sd">    2. Identify columns where the mean missingness is less than or equal to the specified threshold (default=0.90).</span>
<span class="sd">    3. Return a new DataFrame containing only the selected columns, effectively removing columns with high missingness rates.</span>

<span class="sd">    ## Parameters</span>

<span class="sd">    * `df`: input DataFrame</span>
<span class="sd">    * `threshold` (optional): maximum allowed missingness ratio (default=0.90)</span>

<span class="sd">    ## Returns</span>

<span class="sd">    * A new DataFrame with filtered columns.</span>
<span class="sd">    * The number of remaining columns is less than or equal to the input DataFrame&#39;s original column count by at least 1.</span>

<span class="sd">    Note: This function does not modify the original DataFrame, but instead returns a new one with the filtered columns.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Calculate the missingness ratio for each column</span>
    <span class="n">column_missingness</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="c1"># Identify columns to keep</span>
    <span class="n">columns_to_keep</span> <span class="o">=</span> <span class="n">column_missingness</span><span class="p">[</span><span class="n">column_missingness</span> <span class="o">&lt;=</span> <span class="n">threshold</span><span class="p">]</span><span class="o">.</span><span class="n">index</span>
    <span class="k">return</span> <span class="n">df</span><span class="p">[</span><span class="n">columns_to_keep</span><span class="p">]</span>

<span class="k">def</span> <span class="nf">filter_rows</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">0.90</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Filter out rows with missingness greater than the threshold.</span>

<span class="sd">    The `filter_rows` function filters out rows in a DataFrame based on the presence of missing values. It calculates the mean number of missing values per row, sets a threshold to determine which rows to keep, and returns a new DataFrame with only the specified rows.</span>

<span class="sd">    1. Calculate the mean number of missing values per row.</span>
<span class="sd">    2. Identify rows where the mean missingness is less than or equal to the specified threshold (default=0.90).</span>
<span class="sd">    3. Return a new DataFrame containing only the selected rows, effectively removing rows with high missingness rates.</span>

<span class="sd">    ## Parameters</span>

<span class="sd">    * `df`: input DataFrame</span>
<span class="sd">    * `threshold` (optional): maximum allowed missingness ratio (default=0.90)</span>

<span class="sd">    ## Returns</span>

<span class="sd">    * A new DataFrame with filtered rows.</span>
<span class="sd">    * The number of remaining rows is less than or equal to the original DataFrame&#39;s row count by at least 1.</span>

<span class="sd">    Note: This function does not modify the original DataFrame, but instead returns a new one with the filtered rows.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Calculate the missingness ratio for each row</span>
    <span class="n">row_missingness</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="c1"># Keep rows with missingness less than or equal to the threshold</span>
    <span class="k">return</span> <span class="n">df</span><span class="p">[</span><span class="n">row_missingness</span> <span class="o">&lt;=</span> <span class="n">threshold</span><span class="p">]</span>

<span class="c1"># Apply the filtering to `mydata`</span>
<span class="k">if</span> <span class="n">exclude_highly_missing_columns</span><span class="p">:</span>
    <span class="n">mydata</span> <span class="o">=</span> <span class="n">filter_columns</span><span class="p">(</span><span class="n">mydata</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="n">column_threshold</span><span class="p">)</span>

<span class="c1"># Apply column filtering to `testset` and `extval_data` using columns identified from `mydata`</span>
<span class="k">if</span> <span class="n">exclude_highly_missing_columns</span><span class="p">:</span>
    <span class="n">testset</span> <span class="o">=</span> <span class="n">testset</span><span class="p">[</span><span class="n">mydata</span><span class="o">.</span><span class="n">columns</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">external_val</span><span class="p">:</span>
        <span class="n">extval_data</span> <span class="o">=</span> <span class="n">extval_data</span><span class="p">[</span><span class="n">mydata</span><span class="o">.</span><span class="n">columns</span><span class="p">]</span>

<span class="c1"># Apply row filtering to all datasets</span>
<span class="k">if</span> <span class="n">exclude_highly_missing_rows</span><span class="p">:</span>
    <span class="n">mydata</span> <span class="o">=</span> <span class="n">filter_rows</span><span class="p">(</span><span class="n">mydata</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="n">row_threshold</span><span class="p">)</span>
    <span class="n">testset</span> <span class="o">=</span> <span class="n">filter_rows</span><span class="p">(</span><span class="n">testset</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="n">row_threshold</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">external_val</span><span class="p">:</span>
        <span class="n">extval_data</span> <span class="o">=</span> <span class="n">filter_rows</span><span class="p">(</span><span class="n">extval_data</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="n">row_threshold</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="feature-selection-optional-but-recommended-if-the-dataset-is-high-dimensional-e-g-100-features">
<h4>Feature selection (optional but recommended if the dataset is high dimensional, e.g &gt;100 features)<a class="headerlink" href="#feature-selection-optional-but-recommended-if-the-dataset-is-high-dimensional-e-g-100-features" title="Link to this heading">#</a></h4>
<p>Minimum Redundancy Maximum Relevance (mRMR) is one of the most popular algorithms for feature selection. For more information on its implementation see <a class="github reference external" href="https://github.com/smazzanti/mrmr">smazzanti/mrmr</a>.</p>
<p>Reference:
F. Long, H. Peng and C. Ding, “Feature Selection Based on Mutual Information: Criteria of Max-Dependency, Max-Relevance, and Min-Redundancy” in IEEE Transactions on Pattern Analysis &amp; Machine Intelligence, vol. 27, no. 08, pp. 1226-1238, 2005.
doi: 10.1109/TPAMI.2005.159</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">feat_sel</span><span class="p">:</span> <span class="c1"># feature selection</span>
    <span class="c1"># Separate features and outcome variable</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">mydata</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="n">outcome_var</span><span class="p">])</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">mydata</span><span class="p">[</span><span class="n">outcome_var</span><span class="p">]</span>
    
    <span class="n">numerical_columns</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;float64&#39;</span><span class="p">,</span> <span class="s1">&#39;int64&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">columns</span>
    <span class="n">categorical_columns</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;category&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">columns</span>
    
    <span class="n">skf</span> <span class="o">=</span> <span class="n">StratifiedKFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="n">cv_folds</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="c1"># Initialize list to store selected features for each fold</span>
    <span class="n">selected_features_per_fold</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">selected_features_fold</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="c1"># all_selected_features = set()</span>
    <span class="k">for</span> <span class="n">fold</span><span class="p">,</span> <span class="p">(</span><span class="n">train_index</span><span class="p">,</span> <span class="n">test_index</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">skf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">X_train_fold</span><span class="p">,</span> <span class="n">X_test_fold</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
        <span class="n">y_train_fold</span><span class="p">,</span> <span class="n">y_test_fold</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
        
        <span class="c1"># for details see https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html</span>
        <span class="k">if</span> <span class="n">scale_data</span><span class="p">:</span>
            <span class="n">robust_scaler</span> <span class="o">=</span> <span class="n">RobustScaler</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_fold</span><span class="p">[</span><span class="n">numerical_columns</span><span class="p">])</span> 
            
            <span class="c1"># Use the RobustScaler to scale the numerical features</span>
            <span class="n">X_train_fold</span><span class="p">[</span><span class="n">numerical_columns</span><span class="p">]</span> <span class="o">=</span> <span class="n">robust_scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train_fold</span><span class="p">[</span><span class="n">numerical_columns</span><span class="p">])</span>

        <span class="c1"># Impute missing values in continuous features of X_train using KNN</span>
        <span class="n">nn</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">X_train_fold</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span> <span class="c1"># from Devroye, L., Györfi, L., &amp; Lugosi, G. (1996). A Probabilistic Theory of Pattern Recognition. Springer. https://doi.org/10.1007/978-1-4612-0711-5.</span>
        <span class="n">cont_imputer</span> <span class="o">=</span> <span class="n">KNNImputer</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">nn</span><span class="p">,</span> <span class="n">weights</span> <span class="o">=</span> <span class="s1">&#39;distance&#39;</span><span class="p">,</span> <span class="n">keep_empty_features</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>  
        
        <span class="n">X_train_fold_filled</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">cont_imputer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train_fold</span><span class="p">[</span><span class="n">numerical_columns</span><span class="p">]),</span> <span class="n">columns</span><span class="o">=</span><span class="n">numerical_columns</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">X_train_fold</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
        
        <span class="c1"># Combine the categorical features with the normalized continuous features for the training set and the test set</span>
        <span class="n">X_train_fold</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">X_train_fold</span><span class="p">[</span><span class="n">categorical_columns</span><span class="p">],</span> <span class="n">X_train_fold_filled</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        
        <span class="c1"># Replace categorical features with integers using LabelEncoder</span>
        <span class="n">label_encoders</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">categorical_columns</span><span class="p">:</span>
            <span class="n">label_encoders</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
            <span class="n">X_train_fold</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="n">label_encoders</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train_fold</span><span class="p">[</span><span class="n">col</span><span class="p">])</span>

        <span class="c1"># Select top num_features_sel features using mRMR</span>
        <span class="n">selected_features_fold</span> <span class="o">=</span> <span class="n">mrmr_classif</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X_train_fold</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y_train_fold</span><span class="p">,</span> <span class="n">K</span><span class="o">=</span><span class="n">num_features_sel</span><span class="p">)</span>

        <span class="c1"># Append selected features for this fold to the list</span>
        <span class="n">selected_features_per_fold</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">selected_features_fold</span><span class="p">)</span>

    <span class="c1"># Find features common across all folds</span>
    <span class="n">selected_features</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">selected_features_per_fold</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">intersection</span><span class="p">(</span><span class="o">*</span><span class="n">selected_features_per_fold</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
    
    <span class="c1"># # Convert the set to a list if needed</span>
    <span class="n">selected_features</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">selected_features</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Final union of selected features across all folds: </span><span class="si">{</span><span class="n">selected_features</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

    <span class="c1"># Remove categorical features that are not selected</span>
    <span class="c1"># categorical_vars = [feat_name for feat_name in categorical_vars if feat_name in selected_features]</span>
    <span class="n">cat_features</span> <span class="o">=</span> <span class="p">[</span><span class="n">feat_name</span> <span class="k">for</span> <span class="n">feat_name</span> <span class="ow">in</span> <span class="n">cat_features</span> <span class="k">if</span> <span class="n">feat_name</span> <span class="ow">in</span> <span class="n">selected_features</span><span class="p">]</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Selected Features:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">selected_features</span><span class="p">)</span>

    <span class="n">mydata</span> <span class="o">=</span> <span class="n">mydata</span><span class="p">[</span><span class="n">selected_features</span> <span class="o">+</span> <span class="p">[</span><span class="n">outcome_var</span><span class="p">]]</span>
    <span class="n">testset</span> <span class="o">=</span> <span class="n">testset</span><span class="p">[</span><span class="n">selected_features</span> <span class="o">+</span> <span class="p">[</span><span class="n">outcome_var</span><span class="p">]]</span>
    <span class="k">if</span> <span class="n">external_val</span><span class="p">:</span>
        <span class="n">extval_data</span> <span class="o">=</span> <span class="n">extval_data</span><span class="p">[</span><span class="n">selected_features</span> <span class="o">+</span> <span class="p">[</span><span class="n">outcome_var</span><span class="p">]]</span>
    
    <span class="c1"># Sort columns alphabetically (column order can affect the reproducibility of some estimators)</span>
    <span class="n">mydata</span> <span class="o">=</span> <span class="n">mydata</span><span class="o">.</span><span class="n">reindex</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="n">mydata</span><span class="o">.</span><span class="n">columns</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">testset</span> <span class="o">=</span> <span class="n">testset</span><span class="o">.</span><span class="n">reindex</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="n">testset</span><span class="o">.</span><span class="n">columns</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">external_val</span><span class="p">:</span>
        <span class="n">extval_data</span> <span class="o">=</span> <span class="n">extval_data</span><span class="o">.</span><span class="n">reindex</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="n">extval_data</span><span class="o">.</span><span class="n">columns</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="cross-correlation-of-variables">
<h4>Cross correlation of variables<a class="headerlink" href="#cross-correlation-of-variables" title="Link to this heading">#</a></h4>
<p>Here the correlation coefficients between every pair of variables are calculated and presented as a heatmap. It also includes the outcome variable.
method: Spearman rank-order correlation</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Replace NaN with median for each class</span>
<span class="n">mydata_filled</span> <span class="o">=</span> <span class="n">mydata</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="c1"># One-hot encode categorical features</span>
<span class="n">mydata_filled</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">mydata_filled</span><span class="p">,</span> <span class="n">drop_first</span><span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
<span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">mydata</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">mydata</span><span class="p">[</span><span class="n">column</span><span class="p">]</span><span class="o">.</span><span class="n">isna</span><span class="p">()</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
        <span class="n">mydata_filled</span><span class="p">[</span><span class="n">column</span><span class="p">]</span> <span class="o">=</span> <span class="n">mydata</span><span class="p">[</span><span class="n">column</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="n">mydata</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">outcome_var</span><span class="p">)[</span><span class="n">column</span><span class="p">]</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="s1">&#39;median&#39;</span><span class="p">))</span>

<span class="c1"># Now, impute any remaining NaN values with the median of the entire column</span>
<span class="n">mydata_filled</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="n">mydata_filled</span><span class="o">.</span><span class="n">median</span><span class="p">(),</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Calculate Spearman rank-order correlation</span>
<span class="n">correlation_matrix</span> <span class="o">=</span> <span class="n">mydata_filled</span><span class="o">.</span><span class="n">corr</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;spearman&#39;</span><span class="p">)</span>

<span class="c1"># Find pairs of features with NaN values</span>
<span class="n">nan_pairs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">correlation_matrix</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
    <span class="n">nan_in_col</span> <span class="o">=</span> <span class="n">correlation_matrix</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">isna</span><span class="p">()</span>
    <span class="n">nan_pairs</span><span class="o">.</span><span class="n">extend</span><span class="p">([(</span><span class="n">col</span><span class="p">,</span> <span class="n">row</span><span class="p">)</span> <span class="k">for</span> <span class="n">row</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">nan_in_col</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">val</span><span class="p">])</span>

<span class="c1"># Replace NaN values with 0</span>
<span class="n">correlation_matrix</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Print names of pairs with NaN values</span>
<span class="k">if</span> <span class="n">nan_pairs</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Pairs of features with undefined correlation values:&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">pair</span> <span class="ow">in</span> <span class="n">nan_pairs</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">pair</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;No pairs of features had undefined correlation values.&quot;</span><span class="p">)</span>


<span class="c1"># Calculate figure size based on the number of features</span>
<span class="n">num_features</span> <span class="o">=</span> <span class="n">correlation_matrix</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="n">height</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">num_features</span><span class="p">)]))</span> 
<span class="c1"># Ensure height does not exceed the maximum allowed dimension</span>
<span class="n">max_height</span> <span class="o">=</span> <span class="mi">65535</span> <span class="o">/</span> <span class="mi">72</span>  <span class="c1"># Convert pixels to inches</span>
<span class="k">if</span> <span class="n">height</span> <span class="o">&gt;</span> <span class="n">max_height</span><span class="p">:</span>
    <span class="n">height</span> <span class="o">=</span> <span class="n">max_height</span>

<span class="c1"># Create the clustermap</span>
<span class="n">g</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">clustermap</span><span class="p">(</span><span class="n">correlation_matrix</span><span class="p">,</span>
                   <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;viridis&quot;</span><span class="p">,</span>
                   <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="n">height</span><span class="p">,</span> <span class="n">height</span><span class="p">),</span>
                   <span class="n">cbar_pos</span><span class="o">=</span><span class="p">(</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.95</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">),</span>
                   <span class="n">method</span><span class="o">=</span><span class="s2">&quot;ward&quot;</span>
                   <span class="p">)</span>

<span class="c1"># Create a mask to hide the upper triangle</span>
<span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">triu</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">correlation_matrix</span><span class="p">))</span>

<span class="c1"># Apply the mask to the heatmap</span>
<span class="n">values</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">ax_heatmap</span><span class="o">.</span><span class="n">collections</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get_array</span><span class="p">()</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">correlation_matrix</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">new_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ma</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="n">mask</span><span class="p">)</span>
<span class="n">g</span><span class="o">.</span><span class="n">ax_heatmap</span><span class="o">.</span><span class="n">collections</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_array</span><span class="p">(</span><span class="n">new_values</span><span class="p">)</span>

<span class="c1"># Adjust x-axis and y-axis ticks</span>
<span class="n">g</span><span class="o">.</span><span class="n">ax_heatmap</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">correlation_matrix</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">+</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">minor</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">g</span><span class="o">.</span><span class="n">ax_heatmap</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">correlation_matrix</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="o">+</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">minor</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">g</span><span class="o">.</span><span class="n">ax_heatmap</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">(</span><span class="n">correlation_matrix</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
<span class="n">g</span><span class="o">.</span><span class="n">ax_heatmap</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">(</span><span class="n">correlation_matrix</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>

<span class="n">g</span><span class="o">.</span><span class="n">ax_heatmap</span><span class="o">.</span><span class="n">set_facecolor</span><span class="p">(</span><span class="s1">&#39;white&#39;</span><span class="p">)</span>

<span class="c1"># display grid lines</span>
<span class="n">g</span><span class="o">.</span><span class="n">ax_heatmap</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">&#39;both&#39;</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s2">&quot;grey&quot;</span><span class="p">)</span>

<span class="c1"># modify grid lines</span>
<span class="n">g</span><span class="o">.</span><span class="n">ax_heatmap</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">&#39;minor&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">g</span><span class="o">.</span><span class="n">ax_heatmap</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">&#39;major&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>

<span class="c1"># Hide the x-axis dendrogram</span>
<span class="n">g</span><span class="o">.</span><span class="n">ax_col_dendrogram</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
<span class="n">g</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s2">&quot;feature_cor_clustermap.tif&quot;</span><span class="p">,</span> <span class="n">bbox_inches</span><span class="o">=</span><span class="s1">&#39;tight&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="sample-size-assessment">
<h3>Sample size assessment<a class="headerlink" href="#sample-size-assessment" title="Link to this heading">#</a></h3>
<p>The following script provides an analysis of dataset characteristics, including class imbalance, dataset size, and sample distribution per class, to determine the suitability of hyperparameter tuning.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">is_hyperparameter_tuning_suitable</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">outcome_var</span><span class="p">,</span> <span class="n">train_size</span><span class="o">=</span><span class="n">train_size_perc</span><span class="p">,</span> <span class="n">n_splits_outer</span><span class="o">=</span><span class="n">cv_folds</span><span class="p">,</span> <span class="n">n_splits_inner</span><span class="o">=</span><span class="n">cv_folds_hptuning</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Checks whether hyperparameter tuning is suitable for a given dataset.</span>

<span class="sd">    ## Parameters:</span>
<span class="sd">        data (pandas DataFrame): The input dataset.</span>
<span class="sd">        outcome_var (str): The name of the column containing the target variable.</span>
<span class="sd">        train_size (float or int, optional): The proportion of samples to use for training. Defaults to 0.7.</span>
<span class="sd">        n_splits_outer (int, optional): The number of folds for outer cross-validation. Defaults to 5.</span>
<span class="sd">        n_splits_inner (int, optional): The number of folds for inner cross-validation. Defaults to 5.</span>

<span class="sd">    ## Returns</span>
<span class="sd">        None</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Extract features and target variable</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="n">outcome_var</span><span class="p">])</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">outcome_var</span><span class="p">]</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">replace</span><span class="p">({</span><span class="n">class_1</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="n">class_0</span><span class="p">:</span> <span class="mi">0</span><span class="p">})</span>
        
    <span class="c1"># Calculate number of samples used in model training</span>
    <span class="n">n_train_samples</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">*</span> <span class="n">train_size</span><span class="p">)</span>
    
    <span class="c1"># Print the number of samples used in model training</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Number of samples used in model training: </span><span class="si">{</span><span class="n">n_train_samples</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
  
    <span class="c1"># Define cross-validation strategy for outer loop</span>
    <span class="n">cv_outer</span> <span class="o">=</span> <span class="n">StratifiedKFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="n">n_splits_outer</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
    
    <span class="c1"># Initialize arrays to store number of samples per class per fold for outer CV</span>
    <span class="n">n_samples_per_class_outer</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_splits_outer</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
    <span class="n">n_samples_per_class_inner</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="c1"># Iterate over outer folds</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">train_index</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">cv_outer</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)):</span>
        <span class="c1"># Get class distribution in the training fold for outer CV</span>
        <span class="n">y_train_fold_outer</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_index</span><span class="p">]</span>
        <span class="n">class_counts_outer</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span><span class="n">y_train_fold_outer</span><span class="p">)</span>
        <span class="n">n_samples_per_class_outer</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">class_counts_outer</span>
        
        <span class="c1"># Define cross-validation strategy for inner loop</span>
        <span class="n">cv_inner</span> <span class="o">=</span> <span class="n">StratifiedKFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="n">n_splits_inner</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
        
        <span class="c1"># Initialize array to store number of samples per class per fold for inner CV</span>
        <span class="n">n_samples_per_class_inner_fold</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_splits_inner</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
        
        <span class="c1"># Iterate over inner folds</span>
        <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="p">(</span><span class="n">train_index_inner</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">cv_inner</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_index</span><span class="p">])):</span>
            <span class="c1"># Get class distribution in the testing fold for inner CV</span>
            <span class="n">y_train_fold_inner</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_index</span><span class="p">]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_index_inner</span><span class="p">]</span>
            <span class="n">class_counts_inner</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span><span class="n">y_train_fold_inner</span><span class="p">)</span>
            <span class="n">n_samples_per_class_inner_fold</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">class_counts_inner</span>
        
        <span class="c1"># Append the array for inner CV to the list</span>
        <span class="n">n_samples_per_class_inner</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">n_samples_per_class_inner_fold</span><span class="p">)</span>
    
    <span class="c1"># Convert the list of arrays to a numpy array for inner CV</span>
    <span class="n">n_samples_per_class_inner</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">n_samples_per_class_inner</span><span class="p">)</span>
            
    <span class="c1"># Print mean and standard deviation of samples per class per fold for outer CV</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Samples per class per fold for outer CV:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">n_samples_per_class_outer</span><span class="p">)</span>
    
    <span class="c1"># Print mean and standard deviation of samples per class per fold for inner CV</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Samples per class per fold for inner CV:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">n_samples_per_class_inner</span><span class="p">)</span>
    
    <span class="c1"># Check if the number of samples per class in the inner CV is for example less than 10 (10 is chosen arbitrarily here)</span>
    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">n_samples_per_class_inner</span> <span class="o">&lt;</span> <span class="mi">10</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Warning: Number of samples per class in the inner cross-validation is less than 10. Hyperparameter tuning may not be suitable.&quot;</span><span class="p">)</span>
    
    <span class="c1"># Combine outer and inner CV samples per class matrices</span>
    <span class="n">combined_samples_per_class</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">n_samples_per_class_outer</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="p">:],</span> <span class="n">n_samples_per_class_inner</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># Plot heatmap of samples per class per fold</span>
    <span class="n">plot_samples_per_class_per_fold</span><span class="p">(</span><span class="n">combined_samples_per_class</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">plot_samples_per_class_per_fold</span><span class="p">(</span><span class="n">samples_per_class_per_fold</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Plots a heatmap of the samples per class per fold.</span>

<span class="sd">    ## Parameters:</span>
<span class="sd">        samples_per_class_per_fold (numpy array): A 3D array where each element represents the number of samples for a particular class and fold combination.</span>

<span class="sd">    ## Returns</span>
<span class="sd">        None</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">samples_per_class_per_fold</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span> <span class="o">*</span> <span class="n">samples_per_class_per_fold</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">6</span><span class="p">),</span> <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">samples_per_class_per_fold</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="n">ax</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">im</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">samples_per_class_per_fold</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;coolwarm&#39;</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="s1">&#39;nearest&#39;</span><span class="p">)</span>

        <span class="c1"># Add color bar</span>
        <span class="n">cbar</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">figure</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
        <span class="n">cbar</span><span class="o">.</span><span class="n">set_label</span><span class="p">(</span><span class="s1">&#39;Number of samples&#39;</span><span class="p">)</span>

        <span class="c1"># Set axis labels and title</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Fold </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Classes&#39;</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">([</span><span class="s1">&#39;Class 0&#39;</span><span class="p">,</span> <span class="s1">&#39;Class 1&#39;</span><span class="p">])</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Cross validation folds&#39;</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">6</span><span class="p">))</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">([</span><span class="s1">&#39;Outer CV&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="sa">f</span><span class="s1">&#39;Inner CV </span><span class="si">{</span><span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1">&#39;</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">)])</span>
        <span class="c1"># We change the fontsize of minor ticks label </span>
        <span class="n">ax</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;both&#39;</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s1">&#39;major&#39;</span><span class="p">,</span> <span class="n">labelsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;both&#39;</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s1">&#39;minor&#39;</span><span class="p">,</span> <span class="n">labelsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>

        <span class="c1"># Loop over data dimensions and create text annotations</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">samples_per_class_per_fold</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">samples_per_class_per_fold</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]):</span>
                <span class="n">text</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">samples_per_class_per_fold</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">j</span><span class="p">,</span><span class="w"> </span><span class="n">k</span><span class="p">]</span><span class="si">:</span><span class="s1">.0f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span>
                               <span class="n">ha</span><span class="o">=</span><span class="s2">&quot;center&quot;</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s2">&quot;center&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">)</span>

    <span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Samples per class per fold&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">(</span><span class="n">rect</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.03</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mf">0.95</span><span class="p">])</span>

    <span class="c1"># it shows how many samples are expected to be available for the cross validation and hyperparameter tuning</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;font.family&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;sans-serif&#39;</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;font.size&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">8</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s2">&quot;Samples_CV_map.tif&quot;</span><span class="p">,</span> <span class="n">bbox_inches</span><span class="o">=</span><span class="s1">&#39;tight&#39;</span><span class="p">)</span> 
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">is_hyperparameter_tuning_suitable</span><span class="p">(</span><span class="n">mydata</span><span class="p">,</span> <span class="n">outcome_var</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># in case of applying oversampling</span>
<span class="k">if</span> <span class="n">oversampling</span><span class="p">:</span>
    <span class="c1"># Define your features and outcome variable</span>
    <span class="n">X_train</span> <span class="o">=</span> <span class="n">mydata</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">outcome_var</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">y_train</span> <span class="o">=</span> <span class="n">mydata</span><span class="p">[</span><span class="n">outcome_var</span><span class="p">]</span>

    <span class="c1"># Initialize RandomOverSampler to oversample the minority class</span>
    <span class="n">random_oversampler</span> <span class="o">=</span> <span class="n">RandomOverSampler</span><span class="p">(</span><span class="n">sampling_strategy</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>

    <span class="c1"># Oversample the minority class in the training set</span>
    <span class="n">X_train_resampled</span><span class="p">,</span> <span class="n">y_train_resampled</span> <span class="o">=</span> <span class="n">random_oversampler</span><span class="o">.</span><span class="n">fit_resample</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="c1"># Concatenate resampled features and outcome variable back into a dataframe</span>
    <span class="n">mydata</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X_train_resampled</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">X_train</span><span class="o">.</span><span class="n">columns</span><span class="p">),</span> 
                            <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">y_train_resampled</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">outcome_var</span><span class="p">)],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mydata</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
</div>
<section id="statistical-comparision-of-the-training-and-test-sets">
<h4>Statistical comparision of the training and test sets<a class="headerlink" href="#statistical-comparision-of-the-training-and-test-sets" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">data_split</span><span class="p">:</span>

    <span class="c1"># Define a function to check statistical difference for numerical variables</span>
    <span class="k">def</span> <span class="nf">check_numerical_difference</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">test_data</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        check_numerical_difference compares statistical differences between numerical variables in training and testing datasets.</span>

<span class="sd">        This function takes two dataframes (train_data and test_data) as input, identifies the numerical columns, and computes the Mann-Whitney U-statistic to determine if there are significant differences between the distributions of these numerical variables in the training and testing datasets. It returns a dictionary containing the results for each identified variable, including the statistic and p-value.</span>

<span class="sd">        ## Parameters</span>
<span class="sd">        train_data: The original training data.</span>
<span class="sd">        test_data: The test set obtained from train_test_split.</span>
<span class="sd">        </span>
<span class="sd">        ## Returns</span>
<span class="sd">        A dictionary containing the statistical difference results for each numerical variable.</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="n">numerical_vars</span> <span class="o">=</span> <span class="n">train_data</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;float64&#39;</span><span class="p">,</span> <span class="s1">&#39;int64&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
        <span class="n">results</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">numerical_vars</span><span class="p">:</span>
            <span class="n">train_values</span> <span class="o">=</span> <span class="n">train_data</span><span class="p">[</span><span class="n">var</span><span class="p">]</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span>  <span class="c1"># Drop missing values</span>
            <span class="n">test_values</span> <span class="o">=</span> <span class="n">test_data</span><span class="p">[</span><span class="n">var</span><span class="p">]</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span>    <span class="c1"># Drop missing values</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_values</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_values</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">stat</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">mannwhitneyu</span><span class="p">(</span><span class="n">train_values</span><span class="p">,</span> <span class="n">test_values</span><span class="p">)</span>
                <span class="n">results</span><span class="p">[</span><span class="n">var</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;Statistic&#39;</span><span class="p">:</span> <span class="n">stat</span><span class="p">,</span> <span class="s1">&#39;p-value&#39;</span><span class="p">:</span> <span class="n">p</span><span class="p">}</span>
        <span class="k">return</span> <span class="n">results</span>

    <span class="c1"># Check statistical difference for numerical variables</span>
    <span class="n">numerical_results</span> <span class="o">=</span> <span class="n">check_numerical_difference</span><span class="p">(</span><span class="n">mydata</span><span class="p">,</span> <span class="n">testset</span><span class="p">)</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Statistical Difference for Numerical Variables:&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">var</span><span class="p">,</span> <span class="n">result</span> <span class="ow">in</span> <span class="n">numerical_results</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">var</span><span class="si">}</span><span class="s2">: Statistic = </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;Statistic&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">, p-value = </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;p-value&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">check_categorical_difference</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">test_data</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Compares categorical differences between training and testing datasets, </span>
<span class="sd">        using the Chi-square test to determine if there are significant differences in distribution.</span>

<span class="sd">        ## Parameters</span>
<span class="sd">        train_data: The original training data.</span>
<span class="sd">        test_data: The test set obtained from train_test_split.</span>

<span class="sd">        ## Returns</span>
<span class="sd">        A dictionary containing the statistical difference results for each categorical variable.</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="n">categorical_vars</span> <span class="o">=</span> <span class="n">train_data</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;category&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
        <span class="n">results</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">categorical_vars</span><span class="p">:</span>
            <span class="c1"># Ensure &#39;missing&#39; is added to categories in both train and test datasets</span>
            <span class="n">train_data</span><span class="p">[</span><span class="n">var</span><span class="p">]</span> <span class="o">=</span> <span class="n">train_data</span><span class="p">[</span><span class="n">var</span><span class="p">]</span><span class="o">.</span><span class="n">cat</span><span class="o">.</span><span class="n">add_categories</span><span class="p">([</span><span class="s1">&#39;missing&#39;</span><span class="p">])</span>
            <span class="n">test_data</span><span class="p">[</span><span class="n">var</span><span class="p">]</span> <span class="o">=</span> <span class="n">test_data</span><span class="p">[</span><span class="n">var</span><span class="p">]</span><span class="o">.</span><span class="n">cat</span><span class="o">.</span><span class="n">add_categories</span><span class="p">([</span><span class="s1">&#39;missing&#39;</span><span class="p">])</span>

            <span class="n">train_categories</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">train_data</span><span class="p">[</span><span class="n">var</span><span class="p">]</span><span class="o">.</span><span class="n">cat</span><span class="o">.</span><span class="n">categories</span><span class="p">)</span>
            <span class="n">test_categories</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">test_data</span><span class="p">[</span><span class="n">var</span><span class="p">]</span><span class="o">.</span><span class="n">cat</span><span class="o">.</span><span class="n">categories</span><span class="p">)</span>
            <span class="n">common_categories</span> <span class="o">=</span> <span class="n">train_categories</span><span class="o">.</span><span class="n">intersection</span><span class="p">(</span><span class="n">test_categories</span><span class="p">)</span>
            
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">common_categories</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">train_counts</span> <span class="o">=</span> <span class="n">train_data</span><span class="p">[</span><span class="n">var</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="s1">&#39;missing&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
                <span class="n">test_counts</span> <span class="o">=</span> <span class="n">test_data</span><span class="p">[</span><span class="n">var</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="s1">&#39;missing&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
                
                <span class="c1"># Create the contingency table manually</span>
                <span class="n">contingency_table</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">common_categories</span><span class="p">),</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Train&#39;</span><span class="p">,</span> <span class="s1">&#39;Test&#39;</span><span class="p">])</span>
                <span class="k">for</span> <span class="n">category</span> <span class="ow">in</span> <span class="n">common_categories</span><span class="p">:</span>
                    <span class="n">contingency_table</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">category</span><span class="p">,</span> <span class="s1">&#39;Train&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">train_counts</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">category</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
                    <span class="n">contingency_table</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">category</span><span class="p">,</span> <span class="s1">&#39;Test&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">test_counts</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">category</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
                
                <span class="c1"># Remove rows with all zeros to avoid sparse issues</span>
                <span class="n">contingency_table</span> <span class="o">=</span> <span class="n">contingency_table</span><span class="p">[(</span><span class="n">contingency_table</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)]</span>
                
                <span class="c1"># Ensure contingency table has at least a 2x2 structure for Chi-square test</span>
                <span class="k">if</span> <span class="n">contingency_table</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mi">2</span><span class="p">:</span>
                    <span class="k">try</span><span class="p">:</span>
                        <span class="n">chi2</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">chi2_contingency</span><span class="p">(</span><span class="n">contingency_table</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
                        <span class="n">results</span><span class="p">[</span><span class="n">var</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;Chi-square&#39;</span><span class="p">:</span> <span class="n">chi2</span><span class="p">,</span> <span class="s1">&#39;p-value&#39;</span><span class="p">:</span> <span class="n">p</span><span class="p">}</span>
                    <span class="k">except</span> <span class="ne">ValueError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Skipping variable </span><span class="si">{</span><span class="n">var</span><span class="si">}</span><span class="s2"> due to error: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">results</span>

    <span class="c1"># &#39;mydata&#39; is the original dataset and &#39;testset&#39; is the test set obtained from train_test_split</span>
    <span class="n">categorical_results</span> <span class="o">=</span> <span class="n">check_categorical_difference</span><span class="p">(</span><span class="n">mydata</span><span class="p">,</span> <span class="n">testset</span><span class="p">)</span>

    
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Statistical Difference for Categorical Variables (if available):&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">var</span><span class="p">,</span> <span class="n">result</span> <span class="ow">in</span> <span class="n">categorical_results</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">var</span><span class="si">}</span><span class="s2">: Chi-square = </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;Chi-square&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">, p-value = </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;p-value&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="data-overview">
<h3>Data overview<a class="headerlink" href="#data-overview" title="Link to this heading">#</a></h3>
<section id="display-the-type-of-the-variables-columns">
<h4>Display the type of the variables (columns)<a class="headerlink" href="#display-the-type-of-the-variables-columns" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mydata</span><span class="o">.</span><span class="n">dtypes</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mydata</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="check-missing-values">
<h4>Check missing values<a class="headerlink" href="#check-missing-values" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Identify columns with missing values</span>
<span class="n">columns_with_missing_values</span> <span class="o">=</span> <span class="n">mydata</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">mydata</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">any</span><span class="p">()]</span>
<span class="n">columns_with_missing_values</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mydata</span><span class="p">[</span><span class="n">outcome_var</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mydata</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># to report missingness both for categorical and continuous variables, it saves the results in an excel file</span>
<span class="k">def</span> <span class="nf">calculate_missingness</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">output_file</span><span class="o">=</span><span class="s1">&#39;missingness_report.xlsx&#39;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Reports missingness in both categorical and continuous variables and saves the results to an Excel file.</span>

<span class="sd">    This function calculates the percentage of missing values for each column in the input data,</span>
<span class="sd">    corrects these percentages for categorical columns where &#39;missing&#39; is a valid category,</span>
<span class="sd">    and computes the mean and standard deviation of the missingness across all columns.</span>
<span class="sd">    </span>
<span class="sd">    ## Parameters</span>
<span class="sd">        data (pandas.DataFrame): The input data containing both categorical and continuous variables.</span>
<span class="sd">        output_file (str, optional): The file path to save the results. Defaults to &#39;missingness_report.xlsx&#39;.</span>

<span class="sd">    ## Returns</span>
<span class="sd">        None</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

    <span class="c1"># Identify categorical variables</span>
    <span class="n">categorical_variables</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;category&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">columns</span>

    <span class="c1"># Create a dataframe to store missing counts for categorical variables</span>
    <span class="n">missing_counts</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="n">categorical_variables</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Missing Count&#39;</span><span class="p">])</span>

    <span class="c1"># Count missing values for each categorical variable</span>
    <span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">categorical_variables</span><span class="p">:</span>
        <span class="n">missing_counts</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">column</span><span class="p">,</span> <span class="s1">&#39;Missing Count&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">column</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;missing&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

    <span class="c1"># Calculate the total number of missing values for each column</span>
    <span class="n">missing_values</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

    <span class="c1"># Divide by the total number of rows to get missing percentage</span>
    <span class="n">total_rows</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">missing_percentage</span> <span class="o">=</span> <span class="p">(</span><span class="n">missing_values</span> <span class="o">/</span> <span class="n">total_rows</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span>

    <span class="c1"># Correct missing percentages for categorical columns</span>
    <span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">categorical_variables</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">missing_percentage</span><span class="o">.</span><span class="n">index</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">missing_counts</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">column</span><span class="p">,</span> <span class="s1">&#39;Missing Count&#39;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>  <span class="c1"># Only adjust if missing categories exist</span>
                <span class="n">missing_percentage</span><span class="p">[</span><span class="n">column</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">missing_counts</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">column</span><span class="p">,</span> <span class="s1">&#39;Missing Count&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="n">total_rows</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span>

    <span class="c1"># Round the percentages to two decimal points</span>
    <span class="n">missing_percentage</span> <span class="o">=</span> <span class="n">missing_percentage</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>

    <span class="c1"># Sort the percentages in ascending order</span>
    <span class="n">missing_percentage</span> <span class="o">=</span> <span class="n">missing_percentage</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="c1"># Calculate the mean and standard deviation of the missingness</span>
    <span class="n">mean_missingness</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">missing_percentage</span><span class="p">)</span>
    <span class="n">std_missingness</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">missing_percentage</span><span class="p">)</span>

    <span class="c1"># Print the results</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Missing Value Percentages:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">missing_percentage</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mean ± Standard Deviation of Missingness: </span><span class="si">{:.2f}</span><span class="s2"> ± </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">mean_missingness</span><span class="p">,</span> <span class="n">std_missingness</span><span class="p">))</span>
    
    <span class="c1"># Save results to an Excel file</span>
    <span class="k">with</span> <span class="n">pd</span><span class="o">.</span><span class="n">ExcelWriter</span><span class="p">(</span><span class="n">output_file</span><span class="p">)</span> <span class="k">as</span> <span class="n">writer</span><span class="p">:</span>
        <span class="c1"># Save the missing percentage</span>
        <span class="n">missing_percentage</span><span class="o">.</span><span class="n">to_excel</span><span class="p">(</span><span class="n">writer</span><span class="p">,</span> <span class="n">sheet_name</span><span class="o">=</span><span class="s1">&#39;Missing Percentages&#39;</span><span class="p">)</span>
        
        <span class="c1"># Save mean and std as a separate sheet</span>
        <span class="n">summary_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
            <span class="s1">&#39;Mean Missingness&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">mean_missingness</span><span class="p">],</span>
            <span class="s1">&#39;Std Missingness&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">std_missingness</span><span class="p">]</span>
        <span class="p">})</span>
        <span class="n">summary_df</span><span class="o">.</span><span class="n">to_excel</span><span class="p">(</span><span class="n">writer</span><span class="p">,</span> <span class="n">sheet_name</span><span class="o">=</span><span class="s1">&#39;Summary&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">calculate_missingness</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">mydata</span><span class="p">,</span> <span class="n">output_file</span><span class="o">=</span><span class="s1">&#39;missingness_trainingset.xlsx&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">calculate_missingness</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">testset</span><span class="p">,</span> <span class="n">output_file</span><span class="o">=</span><span class="s1">&#39;missingness_testset.xlsx&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df1</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">mydata</span><span class="p">)</span>
<span class="n">df2</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">testset</span><span class="p">)</span>
<span class="k">if</span> <span class="n">external_val</span><span class="p">:</span>
    <span class="n">df3</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">extval_data</span><span class="p">)</span>
<span class="c1"># Function to create the summary table for a single dataset</span>
<span class="k">def</span> <span class="nf">create_summary_table</span><span class="p">(</span><span class="n">dataframe</span><span class="p">,</span> <span class="n">dataset_name</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Creates a summary table for a single dataset.</span>
<span class="sd">    </span>
<span class="sd">    This function generates a table that summarizes key statistics about each variable in the dataset,</span>
<span class="sd">    including numerical variables (median and quartiles) and categorical variables (categories, counts, and percentages).</span>
<span class="sd">    Additionally, it includes information on missing values and adds a column for the dataset name.</span>

<span class="sd">    ## Parameters</span>
<span class="sd">        dataframe (pd.DataFrame): The input DataFrame to generate summary statistics from.</span>
<span class="sd">        dataset_name (str): The name of the dataset being summarized.</span>

<span class="sd">    ## Returns</span>
<span class="sd">        pd.DataFrame: A new DataFrame containing the summary statistics.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">summary_data</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;Variable&#39;</span><span class="p">:</span> <span class="p">[],</span> <span class="s1">&#39;Value&#39;</span><span class="p">:</span> <span class="p">[]}</span>

    <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">dataframe</span><span class="o">.</span><span class="n">columns</span><span class="p">):</span>  <span class="c1"># Sort variable names alphabetically</span>
        <span class="n">summary_data</span><span class="p">[</span><span class="s1">&#39;Variable&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">col</span><span class="p">)</span>
        <span class="n">summary_data</span><span class="p">[</span><span class="s1">&#39;Value&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;Variable Name&#39;</span><span class="p">)</span>

        <span class="c1"># For numerical variables - Median (lower quantile, higher quantile)</span>
        <span class="k">if</span> <span class="n">pd</span><span class="o">.</span><span class="n">api</span><span class="o">.</span><span class="n">types</span><span class="o">.</span><span class="n">is_numeric_dtype</span><span class="p">(</span><span class="n">dataframe</span><span class="p">[</span><span class="n">col</span><span class="p">]):</span>
            <span class="n">median</span> <span class="o">=</span> <span class="n">dataframe</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">median</span><span class="p">()</span>
            <span class="n">q25</span> <span class="o">=</span> <span class="n">dataframe</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="mf">0.25</span><span class="p">)</span>
            <span class="n">q75</span> <span class="o">=</span> <span class="n">dataframe</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="mf">0.75</span><span class="p">)</span>
            <span class="n">summary_data</span><span class="p">[</span><span class="s1">&#39;Variable&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
            <span class="n">summary_data</span><span class="p">[</span><span class="s1">&#39;Value&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">median</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1"> (</span><span class="si">{</span><span class="n">q25</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">, </span><span class="si">{</span><span class="n">q75</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">)</span>

        <span class="c1"># For categorical variables - Categories, Counts, and Percentages</span>
        <span class="k">elif</span> <span class="n">pd</span><span class="o">.</span><span class="n">api</span><span class="o">.</span><span class="n">types</span><span class="o">.</span><span class="n">is_categorical_dtype</span><span class="p">(</span><span class="n">dataframe</span><span class="p">[</span><span class="n">col</span><span class="p">]):</span>
            <span class="n">categories</span> <span class="o">=</span> <span class="n">dataframe</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
            <span class="n">total_count</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataframe</span><span class="p">[</span><span class="n">col</span><span class="p">])</span>
            <span class="n">summary_data</span><span class="p">[</span><span class="s1">&#39;Variable&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">])</span>
            <span class="n">summary_data</span><span class="p">[</span><span class="s1">&#39;Value&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="s1">&#39;Categories&#39;</span><span class="p">,</span> <span class="s1">&#39;Counts&#39;</span><span class="p">])</span>
            
            <span class="k">for</span> <span class="n">category</span><span class="p">,</span> <span class="n">count</span> <span class="ow">in</span> <span class="n">categories</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="n">percentage</span> <span class="o">=</span> <span class="p">(</span><span class="n">count</span> <span class="o">/</span> <span class="n">total_count</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span>
                <span class="n">summary_data</span><span class="p">[</span><span class="s1">&#39;Variable&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">category</span><span class="p">)</span>
                <span class="n">summary_data</span><span class="p">[</span><span class="s1">&#39;Value&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">count</span><span class="si">}</span><span class="s1"> - </span><span class="si">{</span><span class="n">percentage</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">%&#39;</span><span class="p">)</span>

        <span class="c1"># Missing values for all variable types</span>
        <span class="n">missing_count</span> <span class="o">=</span> <span class="n">dataframe</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="n">missing_percentage</span> <span class="o">=</span> <span class="p">(</span><span class="n">missing_count</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataframe</span><span class="p">))</span> <span class="o">*</span> <span class="mi">100</span>
        <span class="n">summary_data</span><span class="p">[</span><span class="s1">&#39;Variable&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
        <span class="n">summary_data</span><span class="p">[</span><span class="s1">&#39;Value&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39; </span><span class="si">{</span><span class="n">missing_percentage</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">%&#39;</span><span class="p">)</span>

    <span class="c1"># Add a column for the dataset name</span>
    <span class="n">summary_data</span><span class="p">[</span><span class="s1">&#39;Variable&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;Dataset&#39;</span><span class="p">)</span>
    <span class="n">summary_data</span><span class="p">[</span><span class="s1">&#39;Value&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dataset_name</span><span class="p">)</span>

    <span class="n">summary_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">summary_data</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">summary_df</span>

<span class="n">summary_table1</span> <span class="o">=</span> <span class="n">create_summary_table</span><span class="p">(</span><span class="n">df1</span><span class="p">,</span> <span class="s1">&#39;training data&#39;</span><span class="p">)</span>
<span class="n">summary_table1</span><span class="o">.</span><span class="n">to_excel</span><span class="p">(</span><span class="s1">&#39;summary_table_devset.xlsx&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="k">if</span> <span class="n">data_split</span><span class="p">:</span>
    <span class="n">summary_table2</span> <span class="o">=</span> <span class="n">create_summary_table</span><span class="p">(</span><span class="n">df2</span><span class="p">,</span> <span class="s1">&#39;test data&#39;</span><span class="p">)</span>
    <span class="n">summary_table2</span><span class="o">.</span><span class="n">to_excel</span><span class="p">(</span><span class="s1">&#39;summary_table_testset.xlsx&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">if</span> <span class="n">external_val</span><span class="p">:</span>
    <span class="n">summary_table3</span> <span class="o">=</span> <span class="n">create_summary_table</span><span class="p">(</span><span class="n">df3</span><span class="p">,</span> <span class="s1">&#39;external validation data&#39;</span><span class="p">)</span>
    <span class="n">summary_table3</span><span class="o">.</span><span class="n">to_excel</span><span class="p">(</span><span class="s1">&#39;summary_table_extvalset.xlsx&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>


<span class="c1"># final summary table</span>
<span class="nb">print</span><span class="p">(</span><span class="n">summary_table1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cat_features</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># for details see https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html</span>
<span class="k">if</span> <span class="n">scale_data</span><span class="p">:</span>
    <span class="c1"># Specify the numerical features you want to scale</span>
    <span class="n">numerical_columns</span> <span class="o">=</span> <span class="n">mydata</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;float64&#39;</span><span class="p">,</span> <span class="s1">&#39;int64&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">columns</span>
    
    <span class="n">robust_scaler</span> <span class="o">=</span> <span class="n">RobustScaler</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">mydata</span><span class="p">[</span><span class="n">numerical_columns</span><span class="p">])</span> 
    
    <span class="c1"># Use the RobustScaler to scale the numerical features</span>
    <span class="n">mydata</span><span class="p">[</span><span class="n">numerical_columns</span><span class="p">]</span> <span class="o">=</span> <span class="n">robust_scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">mydata</span><span class="p">[</span><span class="n">numerical_columns</span><span class="p">])</span>
    <span class="n">testset</span><span class="p">[</span><span class="n">numerical_columns</span><span class="p">]</span> <span class="o">=</span> <span class="n">robust_scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">testset</span><span class="p">[</span><span class="n">numerical_columns</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">external_val</span><span class="p">:</span>
        <span class="n">extval_data</span><span class="p">[</span><span class="n">numerical_columns</span><span class="p">]</span> <span class="o">=</span> <span class="n">robust_scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">extval_data</span><span class="p">[</span><span class="n">numerical_columns</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="data-imputation">
<h3>Data imputation<a class="headerlink" href="#data-imputation" title="Link to this heading">#</a></h3>
<p>Here we apply k-nearest neighbors (KNN) algorithm to impute missing values in continuous variables. This is done in fold-wise as in cross validation so that the informaiton from one fold does not leak to other folds. This means that the training data is split to a number of folds as the same as in cross validation and then the imputation is performed on the fold under test, for all folds. then they are merged back to recreate the training set with imputation. The test set and external datasets are also imputed based on the KNN algorithm.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># for details see https://scikit-learn.org/stable/modules/generated/sklearn.impute.KNNImputer.html</span>

<span class="c1"># Separate features and outcome variable</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">mydata</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="n">outcome_var</span><span class="p">])</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">mydata</span><span class="p">[</span><span class="n">outcome_var</span><span class="p">]</span>

<span class="n">X_test</span> <span class="o">=</span> <span class="n">testset</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="n">outcome_var</span><span class="p">])</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">testset</span><span class="p">[</span><span class="n">outcome_var</span><span class="p">]</span>

<span class="n">numerical_columns</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;float64&#39;</span><span class="p">,</span> <span class="s1">&#39;int64&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">columns</span>
<span class="n">categorical_columns</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;category&#39;</span><span class="p">,</span><span class="s1">&#39;object&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">columns</span>

<span class="n">skf</span> <span class="o">=</span> <span class="n">StratifiedKFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="n">cv_folds</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># List to hold the imputed validation sets</span>
<span class="n">imputed_train_data</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">fold</span><span class="p">,</span> <span class="p">(</span><span class="n">train_index</span><span class="p">,</span> <span class="n">val_index</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">skf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="mi">1</span><span class="p">):</span>
    <span class="n">X_train_fold</span><span class="p">,</span> <span class="n">X_val_fold</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">X_train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">val_index</span><span class="p">]</span>
    <span class="n">y_train_fold</span><span class="p">,</span> <span class="n">y_val_fold</span> <span class="o">=</span> <span class="n">y_train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">y_train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">val_index</span><span class="p">]</span>

    <span class="c1"># Impute missing values in continuous features of X_train using KNN</span>
    <span class="n">nn</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">X_train_fold</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
    <span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">SEED</span><span class="p">)</span>
    <span class="n">cont_imputer</span> <span class="o">=</span> <span class="n">KNNImputer</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">nn</span><span class="p">,</span> <span class="n">weights</span> <span class="o">=</span> <span class="s1">&#39;distance&#39;</span><span class="p">,</span> <span class="n">keep_empty_features</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>  
    <span class="n">cont_imputer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_fold</span><span class="p">[</span><span class="n">numerical_columns</span><span class="p">])</span>  <span class="c1"># Fit the imputer on the training portion of the fold</span>

    <span class="n">X_val_fold_filled</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">cont_imputer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_val_fold</span><span class="p">[</span><span class="n">numerical_columns</span><span class="p">]),</span> <span class="n">columns</span><span class="o">=</span><span class="n">numerical_columns</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">X_val_fold</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
    
    <span class="c1"># Combine the categorical features with the imputed continuous features for the validation set</span>
    <span class="n">X_val_fold_combined</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">X_val_fold</span><span class="p">[</span><span class="n">categorical_columns</span><span class="p">],</span> <span class="n">X_val_fold_filled</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># Combine features and target for the validation fold and append to the list</span>
    <span class="n">imputed_train_data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">X_val_fold_combined</span><span class="p">,</span> <span class="n">y_val_fold</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>

<span class="n">mydata_imputed</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">imputed_train_data</span><span class="p">)</span> <span class="c1"># this is used for cross validation</span>

<span class="n">nn</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
<span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">cont_imputer</span> <span class="o">=</span> <span class="n">KNNImputer</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">weights</span> <span class="o">=</span> <span class="s1">&#39;distance&#39;</span><span class="p">,</span> <span class="n">keep_empty_features</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
<span class="n">X_train_filled</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">cont_imputer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">numerical_columns</span><span class="p">]),</span> <span class="n">columns</span><span class="o">=</span><span class="n">numerical_columns</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">X_train</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
<span class="n">mydata_imputed_nocv</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">X_train</span><span class="p">[</span><span class="n">categorical_columns</span><span class="p">],</span> <span class="n">X_train_filled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># this is used for training the model to be tested on the test set (after cross-validation)</span>

<span class="n">X_test_filled</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">cont_imputer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">[</span><span class="n">numerical_columns</span><span class="p">]),</span> <span class="n">columns</span><span class="o">=</span><span class="n">numerical_columns</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">X_test</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
<span class="c1"># Combine the categorical features with the normalized continuous features for the external validation set</span>
<span class="n">testset_imputed</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">X_test</span><span class="p">[</span><span class="n">categorical_columns</span><span class="p">],</span> <span class="n">X_test_filled</span><span class="p">,</span> <span class="n">y_test</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    

<span class="k">if</span> <span class="n">external_val</span><span class="p">:</span>
    <span class="n">X_extval_data</span> <span class="o">=</span> <span class="n">extval_data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">outcome_var</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">y_extval_data</span> <span class="o">=</span> <span class="n">extval_data</span><span class="p">[</span><span class="n">outcome_var</span><span class="p">]</span>
    <span class="n">X_extval_data_filled_cont</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">cont_imputer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_extval_data</span><span class="p">[</span><span class="n">numerical_columns</span><span class="p">]),</span> <span class="n">columns</span><span class="o">=</span><span class="n">numerical_columns</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">y_extval_data</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
    <span class="c1"># Combine the categorical features with the normalized continuous features for the external validation set</span>
    <span class="n">extval_data_imputed</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">X_extval_data</span><span class="p">[</span><span class="n">categorical_columns</span><span class="p">],</span> <span class="n">X_extval_data_filled_cont</span><span class="p">,</span> <span class="n">y_extval_data</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Reorder the rows of mydata_imputed to match the order of rows in mydata</span>
<span class="n">mydata_imputed</span> <span class="o">=</span> <span class="n">mydata_imputed</span><span class="o">.</span><span class="n">reindex</span><span class="p">(</span><span class="n">mydata</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
<span class="n">mydata_imputed_nocv</span> <span class="o">=</span> <span class="n">mydata_imputed_nocv</span><span class="o">.</span><span class="n">reindex</span><span class="p">(</span><span class="n">mydata</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mydata_imputed</span><span class="o">.</span><span class="n">dtypes</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train_imputed</span> <span class="o">=</span> <span class="n">mydata_imputed</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">outcome_var</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">X_train_imputed_nocv</span> <span class="o">=</span> <span class="n">mydata_imputed_nocv</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">outcome_var</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">X_test_imputed</span> <span class="o">=</span> <span class="n">testset_imputed</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">outcome_var</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Perform one-hot encoding</span>
<span class="k">if</span> <span class="n">external_val</span><span class="p">:</span> <span class="c1"># if there is an external validation set (in addition to the test set)</span>
    <span class="n">X_extval_data_imputed</span> <span class="o">=</span> <span class="n">extval_data_imputed</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">outcome_var</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="n">combined_imputed</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">X_train_imputed</span><span class="p">,</span> <span class="n">X_test_imputed</span><span class="p">,</span> <span class="n">X_train_imputed_nocv</span><span class="p">,</span> <span class="n">X_extval_data_imputed</span><span class="p">],</span> <span class="n">keys</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="s1">&#39;test&#39;</span><span class="p">,</span> <span class="s1">&#39;train_nocv&#39;</span><span class="p">,</span><span class="s1">&#39;ext_val&#39;</span><span class="p">])</span>
    <span class="n">combined_encoded</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">combined_imputed</span><span class="p">,</span> <span class="n">drop_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">X_train_OHE</span> <span class="o">=</span> <span class="n">combined_encoded</span><span class="o">.</span><span class="n">xs</span><span class="p">(</span><span class="s1">&#39;train&#39;</span><span class="p">)</span>
    <span class="n">X_test_OHE</span> <span class="o">=</span> <span class="n">combined_encoded</span><span class="o">.</span><span class="n">xs</span><span class="p">(</span><span class="s1">&#39;test&#39;</span><span class="p">)</span>
    <span class="n">X_train_OHE_nocv</span> <span class="o">=</span> <span class="n">combined_encoded</span><span class="o">.</span><span class="n">xs</span><span class="p">(</span><span class="s1">&#39;train_nocv&#39;</span><span class="p">)</span>
    <span class="n">X_extval_data_OHE</span> <span class="o">=</span> <span class="n">combined_encoded</span><span class="o">.</span><span class="n">xs</span><span class="p">(</span><span class="s1">&#39;ext_val&#39;</span><span class="p">)</span>
    <span class="n">extval_data_imputed_OHE</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">X_extval_data_OHE</span><span class="p">,</span> <span class="n">y_extval_data</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span> <span class="c1"># no external validation</span>
    <span class="n">combined_imputed</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">X_train_imputed</span><span class="p">,</span> <span class="n">X_test_imputed</span><span class="p">,</span> <span class="n">X_train_imputed_nocv</span><span class="p">],</span> <span class="n">keys</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="s1">&#39;test&#39;</span><span class="p">,</span> <span class="s1">&#39;train_nocv&#39;</span><span class="p">])</span>
    <span class="n">combined_encoded</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">combined_imputed</span><span class="p">,</span> <span class="n">drop_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">X_train_OHE</span> <span class="o">=</span> <span class="n">combined_encoded</span><span class="o">.</span><span class="n">xs</span><span class="p">(</span><span class="s1">&#39;train&#39;</span><span class="p">)</span>
    <span class="n">X_test_OHE</span> <span class="o">=</span> <span class="n">combined_encoded</span><span class="o">.</span><span class="n">xs</span><span class="p">(</span><span class="s1">&#39;test&#39;</span><span class="p">)</span>
    <span class="n">X_train_OHE_nocv</span> <span class="o">=</span> <span class="n">combined_encoded</span><span class="o">.</span><span class="n">xs</span><span class="p">(</span><span class="s1">&#39;train_nocv&#39;</span><span class="p">)</span>
    
<span class="n">mydata_imputed_OHE</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">X_train_OHE</span><span class="p">,</span> <span class="n">y_train</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># for cross validation - imputed on folds of the training set</span>
<span class="n">mydata_imputed_OHE_nocv</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">X_train_OHE_nocv</span><span class="p">,</span> <span class="n">y_train</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># for external validation - imputed on the entire training set</span>
<span class="n">testset_imputed_OHE</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">X_test_OHE</span><span class="p">,</span> <span class="n">y_test</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

  
<span class="c1"># Display the resulting dataframe</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X_train_OHE</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="correlation-analysis">
<h3>Correlation analysis<a class="headerlink" href="#correlation-analysis" title="Link to this heading">#</a></h3>
<p>Here we use univariable correlation based on point-biserial correlation and mutual informaiton between the variables (features) and the outcome variable. This is based on one-hot encoded and imputed data (only development/training set).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_imputed</span> <span class="o">=</span> <span class="n">mydata_imputed_OHE</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="c1"># Convert &#39;outcome_var&#39; to numerical variable</span>
<span class="n">df_imputed</span><span class="p">[</span><span class="n">outcome_var</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_imputed</span><span class="p">[</span><span class="n">outcome_var</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">({</span><span class="n">class_1</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="n">class_0</span><span class="p">:</span> <span class="mi">0</span><span class="p">})</span>

<span class="c1"># Generate 1000 subsamples of df_imputed</span>
<span class="k">def</span> <span class="nf">generate_subsample</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">seed</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Generates a subsample of the dataset using random sampling.</span>

<span class="sd">    ## Parameters</span>
<span class="sd">        df (DataFrame): Original dataset.</span>
<span class="sd">        seed (int): Random seed for sampling.</span>

<span class="sd">    ## Returns</span>
<span class="sd">        DataFrame: Subsample of the dataset.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>  <span class="c1"># Set the random state</span>
    <span class="k">return</span> <span class="n">df</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">frac</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span>

<span class="c1"># Calculate point biserial correlation for each variable against the target</span>
<span class="k">def</span> <span class="nf">calculate_biserial_corr</span><span class="p">(</span><span class="n">subsample</span><span class="p">,</span> <span class="n">outcome_var</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculates point-biserial correlation for each variable in the subsample against the target.</span>

<span class="sd">    ## Parameters</span>
<span class="sd">        subsample (DataFrame): Subsample of the dataset.</span>
<span class="sd">        outcome_var (str): Name of the target variable.</span>

<span class="sd">    ## Returns</span>
<span class="sd">        corr_values (dict): Dictionary containing correlation values for each variable.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">corr_values</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">subsample</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">col</span> <span class="o">!=</span> <span class="n">outcome_var</span><span class="p">:</span>
            <span class="n">corr_values</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="n">pointbiserialr</span><span class="p">(</span><span class="n">subsample</span><span class="p">[</span><span class="n">col</span><span class="p">],</span> <span class="n">subsample</span><span class="p">[</span><span class="n">outcome_var</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">corr_values</span>

<span class="c1"># Generate subsamples in parallel</span>
<span class="n">num_iterations</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">seeds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10000</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">num_iterations</span><span class="p">)</span>  <span class="c1"># Generate unique seeds for each iteration</span>

<span class="n">subsamples</span> <span class="o">=</span> <span class="n">Parallel</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=</span><span class="n">n_cpu_model_training</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="s1">&#39;loky&#39;</span><span class="p">)(</span>
    <span class="n">delayed</span><span class="p">(</span><span class="n">generate_subsample</span><span class="p">)(</span><span class="n">df_imputed</span><span class="p">,</span> <span class="n">seed</span><span class="p">)</span> <span class="k">for</span> <span class="n">seed</span> <span class="ow">in</span> <span class="n">seeds</span>
<span class="p">)</span>

<span class="c1"># Calculate point biserial correlation for each subsample</span>
<span class="n">biserial_corr_values</span> <span class="o">=</span> <span class="n">Parallel</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=</span><span class="n">n_cpu_model_training</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="s1">&#39;loky&#39;</span><span class="p">)(</span>
    <span class="n">delayed</span><span class="p">(</span><span class="n">calculate_biserial_corr</span><span class="p">)(</span><span class="n">subsample</span><span class="p">,</span> <span class="n">outcome_var</span><span class="p">)</span> <span class="k">for</span> <span class="n">subsample</span> <span class="ow">in</span> <span class="n">subsamples</span>
<span class="p">)</span>

<span class="n">corr_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">biserial_corr_values</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Calculate the lower and upper quantiles of point-biserial correlation for each feature</span>


<span class="c1"># Calculate lower quartile (25th percentile) excluding NaN values</span>
<span class="n">lower_quantile_corr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nanpercentile</span><span class="p">(</span><span class="n">corr_df</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Calculate median (50th percentile) excluding NaN values</span>
<span class="n">median_corr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nanpercentile</span><span class="p">(</span><span class="n">corr_df</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Calculate upper quartile (75th percentile) excluding NaN values</span>
<span class="n">upper_quantile_corr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nanpercentile</span><span class="p">(</span><span class="n">corr_df</span><span class="p">,</span> <span class="mi">75</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Filter features based on quantiles</span>
<span class="n">significant_features</span> <span class="o">=</span> <span class="p">[</span><span class="n">feature</span> <span class="k">for</span> <span class="n">feature</span><span class="p">,</span> <span class="n">lower</span><span class="p">,</span> <span class="n">upper</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">corr_df</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">lower_quantile_corr</span><span class="p">,</span> <span class="n">upper_quantile_corr</span><span class="p">)</span> <span class="k">if</span> <span class="n">lower</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">upper</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">]</span>

<span class="c1"># Filter the original dataframe to include only significant features</span>
<span class="n">df_imputed_filtered</span> <span class="o">=</span> <span class="n">df_imputed</span><span class="p">[</span><span class="n">significant_features</span><span class="p">]</span>

<span class="c1"># Create a DataFrame with feature names, lower and upper quantiles of point-biserial correlation</span>
<span class="n">corr_summary_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;Feature&#39;</span><span class="p">:</span> <span class="n">df_imputed</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">outcome_var</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span>
                                <span class="s1">&#39;median_Corr&#39;</span><span class="p">:</span> <span class="n">median_corr</span><span class="p">,</span>
                                <span class="s1">&#39;Lower_Quantile_Corr&#39;</span><span class="p">:</span> <span class="n">lower_quantile_corr</span><span class="p">,</span>
                                <span class="s1">&#39;Upper_Quantile_Corr&#39;</span><span class="p">:</span> <span class="n">upper_quantile_corr</span><span class="p">})</span>
<span class="n">corr_summary_df</span>
<span class="n">corr_summary_df</span><span class="o">.</span><span class="n">to_excel</span><span class="p">(</span><span class="s1">&#39;pb_corr_summary_df.xlsx&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Sort DataFrame by median correlation for better visualization</span>
<span class="n">corr_summary_df</span> <span class="o">=</span> <span class="n">corr_summary_df</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s1">&#39;median_Corr&#39;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="c1"># corr_summary_df = corr_summary_df[~(corr_summary_df[&quot;median_Corr&quot;] == 0) &amp; ~(corr_summary_df[&quot;median_Corr&quot;].isna())]</span>

<span class="n">num_rows</span> <span class="o">=</span> <span class="n">corr_summary_df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="c1"># Set the fixed width</span>
<span class="n">width</span> <span class="o">=</span> <span class="mi">6</span>
<span class="c1"># Calculate the height based on the number of rows</span>
<span class="n">height</span> <span class="o">=</span> <span class="n">num_rows</span> <span class="o">/</span> <span class="mi">5</span>  <span class="c1"># Assuming each row takes about 0.2 inches</span>
<span class="c1"># Ensure height does not exceed the maximum allowed dimension</span>
<span class="n">max_height</span> <span class="o">=</span> <span class="mi">65535</span> <span class="o">/</span> <span class="mi">72</span>  <span class="c1"># Convert pixels to inches</span>
<span class="k">if</span> <span class="n">height</span> <span class="o">&gt;</span> <span class="n">max_height</span><span class="p">:</span>
    <span class="n">height</span> <span class="o">=</span> <span class="n">max_height</span>
<span class="c1"># Set the figure size</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="n">width</span><span class="p">,</span> <span class="n">height</span><span class="p">))</span>
<span class="c1"># Plot error bars for all features</span>
<span class="n">plt</span><span class="o">.</span><span class="n">errorbar</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">corr_summary_df</span><span class="p">[</span><span class="s1">&#39;median_Corr&#39;</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">corr_summary_df</span><span class="p">[</span><span class="s1">&#39;Feature&#39;</span><span class="p">],</span>
             <span class="n">xerr</span><span class="o">=</span><span class="p">[</span><span class="n">corr_summary_df</span><span class="p">[</span><span class="s1">&#39;median_Corr&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">corr_summary_df</span><span class="p">[</span><span class="s1">&#39;Lower_Quantile_Corr&#39;</span><span class="p">],</span> 
                   <span class="n">corr_summary_df</span><span class="p">[</span><span class="s1">&#39;Upper_Quantile_Corr&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">corr_summary_df</span><span class="p">[</span><span class="s1">&#39;median_Corr&#39;</span><span class="p">]],</span>
             <span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">capsize</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;IQR&#39;</span><span class="p">)</span>

<span class="c1"># Add a vertical dotted line at x=0</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;grey&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Median and quantile correlation coefficients for features</span><span class="se">\n</span><span class="s1">based on random subsamples of the development set</span><span class="se">\n</span><span class="s1">with replication across 1000 iterations&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;PB Correlation Values&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Feature&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span> 
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;both&#39;</span><span class="p">,</span> <span class="n">labelsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span> 
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="s2">&quot;medium&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">set_facecolor</span><span class="p">(</span><span class="s1">&#39;white&#39;</span><span class="p">)</span>
<span class="c1"># display grid lines</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">&#39;both&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;grey&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">&#39;minor&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">&#39;major&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;font.family&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;sans-serif&#39;</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;font.size&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s2">&quot;pointbiserial.tif&quot;</span><span class="p">,</span> <span class="n">bbox_inches</span><span class="o">=</span><span class="s1">&#39;tight&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">significant_features</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_imputed</span> <span class="o">=</span> <span class="n">mydata_imputed_OHE</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="c1"># Convert &#39;outcome_var&#39; to numerical variable</span>
<span class="n">df_imputed</span><span class="p">[</span><span class="n">outcome_var</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_imputed</span><span class="p">[</span><span class="n">outcome_var</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">({</span><span class="n">class_1</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="n">class_0</span><span class="p">:</span> <span class="mi">0</span><span class="p">})</span>

<span class="c1"># Calculate mutual information for each variable against the target</span>
<span class="k">def</span> <span class="nf">calculate_mutual_info</span><span class="p">(</span><span class="n">subsample</span><span class="p">,</span> <span class="n">outcome_var</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculates mutual information between each feature in the subsample and the target variable.</span>

<span class="sd">    ## Parameters</span>
<span class="sd">        subsample (DataFrame): Subsample of the dataset.</span>
<span class="sd">        outcome_var (str): Name of the target variable.</span>

<span class="sd">    ## Returns</span>
<span class="sd">        mi_values (dict): Dictionary containing mutual information values for each feature.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">mi_values</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">subsample</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">col</span> <span class="o">!=</span> <span class="n">outcome_var</span><span class="p">:</span>
            <span class="n">mi_values</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="n">mutual_info_classif</span><span class="p">(</span><span class="n">subsample</span><span class="p">[[</span><span class="n">col</span><span class="p">]],</span> <span class="n">subsample</span><span class="p">[</span><span class="n">outcome_var</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">mi_values</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">num_iterations</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">seeds</span> <span class="o">=</span> <span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10000</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">num_iterations</span><span class="p">)</span>  <span class="c1"># Generate unique seeds for each iteration</span>

<span class="n">subsamples</span> <span class="o">=</span> <span class="n">Parallel</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=</span><span class="n">n_cpu_model_training</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="s1">&#39;loky&#39;</span><span class="p">)(</span>
    <span class="n">delayed</span><span class="p">(</span><span class="n">generate_subsample</span><span class="p">)(</span><span class="n">df_imputed</span><span class="p">,</span> <span class="n">seed</span><span class="p">)</span> <span class="k">for</span> <span class="n">seed</span> <span class="ow">in</span> <span class="n">seeds</span>
<span class="p">)</span>

<span class="n">mi_values</span> <span class="o">=</span> <span class="n">Parallel</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=</span><span class="n">n_cpu_model_training</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="s1">&#39;loky&#39;</span><span class="p">)(</span>
    <span class="n">delayed</span><span class="p">(</span><span class="n">calculate_mutual_info</span><span class="p">)(</span><span class="n">subsample</span><span class="p">,</span> <span class="n">outcome_var</span><span class="p">)</span> <span class="k">for</span> <span class="n">subsample</span> <span class="ow">in</span> <span class="n">subsamples</span>
<span class="p">)</span>

<span class="n">mi_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">mi_values</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Calculate the lower and upper quantiles of point-biserial correlation for each feature</span>
<span class="n">lower_quantile_mi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">mi_df</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">median_mi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">mi_df</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">upper_quantile_mi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">mi_df</span><span class="p">,</span> <span class="mi">75</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Filter features based on quantiles</span>
<span class="n">significant_features</span> <span class="o">=</span> <span class="p">[</span><span class="n">feature</span> <span class="k">for</span> <span class="n">feature</span><span class="p">,</span> <span class="n">lower</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">mi_df</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">lower_quantile_mi</span><span class="p">)</span> <span class="k">if</span> <span class="n">lower</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">]</span>

<span class="c1"># Filter the original dataframe to include only significant features</span>
<span class="n">df_imputed_filtered</span> <span class="o">=</span> <span class="n">df_imputed</span><span class="p">[</span><span class="n">significant_features</span><span class="p">]</span>

<span class="c1"># Create a dataframe with feature names, lower and upper quantiles of point-biserial correlation</span>
<span class="n">mi_summary_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;Feature&#39;</span><span class="p">:</span> <span class="n">df_imputed</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">outcome_var</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span>
                                <span class="s1">&#39;median_MI&#39;</span><span class="p">:</span> <span class="n">median_mi</span><span class="p">,</span>
                                <span class="s1">&#39;Lower_Quantile_MI&#39;</span><span class="p">:</span> <span class="n">lower_quantile_mi</span><span class="p">,</span>
                                <span class="s1">&#39;Upper_Quantile_MI&#39;</span><span class="p">:</span> <span class="n">upper_quantile_mi</span><span class="p">})</span>
<span class="n">mi_summary_df</span>
<span class="n">mi_summary_df</span><span class="o">.</span><span class="n">to_excel</span><span class="p">(</span><span class="s1">&#39;mi_summary_df.xlsx&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Mark significant features with a different color</span>
<span class="n">mi_summary_df</span><span class="p">[</span><span class="s1">&#39;Color&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">mi_summary_df</span><span class="p">[</span><span class="s1">&#39;Feature&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">significant_features</span><span class="p">),</span> <span class="s1">&#39;significant&#39;</span><span class="p">,</span> <span class="s1">&#39;not significant&#39;</span><span class="p">)</span>

<span class="c1"># Sort dataframe by median correlation for better visualization</span>
<span class="n">mi_summary_df</span> <span class="o">=</span> <span class="n">mi_summary_df</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s1">&#39;median_MI&#39;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Plotting</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="n">width</span><span class="p">,</span> <span class="n">height</span><span class="p">))</span>

<span class="c1"># Plot error bars for all features</span>
<span class="n">plt</span><span class="o">.</span><span class="n">errorbar</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">mi_summary_df</span><span class="p">[</span><span class="s1">&#39;median_MI&#39;</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">mi_summary_df</span><span class="p">[</span><span class="s1">&#39;Feature&#39;</span><span class="p">],</span>
             <span class="n">xerr</span><span class="o">=</span><span class="p">[</span><span class="n">mi_summary_df</span><span class="p">[</span><span class="s1">&#39;median_MI&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">mi_summary_df</span><span class="p">[</span><span class="s1">&#39;Lower_Quantile_MI&#39;</span><span class="p">],</span> 
                   <span class="n">mi_summary_df</span><span class="p">[</span><span class="s1">&#39;Upper_Quantile_MI&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">mi_summary_df</span><span class="p">[</span><span class="s1">&#39;median_MI&#39;</span><span class="p">]],</span>
             <span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">capsize</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;IQR&#39;</span><span class="p">)</span>

<span class="c1"># Add a vertical dotted line at x=0</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;grey&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Median and quantile mutual informaiton for features</span><span class="se">\n</span><span class="s1">based on random subsamples of the development set</span><span class="se">\n</span><span class="s1">with replication across 1000 iterations&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;mutual information&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Feature&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span> 
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;both&#39;</span><span class="p">,</span> <span class="n">labelsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span> 
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="s2">&quot;medium&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">set_facecolor</span><span class="p">(</span><span class="s1">&#39;white&#39;</span><span class="p">)</span>
<span class="c1"># display grid lines</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">&#39;both&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;grey&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">&#39;minor&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">&#39;major&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;font.family&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;sans-serif&#39;</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;font.size&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s2">&quot;mutual_information.tif&quot;</span><span class="p">,</span> <span class="n">bbox_inches</span><span class="o">=</span><span class="s1">&#39;tight&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mydata</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
</div>
<section id="checking-the-outcome-variable-and-its-categories-binary">
<h4>Checking the outcome variable and its categories (binary)<a class="headerlink" href="#checking-the-outcome-variable-and-its-categories-binary" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">mydata</span><span class="p">[</span><span class="n">outcome_var</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">mydata_imputed</span><span class="p">[</span><span class="n">outcome_var</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">mydata_imputed_OHE</span><span class="p">[</span><span class="n">outcome_var</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">mydata_imputed_nocv</span><span class="p">[</span><span class="n">outcome_var</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">mydata_imputed_OHE_nocv</span><span class="p">[</span><span class="n">outcome_var</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mydata</span><span class="p">[</span><span class="n">outcome_var</span><span class="p">]</span> <span class="o">=</span> <span class="n">mydata</span><span class="p">[</span><span class="n">outcome_var</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">({</span><span class="n">class_0</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span> <span class="n">class_1</span><span class="p">:</span> <span class="kc">True</span><span class="p">})</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">bool</span><span class="p">)</span>
<span class="n">mydata_imputed</span><span class="p">[</span><span class="n">outcome_var</span><span class="p">]</span> <span class="o">=</span> <span class="n">mydata_imputed</span><span class="p">[</span><span class="n">outcome_var</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">({</span><span class="n">class_0</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span> <span class="n">class_1</span><span class="p">:</span> <span class="kc">True</span><span class="p">})</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">bool</span><span class="p">)</span>
<span class="n">mydata_imputed_nocv</span><span class="p">[</span><span class="n">outcome_var</span><span class="p">]</span> <span class="o">=</span> <span class="n">mydata_imputed_nocv</span><span class="p">[</span><span class="n">outcome_var</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">({</span><span class="n">class_0</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span> <span class="n">class_1</span><span class="p">:</span> <span class="kc">True</span><span class="p">})</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">bool</span><span class="p">)</span>
<span class="n">mydata_imputed_OHE</span><span class="p">[</span><span class="n">outcome_var</span><span class="p">]</span> <span class="o">=</span> <span class="n">mydata_imputed_OHE</span><span class="p">[</span><span class="n">outcome_var</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">({</span><span class="n">class_0</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span> <span class="n">class_1</span><span class="p">:</span> <span class="kc">True</span><span class="p">})</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">bool</span><span class="p">)</span>
<span class="n">mydata_imputed_OHE_nocv</span><span class="p">[</span><span class="n">outcome_var</span><span class="p">]</span> <span class="o">=</span> <span class="n">mydata_imputed_OHE_nocv</span><span class="p">[</span><span class="n">outcome_var</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">({</span><span class="n">class_0</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span> <span class="n">class_1</span><span class="p">:</span> <span class="kc">True</span><span class="p">})</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">bool</span><span class="p">)</span>
<span class="n">testset_imputed</span><span class="p">[</span><span class="n">outcome_var</span><span class="p">]</span> <span class="o">=</span> <span class="n">testset_imputed</span><span class="p">[</span><span class="n">outcome_var</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">({</span><span class="n">class_0</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span> <span class="n">class_1</span><span class="p">:</span> <span class="kc">True</span><span class="p">})</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">bool</span><span class="p">)</span>
<span class="k">if</span> <span class="n">external_val</span><span class="p">:</span>
    <span class="n">extval_data_imputed</span><span class="p">[</span><span class="n">outcome_var</span><span class="p">]</span> <span class="o">=</span> <span class="n">extval_data_imputed</span><span class="p">[</span><span class="n">outcome_var</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">({</span><span class="n">class_0</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span> <span class="n">class_1</span><span class="p">:</span> <span class="kc">True</span><span class="p">})</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">bool</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">mydata</span><span class="p">[</span><span class="n">outcome_var</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">mydata_imputed</span><span class="p">[</span><span class="n">outcome_var</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">mydata_imputed_OHE</span><span class="p">[</span><span class="n">outcome_var</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">mydata_imputed_nocv</span><span class="p">[</span><span class="n">outcome_var</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">mydata_imputed_OHE_nocv</span><span class="p">[</span><span class="n">outcome_var</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mydata</span><span class="o">.</span><span class="n">dtypes</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="data-visualization">
<h3>Data visualization<a class="headerlink" href="#data-visualization" title="Link to this heading">#</a></h3>
<p>Here we plot all variables of the dataset both categorical and numerical ones in box plots that represents the distributions of the variables. Here you can inspect if there is any outlier or data anomally (e.g., values outside range).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Select continuous variables from the dataframe</span>
<span class="n">continuous_vars</span> <span class="o">=</span> <span class="n">mydata_imputed</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;float64&#39;</span><span class="p">,</span> <span class="s1">&#39;int64&#39;</span><span class="p">])</span>
<span class="c1"># select categorical variables</span>
<span class="n">categorical_vars</span> <span class="o">=</span> <span class="n">mydata_imputed</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;category&#39;</span><span class="p">,</span><span class="s2">&quot;object&quot;</span><span class="p">,</span><span class="s2">&quot;bool&quot;</span><span class="p">])</span>
<span class="c1"># get a copy of the outcome variable</span>
<span class="n">outcome_variable</span> <span class="o">=</span> <span class="n">mydata_imputed</span><span class="p">[</span><span class="n">outcome_var</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

<span class="c1"># Calculate the number of rows and columns for subplots</span>
<span class="n">num_continuous_vars</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">continuous_vars</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
<span class="n">num_categorical_vars</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">categorical_vars</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
<span class="n">num_cols_to_plot</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">num_rows</span> <span class="o">=</span> <span class="p">(</span><span class="n">num_continuous_vars</span> <span class="o">+</span> <span class="n">num_categorical_vars</span> <span class="o">+</span> <span class="n">num_cols_to_plot</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="n">num_cols_to_plot</span> <span class="o">+</span> <span class="mi">1</span>  <span class="c1"># Adjust the number of rows based on the number of variables</span>

<span class="n">mapping</span> <span class="o">=</span> <span class="p">{</span><span class="kc">True</span><span class="p">:</span> <span class="n">class_1</span><span class="p">,</span> <span class="kc">False</span><span class="p">:</span> <span class="n">class_0</span><span class="p">}</span>
<span class="n">outcome_variable_mapped</span> <span class="o">=</span> <span class="n">outcome_variable</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">mapping</span><span class="p">)</span>

<span class="c1"># Create subplots for continuous variables</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">num_rows</span><span class="p">,</span> <span class="n">num_cols_to_plot</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="n">num_rows</span> <span class="o">*</span> <span class="mi">2</span><span class="p">))</span> 

<span class="c1"># Iterate over continuous variables</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">column</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">continuous_vars</span><span class="o">.</span><span class="n">columns</span><span class="p">):</span>
    <span class="c1"># Determine the subplot indices</span>
    <span class="n">row_idx</span> <span class="o">=</span> <span class="n">i</span> <span class="o">//</span> <span class="n">num_cols_to_plot</span>
    <span class="n">col_idx</span> <span class="o">=</span> <span class="n">i</span> <span class="o">%</span> <span class="n">num_cols_to_plot</span>

    <span class="c1"># Check if subplot index is within the bounds of axes</span>
    <span class="k">if</span> <span class="n">row_idx</span> <span class="o">&lt;</span> <span class="n">num_rows</span><span class="p">:</span>
        <span class="c1"># Get the axis for the current subplot</span>
        <span class="n">ax</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="n">row_idx</span><span class="p">,</span> <span class="n">col_idx</span><span class="p">]</span>

        <span class="c1"># Iterate over each outcome category</span>
        <span class="k">for</span> <span class="n">outcome_category</span><span class="p">,</span> <span class="n">ax_offset</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">outcome_variable</span><span class="o">.</span><span class="n">unique</span><span class="p">(),</span> <span class="p">[</span><span class="o">-</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">]):</span>
            <span class="c1"># Filter the data for the current outcome category</span>
            <span class="n">filtered_data</span> <span class="o">=</span> <span class="n">continuous_vars</span><span class="p">[</span><span class="n">outcome_variable</span> <span class="o">==</span> <span class="n">outcome_category</span><span class="p">][</span><span class="n">column</span><span class="p">]</span>

            <span class="c1"># Create a box plot for the current outcome category</span>
            <span class="n">positions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span> <span class="o">+</span> <span class="n">ax_offset</span><span class="p">])</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">filtered_data</span><span class="o">.</span><span class="n">dropna</span><span class="p">(),</span> <span class="n">positions</span><span class="o">=</span><span class="n">positions</span><span class="p">,</span> <span class="n">widths</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">vert</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>  <span class="c1"># Vert=False for horizontal box plots</span>

        <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">column</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">([</span><span class="mi">1</span> <span class="o">-</span> <span class="n">ax_offset</span><span class="p">,</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">ax_offset</span><span class="p">])</span>
        <span class="c1"># ax.set_yticklabels(outcome_variable.unique(), fontsize=8)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">(</span><span class="n">outcome_variable_mapped</span><span class="o">.</span><span class="n">unique</span><span class="p">(),</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;both&#39;</span><span class="p">,</span> <span class="n">labelsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="s2">&quot;medium&quot;</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_facecolor</span><span class="p">(</span><span class="s1">&#39;white&#39;</span><span class="p">)</span>
        
        <span class="c1"># show both grid lines</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">&#39;both&#39;</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s2">&quot;grey&quot;</span><span class="p">)</span>

        <span class="c1"># modify grid lines:</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">&#39;minor&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">&#39;major&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>

<span class="c1"># Iterate over categorical variables</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">column</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">categorical_vars</span><span class="o">.</span><span class="n">columns</span><span class="p">):</span>
    <span class="c1"># Determine the subplot indices</span>
    <span class="n">row_idx</span> <span class="o">=</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="n">num_continuous_vars</span><span class="p">)</span> <span class="o">//</span> <span class="n">num_cols_to_plot</span>
    <span class="n">col_idx</span> <span class="o">=</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="n">num_continuous_vars</span><span class="p">)</span> <span class="o">%</span> <span class="n">num_cols_to_plot</span>

    <span class="c1"># Check if subplot index is within the bounds of axes</span>
    <span class="k">if</span> <span class="n">row_idx</span> <span class="o">&lt;</span> <span class="n">num_rows</span><span class="p">:</span>
        <span class="c1"># Get the axis for the current subplot</span>
        <span class="n">ax</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="n">row_idx</span><span class="p">,</span> <span class="n">col_idx</span><span class="p">]</span>

        <span class="c1"># Normalize the counts for the current categorical variable stratified by outcome variable</span>
        <span class="n">category_counts</span> <span class="o">=</span> <span class="n">categorical_vars</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">outcome_variable</span><span class="p">)[</span><span class="n">column</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">unstack</span><span class="p">()</span>
        <span class="n">category_counts</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">&#39;barh&#39;</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>

        <span class="c1"># Set the title with the feature name</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">column</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">(</span><span class="n">outcome_variable_mapped</span><span class="o">.</span><span class="n">unique</span><span class="p">(),</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;both&#39;</span><span class="p">,</span> <span class="n">labelsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="s2">&quot;medium&quot;</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_facecolor</span><span class="p">(</span><span class="s1">&#39;white&#39;</span><span class="p">)</span>
        
        <span class="c1"># display grid lines</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">&#39;both&#39;</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s2">&quot;grey&quot;</span><span class="p">)</span>

        <span class="c1"># modify grid lines</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">&#39;minor&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">&#39;major&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>

<span class="c1"># Remove any empty subplots at the end</span>
<span class="k">if</span> <span class="n">num_continuous_vars</span> <span class="o">+</span> <span class="n">num_categorical_vars</span> <span class="o">&lt;</span> <span class="n">num_rows</span> <span class="o">*</span> <span class="n">num_cols_to_plot</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_continuous_vars</span> <span class="o">+</span> <span class="n">num_categorical_vars</span><span class="p">,</span> <span class="n">num_rows</span> <span class="o">*</span> <span class="n">num_cols_to_plot</span><span class="p">):</span>
        <span class="n">fig</span><span class="o">.</span><span class="n">delaxes</span><span class="p">(</span><span class="n">axes</span><span class="o">.</span><span class="n">flatten</span><span class="p">()[</span><span class="n">i</span><span class="p">])</span>

<span class="c1"># Remove the subplot for outcome_var at the end</span>
<span class="n">last_ax_index</span> <span class="o">=</span> <span class="n">num_continuous_vars</span> <span class="o">+</span> <span class="n">num_categorical_vars</span> <span class="o">-</span> <span class="mi">1</span>
<span class="n">fig</span><span class="o">.</span><span class="n">delaxes</span><span class="p">(</span><span class="n">axes</span><span class="o">.</span><span class="n">flatten</span><span class="p">()[</span><span class="n">last_ax_index</span><span class="p">])</span>

<span class="c1"># Adjust the layout and spacing</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;font.family&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;sans-serif&#39;</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;font.size&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s2">&quot;data_distribution.tif&quot;</span><span class="p">,</span> <span class="n">bbox_inches</span><span class="o">=</span><span class="s1">&#39;tight&#39;</span><span class="p">)</span>

<span class="c1"># Show the plot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Count the number of samples per class in devset</span>
<span class="n">ymap</span> <span class="o">=</span> <span class="p">{</span><span class="kc">True</span><span class="p">:</span> <span class="n">class_1</span><span class="p">,</span> <span class="kc">False</span><span class="p">:</span> <span class="n">class_0</span><span class="p">}</span>
<span class="n">mydata_class_counts</span> <span class="o">=</span> <span class="n">mydata</span><span class="p">[</span><span class="n">outcome_var</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">ymap</span><span class="p">)</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>

<span class="c1"># Calculate the percentage of samples per class in devset</span>
<span class="n">mydata_class_percentages</span> <span class="o">=</span> <span class="p">(</span><span class="n">mydata_class_counts</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">mydata</span><span class="p">))</span> <span class="o">*</span> <span class="mi">100</span>

<span class="c1"># Count the number of samples per class in testset</span>
<span class="n">testset_class_counts</span> <span class="o">=</span> <span class="n">testset</span><span class="p">[</span><span class="n">outcome_var</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>

<span class="c1"># Calculate the percentage of samples per class in testset</span>
<span class="n">testset_class_percentages</span> <span class="o">=</span> <span class="p">(</span><span class="n">testset_class_counts</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">testset</span><span class="p">))</span> <span class="o">*</span> <span class="mi">100</span>

<span class="c1"># summary of the number of samples per class and their percentages</span>
<span class="k">if</span> <span class="n">data_split</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;training set:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">mydata_class_counts</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">mydata_class_percentages</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Test Set:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">testset_class_counts</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">testset_class_percentages</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;whole dataset:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">mydata_class_counts</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">mydata_class_percentages</span><span class="p">)</span>

<span class="k">if</span> <span class="n">external_val</span><span class="p">:</span>
    <span class="c1"># Count the number of samples per class in extval_data</span>
    <span class="n">extval_data_class_counts</span> <span class="o">=</span> <span class="n">extval_data</span><span class="p">[</span><span class="n">outcome_var</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>

    <span class="c1"># Calculate the percentage of samples per class in extval_data</span>
    <span class="n">extval_data_class_percentages</span> <span class="o">=</span> <span class="p">(</span><span class="n">extval_data_class_counts</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">extval_data</span><span class="p">))</span> <span class="o">*</span> <span class="mi">100</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">External validation set:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">extval_data_class_counts</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">extval_data_class_percentages</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<section id="function-to-evaluate-models-and-generate-roc-curve-pr-curve-and-confusion-matrix">
<h4>Function to evaluate models and generate ROC curve, PR curve and confusion matrix<a class="headerlink" href="#function-to-evaluate-models-and-generate-roc-curve-pr-curve-and-confusion-matrix" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define a function for bootstrap sampling</span>
<span class="k">def</span> <span class="nf">bootstrap_sample</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Perform bootstrap sampling on the input data.</span>

<span class="sd">    ## Parameters:</span>
<span class="sd">    - data (array-like): Input data to be sampled.</span>
<span class="sd">    - n_samples (int): Number of samples to generate.</span>

<span class="sd">    ## Returns</span>
<span class="sd">    - indices (numpy array): Indices of the original data used for bootstrapping.</span>
<span class="sd">    - resampled_data (array-like): Resampled data with shape (n_samples, len(data)).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">SEED</span><span class="p">)</span>
    <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)))</span>
    <span class="k">return</span> <span class="n">data</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>

<span class="k">def</span> <span class="nf">calculate_confidence_interval</span><span class="p">(</span><span class="n">metric_values</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.95</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate the confidence interval for the given metric values.</span>

<span class="sd">    ## Parameters:</span>
<span class="sd">    - metric_values (array-like): Input metric values.</span>
<span class="sd">    - alpha (float, optional): Confidence level. Defaults to 0.95.</span>

<span class="sd">    ## Returns</span>
<span class="sd">    - lower_bound (float or numpy array): Lower bound of the confidence interval.</span>
<span class="sd">    - upper_bound (float or numpy array): Upper bound of the confidence interval.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Filter out NaN values from metric_values</span>
    <span class="n">non_nan_values</span> <span class="o">=</span> <span class="n">metric_values</span><span class="p">[</span><span class="o">~</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">metric_values</span><span class="p">)]</span>
    
    <span class="c1"># Check if there are non-NaN values to calculate the confidence interval</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">non_nan_values</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
    
    <span class="c1"># Calculate confidence intervals for non-NaN values</span>
    <span class="n">lower_bound</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">non_nan_values</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span> <span class="o">*</span> <span class="mi">100</span><span class="p">)</span>
    <span class="n">upper_bound</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">non_nan_values</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span> <span class="o">*</span> <span class="mi">100</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">lower_bound</span><span class="p">,</span> <span class="n">upper_bound</span>

<span class="k">def</span> <span class="nf">evaluate_and_plot_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">testset</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">filename</span><span class="p">,</span> <span class="n">class_labels</span> <span class="o">=</span> <span class="n">class_labels_display</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">bootstrap_samples</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">min_positive_instances</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculates and visualizes model performance using ROC curve, PR curve, and confusion matrix.</span>
<span class="sd">    </span>
<span class="sd">    ## Parameters</span>
<span class="sd">        y_test (np.ndarray): Ground truth labels for the test dataset.</span>
<span class="sd">        predictions_class (np.ndarray): Predicted labels for the test dataset.</span>
<span class="sd">        class_labels_display (list or tuple): List of unique class labels in the data for display purposes.</span>
<span class="sd">        threshold (float): Threshold value for model evaluation.</span>
<span class="sd">        filename (str): Output file name for visualization.</span>

<span class="sd">    ## Returns</span>
<span class="sd">        results_df (DataFrame): DataFrame containing model performance metrics.</span>
<span class="sd">        missclassified_samples (list): List of indices of samples that were misclassified by the model.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">bootstrap_values</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">bootstrap_samples</span><span class="p">):</span>
        <span class="c1"># Perform bootstrap sampling</span>
        <span class="n">bootstrap_sample_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">testset</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">testset</span><span class="p">),</span> <span class="n">replace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">bootstrap_sample_testset</span> <span class="o">=</span> <span class="n">testset</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">bootstrap_sample_indices</span><span class="p">]</span>
        <span class="n">bootstrap_sample_y_test</span> <span class="o">=</span> <span class="n">y_test</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">bootstrap_sample_indices</span><span class="p">]</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="p">(</span><span class="n">cb</span><span class="o">.</span><span class="n">CatBoostClassifier</span><span class="p">,</span> <span class="n">lgb</span><span class="o">.</span><span class="n">LGBMClassifier</span><span class="p">,</span> <span class="n">GaussianNB</span><span class="p">,</span><span class="n">RandomForestClassifier</span><span class="p">,</span> <span class="n">LogisticRegression</span><span class="p">,</span> <span class="n">RandomForestClassifier</span><span class="p">,</span> <span class="n">HistGradientBoostingClassifier</span><span class="p">)):</span>
            <span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">bootstrap_sample_testset</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
            <span class="c1"># print(predictions)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">bootstrap_sample_testset</span><span class="p">)</span>

        <span class="n">predictions_class</span> <span class="o">=</span> <span class="p">[</span><span class="kc">True</span> <span class="k">if</span> <span class="n">x</span> <span class="o">&gt;=</span> <span class="n">threshold</span> <span class="k">else</span> <span class="kc">False</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">predictions</span><span class="p">]</span>

        <span class="c1"># Check if the number of positive instances is below the threshold</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">bootstrap_sample_y_test</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">min_positive_instances</span><span class="p">:</span>
            <span class="c1"># Set metrics to NaN or another suitable value</span>
            <span class="n">PPV</span><span class="p">,</span> <span class="n">NPV</span><span class="p">,</span> <span class="n">sensitivity</span><span class="p">,</span> <span class="n">specificity</span><span class="p">,</span> <span class="n">balanced_accuracy</span><span class="p">,</span> <span class="n">MCC</span><span class="p">,</span> <span class="n">roc_auc</span><span class="p">,</span> <span class="n">pr_auc</span><span class="p">,</span> <span class="n">brier_score</span><span class="p">,</span> <span class="n">f1</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">]</span> <span class="o">*</span> <span class="mi">10</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">bootstrap_sample_y_test</span><span class="p">,</span> <span class="n">predictions_class</span><span class="p">)</span>
            <span class="n">tn</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">fn</span><span class="p">,</span> <span class="n">tp</span> <span class="o">=</span> <span class="n">cm</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>

            <span class="n">PPV</span> <span class="o">=</span> <span class="n">tp</span> <span class="o">/</span> <span class="p">(</span><span class="n">tp</span> <span class="o">+</span> <span class="n">fp</span><span class="p">)</span>
            <span class="n">NPV</span> <span class="o">=</span> <span class="n">tn</span> <span class="o">/</span> <span class="p">(</span><span class="n">tn</span> <span class="o">+</span> <span class="n">fn</span><span class="p">)</span>
            <span class="n">sensitivity</span> <span class="o">=</span> <span class="n">tp</span> <span class="o">/</span> <span class="p">(</span><span class="n">tp</span> <span class="o">+</span> <span class="n">fn</span><span class="p">)</span>
            <span class="n">specificity</span> <span class="o">=</span> <span class="n">tn</span> <span class="o">/</span> <span class="p">(</span><span class="n">tn</span> <span class="o">+</span> <span class="n">fp</span><span class="p">)</span>
            <span class="n">balanced_accuracy</span> <span class="o">=</span> <span class="p">(</span><span class="n">sensitivity</span> <span class="o">+</span> <span class="n">specificity</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>
            <span class="n">MCC</span> <span class="o">=</span> <span class="p">(</span><span class="n">tp</span> <span class="o">*</span> <span class="n">tn</span> <span class="o">-</span> <span class="n">fp</span> <span class="o">*</span> <span class="n">fn</span><span class="p">)</span> <span class="o">/</span> <span class="p">((</span><span class="n">tp</span> <span class="o">+</span> <span class="n">fp</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">tp</span> <span class="o">+</span> <span class="n">fn</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">tn</span> <span class="o">+</span> <span class="n">fp</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">tn</span> <span class="o">+</span> <span class="n">fn</span><span class="p">))</span> <span class="o">**</span> <span class="mf">0.5</span>
            <span class="n">roc_auc</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">bootstrap_sample_y_test</span><span class="p">,</span> <span class="n">y_score</span><span class="o">=</span><span class="n">predictions</span><span class="p">)</span>
            <span class="n">brier_score</span> <span class="o">=</span> <span class="n">brier_score_loss</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">bootstrap_sample_y_test</span><span class="p">,</span> <span class="n">y_prob</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">precision_recall_curve</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">bootstrap_sample_y_test</span><span class="p">,</span> <span class="n">probas_pred</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">pr_auc</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">auc</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">recall</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">precision</span><span class="p">)</span>
            <span class="n">f1</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">bootstrap_sample_y_test</span><span class="p">,</span> <span class="n">predictions_class</span><span class="p">)</span>

        <span class="c1"># Store the metric values for each bootstrap iteration</span>
        <span class="n">bootstrap_values</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">PPV</span><span class="p">,</span> <span class="n">NPV</span><span class="p">,</span> <span class="n">sensitivity</span><span class="p">,</span> <span class="n">specificity</span><span class="p">,</span> <span class="n">balanced_accuracy</span><span class="p">,</span> <span class="n">MCC</span><span class="p">,</span> <span class="n">roc_auc</span><span class="p">,</span> <span class="n">pr_auc</span><span class="p">,</span> <span class="n">brier_score</span><span class="p">,</span> <span class="n">f1</span><span class="p">])</span>


    <span class="c1"># Convert the list of metric values into a numpy array for easier manipulation</span>
    <span class="n">bootstrap_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">bootstrap_values</span><span class="p">)</span>

    <span class="c1"># Calculate confidence intervals for each metric</span>
    <span class="n">lower_bounds</span><span class="p">,</span> <span class="n">upper_bounds</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">calculate_confidence_interval</span><span class="p">(</span><span class="n">bootstrap_values</span><span class="p">[:,</span> <span class="n">i</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">bootstrap_values</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])])</span>

    <span class="c1"># Calculate the measures for the whole testset</span>
    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">min_positive_instances</span><span class="p">:</span>
        <span class="c1"># Set metrics to NaN or another suitable value</span>
        <span class="n">PPV</span><span class="p">,</span> <span class="n">NPV</span><span class="p">,</span> <span class="n">sensitivity</span><span class="p">,</span> <span class="n">specificity</span><span class="p">,</span> <span class="n">balanced_accuracy</span><span class="p">,</span> <span class="n">MCC</span><span class="p">,</span> <span class="n">roc_auc</span><span class="p">,</span> <span class="n">pr_auc</span><span class="p">,</span> <span class="n">brier_score</span><span class="p">,</span> <span class="n">f1</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">]</span> <span class="o">*</span> <span class="mi">10</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="p">(</span><span class="n">cb</span><span class="o">.</span><span class="n">CatBoostClassifier</span><span class="p">,</span> <span class="n">lgb</span><span class="o">.</span><span class="n">LGBMClassifier</span><span class="p">,</span> <span class="n">GaussianNB</span><span class="p">,</span> <span class="n">RandomForestClassifier</span><span class="p">,</span> <span class="n">LogisticRegression</span><span class="p">,</span> <span class="n">HistGradientBoostingClassifier</span><span class="p">)):</span>
            <span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">testset</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
            <span class="c1"># print(predictions)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">testset</span><span class="p">)</span>

        <span class="n">predictions_class</span> <span class="o">=</span> <span class="p">[</span><span class="kc">True</span> <span class="k">if</span> <span class="n">x</span> <span class="o">&gt;=</span> <span class="n">threshold</span> <span class="k">else</span> <span class="kc">False</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">predictions</span><span class="p">]</span>

        <span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">predictions_class</span><span class="p">)</span>
        <span class="n">tn</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">fn</span><span class="p">,</span> <span class="n">tp</span> <span class="o">=</span> <span class="n">cm</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>

        <span class="n">PPV</span> <span class="o">=</span> <span class="n">tp</span> <span class="o">/</span> <span class="p">(</span><span class="n">tp</span> <span class="o">+</span> <span class="n">fp</span><span class="p">)</span>
        <span class="n">NPV</span> <span class="o">=</span> <span class="n">tn</span> <span class="o">/</span> <span class="p">(</span><span class="n">tn</span> <span class="o">+</span> <span class="n">fn</span><span class="p">)</span>
        <span class="n">sensitivity</span> <span class="o">=</span> <span class="n">tp</span> <span class="o">/</span> <span class="p">(</span><span class="n">tp</span> <span class="o">+</span> <span class="n">fn</span><span class="p">)</span>
        <span class="n">specificity</span> <span class="o">=</span> <span class="n">tn</span> <span class="o">/</span> <span class="p">(</span><span class="n">tn</span> <span class="o">+</span> <span class="n">fp</span><span class="p">)</span>
        <span class="n">balanced_accuracy</span> <span class="o">=</span> <span class="p">(</span><span class="n">sensitivity</span> <span class="o">+</span> <span class="n">specificity</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>
        <span class="n">MCC</span> <span class="o">=</span> <span class="p">(</span><span class="n">tp</span> <span class="o">*</span> <span class="n">tn</span> <span class="o">-</span> <span class="n">fp</span> <span class="o">*</span> <span class="n">fn</span><span class="p">)</span> <span class="o">/</span> <span class="p">((</span><span class="n">tp</span> <span class="o">+</span> <span class="n">fp</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">tp</span> <span class="o">+</span> <span class="n">fn</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">tn</span> <span class="o">+</span> <span class="n">fp</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">tn</span> <span class="o">+</span> <span class="n">fn</span><span class="p">))</span> <span class="o">**</span> <span class="mf">0.5</span>
        <span class="n">roc_auc</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_score</span><span class="o">=</span><span class="n">predictions</span><span class="p">)</span>
        <span class="n">brier_score</span> <span class="o">=</span> <span class="n">brier_score_loss</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_prob</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">precision_recall_curve</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span> <span class="n">probas_pred</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">pr_auc</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">auc</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">recall</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">precision</span><span class="p">)</span>
        <span class="n">f1</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">predictions_class</span><span class="p">)</span>

    <span class="c1"># Convert the list of metric values into a numpy array for easier manipulation</span>
    <span class="n">bootstrap_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">bootstrap_values</span><span class="p">)</span>

    <span class="c1"># Calculate confidence intervals for each metric</span>
    <span class="n">lower_bounds</span><span class="p">,</span> <span class="n">upper_bounds</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">calculate_confidence_interval</span><span class="p">(</span><span class="n">bootstrap_values</span><span class="p">[:,</span> <span class="n">i</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">bootstrap_values</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])])</span>

    <span class="c1"># Calculate the measures for the whole testset</span>
    <span class="n">results</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;Metric&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;PPV&#39;</span><span class="p">,</span> <span class="s1">&#39;NPV&#39;</span><span class="p">,</span> <span class="s1">&#39;Sensitivity&#39;</span><span class="p">,</span> <span class="s1">&#39;Specificity&#39;</span><span class="p">,</span> <span class="s1">&#39;Balanced Accuracy&#39;</span><span class="p">,</span> <span class="s1">&#39;MCC&#39;</span><span class="p">,</span> <span class="s1">&#39;ROCAUC&#39;</span><span class="p">,</span> <span class="s1">&#39;PRAUC&#39;</span><span class="p">,</span> <span class="s1">&#39;Brier Score&#39;</span><span class="p">,</span> <span class="s1">&#39;F1 Score&#39;</span><span class="p">],</span>
        <span class="s1">&#39;Value&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">PPV</span><span class="p">,</span> <span class="n">NPV</span><span class="p">,</span> <span class="n">sensitivity</span><span class="p">,</span> <span class="n">specificity</span><span class="p">,</span> <span class="n">balanced_accuracy</span><span class="p">,</span> <span class="n">MCC</span><span class="p">,</span> <span class="n">roc_auc</span><span class="p">,</span> <span class="n">pr_auc</span><span class="p">,</span> <span class="n">brier_score</span><span class="p">,</span> <span class="n">f1</span><span class="p">],</span>
        <span class="s1">&#39;Lower Bound&#39;</span><span class="p">:</span> <span class="n">lower_bounds</span><span class="p">,</span>
        <span class="s1">&#39;Upper Bound&#39;</span><span class="p">:</span> <span class="n">upper_bounds</span>
    <span class="p">}</span>

    <span class="n">results_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
    <span class="n">results_df</span><span class="p">[</span><span class="s1">&#39;Value&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">results_df</span><span class="p">[</span><span class="s1">&#39;Value&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">results_df</span><span class="p">[</span><span class="s1">&#39;Lower Bound&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">results_df</span><span class="p">[</span><span class="s1">&#39;Lower Bound&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">results_df</span><span class="p">[</span><span class="s1">&#39;Upper Bound&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">results_df</span><span class="p">[</span><span class="s1">&#39;Upper Bound&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">results_df</span><span class="p">)</span>

    <span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">drop_intermediate</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">,</span> <span class="n">pr_thresholds</span> <span class="o">=</span> <span class="n">precision_recall_curve</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    
    <span class="c1"># Find missclassified samples</span>
    <span class="n">predictions_class</span> <span class="o">=</span> <span class="p">[</span><span class="kc">True</span> <span class="k">if</span> <span class="n">x</span> <span class="o">&gt;=</span> <span class="n">threshold</span> <span class="k">else</span> <span class="kc">False</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">predictions</span><span class="p">]</span>
    <span class="n">missclassified_samples</span> <span class="o">=</span> <span class="n">y_test</span><span class="o">.</span><span class="n">index</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y_test</span> <span class="o">!=</span> <span class="n">predictions_class</span><span class="p">)[</span><span class="mi">0</span><span class="p">]]</span>

    <span class="c1"># Finding the index closest to the custom threshold instead of 0.5</span>
    <span class="n">threshold_index</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">thresholds</span> <span class="o">-</span> <span class="n">threshold</span><span class="p">))</span><span class="o">.</span><span class="n">argmin</span><span class="p">()</span>
    <span class="n">threshold_custom</span> <span class="o">=</span> <span class="n">thresholds</span><span class="p">[</span><span class="n">threshold_index</span><span class="p">]</span>
    <span class="n">tpr_custom</span> <span class="o">=</span> <span class="n">tpr</span><span class="p">[</span><span class="n">threshold_index</span><span class="p">]</span>
    <span class="n">fpr_custom</span> <span class="o">=</span> <span class="n">fpr</span><span class="p">[</span><span class="n">threshold_index</span><span class="p">]</span>

    <span class="n">pr_threshold_index</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">pr_thresholds</span> <span class="o">-</span> <span class="n">threshold</span><span class="p">))</span><span class="o">.</span><span class="n">argmin</span><span class="p">()</span>
    <span class="n">pr_threshold_custom</span> <span class="o">=</span> <span class="n">pr_thresholds</span><span class="p">[</span><span class="n">pr_threshold_index</span><span class="p">]</span>
    <span class="n">precision_custom</span> <span class="o">=</span> <span class="n">precision</span><span class="p">[</span><span class="n">pr_threshold_index</span><span class="p">]</span>
    <span class="n">recall_custom</span> <span class="o">=</span> <span class="n">recall</span><span class="p">[</span><span class="n">pr_threshold_index</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">display_confusion_matrix</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Displays a confusion matrix for model performance evaluation.</span>

<span class="sd">        ## Parameters</span>
<span class="sd">            y_true (np.ndarray): Ground truth labels.</span>
<span class="sd">            y_pred (np.ndarray): Predicted labels.</span>
<span class="sd">            labels (list or tuple): List of unique class labels in the data.</span>

<span class="sd">        ## Returns</span>
<span class="sd">            None: The function modifies the specified axes object and displays the plot.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
        <span class="n">disp</span> <span class="o">=</span> <span class="n">ConfusionMatrixDisplay</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="o">=</span><span class="n">cm</span><span class="p">,</span> <span class="n">display_labels</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
        <span class="n">disp</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;Blues&#39;</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax3</span><span class="p">,</span> <span class="n">xticks_rotation</span><span class="o">=</span><span class="s1">&#39;vertical&#39;</span><span class="p">,</span> <span class="n">values_format</span><span class="o">=</span><span class="s1">&#39;d&#39;</span><span class="p">)</span>
        <span class="n">ax3</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">(</span><span class="n">ax3</span><span class="o">.</span><span class="n">get_xticklabels</span><span class="p">(),</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
        <span class="n">ax3</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">(</span><span class="n">ax3</span><span class="o">.</span><span class="n">get_yticklabels</span><span class="p">(),</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Predicted&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;True&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
        <span class="n">ax3</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
        <span class="n">ax3</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">()</span>
  
    <span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">,</span> <span class="n">ax3</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
    
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_facecolor</span><span class="p">(</span><span class="s1">&#39;white&#39;</span><span class="p">)</span>
    <span class="c1"># show both grid lines</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">&#39;both&#39;</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s2">&quot;grey&quot;</span><span class="p">)</span>
    <span class="c1"># modify grid lines:</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">&#39;minor&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">&#39;major&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;ROC AUC ≈ </span><span class="si">{:.2f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">roc_auc</span><span class="p">))</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;chance level&#39;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">fpr_custom</span><span class="p">,</span> <span class="n">tpr_custom</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Threshold = </span><span class="si">{</span><span class="n">threshold_custom</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mf">1.1</span><span class="p">])</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;False Positive Rate&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;True Positive Rate&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;ROC curve&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s2">&quot;lower right&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;grey&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;-&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>  

    

    <span class="n">chance_level_precision</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_facecolor</span><span class="p">(</span><span class="s1">&#39;white&#39;</span><span class="p">)</span>
    <span class="c1"># show both grid lines</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">&#39;both&#39;</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s2">&quot;grey&quot;</span><span class="p">)</span>
    <span class="c1"># modify grid lines:</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">&#39;minor&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">&#39;major&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">recall</span><span class="p">,</span> <span class="n">precision</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;PR AUC ≈ </span><span class="si">{:.2f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">pr_auc</span><span class="p">))</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">recall_custom</span><span class="p">,</span> <span class="n">precision_custom</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;orange&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Threshold = </span><span class="si">{</span><span class="n">pr_threshold_custom</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">chance_level_precision</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;chance level&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mf">1.1</span><span class="p">])</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Recall&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Precision&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Precision-Recall curve&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s2">&quot;upper right&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;grey&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;-&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>  


    <span class="c1"># ax2.legend(loc=&quot;lower left&quot;, fontsize=8)</span>

    <span class="n">display_confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">predictions_class</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">class_labels_display</span><span class="p">)</span>
    <span class="n">ax3</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Confusion matrix&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">wspace</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;font.family&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;sans-serif&#39;</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;font.size&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">8</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">300</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Threshold closest to </span><span class="si">{</span><span class="n">threshold</span><span class="si">}</span><span class="s1"> (ROC): </span><span class="si">{</span><span class="n">threshold_custom</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Threshold closest to </span><span class="si">{</span><span class="n">threshold</span><span class="si">}</span><span class="s1"> (PR): </span><span class="si">{</span><span class="n">pr_threshold_custom</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">results_df</span><span class="p">,</span> <span class="n">missclassified_samples</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cat_features</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Convert outcome variable to boolean</span>
<span class="n">outcome_mapping</span> <span class="o">=</span> <span class="p">{</span><span class="n">class_1</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span> <span class="n">class_0</span><span class="p">:</span> <span class="kc">False</span><span class="p">}</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">y_train</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">outcome_mapping</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">bool</span><span class="p">)</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">y_test</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">outcome_mapping</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">bool</span><span class="p">)</span>
<span class="k">if</span> <span class="n">external_val</span><span class="p">:</span>
    <span class="n">y_extval_data</span> <span class="o">=</span> <span class="n">y_extval_data</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">outcome_mapping</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">bool</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>
<section id="initiate-machine-learning-models">
<h2>Initiate machine learning models<a class="headerlink" href="#initiate-machine-learning-models" title="Link to this heading">#</a></h2>
<p>This part is focused on binary classification.</p>
<section id="variable-type-encoding-for-qlattice-model-only-required-for-qlattice">
<h3>Variable type encoding for QLattice model (only required for QLattice)<a class="headerlink" href="#variable-type-encoding-for-qlattice-model-only-required-for-qlattice" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># empty dictionary to store the stypes</span>
<span class="n">stypes</span> <span class="o">=</span> <span class="p">{}</span>

<span class="c1"># iterate over each column in the dataset</span>
<span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">mydata_imputed</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
    <span class="c1"># check if the column dtype is &#39;category&#39;</span>
    <span class="k">if</span> <span class="n">pd</span><span class="o">.</span><span class="n">api</span><span class="o">.</span><span class="n">types</span><span class="o">.</span><span class="n">is_categorical_dtype</span><span class="p">(</span><span class="n">mydata_imputed</span><span class="p">[</span><span class="n">col</span><span class="p">]):</span>
        <span class="c1"># if it is, add the column name to the stypes dictionary with a value of &#39;c&#39;</span>
        <span class="n">stypes</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;c&#39;</span>

<span class="n">stypes</span><span class="p">[</span><span class="n">outcome_var</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;b&#39;</span>
<span class="c1"># print the stypes dictionary</span>
<span class="nb">print</span><span class="p">(</span><span class="n">stypes</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="set-model-weights-based-on-class-balance-from-the-training-development-set">
<h3>Set model weights based on class balance from the training (development) set<a class="headerlink" href="#set-model-weights-based-on-class-balance-from-the-training-development-set" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sample_weights</span> <span class="o">=</span> <span class="n">compute_sample_weight</span><span class="p">(</span><span class="n">class_weight</span><span class="o">=</span><span class="s1">&#39;balanced&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">mydata_imputed</span><span class="p">[</span><span class="n">outcome_var</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="define-the-parameter-grid-for-random-search">
<h3>Define the parameter grid for random search<a class="headerlink" href="#define-the-parameter-grid-for-random-search" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># this is done when hyperparameter tuning is done</span>
<span class="k">def</span> <span class="nf">adjust_hyperparameters</span><span class="p">(</span><span class="n">n_rows</span><span class="p">,</span> <span class="n">n_cols</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns a dictionary of hyperparameter distributions for various machine learning models.</span>

<span class="sd">    ## Parameters</span>
<span class="sd">        n_rows (int): The number of rows in the dataset.</span>
<span class="sd">        n_cols (int): The number of columns in the dataset.</span>

<span class="sd">    ## Returns</span>
<span class="sd">        dict: A dictionary containing the following keys:</span>
<span class="sd">            - &#39;adjusted_rf_param_dist&#39;: Hyperparameters for Random Forest Classifier.</span>
<span class="sd">            - &#39;adjusted_lgbm_param_dist&#39;: Hyperparameters for LightGBM Classifier.</span>
<span class="sd">            - &#39;adjusted_hgbc_param_dist&#39;: Hyperparameters for Histogram-Based Gradient Boosting Classifier.</span>
<span class="sd">            - &#39;adjusted_cb_param_dist&#39;: Hyperparameters for CatBoost Classifier.</span>
<span class="sd">            - &#39;adjusted_lr_param_dist&#39;: Hyperparameters for Logistic Regression.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">SEED</span><span class="p">)</span>
    <span class="c1"># Adjust hyperparameters based on dataset size and class proportion</span>
    <span class="c1"># Random Forest Classifier parameters:</span>
    <span class="n">adjusted_rf_param_dist</span> <span class="o">=</span> <span class="p">{</span>
        <span class="c1"># Number of trees in the forest</span>
        <span class="s2">&quot;n_estimators&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n_rows</span><span class="p">))),</span> <span class="n">num</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">),</span>
        <span class="c1"># Maximum depth of the tree</span>
        <span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">n_cols</span><span class="p">],</span>
        <span class="c1"># Minimum number of samples required to split a node</span>
        <span class="s1">&#39;min_samples_split&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n_rows</span><span class="p">))],</span>
        <span class="c1"># Minimum number of samples required at each leaf node</span>
        <span class="s1">&#39;min_samples_leaf&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n_rows</span><span class="p">))],</span>
        <span class="c1"># The number of features to consider when looking for the best split</span>
        <span class="s1">&#39;max_features&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;sqrt&#39;</span><span class="p">,</span> <span class="s1">&#39;log2&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span>
    <span class="p">}</span>
    
    <span class="c1"># LightGBM Classifier parameters:</span>
    <span class="n">adjusted_lgbm_param_dist</span> <span class="o">=</span> <span class="p">{</span>
        <span class="c1"># Maximum number of leaves in one tree</span>
        <span class="s2">&quot;num_leaves&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">),</span>
        <span class="c1"># Minimum number of data needed in a child (leaf) node</span>
        <span class="s1">&#39;min_child_samples&#39;</span><span class="p">:</span> <span class="n">randint</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="nb">min</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n_rows</span><span class="p">)),</span> <span class="mi">100</span><span class="p">),</span> <span class="n">size</span> <span class="o">=</span> <span class="mi">10</span><span class="p">),</span>
        <span class="c1"># Minimum sum of instance weight (hessian) needed in a child (leaf) node</span>
        <span class="s1">&#39;min_child_weight&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">1e-5</span><span class="p">,</span> <span class="mf">1e-3</span><span class="p">,</span> <span class="mf">1e-2</span><span class="p">,</span> <span class="mf">1e-1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mf">1e1</span><span class="p">,</span> <span class="mf">1e2</span><span class="p">,</span> <span class="mf">1e3</span><span class="p">,</span> <span class="mf">1e4</span><span class="p">],</span>
        <span class="c1"># Subsample ratio of the training instance</span>
        <span class="s1">&#39;subsample&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span>
        <span class="c1"># Subsample ratio of columns when constructing each tree</span>
        <span class="s1">&#39;colsample_bytree&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span>
        <span class="c1"># L1 regularization term on weights</span>
        <span class="s1">&#39;reg_alpha&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">1e-1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span>
        <span class="c1"># L2 regularization term on weights</span>
        <span class="s1">&#39;reg_lambda&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">1e-1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span>
        <span class="c1"># Number of boosting iterations</span>
        <span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n_rows</span><span class="p">))),</span> <span class="n">num</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">),</span>
        <span class="c1"># Maximum depth of tree</span>
        <span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">]</span>
    <span class="p">}</span>

    <span class="c1"># Histogram-Based Gradient Boosting Classifier parameters:</span>
    <span class="n">adjusted_hgbc_param_dist</span> <span class="o">=</span> <span class="p">{</span>
        <span class="c1"># maximum iterations (number of trees)</span>
        <span class="s2">&quot;max_iter&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n_rows</span><span class="p">))),</span> <span class="n">num</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">),</span>
        <span class="c1"># validation data proportion</span>
        <span class="s2">&quot;validation_fraction&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
        <span class="c1"># Boosting learning rate</span>
        <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
        <span class="c1"># Maximum depth of the individual estimators</span>
        <span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">n_cols</span><span class="p">],</span>
        <span class="c1"># Minimum number of samples per leaf</span>
        <span class="s1">&#39;min_samples_leaf&#39;</span><span class="p">:</span> <span class="n">randint</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">min</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="n">n_rows</span><span class="p">),</span> <span class="n">size</span> <span class="o">=</span> <span class="mi">10</span><span class="p">),</span>
        <span class="c1"># Grow trees with max_leaf_nodes in best-first fashion</span>
        <span class="s1">&#39;max_leaf_nodes&#39;</span><span class="p">:</span> <span class="n">randint</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="n">size</span> <span class="o">=</span> <span class="mi">10</span><span class="p">),</span>
        <span class="c1"># L2 regularization term on weights</span>
        <span class="s1">&#39;l2_regularization&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
    <span class="p">}</span>
    
    <span class="c1"># CatBoost Classifier parameters:</span>
    <span class="n">adjusted_cb_param_dist</span> <span class="o">=</span> <span class="p">{</span>
        <span class="c1"># Learning rate (like step size)</span>
        <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">10</span><span class="p">),</span>
        <span class="c1"># Depth of the trees (the deeper the more detailed but more vulnerable to overfitting)</span>
        <span class="s1">&#39;depth&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">n_cols</span><span class="p">],</span>
        <span class="c1"># L2 regularization coefficient (for generalizability)</span>
        <span class="s1">&#39;l2_leaf_reg&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">100</span><span class="p">),</span>
        <span class="c1"># The number of trees to fit</span>
        <span class="s1">&#39;iterations&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n_rows</span><span class="p">))),</span> <span class="n">num</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">),</span>
        <span class="c1"># Subsample ratio of the training instance</span>
        <span class="s1">&#39;subsample&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
        <span class="c1"># Random strength</span>
        <span class="s1">&#39;random_strength&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
    <span class="p">}</span>

    <span class="c1"># Logistic Regression parameters:</span>
    <span class="n">adjusted_lr_param_dist</span> <span class="o">=</span> <span class="p">{</span>
        <span class="c1"># Inverse of regularization strength</span>
        <span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span>
        <span class="c1"># Maximum number of iterations for optimization</span>
        <span class="s1">&#39;max_iter&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">500</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="mi">2000</span><span class="p">,</span> <span class="mi">5000</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n_rows</span><span class="p">))],</span> 
        <span class="c1"># Tolerance for stopping criteria</span>
        <span class="s1">&#39;tol&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">1e-3</span><span class="p">,</span> <span class="mf">1e-4</span><span class="p">,</span> <span class="mf">1e-5</span><span class="p">]</span>
    <span class="p">}</span>

    <span class="k">return</span> <span class="n">adjusted_rf_param_dist</span><span class="p">,</span> <span class="n">adjusted_lgbm_param_dist</span><span class="p">,</span> <span class="n">adjusted_hgbc_param_dist</span><span class="p">,</span> <span class="n">adjusted_cb_param_dist</span><span class="p">,</span> <span class="n">adjusted_lr_param_dist</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="set-parameters-for-models-when-the-datset-is-small">
<h3>Set parameters for models (when the datset is small)<a class="headerlink" href="#set-parameters-for-models-when-the-datset-is-small" title="Link to this heading">#</a></h3>
<p>This is used when there is no hyperparameter tuning. The parameters are set according to the data characteristics.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># this is done when hyperparameter tuning is not done</span>
<span class="k">def</span> <span class="nf">set_parameters</span><span class="p">(</span><span class="n">n_rows</span><span class="p">,</span> <span class="n">n_cols</span><span class="p">,</span> <span class="n">class_proportion</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Sets the parameters for different machine learning classifiers based on the given dataset characteristics.</span>

<span class="sd">    ## Parameters:</span>
<span class="sd">        n_rows (int): The number of rows in the dataset.</span>
<span class="sd">        n_cols (int): The number of columns in the dataset.</span>
<span class="sd">        class_proportion (float): The proportion of classes in the dataset.</span>

<span class="sd">    ## Returns</span>
<span class="sd">        A dictionary containing the parameters for each classifier, including:</span>
<span class="sd">            - Balanced Random Forest Classifier</span>
<span class="sd">            - LightGBM Classifier</span>
<span class="sd">            - Histogram-Based Gradient Boosting Classifier</span>
<span class="sd">            - CatBoost Classifier</span>
<span class="sd">            - Logistic Regression</span>

<span class="sd">    Note that this function assumes hyperparameter tuning is not done and sets default values based on the dataset characteristics.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Balanced Random Forest Classifier parameters:</span>
    <span class="n">rf_params</span> <span class="o">=</span> <span class="p">{</span>
        <span class="c1"># Number of trees in the forest</span>
        <span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="nb">max</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_rows</span> <span class="o">/</span> <span class="mi">100</span><span class="p">)),</span>
        <span class="c1"># Maximum depth of the tree</span>
        <span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span>
        <span class="c1"># Minimum number of samples required to split a node</span>
        <span class="s1">&#39;min_samples_split&#39;</span><span class="p">:</span> <span class="mi">2</span> <span class="k">if</span> <span class="n">class_proportion</span> <span class="o">&gt;</span> <span class="mf">0.1</span> <span class="k">else</span> <span class="mi">10</span><span class="p">,</span>
        <span class="c1"># Minimum number of samples required at each leaf node</span>
        <span class="s1">&#39;min_samples_leaf&#39;</span><span class="p">:</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">class_proportion</span> <span class="o">&gt;</span> <span class="mf">0.1</span> <span class="k">else</span> <span class="mi">4</span><span class="p">,</span>
        <span class="c1"># The number of features to consider when looking for the best split</span>
        <span class="s1">&#39;max_features&#39;</span><span class="p">:</span> <span class="s1">&#39;sqrt&#39;</span>
    <span class="p">}</span>

    <span class="c1"># LightGBM Classifier parameters:</span>
    <span class="n">lgbm_params</span> <span class="o">=</span> <span class="p">{</span>
        <span class="c1"># Maximum number of leaves in one tree</span>
        <span class="s1">&#39;num_leaves&#39;</span><span class="p">:</span> <span class="nb">min</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="nb">min</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="mi">2</span><span class="o">*</span><span class="n">n_rows</span><span class="p">)),</span>
        <span class="c1"># Minimum number of data needed in a child (leaf) node</span>
        <span class="s1">&#39;min_child_samples&#39;</span><span class="p">:</span> <span class="nb">min</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_rows</span> <span class="o">/</span> <span class="mi">20</span><span class="p">)),</span>
        <span class="c1"># Minimum sum of instance weight (hessian) needed in a child (leaf) node</span>
        <span class="s1">&#39;min_child_weight&#39;</span><span class="p">:</span> <span class="mf">1e-3</span><span class="p">,</span>
        <span class="c1"># Subsample ratio of the training instance</span>
        <span class="s1">&#39;subsample&#39;</span><span class="p">:</span> <span class="nb">min</span><span class="p">(</span><span class="mf">0.8</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.5</span> <span class="o">+</span> <span class="p">(</span><span class="n">class_proportion</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)),</span>
        <span class="c1"># Subsample ratio of columns when constructing each tree</span>
        <span class="s1">&#39;colsample_bytree&#39;</span><span class="p">:</span> <span class="mf">0.8</span><span class="p">,</span>
        <span class="c1"># L1 regularization term on weights</span>
        <span class="s1">&#39;reg_alpha&#39;</span><span class="p">:</span> <span class="mf">0.01</span><span class="p">,</span>
        <span class="c1"># L2 regularization term on weights</span>
        <span class="s1">&#39;reg_lambda&#39;</span><span class="p">:</span> <span class="mf">0.01</span><span class="p">,</span>
        <span class="c1"># Number of boosting iterations</span>
        <span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="nb">min</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">2</span><span class="o">*</span><span class="n">n_rows</span><span class="p">),</span>
        <span class="c1"># Maximum depth of tree</span>
        <span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="mi">10</span>
    <span class="p">}</span>

    <span class="c1"># Histogram-Based Gradient Boosting Classifier parameters:</span>
    <span class="n">hgbc_params</span> <span class="o">=</span> <span class="p">{</span>
        <span class="c1"># maximum iterations (number of trees)</span>
        <span class="s2">&quot;max_iter&quot;</span><span class="p">:</span><span class="nb">min</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">2</span><span class="o">*</span><span class="n">n_rows</span><span class="p">),</span>
        <span class="c1"># Boosting learning rate</span>
        <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span>
        <span class="c1"># Maximum depth of the individual estimators</span>
        <span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span>
        <span class="c1"># Minimum number of samples per leaf</span>
        <span class="s1">&#39;min_samples_leaf&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
        <span class="c1"># Grow trees with max_leaf_nodes in best-first fashion</span>
        <span class="s1">&#39;max_leaf_nodes&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
        <span class="c1"># L2 regularization term on weights</span>
        <span class="s1">&#39;l2_regularization&#39;</span><span class="p">:</span> <span class="mf">0.1</span>
    <span class="p">}</span>

    <span class="c1"># CatBoost Classifier parameters:</span>
    <span class="n">cb_params</span> <span class="o">=</span> <span class="p">{</span>
        <span class="c1"># Learning rate</span>
        <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span>
        <span class="c1"># Depth of the trees</span>
        <span class="s1">&#39;depth&#39;</span><span class="p">:</span> <span class="nb">min</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_cols</span><span class="o">/</span><span class="mi">2</span><span class="p">)),</span>
        <span class="c1"># L2 regularization coefficient</span>
        <span class="s1">&#39;l2_leaf_reg&#39;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span>
        <span class="c1"># The number of trees to fit</span>
        <span class="s1">&#39;iterations&#39;</span><span class="p">:</span> <span class="nb">min</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">2</span><span class="o">*</span><span class="n">n_rows</span><span class="p">),</span>
        <span class="c1"># Subsample ratio of the training instance</span>
        <span class="s1">&#39;subsample&#39;</span><span class="p">:</span> <span class="mf">0.8</span><span class="p">,</span>
        <span class="c1"># Random strength</span>
        <span class="s1">&#39;random_strength&#39;</span><span class="p">:</span> <span class="mi">5</span>
    <span class="p">}</span>

    <span class="c1"># Logistic Regression parameters:</span>
    <span class="n">lr_params</span> <span class="o">=</span> <span class="p">{</span>
        <span class="c1"># Inverse of regularization strength</span>
        <span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span>
        <span class="c1"># Maximum number of iterations for optimization</span>
        <span class="s1">&#39;max_iter&#39;</span><span class="p">:</span> <span class="mi">1000</span><span class="p">,</span>
        <span class="c1"># Tolerance for stopping criteria</span>
        <span class="s1">&#39;tol&#39;</span><span class="p">:</span> <span class="mf">1e-4</span>
    <span class="p">}</span>

    <span class="k">return</span> <span class="n">rf_params</span><span class="p">,</span> <span class="n">lgbm_params</span><span class="p">,</span> <span class="n">hgbc_params</span><span class="p">,</span> <span class="n">cb_params</span><span class="p">,</span> <span class="n">lr_params</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">PFI_median_wrap</span><span class="p">(</span><span class="n">PFI_folds</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes the median importance across all folds and normalizes the importance values.</span>

<span class="sd">    ## Parameters:</span>
<span class="sd">    PFI_folds (list of feature importance values in folds): List of DataFrames where each DataFrame contains &#39;Feature&#39; and &#39;Importance&#39; columns.</span>

<span class="sd">    ## Returns</span>
<span class="sd">    pd.DataFrame: DataFrame with &#39;Feature&#39; and normalized &#39;Importance&#39; sorted by importance.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># Get the number of folds</span>
    <span class="n">num_folds</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">PFI_folds</span><span class="p">)</span>
    
    <span class="c1"># Start with the &#39;Feature&#39; column from the first DataFrame</span>
    <span class="n">merged_df</span> <span class="o">=</span> <span class="n">PFI_folds</span><span class="p">[</span><span class="mi">0</span><span class="p">][[</span><span class="s1">&#39;Feature&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    
    <span class="c1"># Loop through each fold and add the &#39;Importance&#39; column to the DataFrame</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_folds</span><span class="p">):</span>
        <span class="n">fold_column</span> <span class="o">=</span> <span class="n">PFI_folds</span><span class="p">[</span><span class="n">i</span><span class="p">][[</span><span class="s1">&#39;Importance&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;Importance&#39;</span><span class="p">:</span> <span class="sa">f</span><span class="s1">&#39;Importance Fold </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">})</span>
        <span class="n">merged_df</span> <span class="o">=</span> <span class="n">merged_df</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">fold_column</span><span class="p">,</span> <span class="n">left_index</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">right_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    
    <span class="c1"># Calculate the median of importance values for each feature</span>
    <span class="n">importance_columns</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s1">&#39;Importance Fold </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1">&#39;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_folds</span><span class="p">)]</span>
    <span class="n">merged_df</span><span class="p">[</span><span class="s1">&#39;Importance&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">merged_df</span><span class="p">[</span><span class="n">importance_columns</span><span class="p">]</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="n">PFI_median</span> <span class="o">=</span> <span class="n">merged_df</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="c1"># # Select only the &#39;Feature&#39; and &#39;Importance&#39; columns</span>
    <span class="c1"># PFI_median = merged_df[[&#39;Feature&#39;, &#39;Importance&#39;]]</span>
    
    <span class="c1"># Sort the DataFrame by &#39;Importance&#39; in descending order</span>
    <span class="n">PFI_median</span> <span class="o">=</span> <span class="n">PFI_median</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s1">&#39;Importance&#39;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    
    <span class="c1"># Normalize the &#39;Importance&#39; column</span>
    <span class="n">PFI_median</span><span class="p">[</span><span class="s1">&#39;Importance&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">minmax_scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">PFI_median</span><span class="p">[[</span><span class="s1">&#39;Importance&#39;</span><span class="p">]])</span>
    
    <span class="k">return</span> <span class="n">PFI_median</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_PFI</span><span class="p">(</span><span class="n">PFI_folds</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">model_name</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Plot permutation-based feature importances (PFI) from multiple folds using a strip plot.</span>

<span class="sd">    ## Parameters:</span>
<span class="sd">    - PFI_folds (list of DataFrames): List where each DataFrame contains &#39;Feature&#39; and &#39;Importance&#39; columns for each fold.</span>
<span class="sd">    - X (DataFrame): DataFrame used to determine the number of features for plot sizing.</span>
<span class="sd">    - model_name (str): A string representing the name of the model or experiment, used for naming the output files.</span>

<span class="sd">    ## Returns:</span>
<span class="sd">    - Saves the plot with filenames including the model_name parameter and displays it.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Combine feature importances from all folds into a single DataFrame</span>
    <span class="n">combined_importances</span> <span class="o">=</span> <span class="n">PFI_median_wrap</span><span class="p">(</span><span class="n">PFI_folds</span><span class="p">)</span>
    <span class="n">median_importance</span> <span class="o">=</span> <span class="n">combined_importances</span><span class="p">[[</span><span class="s1">&#39;Feature&#39;</span><span class="p">,</span> <span class="s1">&#39;Importance&#39;</span><span class="p">]]</span>
    
    <span class="c1"># Plot boxplot for feature importances</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">stripplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">&quot;Importance&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;Feature&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">PFI_folds</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">order</span><span class="o">=</span><span class="n">median_importance</span><span class="p">[</span><span class="s1">&#39;Feature&#39;</span><span class="p">],</span> <span class="n">jitter</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Fold-wise mean permutation importances for </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Importance&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Feature&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;font.family&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;sans-serif&#39;</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;font.size&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">8</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;:&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;both&#39;</span><span class="p">,</span> <span class="n">labelsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span> 
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">set_facecolor</span><span class="p">(</span><span class="s1">&#39;white&#39;</span><span class="p">)</span>  
    <span class="c1"># Display grid lines</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">&#39;both&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;grey&quot;</span><span class="p">)</span>
    <span class="c1"># Modify grid lines</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">&#39;minor&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">&#39;major&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
    <span class="c1"># Add a dotted line at x = 0</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;k&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="c1"># Save plot with model_name in the filename</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;FI_perm_</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">.tif&quot;</span><span class="p">,</span> <span class="n">bbox_inches</span><span class="o">=</span><span class="s1">&#39;tight&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_TFI</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">tree_FI</span><span class="p">,</span> <span class="n">model_name</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Plots the tree-based feature importances for a given model.</span>

<span class="sd">    ## Parameters:</span>
<span class="sd">    X (pd.DataFrame): The training data used for feature names.</span>
<span class="sd">    tree_FI (list of pd.Series): List of feature importance scores for tree-based feature importance from each fold.</span>
<span class="sd">    model_name (str): Name of the model to use in the plot title and filenames.</span>

<span class="sd">    ## Returns</span>
<span class="sd">    None: Displays and saves the plot.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Extract feature names from X</span>
    <span class="n">feature_names</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">columns</span>

    <span class="c1"># Combine feature importances from all folds into a single DataFrame</span>
    <span class="n">combined_importances</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span>
        <span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;Feature&#39;</span><span class="p">:</span> <span class="n">feature_names</span><span class="p">,</span> <span class="s1">&#39;Importance&#39;</span><span class="p">:</span> <span class="n">fold</span><span class="p">})</span> <span class="k">for</span> <span class="n">fold</span> <span class="ow">in</span> <span class="n">tree_FI</span><span class="p">],</span>
        <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">ignore_index</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">)</span>

    <span class="c1"># Calculate the median importance across folds for each feature</span>
    <span class="n">median_importance</span> <span class="o">=</span> <span class="n">combined_importances</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">&quot;Feature&quot;</span><span class="p">)[</span><span class="s2">&quot;Importance&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">median</span><span class="p">()</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>

    <span class="c1"># Sort features by their median importance</span>
    <span class="n">median_importance</span> <span class="o">=</span> <span class="n">median_importance</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s2">&quot;Importance&quot;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="c1"># Plot feature importances</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">stripplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">&quot;Importance&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;Feature&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">combined_importances</span><span class="p">,</span> 
                  <span class="n">order</span><span class="o">=</span><span class="n">median_importance</span><span class="p">[</span><span class="s1">&#39;Feature&#39;</span><span class="p">],</span> <span class="n">jitter</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Mean tree-based feature importances per fold (</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Importance&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Feature&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;font.family&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;sans-serif&#39;</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;font.size&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">8</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;:&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;k&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;both&#39;</span><span class="p">,</span> <span class="n">labelsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">set_facecolor</span><span class="p">(</span><span class="s1">&#39;white&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">&#39;both&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;grey&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">&#39;minor&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">&#39;major&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
    
    <span class="c1"># Save the plot to files</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;FI_tree_</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">.tif&quot;</span><span class="p">,</span> <span class="n">bbox_inches</span><span class="o">=</span><span class="s1">&#39;tight&#39;</span><span class="p">)</span>
    
    <span class="c1"># Show the plot</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">shap_summary_plot</span><span class="p">(</span><span class="n">shap_values</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">model_name</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Generates and saves a SHAP summary plot based on provided SHAP values and data from cross validation</span>
<span class="sd">    </span>
<span class="sd">    Parameters:</span>
<span class="sd">    - shap_values: concatenated list of SHAP values arrays from different folds</span>
<span class="sd">    - data: DataFrames (trainset or testset)</span>
<span class="sd">    - model_name: Name of the model (e.g., &quot;CB&quot; for CatBoost)</span>
<span class="sd">    </span>
<span class="sd">    ## Returns</span>
<span class="sd">    - None: Saves the plot as a .tif file and displays it.</span>
<span class="sd">    &quot;&quot;&quot;</span>
   
    <span class="c1"># Create the SHAP summary plot</span>
    <span class="n">shap</span><span class="o">.</span><span class="n">summary_plot</span><span class="p">(</span>
        <span class="n">shap_values</span><span class="p">,</span> 
        <span class="n">data</span><span class="p">,</span> 
        <span class="n">color</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">get_cmap</span><span class="p">(</span><span class="s2">&quot;viridis&quot;</span><span class="p">),</span> 
        <span class="n">show</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
        <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span> <span class="n">max_display</span><span class="o">=</span><span class="n">top_n_f</span>
    <span class="p">)</span>
    
    <span class="c1"># Customize the plot appearance</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gcf</span><span class="p">()</span><span class="o">.</span><span class="n">axes</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">labelsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;:&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;font.family&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;sans-serif&#39;</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;font.size&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">8</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;SHAP value&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;feature&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gcf</span><span class="p">(),</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">axes</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;feature value&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;both&#39;</span><span class="p">,</span> <span class="n">labelsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">set_facecolor</span><span class="p">(</span><span class="s1">&#39;white&#39;</span><span class="p">)</span>
    
    <span class="c1"># Display grid lines</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">&#39;both&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;grey&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">&#39;minor&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">&#39;major&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
    
    <span class="c1"># Save and display the plot</span>
    <span class="n">plot_filename</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;SHAP_summary_plot_</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">.tif&quot;</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">plot_filename</span><span class="p">,</span> <span class="n">bbox_inches</span><span class="o">=</span><span class="s1">&#39;tight&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    
    <span class="c1"># Check if there are categorical features and generate a plot with categories if needed</span>
    <span class="k">if</span> <span class="s1">&#39;category&#39;</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">dtypes</span><span class="o">.</span><span class="n">values</span><span class="p">:</span>
        <span class="n">feature_names_with_shapvalues</span> <span class="o">=</span> <span class="p">[</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">feature</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">value</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="k">for</span> <span class="n">feature</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">shap_values</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
        <span class="p">]</span>
        <span class="c1"># SHAP summary plot with categories</span>
        <span class="n">categorical_shap_plot</span><span class="p">(</span>
            <span class="n">shap_values</span><span class="o">=</span><span class="n">shap_values</span><span class="p">,</span> 
            <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span>
            <span class="n">top_n</span><span class="o">=</span><span class="nb">min</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">feature_names_with_shapvalues</span><span class="p">),</span><span class="n">top_n_f</span><span class="p">),</span>
            <span class="n">jitter</span><span class="o">=</span><span class="mf">0.1</span>
        <span class="p">)</span>
        
        <span class="c1"># Customize the second plot appearance</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">set_facecolor</span><span class="p">(</span><span class="s1">&#39;white&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">&#39;both&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;grey&quot;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">&#39;minor&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">&#39;major&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
        
        <span class="c1"># Save the plot with categories</span>
        <span class="n">plot_filename_with_cats</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;SHAP_summary_plot_</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">_withcats.tif&quot;</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">plot_filename_with_cats</span><span class="p">,</span> <span class="n">dpi</span> <span class="o">=</span> <span class="mi">300</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="k-fold-stratified-cross-validation-of-binary-classification-models">
<h3>K-fold stratified cross validation of binary classification models<a class="headerlink" href="#k-fold-stratified-cross-validation-of-binary-classification-models" title="Link to this heading">#</a></h3>
<p>This block contains the code to perform cross-validation for all selected binary classification models. The code calculates performance measures for all models, applies hyperparameter tuning and training, and generates visualizations for feature importance using various approaches (e.g., SHAP, feature permutation, tree-based feature importance). Additionally, it produces performance metrics such as ROC and PR curves.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Function to calculate evaluation metrics</span>
<span class="k">def</span> <span class="nf">calculate_metrics</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">y_pred_proba</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculates various evaluation metrics for binary classification models.</span>

<span class="sd">    ## Parameters</span>
<span class="sd">        y_true (array-like): True labels.</span>
<span class="sd">        y_pred (array-like): Predicted labels.</span>
<span class="sd">        y_pred_proba (array-like): Predicted probabilities of positive outcomes.</span>

<span class="sd">    ## Returns</span>
<span class="sd">        dict: Dictionary containing the following evaluation metrics:</span>
<span class="sd">            - PPV (Positive Predictive Value)</span>
<span class="sd">            - NPV (Negative Predictive Value)</span>
<span class="sd">            - Sensitivity (True Positive Rate)</span>
<span class="sd">            - Specificity (True Negative Rate)</span>
<span class="sd">            - Balanced Accuracy</span>
<span class="sd">            - Matthews Correlation Coefficient (MCC)</span>
<span class="sd">            - Receiver Operating Characteristic AUC Score (ROCAUC)</span>
<span class="sd">            - Precision-Recall AUC Score (PRAUC)</span>
<span class="sd">            - Brier Score</span>
<span class="sd">            - F1 Score</span>

<span class="sd">    Notes:</span>
<span class="sd">        The evaluation metrics are calculated based on the true labels, predicted labels, and predicted probabilities.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Calculate confusion matrix</span>
    <span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span> <span class="p">[</span><span class="kc">False</span><span class="p">,</span> <span class="kc">True</span><span class="p">])</span>
    <span class="n">tn</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">fn</span><span class="p">,</span> <span class="n">tp</span> <span class="o">=</span> <span class="n">cm</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
    <span class="c1"># Positive Predictive Value (Precision)</span>
    <span class="n">PPV</span> <span class="o">=</span> <span class="n">tp</span> <span class="o">/</span> <span class="p">(</span><span class="n">tp</span> <span class="o">+</span> <span class="n">fp</span><span class="p">)</span>
    <span class="c1"># Negative Predictive Value</span>
    <span class="n">NPV</span> <span class="o">=</span> <span class="n">tn</span> <span class="o">/</span> <span class="p">(</span><span class="n">tn</span> <span class="o">+</span> <span class="n">fn</span><span class="p">)</span>
    <span class="c1"># True Positive Rate (Recall)</span>
    <span class="n">Sensitivity</span> <span class="o">=</span> <span class="n">tp</span> <span class="o">/</span> <span class="p">(</span><span class="n">tp</span> <span class="o">+</span> <span class="n">fn</span><span class="p">)</span>
    <span class="c1"># True Negative Rate</span>
    <span class="n">Specificity</span> <span class="o">=</span> <span class="n">tn</span> <span class="o">/</span> <span class="p">(</span><span class="n">tn</span> <span class="o">+</span> <span class="n">fp</span><span class="p">)</span>
    <span class="n">Balanced_Accuracy</span> <span class="o">=</span> <span class="p">(</span><span class="n">Sensitivity</span> <span class="o">+</span> <span class="n">Specificity</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span> <span class="c1"># Balanced Accuracy</span>
    <span class="n">MCC</span> <span class="o">=</span> <span class="n">matthews_corrcoef</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span> <span class="c1"># Matthews Correlation Coefficient</span>
    <span class="n">ROC_AUC</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred_proba</span><span class="p">)</span> <span class="c1"># ROC AUC Score</span>
    <span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">precision_recall_curve</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred_proba</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">PR_AUC</span> <span class="o">=</span> <span class="n">auc</span><span class="p">(</span><span class="n">recall</span><span class="p">,</span> <span class="n">precision</span><span class="p">)</span> <span class="c1"># Precision-Recall AUC Score</span>
    <span class="n">Brier_Score</span> <span class="o">=</span> <span class="n">brier_score_loss</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred_proba</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="c1"># Brier Score</span>
    <span class="n">F1_Score</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span> <span class="c1"># F1 Score</span>
    <span class="k">return</span> <span class="p">{</span>
        <span class="s1">&#39;PPV&#39;</span><span class="p">:</span> <span class="n">PPV</span><span class="p">,</span>
        <span class="s1">&#39;NPV&#39;</span><span class="p">:</span> <span class="n">NPV</span><span class="p">,</span>
        <span class="s1">&#39;Sensitivity&#39;</span><span class="p">:</span> <span class="n">Sensitivity</span><span class="p">,</span>
        <span class="s1">&#39;Specificity&#39;</span><span class="p">:</span> <span class="n">Specificity</span><span class="p">,</span>
        <span class="s1">&#39;Balanced Accuracy&#39;</span><span class="p">:</span> <span class="n">Balanced_Accuracy</span><span class="p">,</span>
        <span class="s1">&#39;MCC&#39;</span><span class="p">:</span> <span class="n">MCC</span><span class="p">,</span>
        <span class="s1">&#39;ROCAUC&#39;</span><span class="p">:</span> <span class="n">ROC_AUC</span><span class="p">,</span>
        <span class="s1">&#39;PRAUC&#39;</span><span class="p">:</span> <span class="n">PR_AUC</span><span class="p">,</span>
        <span class="s1">&#39;Brier Score&#39;</span><span class="p">:</span> <span class="n">Brier_Score</span><span class="p">,</span>
        <span class="s1">&#39;F1 Score&#39;</span><span class="p">:</span> <span class="n">F1_Score</span>
    <span class="p">}</span>
<span class="c1"># Function to cross-validate the model</span>
<span class="k">def</span> <span class="nf">cross_validate_model</span><span class="p">(</span><span class="n">model_class</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">n_splits</span><span class="o">=</span><span class="n">cv_folds</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">,</span> <span class="n">measures</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                         <span class="n">use_default_threshold</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">model_params</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Perform k-fold cross-validation and evaluate the model.</span>

<span class="sd">    ## Parameters:</span>
<span class="sd">        X (array-like): Feature data.</span>
<span class="sd">        y (array-like): Target labels.</span>
<span class="sd">        model: Trained model instance.</span>
<span class="sd">        use_default_threshold (bool, optional): Use default threshold (0.5) for classification. Defaults to True.</span>

<span class="sd">    ## Returns</span>
<span class="sd">        tuple: Fold results, aggregated results table, optimal threshold, feature importance lists, and SHAP values list.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n_repeats</span> <span class="o">=</span> <span class="n">n_rep_feature_permutation</span> <span class="c1"># number of repetitions for feature permutation</span>
    <span class="k">if</span> <span class="n">measures</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">measures</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;PPV&#39;</span><span class="p">,</span> <span class="s1">&#39;NPV&#39;</span><span class="p">,</span> <span class="s1">&#39;Sensitivity&#39;</span><span class="p">,</span> <span class="s1">&#39;Specificity&#39;</span><span class="p">,</span> <span class="s1">&#39;Balanced Accuracy&#39;</span><span class="p">,</span> <span class="s1">&#39;MCC&#39;</span><span class="p">,</span> <span class="s1">&#39;ROCAUC&#39;</span><span class="p">,</span> <span class="s1">&#39;PRAUC&#39;</span><span class="p">,</span> <span class="s1">&#39;Brier Score&#39;</span><span class="p">,</span> <span class="s1">&#39;F1 Score&#39;</span><span class="p">]</span>
    <span class="n">fold_data</span> <span class="o">=</span> <span class="p">[]</span> <span class="c1"># to save the data that are split by folds for subsequent analyses</span>
    <span class="n">y_fold_data</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">fold_results</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
    <span class="n">fold_results_plt</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
    <span class="n">aggregated_thr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([])</span> <span class="c1"># aggregated list of estimated optimal thresholds per fold</span>
    <span class="n">aggregated_predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([])</span>
    <span class="n">aggregated_labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([])</span>
    <span class="n">skf</span> <span class="o">=</span> <span class="n">StratifiedKFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="n">n_splits</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">feature_importance_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">treebased_feature_importance_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">shap_values_list</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># To store SHAP values for each fold</span>
    <span class="n">missclassified_samples</span> <span class="o">=</span> <span class="p">[]</span> <span class="c1"># to store the index of missclassified samples</span>
    <span class="c1">########</span>
    <span class="n">overlapping_samples</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">test_indices_list</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># To store test indices of samples in each fold</span>
    <span class="c1">########</span>
    <span class="n">predictions_proba_fold_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">predictions_proba_fold_train_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">fold</span><span class="p">,</span> <span class="p">(</span><span class="n">train_index</span><span class="p">,</span> <span class="n">test_index</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">skf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">X_train_fold</span><span class="p">,</span> <span class="n">X_test_fold</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
        <span class="n">y_train_fold</span><span class="p">,</span> <span class="n">y_test_fold</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>

        <span class="c1"># Check for overlapping test samples across previous folds</span>
        <span class="k">if</span> <span class="n">fold</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">current_test_index</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">test_index</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">prev_test_index</span> <span class="ow">in</span> <span class="n">test_indices_list</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">current_test_index</span><span class="o">.</span><span class="n">isdisjoint</span><span class="p">(</span><span class="n">prev_test_index</span><span class="p">):</span>
                    <span class="n">overlapping_samples</span> <span class="o">=</span> <span class="kc">True</span>
                    <span class="k">break</span>
        <span class="c1"># Store test indices of samples in this fold</span>
        <span class="n">test_indices_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">test_index</span><span class="p">))</span>
        <span class="c1">#####################</span>
        <span class="n">sample_weights_fold</span> <span class="o">=</span> <span class="n">sample_weights</span><span class="p">[</span><span class="n">train_index</span><span class="p">]</span> <span class="k">if</span> <span class="n">sample_weights</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="c1"># Calculate necessary information for adjusting hyperparameters</span>
        <span class="n">n_rows</span> <span class="o">=</span> <span class="n">X_train_fold</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">n_cols</span> <span class="o">=</span> <span class="n">X_train_fold</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">class_proportion</span> <span class="o">=</span> <span class="n">y_train_fold</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>  <span class="c1"># binary classification</span>
        <span class="c1"># Adjust hyperparameters based on the training data in this fold</span>
        <span class="n">rf_param_dist</span><span class="p">,</span> <span class="n">lgbm_param_dist</span><span class="p">,</span> <span class="n">hgbc_param_dist</span><span class="p">,</span> <span class="n">cb_param_dist</span><span class="p">,</span> <span class="n">lr_param_dist</span> <span class="o">=</span> <span class="n">adjust_hyperparameters</span><span class="p">(</span><span class="n">n_rows</span><span class="p">,</span> <span class="n">n_cols</span><span class="p">)</span>
        <span class="n">rf_params</span><span class="p">,</span> <span class="n">lgbm_params</span><span class="p">,</span> <span class="n">hgbc_params</span><span class="p">,</span> <span class="n">cb_params</span><span class="p">,</span> <span class="n">lr_params</span> <span class="o">=</span> <span class="n">set_parameters</span><span class="p">(</span><span class="n">n_rows</span><span class="p">,</span> <span class="n">n_cols</span><span class="p">,</span> <span class="n">class_proportion</span><span class="p">)</span>
        <span class="c1"># Check if the model is a RandomForestClassifier</span>
        <span class="k">if</span> <span class="n">model_class</span> <span class="o">==</span> <span class="n">RandomForestClassifier</span><span class="p">:</span>
            <span class="c1"># Explicitly set sampling_strategy to &#39;all&#39;</span>
            <span class="n">rf_model</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_cpu_model_training</span><span class="p">,</span> <span class="o">**</span><span class="n">rf_params</span><span class="p">)</span> <span class="c1"># , class_weight = &#39;balanced&#39;</span>
            <span class="c1"># if hyperparameter tuning should be done or not</span>
            <span class="k">if</span> <span class="n">hp_tuning</span><span class="p">:</span>
                <span class="n">random_search</span> <span class="o">=</span> <span class="n">RandomizedSearchCV</span><span class="p">(</span>
                <span class="n">estimator</span><span class="o">=</span><span class="n">rf_model</span><span class="p">,</span> 
                <span class="n">param_distributions</span><span class="o">=</span><span class="n">rf_param_dist</span><span class="p">,</span> 
                <span class="n">n_iter</span><span class="o">=</span><span class="n">n_iter_hptuning</span><span class="p">,</span>
                <span class="n">scoring</span><span class="o">=</span> <span class="n">custom_scorer</span><span class="p">,</span>  
                <span class="n">cv</span><span class="o">=</span><span class="n">cv_folds_hptuning</span><span class="p">,</span>
                <span class="n">refit</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
                <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span>
                <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> 
                <span class="n">n_jobs</span> <span class="o">=</span> <span class="n">n_cpu_for_tuning</span><span class="p">)</span>
                <span class="c1"># Fit the RandomizedSearchCV object to the data</span>
                <span class="n">random_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_fold</span><span class="p">,</span> <span class="n">y_train_fold</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weights_fold</span><span class="p">)</span>
                <span class="c1"># Get the best parameters and best estimator from the random search</span>
                <span class="n">best_params</span> <span class="o">=</span> <span class="n">random_search</span><span class="o">.</span><span class="n">best_params_</span>
                <span class="n">rf_model</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">,</span><span class="n">n_jobs</span><span class="o">=</span><span class="n">n_cpu_model_training</span><span class="p">,</span> <span class="o">**</span><span class="n">best_params</span><span class="p">)</span> <span class="c1"># , class_weight = &#39;balanced&#39; (note: class weight should not be used simultaneously with sample weight, it messes up the sample weighting)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">rf_model</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_cpu_model_training</span><span class="p">,</span> <span class="o">**</span><span class="n">rf_params</span><span class="p">)</span> <span class="c1"># , class_weight = &#39;balanced&#39;</span>
            <span class="c1"># Fit the best estimator on the entire training data</span>
            <span class="n">rf_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_fold</span><span class="p">,</span> <span class="n">y_train_fold</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weights_fold</span><span class="p">)</span>
            <span class="c1"># Get predictions on the test data</span>
            <span class="n">predictions_proba</span> <span class="o">=</span> <span class="n">rf_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test_fold</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
            <span class="n">treebased_feature_importance</span> <span class="o">=</span> <span class="n">rf_model</span><span class="o">.</span><span class="n">feature_importances_</span>
            <span class="n">treebased_feature_importance_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">treebased_feature_importance</span><span class="p">)</span>
            <span class="c1"># Use permutation_importance to get feature importances</span>
            <span class="n">perm_result</span> <span class="o">=</span> <span class="n">permutation_importance</span><span class="p">(</span>
                <span class="n">rf_model</span><span class="p">,</span> <span class="n">X_test_fold</span><span class="p">,</span> <span class="n">y_test_fold</span><span class="p">,</span> <span class="n">n_repeats</span><span class="o">=</span><span class="n">n_repeats</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_cpu_model_training</span><span class="p">,</span> <span class="n">scoring</span> <span class="o">=</span> <span class="n">custom_scorer</span> <span class="c1"># &quot;roc_auc&quot;</span>
            <span class="p">)</span>
            <span class="c1"># Get feature importances and sort them</span>
            <span class="n">feature_importance</span> <span class="o">=</span> <span class="n">perm_result</span><span class="o">.</span><span class="n">importances_mean</span> <span class="c1"># Mean of feature importance over n_repeats</span>
            <span class="n">feature_importance_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
                <span class="p">{</span><span class="s2">&quot;Feature&quot;</span><span class="p">:</span> <span class="n">X_train_fold</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="s2">&quot;Importance&quot;</span><span class="p">:</span> <span class="n">feature_importance</span><span class="p">}</span>
            <span class="p">)</span>
            <span class="n">feature_importance_df</span> <span class="o">=</span> <span class="n">feature_importance_df</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span>
                <span class="n">by</span><span class="o">=</span><span class="s2">&quot;Importance&quot;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span>
            <span class="p">)</span>
            <span class="c1"># Append to the list</span>
            <span class="n">feature_importance_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">feature_importance_df</span><span class="p">)</span>
            <span class="c1"># Compute SHAP values</span>
            <span class="n">explainer</span> <span class="o">=</span> <span class="n">shap</span><span class="o">.</span><span class="n">TreeExplainer</span><span class="p">(</span><span class="n">rf_model</span><span class="p">)</span>
            <span class="n">shap_values</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">shap_values</span><span class="p">(</span><span class="n">X_test_fold</span><span class="p">)</span>
            <span class="n">shap_values_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">shap_values</span><span class="p">)</span>
            <span class="n">fold_data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">X_test_fold</span><span class="p">)</span> <span class="c1"># for subsequent SHAP vs feature value analyses</span>
            <span class="n">y_fold_data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_test_fold</span><span class="p">)</span>
            
            <span class="c1">############</span>
            <span class="n">predictions_proba_fold</span> <span class="o">=</span> <span class="n">rf_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test_fold</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
            <span class="n">predictions_proba_fold_train</span> <span class="o">=</span> <span class="n">rf_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_train_fold</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
            <span class="n">predictions_proba_fold_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">predictions_proba_fold</span><span class="p">)</span>
            <span class="n">predictions_proba_fold_train_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">predictions_proba_fold_train</span><span class="p">)</span>
            <span class="c1"># Check if the model is a QLattice</span>
        <span class="k">elif</span> <span class="n">model_class</span> <span class="o">==</span> <span class="s1">&#39;QLattice&#39;</span><span class="p">:</span>
            <span class="n">X_train_fold_ql</span> <span class="o">=</span> <span class="n">X_train_fold</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
            <span class="n">X_train_fold_ql</span><span class="p">[</span><span class="n">outcome_var</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_train_fold</span><span class="o">.</span><span class="n">values</span>
            <span class="k">if</span> <span class="n">hp_tuning</span><span class="p">:</span>
                <span class="n">best_composite_score</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="n">best_parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;n_epochs&#39;</span><span class="p">:</span> <span class="mi">50</span><span class="p">,</span> <span class="s1">&#39;max_complexity&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
                <span class="k">def</span> <span class="nf">evaluate_params_kfold</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">,</span> <span class="n">max_complexity</span><span class="p">):</span>
<span class="w">                    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">                    Evaluate a QLattice model for given hyperparameters.</span>

<span class="sd">                    ## Parameters:</span>
<span class="sd">                        n_epochs (int): The number of epochs used for training.</span>
<span class="sd">                        max_complexity (int): The maximum complexity of the model.</span>

<span class="sd">                    ## Returns</span>
<span class="sd">                        QL_composite_score (float): The composite score of the model.</span>
<span class="sd">                        params (dict): The hyperparameters used to achieve this score.</span>
<span class="sd">                    &quot;&quot;&quot;</span>
                    <span class="n">ql</span> <span class="o">=</span> <span class="n">feyn</span><span class="o">.</span><span class="n">QLattice</span><span class="p">(</span><span class="n">random_seed</span><span class="o">=</span><span class="n">random_state</span><span class="p">)</span>
                    <span class="n">models</span> <span class="o">=</span> <span class="n">ql</span><span class="o">.</span><span class="n">auto_run</span><span class="p">(</span>
                        <span class="n">data</span><span class="o">=</span><span class="n">X_train_fold_ql</span><span class="p">,</span>
                        <span class="n">output_name</span><span class="o">=</span><span class="n">outcome_var</span><span class="p">,</span>
                        <span class="n">kind</span><span class="o">=</span><span class="s1">&#39;classification&#39;</span><span class="p">,</span>
                        <span class="n">n_epochs</span><span class="o">=</span><span class="n">n_epochs</span><span class="p">,</span>
                        <span class="n">stypes</span><span class="o">=</span><span class="n">stypes</span><span class="p">,</span>
                        <span class="n">criterion</span><span class="o">=</span><span class="s2">&quot;aic&quot;</span><span class="p">,</span>
                        <span class="n">loss_function</span><span class="o">=</span><span class="s1">&#39;binary_cross_entropy&#39;</span><span class="p">,</span>
                        <span class="n">max_complexity</span><span class="o">=</span><span class="n">max_complexity</span><span class="p">,</span>
                        <span class="n">sample_weights</span><span class="o">=</span><span class="n">sample_weights_fold</span>
                    <span class="p">)</span>
                    <span class="n">best_model</span> <span class="o">=</span> <span class="n">models</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                    <span class="n">predictions_proba</span> <span class="o">=</span> <span class="n">best_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_fold</span><span class="p">)</span>
                    <span class="n">QL_composite_score</span> <span class="o">=</span> <span class="p">(</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_true</span> <span class="o">=</span> <span class="n">y_test_fold</span><span class="p">,</span> <span class="n">y_score</span> <span class="o">=</span> <span class="n">predictions_proba</span><span class="p">)</span> <span class="o">+</span>
                                          <span class="n">average_precision_score</span><span class="p">(</span><span class="n">y_true</span> <span class="o">=</span> <span class="n">y_test_fold</span><span class="p">,</span> <span class="n">y_score</span> <span class="o">=</span> <span class="n">predictions_proba</span><span class="p">))</span><span class="o">/</span><span class="mi">2</span>
                    <span class="k">return</span> <span class="n">QL_composite_score</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;n_epochs&#39;</span><span class="p">:</span> <span class="n">n_epochs</span><span class="p">,</span> <span class="s1">&#39;max_complexity&#39;</span><span class="p">:</span> <span class="n">max_complexity</span><span class="p">}</span>
                <span class="n">results</span> <span class="o">=</span> <span class="n">Parallel</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=</span><span class="n">n_cpu_for_tuning</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="s1">&#39;loky&#39;</span><span class="p">)(</span>
                    <span class="n">delayed</span><span class="p">(</span><span class="n">evaluate_params_kfold</span><span class="p">)(</span><span class="n">n_epochs</span><span class="p">,</span> <span class="n">max_complexity</span><span class="p">)</span>
                    <span class="k">for</span> <span class="n">n_epochs</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">]</span>
                    <span class="k">for</span> <span class="n">max_complexity</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">]</span>
                <span class="p">)</span>
                <span class="k">for</span> <span class="n">QL_composite_score</span><span class="p">,</span> <span class="n">params</span> <span class="ow">in</span> <span class="n">results</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">QL_composite_score</span> <span class="o">&gt;</span> <span class="n">best_composite_score</span><span class="p">:</span>
                        <span class="n">best_composite_score</span> <span class="o">=</span> <span class="n">QL_composite_score</span>
                        <span class="n">best_parameters</span> <span class="o">=</span> <span class="n">params</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best Parameters:&quot;</span><span class="p">,</span> <span class="n">best_parameters</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best composite score:&quot;</span><span class="p">,</span> <span class="n">best_composite_score</span><span class="p">)</span>
                <span class="c1"># Use the best parameters from the grid search</span>
                <span class="n">best_n_epochs</span> <span class="o">=</span> <span class="n">best_parameters</span><span class="p">[</span><span class="s1">&#39;n_epochs&#39;</span><span class="p">]</span>
                <span class="n">best_max_complexity</span> <span class="o">=</span> <span class="n">best_parameters</span><span class="p">[</span><span class="s1">&#39;max_complexity&#39;</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">best_n_epochs</span> <span class="o">=</span> <span class="mi">50</span>
                <span class="n">best_max_complexity</span> <span class="o">=</span> <span class="mi">10</span>
            <span class="c1"># Train the final model with the best parameters</span>
            <span class="n">ql</span> <span class="o">=</span> <span class="n">feyn</span><span class="o">.</span><span class="n">QLattice</span><span class="p">(</span><span class="n">random_seed</span><span class="o">=</span><span class="n">random_state</span><span class="p">)</span>
            <span class="n">models</span> <span class="o">=</span> <span class="n">ql</span><span class="o">.</span><span class="n">auto_run</span><span class="p">(</span>
                <span class="n">data</span><span class="o">=</span><span class="n">X_train_fold_ql</span><span class="p">,</span>
                <span class="n">output_name</span><span class="o">=</span><span class="n">outcome_var</span><span class="p">,</span>
                <span class="n">kind</span><span class="o">=</span><span class="s1">&#39;classification&#39;</span><span class="p">,</span>
                <span class="n">n_epochs</span><span class="o">=</span><span class="n">best_n_epochs</span><span class="p">,</span>
                <span class="n">stypes</span><span class="o">=</span><span class="n">stypes</span><span class="p">,</span>
                <span class="n">criterion</span><span class="o">=</span><span class="s2">&quot;aic&quot;</span><span class="p">,</span>
                <span class="n">loss_function</span><span class="o">=</span><span class="s1">&#39;binary_cross_entropy&#39;</span><span class="p">,</span>
                <span class="n">max_complexity</span><span class="o">=</span><span class="n">best_max_complexity</span><span class="p">,</span>
                <span class="n">sample_weights</span><span class="o">=</span><span class="n">sample_weights_fold</span>
            <span class="p">)</span>
            <span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">predictions_proba</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_fold</span><span class="p">)</span>
            <span class="c1"># Calculate the baseline custom score = (AUC+PRAUC)/2</span>
            <span class="n">baseline_score</span> <span class="o">=</span> <span class="n">combined_metric</span><span class="p">(</span><span class="n">y_true</span> <span class="o">=</span> <span class="n">y_test_fold</span><span class="p">,</span> <span class="n">y_pred_proba</span><span class="o">=</span><span class="n">predictions_proba</span><span class="p">)</span>
            <span class="c1"># baseline_roc_auc = roc_auc_score(y_test_fold, predictions_proba)</span>
            <span class="c1"># Initialize an array to store the permutation importances</span>
            <span class="n">perm_importances</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="c1"># Iterate over each feature and permute its values</span>
            <span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="n">X_test_fold</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
                <span class="c1"># Permute the feature values</span>
                <span class="n">permuted_features</span> <span class="o">=</span> <span class="n">X_test_fold</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
                <span class="n">permuted_features</span><span class="p">[</span><span class="n">feature</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">permuted_features</span><span class="p">[</span><span class="n">feature</span><span class="p">])</span>
                <span class="c1"># Make predictions on the entire dataset with permuted feature</span>
                <span class="n">permuted_predictions</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">permuted_features</span><span class="p">)</span>
                <span class="c1"># Calculate the custom score = (AUC+PRAUC)/2 with permuted feature</span>
                <span class="n">permuted_score</span> <span class="o">=</span> <span class="n">combined_metric</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_test_fold</span><span class="p">,</span> <span class="n">y_pred_proba</span><span class="o">=</span><span class="n">permuted_predictions</span><span class="p">)</span>
                <span class="c1"># Calculate permutation importance for the feature</span>
                <span class="n">perm_importance</span> <span class="o">=</span> <span class="n">baseline_score</span> <span class="o">-</span> <span class="n">permuted_score</span>
                <span class="n">perm_importances</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">feature</span><span class="p">,</span> <span class="n">perm_importance</span><span class="p">))</span>
            <span class="c1"># Sort the permutation importances</span>
            <span class="n">perm_importances</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="c1"># Get feature importances and sort them</span>
            <span class="n">feature_importance</span> <span class="o">=</span> <span class="p">[</span><span class="n">importance</span> <span class="k">for</span> <span class="n">feature</span><span class="p">,</span> <span class="n">importance</span> <span class="ow">in</span> <span class="n">perm_importances</span><span class="p">]</span>
            <span class="n">feature_importance_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
                <span class="p">{</span><span class="s2">&quot;Feature&quot;</span><span class="p">:</span> <span class="n">X_test_fold</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="s2">&quot;Importance&quot;</span><span class="p">:</span> <span class="n">feature_importance</span><span class="p">}</span>
            <span class="p">)</span>
            <span class="n">feature_importance_df</span> <span class="o">=</span> <span class="n">feature_importance_df</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span>
                <span class="n">by</span><span class="o">=</span><span class="s2">&quot;Importance&quot;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span>
            <span class="p">)</span>
            <span class="c1"># Append to the list</span>
            <span class="n">feature_importance_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">feature_importance_df</span><span class="p">)</span>
            <span class="n">treebased_feature_importance</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">treebased_feature_importance_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">treebased_feature_importance</span><span class="p">)</span>
            <span class="n">predictions_proba_fold</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_fold</span><span class="p">)</span>
            <span class="n">predictions_proba_fold_train</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train_fold</span><span class="p">)</span>
            <span class="n">predictions_proba_fold_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">predictions_proba_fold</span><span class="p">)</span>
            <span class="n">predictions_proba_fold_train_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">predictions_proba_fold_train</span><span class="p">)</span>
            <span class="c1"># Clear memory from QLattice models</span>
            <span class="n">ql</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">models</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">elif</span> <span class="n">model_class</span> <span class="o">==</span> <span class="n">HistGradientBoostingClassifier</span><span class="p">:</span>
            <span class="c1"># Create a HistGradientBoostingClassifier instance</span>
            <span class="n">hgbc_model</span> <span class="o">=</span> <span class="n">HistGradientBoostingClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span> <span class="n">early_stopping</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">hgbc_params</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">hp_tuning</span><span class="p">:</span>
                <span class="c1"># Create a RandomizedSearchCV instance</span>
                <span class="n">random_search</span> <span class="o">=</span> <span class="n">RandomizedSearchCV</span><span class="p">(</span>
                    <span class="n">estimator</span><span class="o">=</span><span class="n">hgbc_model</span><span class="p">,</span> 
                    <span class="n">param_distributions</span><span class="o">=</span><span class="n">hgbc_param_dist</span><span class="p">,</span> 
                    <span class="n">n_iter</span><span class="o">=</span><span class="n">n_iter_hptuning</span><span class="p">,</span>
                    <span class="n">scoring</span><span class="o">=</span> <span class="n">custom_scorer</span><span class="p">,</span> 
                    <span class="n">cv</span><span class="o">=</span><span class="n">cv_folds_hptuning</span><span class="p">,</span>
                    <span class="n">refit</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
                    <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span>
                    <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                <span class="n">n_jobs</span> <span class="o">=</span> <span class="n">n_cpu_for_tuning</span><span class="p">)</span>
                <span class="c1"># Perform the random search on the training data</span>
                <span class="n">random_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_fold</span><span class="p">,</span> <span class="n">y_train_fold</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weights_fold</span><span class="p">)</span>
                <span class="c1"># Get the best parameters and best estimator</span>
                <span class="n">best_params</span> <span class="o">=</span> <span class="n">random_search</span><span class="o">.</span><span class="n">best_params_</span>
                <span class="n">hgbc_model</span> <span class="o">=</span> <span class="n">HistGradientBoostingClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span> <span class="n">early_stopping</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">best_params</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">hgbc_model</span> <span class="o">=</span> <span class="n">HistGradientBoostingClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span> <span class="n">early_stopping</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">hgbc_params</span><span class="p">)</span>
            <span class="c1"># model = random_search.best_estimator_</span>
            <span class="c1"># Fit the best estimator on the entire training data</span>
            <span class="n">hgbc_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_fold</span><span class="p">,</span> <span class="n">y_train_fold</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weights_fold</span><span class="p">)</span>
            <span class="c1"># Get predictions on the test data</span>
            <span class="n">predictions_proba</span> <span class="o">=</span> <span class="n">hgbc_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test_fold</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
            <span class="n">treebased_feature_importance</span> <span class="o">=</span> <span class="p">[]</span> <span class="c1"># model.feature_importances_ is not implemented for HistGradientBoostingClassifier</span>
            <span class="n">treebased_feature_importance_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">treebased_feature_importance</span><span class="p">)</span>
            <span class="c1"># feature_importance = model.feature_importances_</span>
            <span class="c1"># feature_importance_list.append(feature_importance)</span>
            <span class="n">perm_result</span> <span class="o">=</span> <span class="n">permutation_importance</span><span class="p">(</span>
                <span class="n">hgbc_model</span><span class="p">,</span> <span class="n">X_test_fold</span><span class="p">,</span> <span class="n">y_test_fold</span><span class="p">,</span> <span class="n">n_repeats</span><span class="o">=</span><span class="n">n_repeats</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_cpu_model_training</span><span class="p">,</span> <span class="n">scoring</span> <span class="o">=</span> <span class="n">custom_scorer</span> <span class="c1"># &quot;roc_auc&quot;</span>
            <span class="p">)</span>
            <span class="c1"># Get feature importances and sort them</span>
            <span class="n">feature_importance</span> <span class="o">=</span> <span class="n">perm_result</span><span class="o">.</span><span class="n">importances_mean</span> <span class="c1"># Mean of feature importance over n_repeats</span>
            <span class="n">feature_importance_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
                <span class="p">{</span><span class="s2">&quot;Feature&quot;</span><span class="p">:</span> <span class="n">X_train_fold</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="s2">&quot;Importance&quot;</span><span class="p">:</span> <span class="n">feature_importance</span><span class="p">}</span>
            <span class="p">)</span>
            <span class="n">feature_importance_df</span> <span class="o">=</span> <span class="n">feature_importance_df</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span>
                <span class="n">by</span><span class="o">=</span><span class="s2">&quot;Importance&quot;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span>
            <span class="p">)</span>
            <span class="c1"># Append to the list</span>
            <span class="n">feature_importance_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">feature_importance_df</span><span class="p">)</span>
            <span class="c1"># Compute SHAP values</span>
            <span class="n">explainer</span> <span class="o">=</span> <span class="n">shap</span><span class="o">.</span><span class="n">TreeExplainer</span><span class="p">(</span><span class="n">hgbc_model</span><span class="p">)</span>
            <span class="n">shap_values</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">shap_values</span><span class="p">(</span><span class="n">X_test_fold</span><span class="p">)</span>
            <span class="n">shap_values_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">shap_values</span><span class="p">)</span>
            <span class="n">fold_data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">X_test_fold</span><span class="p">)</span> <span class="c1"># for subsequent SHAP vs feature value analyses</span>
            <span class="n">y_fold_data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_test_fold</span><span class="p">)</span>
            
            <span class="n">predictions_proba_fold</span> <span class="o">=</span> <span class="n">hgbc_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test_fold</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
            <span class="n">predictions_proba_fold_train</span> <span class="o">=</span> <span class="n">hgbc_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_train_fold</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
            <span class="n">predictions_proba_fold_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">predictions_proba_fold</span><span class="p">)</span>
            <span class="n">predictions_proba_fold_train_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">predictions_proba_fold_train</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">model_class</span> <span class="o">==</span> <span class="n">lgb</span><span class="o">.</span><span class="n">LGBMClassifier</span><span class="p">:</span>
            <span class="c1"># LightGBM instance</span>
            <span class="k">if</span> <span class="n">GPU_avail</span><span class="p">:</span>
                <span class="n">lgbm_model</span> <span class="o">=</span> <span class="n">lgb</span><span class="o">.</span><span class="n">LGBMClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_cpu_model_training</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span><span class="n">device</span><span class="o">=</span><span class="s2">&quot;gpu&quot;</span><span class="p">,</span> <span class="o">**</span><span class="n">lgbm_params</span><span class="p">)</span> 
            <span class="k">else</span><span class="p">:</span>
                <span class="n">lgbm_model</span> <span class="o">=</span> <span class="n">lgb</span><span class="o">.</span><span class="n">LGBMClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_cpu_model_training</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="o">**</span><span class="n">lgbm_params</span><span class="p">)</span> 
            <span class="k">if</span> <span class="n">hp_tuning</span><span class="p">:</span>
                <span class="n">random_search</span> <span class="o">=</span> <span class="n">RandomizedSearchCV</span><span class="p">(</span>
                    <span class="n">estimator</span><span class="o">=</span><span class="n">lgbm_model</span><span class="p">,</span> 
                    <span class="n">param_distributions</span><span class="o">=</span><span class="n">lgbm_param_dist</span><span class="p">,</span> 
                    <span class="n">n_iter</span><span class="o">=</span><span class="n">n_iter_hptuning</span><span class="p">,</span>
                    <span class="n">scoring</span><span class="o">=</span> <span class="n">custom_scorer</span><span class="p">,</span> 
                    <span class="n">cv</span><span class="o">=</span><span class="n">cv_folds_hptuning</span><span class="p">,</span>
                    <span class="n">refit</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
                    <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span>
                    <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> 
                    <span class="n">n_jobs</span> <span class="o">=</span> <span class="n">n_cpu_for_tuning</span><span class="p">)</span>
                <span class="c1"># Perform the random search on the training data</span>
                <span class="n">random_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_fold</span><span class="p">,</span> <span class="n">y_train_fold</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weights_fold</span><span class="p">)</span>
                <span class="c1"># Get the best parameters and best estimator</span>
                <span class="n">best_params</span> <span class="o">=</span> <span class="n">random_search</span><span class="o">.</span><span class="n">best_params_</span>
                <span class="k">if</span> <span class="n">GPU_avail</span><span class="p">:</span>
                    <span class="n">lgbm_model</span> <span class="o">=</span> <span class="n">lgb</span><span class="o">.</span><span class="n">LGBMClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_cpu_model_training</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;gpu&quot;</span><span class="p">,</span> <span class="o">**</span><span class="n">best_params</span><span class="p">)</span> 
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">lgbm_model</span> <span class="o">=</span> <span class="n">lgb</span><span class="o">.</span><span class="n">LGBMClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_cpu_model_training</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="o">**</span><span class="n">best_params</span><span class="p">)</span> 
            <span class="c1"># Fit the best estimator on the entire training data</span>
            <span class="n">lgbm_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_fold</span><span class="p">,</span> <span class="n">y_train_fold</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weights_fold</span><span class="p">)</span>
            <span class="c1"># Get predictions on the test data</span>
            <span class="n">predictions_proba</span> <span class="o">=</span> <span class="n">lgbm_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test_fold</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
            <span class="n">treebased_feature_importance</span> <span class="o">=</span> <span class="n">lgbm_model</span><span class="o">.</span><span class="n">feature_importances_</span>
            <span class="n">treebased_feature_importance_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">treebased_feature_importance</span><span class="p">)</span>
            <span class="c1"># feature_importance = model.feature_importances_</span>
            <span class="c1"># feature_importance_list.append(feature_importance)</span>
            <span class="n">perm_result</span> <span class="o">=</span> <span class="n">permutation_importance</span><span class="p">(</span>
                <span class="n">lgbm_model</span><span class="p">,</span> <span class="n">X_test_fold</span><span class="p">,</span> <span class="n">y_test_fold</span><span class="p">,</span> <span class="n">n_repeats</span><span class="o">=</span><span class="n">n_repeats</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_cpu_model_training</span><span class="p">,</span> <span class="n">scoring</span> <span class="o">=</span> <span class="n">custom_scorer</span> <span class="c1"># &quot;roc_auc&quot;</span>
            <span class="p">)</span>
            <span class="c1"># Get feature importances and sort them</span>
            <span class="n">feature_importance</span> <span class="o">=</span> <span class="n">perm_result</span><span class="o">.</span><span class="n">importances_mean</span> <span class="c1"># Mean of feature importance over n_repeats</span>
            <span class="n">feature_importance_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
                <span class="p">{</span><span class="s2">&quot;Feature&quot;</span><span class="p">:</span> <span class="n">X_train_fold</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="s2">&quot;Importance&quot;</span><span class="p">:</span> <span class="n">feature_importance</span><span class="p">}</span>
            <span class="p">)</span>
            <span class="n">feature_importance_df</span> <span class="o">=</span> <span class="n">feature_importance_df</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span>
                <span class="n">by</span><span class="o">=</span><span class="s2">&quot;Importance&quot;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span>
            <span class="p">)</span>
            <span class="c1"># Append to the list</span>
            <span class="n">feature_importance_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">feature_importance_df</span><span class="p">)</span>
            <span class="c1"># Compute SHAP values</span>
            <span class="n">explainer</span> <span class="o">=</span> <span class="n">shap</span><span class="o">.</span><span class="n">TreeExplainer</span><span class="p">(</span><span class="n">lgbm_model</span><span class="p">)</span>
            <span class="n">shap_values</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">shap_values</span><span class="p">(</span><span class="n">X_test_fold</span><span class="p">)</span>
            <span class="n">shap_values_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">shap_values</span><span class="p">)</span>
            <span class="n">fold_data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">X_test_fold</span><span class="p">)</span> <span class="c1"># for subsequent SHAP vs feature value analyses</span>
            <span class="n">y_fold_data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_test_fold</span><span class="p">)</span>
            
            <span class="n">predictions_proba_fold</span> <span class="o">=</span> <span class="n">lgbm_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test_fold</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
            <span class="n">predictions_proba_fold_train</span> <span class="o">=</span> <span class="n">lgbm_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_train_fold</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
            <span class="n">predictions_proba_fold_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">predictions_proba_fold</span><span class="p">)</span>
            <span class="n">predictions_proba_fold_train_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">predictions_proba_fold_train</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">model_class</span> <span class="o">==</span> <span class="n">cb</span><span class="o">.</span><span class="n">CatBoostClassifier</span><span class="p">:</span> <span class="c1"># cb.CatBoostClassifier</span>
            <span class="c1"># Define the CatBoost classifier</span>
            <span class="c1"># if GPU_avail:</span>
            <span class="c1">#     cb_model = cb.CatBoostClassifier(random_state=random_state, cat_features=cat_features, silent=True, task_type=&quot;GPU&quot;, bootstrap_type = &quot;No&quot;) # , logging_level=&#39;Silent&#39; verbose=0, </span>
            <span class="c1"># else:</span>
            <span class="n">cb_model</span> <span class="o">=</span> <span class="n">cb</span><span class="o">.</span><span class="n">CatBoostClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span> <span class="n">cat_features</span><span class="o">=</span><span class="n">cat_features</span><span class="p">,</span> <span class="n">silent</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="o">**</span><span class="n">cb_params</span><span class="p">)</span> <span class="c1"># , **cb_params, logging_level=&#39;Silent&#39; verbose=0, silent=True,</span>
            <span class="k">if</span> <span class="n">hp_tuning</span><span class="p">:</span>
                <span class="c1"># Create a RandomizedSearchCV instance</span>
                <span class="n">random_search</span> <span class="o">=</span> <span class="n">RandomizedSearchCV</span><span class="p">(</span>
                    <span class="n">estimator</span><span class="o">=</span><span class="n">cb_model</span><span class="p">,</span> 
                    <span class="n">param_distributions</span><span class="o">=</span><span class="n">cb_param_dist</span><span class="p">,</span> 
                    <span class="n">n_iter</span><span class="o">=</span><span class="n">n_iter_hptuning</span><span class="p">,</span>
                    <span class="n">scoring</span><span class="o">=</span> <span class="n">custom_scorer</span><span class="p">,</span> 
                    <span class="n">cv</span><span class="o">=</span><span class="n">cv_folds_hptuning</span><span class="p">,</span>
                    <span class="n">refit</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
                    <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span>
                    <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> 
                    <span class="n">n_jobs</span> <span class="o">=</span> <span class="n">n_cpu_for_tuning</span>
                <span class="p">)</span>
                <span class="c1"># Perform the random search on the training data</span>
                <span class="n">random_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_fold</span><span class="p">,</span> <span class="n">y_train_fold</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weights_fold</span><span class="p">)</span>
                <span class="c1"># Get the best parameters and best estimator</span>
                <span class="n">best_params</span> <span class="o">=</span> <span class="n">random_search</span><span class="o">.</span><span class="n">best_params_</span>
                <span class="n">cb_model</span> <span class="o">=</span> <span class="n">cb</span><span class="o">.</span><span class="n">CatBoostClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span> <span class="n">cat_features</span><span class="o">=</span><span class="n">cat_features</span><span class="p">,</span> <span class="n">silent</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="o">**</span><span class="n">best_params</span><span class="p">)</span> <span class="c1"># logging_level=&#39;Silent&#39;, verbose=0, silent=True,</span>
            <span class="c1"># Fit the best estimator on the entire training data</span>
            <span class="n">cb_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_fold</span><span class="p">,</span> <span class="n">y_train_fold</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weights_fold</span><span class="p">)</span>
            <span class="c1"># Get predictions on the test data</span>
            <span class="n">predictions_proba</span> <span class="o">=</span> <span class="n">cb_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test_fold</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
            <span class="n">treebased_feature_importance</span> <span class="o">=</span> <span class="n">cb_model</span><span class="o">.</span><span class="n">feature_importances_</span>
            <span class="n">treebased_feature_importance_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">treebased_feature_importance</span><span class="p">)</span>

            <span class="n">perm_result</span> <span class="o">=</span> <span class="n">permutation_importance</span><span class="p">(</span>
                <span class="n">cb_model</span><span class="p">,</span> <span class="n">X_test_fold</span><span class="p">,</span> <span class="n">y_test_fold</span><span class="p">,</span> <span class="n">n_repeats</span><span class="o">=</span><span class="n">n_repeats</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_cpu_model_training</span><span class="p">,</span> <span class="n">scoring</span> <span class="o">=</span> <span class="n">custom_scorer</span> <span class="c1"># &quot;roc_auc&quot;</span>
            <span class="p">)</span>
            <span class="c1"># Get feature importances and sort them</span>
            <span class="n">feature_importance</span> <span class="o">=</span> <span class="n">perm_result</span><span class="o">.</span><span class="n">importances_mean</span> <span class="c1"># Mean of feature importance over n_repeats</span>
            <span class="n">feature_importance_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
                <span class="p">{</span><span class="s2">&quot;Feature&quot;</span><span class="p">:</span> <span class="n">X_train_fold</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="s2">&quot;Importance&quot;</span><span class="p">:</span> <span class="n">feature_importance</span><span class="p">}</span>
            <span class="p">)</span>
            <span class="n">feature_importance_df</span> <span class="o">=</span> <span class="n">feature_importance_df</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span>
                <span class="n">by</span><span class="o">=</span><span class="s2">&quot;Importance&quot;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span>
            <span class="p">)</span>
            <span class="c1"># Append to the list</span>
            <span class="n">feature_importance_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">feature_importance_df</span><span class="p">)</span>
            <span class="c1"># Compute SHAP values</span>
            <span class="n">explainer</span> <span class="o">=</span> <span class="n">shap</span><span class="o">.</span><span class="n">TreeExplainer</span><span class="p">(</span><span class="n">cb_model</span><span class="p">)</span>
            <span class="n">shap_values</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">shap_values</span><span class="p">(</span><span class="n">X_test_fold</span><span class="p">)</span>
            <span class="n">shap_values_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">shap_values</span><span class="p">)</span>
            <span class="n">fold_data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">X_test_fold</span><span class="p">)</span> <span class="c1"># for subsequent SHAP vs feature value analyses</span>
            <span class="n">y_fold_data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_test_fold</span><span class="p">)</span>
            
            <span class="n">predictions_proba_fold</span> <span class="o">=</span> <span class="n">cb_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test_fold</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
            <span class="n">predictions_proba_fold_train</span> <span class="o">=</span> <span class="n">cb_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_train_fold</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
            <span class="n">predictions_proba_fold_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">predictions_proba_fold</span><span class="p">)</span>
            <span class="n">predictions_proba_fold_train_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">predictions_proba_fold_train</span><span class="p">)</span>

        <span class="c1"># Check if the specified model class is LogisticRegression (logistic regression regularized on both L1 and L2 terms - elasticnet)</span>
        <span class="k">elif</span> <span class="n">model_class</span> <span class="o">==</span> <span class="n">LogisticRegression</span><span class="p">:</span>
            <span class="c1"># Define the Logistic Regression classifier (configured as elasticnet)</span>
            <span class="n">lr_model</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">penalty</span><span class="o">=</span><span class="s1">&#39;l1&#39;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s2">&quot;liblinear&quot;</span><span class="p">,</span> <span class="o">**</span><span class="n">lr_params</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">hp_tuning</span><span class="p">:</span>
                <span class="c1"># Create a RandomizedSearchCV instance</span>
                <span class="n">random_search</span> <span class="o">=</span> <span class="n">RandomizedSearchCV</span><span class="p">(</span>
                    <span class="n">estimator</span><span class="o">=</span><span class="n">lr_model</span><span class="p">,</span> 
                    <span class="n">param_distributions</span><span class="o">=</span><span class="n">lr_param_dist</span><span class="p">,</span> 
                    <span class="n">n_iter</span><span class="o">=</span><span class="n">n_iter_hptuning</span><span class="p">,</span>
                    <span class="n">scoring</span><span class="o">=</span> <span class="n">custom_scorer</span><span class="p">,</span> 
                    <span class="n">cv</span><span class="o">=</span><span class="n">cv_folds_hptuning</span><span class="p">,</span>
                    <span class="n">refit</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
                    <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span>
                    <span class="n">verbose</span><span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
                    <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_cpu_for_tuning</span>
                <span class="p">)</span>
                <span class="c1"># Perform the random search on the training data</span>
                <span class="n">random_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_fold</span><span class="p">,</span> <span class="n">y_train_fold</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weights_fold</span><span class="p">)</span>
                <span class="c1"># Get the best parameters and best estimator</span>
                <span class="n">best_params</span> <span class="o">=</span> <span class="n">random_search</span><span class="o">.</span><span class="n">best_params_</span>
                <span class="n">lr_model</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">penalty</span><span class="o">=</span><span class="s1">&#39;l1&#39;</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s2">&quot;liblinear&quot;</span><span class="p">,</span> <span class="o">**</span><span class="n">best_params</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">lr_model</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">penalty</span><span class="o">=</span><span class="s1">&#39;l1&#39;</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s2">&quot;liblinear&quot;</span><span class="p">,</span> <span class="o">**</span><span class="n">lr_params</span><span class="p">)</span>
            <span class="c1"># Fit the best estimator on the entire training data</span>
            <span class="n">lr_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_fold</span><span class="p">,</span> <span class="n">y_train_fold</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weights_fold</span><span class="p">)</span>
            <span class="c1"># Get predictions on the test data</span>
            <span class="n">predictions_proba</span> <span class="o">=</span> <span class="n">lr_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test_fold</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
            <span class="n">perm_result</span> <span class="o">=</span> <span class="n">permutation_importance</span><span class="p">(</span>
                <span class="n">lr_model</span><span class="p">,</span> <span class="n">X_test_fold</span><span class="p">,</span> <span class="n">y_test_fold</span><span class="p">,</span> <span class="n">n_repeats</span><span class="o">=</span><span class="n">n_repeats</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_cpu_model_training</span><span class="p">,</span> <span class="n">scoring</span> <span class="o">=</span> <span class="n">custom_scorer</span> <span class="c1">#&quot;roc_auc&quot;</span>
            <span class="p">)</span>
            <span class="c1"># Get feature importances and sort them</span>
            <span class="n">feature_importance</span> <span class="o">=</span> <span class="n">perm_result</span><span class="o">.</span><span class="n">importances_mean</span> <span class="c1"># Mean of feature importance over n_repeats</span>
            <span class="n">feature_importance_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
                <span class="p">{</span><span class="s2">&quot;Feature&quot;</span><span class="p">:</span> <span class="n">X_train_fold</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="s2">&quot;Importance&quot;</span><span class="p">:</span> <span class="n">feature_importance</span><span class="p">}</span>
            <span class="p">)</span>
            <span class="n">feature_importance_df</span> <span class="o">=</span> <span class="n">feature_importance_df</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span>
                <span class="n">by</span><span class="o">=</span><span class="s2">&quot;Importance&quot;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span>
            <span class="p">)</span>
            <span class="c1"># Append to the list</span>
            <span class="n">feature_importance_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">feature_importance_df</span><span class="p">)</span>
            <span class="c1"># Compute SHAP values</span>
            <span class="n">explainer</span> <span class="o">=</span> <span class="n">shap</span><span class="o">.</span><span class="n">LinearExplainer</span><span class="p">(</span><span class="n">lr_model</span><span class="p">,</span> <span class="n">X_train_fold</span><span class="p">)</span>
            <span class="n">shap_values</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">shap_values</span><span class="p">(</span><span class="n">X_test_fold</span><span class="p">)</span>
            <span class="n">shap_values_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">shap_values</span><span class="p">)</span>
            <span class="n">fold_data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">X_test_fold</span><span class="p">)</span> <span class="c1"># for subsequent SHAP vs feature value analyses</span>
            <span class="n">y_fold_data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_test_fold</span><span class="p">)</span>
            
            <span class="n">predictions_proba_fold</span> <span class="o">=</span> <span class="n">lr_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test_fold</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
            <span class="n">predictions_proba_fold_train</span> <span class="o">=</span> <span class="n">lr_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_train_fold</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
            <span class="n">predictions_proba_fold_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">predictions_proba_fold</span><span class="p">)</span>
            <span class="n">predictions_proba_fold_train_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">predictions_proba_fold_train</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">model_class</span> <span class="o">==</span> <span class="n">GaussianNB</span><span class="p">:</span> <span class="c1"># Naive Bayes</span>
            <span class="n">nb_model</span> <span class="o">=</span> <span class="n">GaussianNB</span><span class="p">()</span>
            <span class="n">nb_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_fold</span><span class="p">,</span> <span class="n">y_train_fold</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weights_fold</span><span class="p">)</span>
            <span class="n">predictions_proba</span> <span class="o">=</span> <span class="n">nb_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test_fold</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
            <span class="n">perm_result</span> <span class="o">=</span> <span class="n">permutation_importance</span><span class="p">(</span>
                <span class="n">nb_model</span><span class="p">,</span> <span class="n">X_test_fold</span><span class="p">,</span> <span class="n">y_test_fold</span><span class="p">,</span> <span class="n">n_repeats</span><span class="o">=</span><span class="n">n_repeats</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_cpu_model_training</span><span class="p">,</span> <span class="n">scoring</span> <span class="o">=</span> <span class="n">custom_scorer</span> <span class="c1"># &quot;roc_auc&quot;</span>
            <span class="p">)</span>
            <span class="c1"># Get feature importances and sort them</span>
            <span class="n">feature_importance</span> <span class="o">=</span> <span class="n">perm_result</span><span class="o">.</span><span class="n">importances_mean</span> <span class="c1"># Mean of feature importance over n_repeats</span>
            <span class="n">feature_importance_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
                <span class="p">{</span><span class="s2">&quot;Feature&quot;</span><span class="p">:</span> <span class="n">X_train_fold</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="s2">&quot;Importance&quot;</span><span class="p">:</span> <span class="n">feature_importance</span><span class="p">}</span>
            <span class="p">)</span>
            <span class="n">feature_importance_df</span> <span class="o">=</span> <span class="n">feature_importance_df</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span>
                <span class="n">by</span><span class="o">=</span><span class="s2">&quot;Importance&quot;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span>
            <span class="p">)</span>
            <span class="c1"># Append to the list</span>
            <span class="n">feature_importance_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">feature_importance_df</span><span class="p">)</span>
            <span class="n">treebased_feature_importance</span> <span class="o">=</span> <span class="p">[]</span> <span class="c1"># empty as it is not defined for Naive Bayes model </span>
            <span class="n">treebased_feature_importance_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">treebased_feature_importance</span><span class="p">)</span>
            <span class="c1"># Compute SHAP values </span>
            <span class="n">explainer</span> <span class="o">=</span> <span class="n">shap</span><span class="o">.</span><span class="n">Explainer</span><span class="p">(</span><span class="n">nb_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">,</span> <span class="n">X_train_fold</span><span class="p">)</span>
            <span class="n">shap_values</span> <span class="o">=</span> <span class="n">explainer</span><span class="p">(</span><span class="n">X_test_fold</span><span class="p">)</span>
            <span class="n">shap_values_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">shap_values</span><span class="p">)</span>
            <span class="n">fold_data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">X_test_fold</span><span class="p">)</span> <span class="c1"># for subsequent SHAP vs feature value analyses</span>
            <span class="n">y_fold_data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_test_fold</span><span class="p">)</span>
            
            <span class="n">predictions_proba_fold</span> <span class="o">=</span> <span class="n">nb_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test_fold</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
            <span class="n">predictions_proba_fold_train</span> <span class="o">=</span> <span class="n">nb_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_train_fold</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
            <span class="n">predictions_proba_fold_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">predictions_proba_fold</span><span class="p">)</span>
            <span class="n">predictions_proba_fold_train_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">predictions_proba_fold_train</span><span class="p">)</span>
        <span class="c1"># Aggregate predictions and labels</span>
        <span class="n">aggregated_predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">aggregated_predictions</span><span class="p">,</span> <span class="n">predictions_proba</span><span class="p">))</span>
        <span class="n">aggregated_labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">aggregated_labels</span><span class="p">,</span> <span class="n">y_test_fold</span><span class="p">))</span>
    <span class="c1"># Other processing for each fold goes here</span>
    <span class="k">if</span> <span class="n">overlapping_samples</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Warning: Overlapping test samples found across folds.&quot;</span><span class="p">)</span>
    
    <span class="c1"># Initialize plot objects</span>
    <span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;ROC Curve&#39;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;False Positive Rate&#39;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;True Positive Rate&#39;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Precision-Recall Curve&#39;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Recall&#39;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Precision&#39;</span><span class="p">)</span>
    <span class="c1"># Initialize a list to store thresholds for each fold</span>
    <span class="n">thresholds_per_fold</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">]</span>
    <span class="c1"># Calculate and store metrics for each fold</span>
    <span class="k">for</span> <span class="n">fold</span><span class="p">,</span> <span class="p">(</span><span class="n">train_index</span><span class="p">,</span> <span class="n">test_index</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">skf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">X_test_fold</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
        <span class="n">y_test_fold</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
        <span class="n">predictions_proba_fold</span> <span class="o">=</span> <span class="n">predictions_proba_fold_list</span><span class="p">[</span><span class="n">fold</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
        <span class="n">predictions_proba_fold_train</span> <span class="o">=</span> <span class="n">predictions_proba_fold_train_list</span><span class="p">[</span><span class="n">fold</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
        <span class="n">y_train_fold</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_index</span><span class="p">]</span>
        <span class="c1"># # Get predictions for the current fold using the optimal threshold</span>
            <span class="c1"># Use default threshold if specified</span>
        <span class="k">if</span> <span class="n">use_default_threshold</span><span class="p">:</span>
            <span class="n">opt_threshold_fold</span> <span class="o">=</span> <span class="mf">0.5</span>
        <span class="k">else</span><span class="p">:</span> <span class="c1"># we use prediction probabilities from the train subsets to estimate the optimal threshold for classification</span>
            <span class="n">class_1_probs</span> <span class="o">=</span> <span class="n">predictions_proba_fold_train</span><span class="p">[</span><span class="n">y_train_fold</span> <span class="o">==</span> <span class="kc">True</span><span class="p">]</span>
            <span class="n">class_0_probs</span> <span class="o">=</span> <span class="n">predictions_proba_fold_train</span><span class="p">[</span><span class="n">y_train_fold</span> <span class="o">==</span> <span class="kc">False</span><span class="p">]</span>
            <span class="n">median_class_1_probs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">class_1_probs</span><span class="p">)</span>
            <span class="n">median_class_0_probs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">class_0_probs</span><span class="p">)</span>
            <span class="c1"># Update threshold based on previous folds</span>
            <span class="n">opt_threshold_fold</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">([</span><span class="n">threshold</span> <span class="k">for</span> <span class="n">threshold</span> <span class="ow">in</span> <span class="n">thresholds_per_fold</span><span class="p">])</span>
            <span class="c1"># Append current fold&#39;s threshold to the list</span>
            <span class="n">threshold</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">([</span><span class="n">median_class_1_probs</span><span class="p">,</span> <span class="n">median_class_0_probs</span><span class="p">])</span>
            <span class="n">thresholds_per_fold</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">threshold</span><span class="p">)</span>
        <span class="n">predictions_class_fold</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">predictions_proba_fold</span> <span class="o">&gt;=</span> <span class="n">opt_threshold_fold</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
        <span class="c1">###########</span>
        <span class="c1"># Find the indices where y_test_fold does not equal predictions_class_fold</span>
        <span class="n">missclassified_samples_fold</span> <span class="o">=</span> <span class="n">y_test_fold</span><span class="o">.</span><span class="n">index</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y_test_fold</span> <span class="o">!=</span> <span class="n">predictions_class_fold</span><span class="p">)[</span><span class="mi">0</span><span class="p">]]</span>
        <span class="n">missclassified_samples</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">missclassified_samples_fold</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
        <span class="c1">###########</span>
        <span class="c1"># Calculate metrics</span>
        <span class="n">metrics</span> <span class="o">=</span> <span class="n">calculate_metrics</span><span class="p">(</span><span class="n">y_test_fold</span><span class="p">,</span> <span class="n">predictions_class_fold</span><span class="p">,</span> <span class="n">predictions_proba_fold</span><span class="p">)</span>
        <span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;Fold&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">fold</span>
        <span class="c1"># fold_results = fold_results.append(metrics, ignore_index=True)</span>
        <span class="n">fold_results</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">fold_results</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">metrics</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">])],</span> <span class="n">ignore_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="c1"># Compute ROC and PR curve values</span>
        <span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test_fold</span><span class="p">,</span> <span class="n">predictions_proba_fold</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">drop_intermediate</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">precision_recall_curve</span><span class="p">(</span><span class="n">y_test_fold</span><span class="p">,</span> <span class="n">predictions_proba_fold</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="c1"># Create a DataFrame for the current fold&#39;s results</span>
        <span class="n">fold_results_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
            <span class="s1">&#39;fold&#39;</span><span class="p">:</span> <span class="n">fold</span><span class="p">,</span>
            <span class="s1">&#39;fpr&#39;</span><span class="p">:</span> <span class="nb">list</span><span class="p">(</span><span class="n">fpr</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">recall</span><span class="p">)</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">fpr</span><span class="p">)),</span>  <span class="c1"># Padding to match lengths</span>
            <span class="s1">&#39;tpr&#39;</span><span class="p">:</span> <span class="nb">list</span><span class="p">(</span><span class="n">tpr</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">recall</span><span class="p">)</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">tpr</span><span class="p">)),</span>  <span class="c1"># Padding to match lengths</span>
            <span class="s1">&#39;precision&#39;</span><span class="p">:</span> <span class="nb">list</span><span class="p">(</span><span class="n">precision</span><span class="p">),</span>
            <span class="s1">&#39;recall&#39;</span><span class="p">:</span> <span class="nb">list</span><span class="p">(</span><span class="n">recall</span><span class="p">)</span>
        <span class="p">})</span>
        <span class="c1"># Append the current fold&#39;s results to the existing results DataFrame</span>
        <span class="n">fold_results_plt</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">fold_results_plt</span><span class="p">,</span> <span class="n">fold_results_df</span><span class="p">],</span> <span class="n">ignore_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="c1"># Plot ROC and PR curves for the current fold</span>
        <span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Fold </span><span class="si">{</span><span class="n">fold</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
        <span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">recall</span><span class="p">,</span> <span class="n">precision</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Fold </span><span class="si">{</span><span class="n">fold</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="c1"># Finalize plots</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;lower right&#39;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;lower left&#39;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_facecolor</span><span class="p">(</span><span class="s1">&#39;white&#39;</span><span class="p">)</span>
    <span class="c1"># show both grid lines</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">&#39;both&#39;</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s2">&quot;grey&quot;</span><span class="p">)</span>
    <span class="c1"># modify grid lines:</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">&#39;minor&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">&#39;major&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;chance level&#39;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mf">1.1</span><span class="p">])</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;False Positive Rate&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;True Positive Rate&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;ROC curve&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s2">&quot;lower right&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;grey&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;-&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>  
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_facecolor</span><span class="p">(</span><span class="s1">&#39;white&#39;</span><span class="p">)</span>
    <span class="c1"># show both grid lines</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">&#39;both&#39;</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s2">&quot;grey&quot;</span><span class="p">)</span>
    <span class="c1"># modify grid lines:</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">&#39;minor&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">&#39;major&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mf">1.1</span><span class="p">])</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Recall&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Precision&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Precision-Recall curve&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s2">&quot;lower left&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;grey&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;-&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>  
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    <span class="c1"># Aggregate results across folds</span>
    <span class="k">if</span> <span class="n">use_default_threshold</span><span class="p">:</span>
        <span class="n">opt_threshold</span> <span class="o">=</span> <span class="mf">0.5</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># Drop the first entry of thresholds_per_fold that is 0.5</span>
        <span class="n">thresholds_per_fold</span> <span class="o">=</span> <span class="n">thresholds_per_fold</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
        <span class="n">opt_threshold</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">thresholds_per_fold</span><span class="p">)</span>
    <span class="n">aggregated_results</span> <span class="o">=</span> <span class="p">{</span><span class="n">metric</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">nanmean</span><span class="p">(</span><span class="n">fold_results</span><span class="p">[</span><span class="n">metric</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="k">for</span> <span class="n">metric</span> <span class="ow">in</span> <span class="n">measures</span><span class="p">}</span>
    <span class="n">aggregated_results_sd</span> <span class="o">=</span> <span class="p">{</span><span class="n">metric</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">nanstd</span><span class="p">(</span><span class="n">fold_results</span><span class="p">[</span><span class="n">metric</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="k">for</span> <span class="n">metric</span> <span class="ow">in</span> <span class="n">measures</span><span class="p">}</span>
    <span class="c1"># Combining mean and standard deviation</span>
    <span class="n">combined_results</span> <span class="o">=</span> <span class="p">{</span><span class="n">metric</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">mean</span><span class="si">}</span><span class="s2"> ± </span><span class="si">{</span><span class="n">sd</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">metric</span><span class="p">,</span> <span class="n">mean</span> <span class="ow">in</span> <span class="n">aggregated_results</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">sd</span> <span class="ow">in</span> <span class="n">aggregated_results_sd</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">metric</span> <span class="o">==</span> <span class="n">_</span><span class="p">}</span>
    <span class="c1"># Creating a DataFrame for tabular display</span>
    <span class="n">results_table</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">combined_results</span><span class="o">.</span><span class="n">items</span><span class="p">()),</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Metric&#39;</span><span class="p">,</span> <span class="s1">&#39;Result&#39;</span><span class="p">])</span>
    <span class="c1"># Displaying the results</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Aggregated Results:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">results_table</span><span class="o">.</span><span class="n">to_string</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">fold_results</span><span class="p">,</span> <span class="n">results_table</span><span class="p">,</span> <span class="n">opt_threshold</span><span class="p">,</span> <span class="n">feature_importance_list</span><span class="p">,</span> <span class="n">treebased_feature_importance_list</span><span class="p">,</span> <span class="n">shap_values_list</span><span class="p">,</span> <span class="n">fold_results_plt</span><span class="p">,</span> <span class="n">fold_data</span><span class="p">,</span> <span class="n">missclassified_samples</span><span class="p">,</span> <span class="n">y_fold_data</span><span class="p">,</span> <span class="n">predictions_proba_fold_list</span>
</pre></div>
</div>
</div>
</div>
<section id="shap-summary-plot-for-when-the-model-uses-categorical-features">
<h4>SHAP summary plot for when the model uses categorical features<a class="headerlink" href="#shap-summary-plot-for-when-the-model-uses-categorical-features" title="Link to this heading">#</a></h4>
<p>This function resolves the issue of not showing the levels of categorical features on the SHAP summary plot from shap package in Python.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">categorical_shap_plot</span><span class="p">(</span><span class="n">shap_values</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">top_n</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">jitter</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This function creates a plot of SHAP values for the top N features in a dataset, where categorical features are displayed as scatter plots with different colors and numerical features are displayed as individual points. The plot includes a colorbar for numerical features and labels for categorical features.</span>

<span class="sd">    ## Parameters:</span>
<span class="sd">        shap_values (numpy array): Matrix of SHAP values to be plotted.</span>
<span class="sd">        data (pandas DataFrame): Dataset containing feature names and values.</span>
<span class="sd">        top_n (int, optional): Number of top features to include in the plot. Defaults to 10.</span>
<span class="sd">        jitter (float, optional): Jitter value for scatter plots. Defaults to 0.1.</span>

<span class="sd">    ## Returns</span>
<span class="sd">        fig: Matplotlib figure object containing the SHAP plot.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Ensure data and shap_values are consistent</span>
    <span class="k">assert</span> <span class="n">shap_values</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="s2">&quot;Mismatch between shap_values and data&quot;</span>

    <span class="n">feature_names</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">columns</span>

    <span class="c1"># Calculate the mean absolute SHAP values to rank feature importance</span>
    <span class="n">mean_shap_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">shap_values</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">sorted_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">mean_shap_values</span><span class="p">)[::</span><span class="o">-</span><span class="mi">1</span><span class="p">][:</span><span class="n">top_n</span><span class="p">]</span>

    <span class="n">top_n_features</span> <span class="o">=</span> <span class="n">feature_names</span><span class="p">[</span><span class="n">sorted_indices</span><span class="p">]</span>

    <span class="c1"># an empty dictionary to store categorical features and their categories</span>
    <span class="n">cat_features</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="c1"># Identify and store categories for categorical features</span>
    <span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="n">top_n_features</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">data</span><span class="p">[</span><span class="n">feature</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">name</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;category&#39;</span><span class="p">,</span> <span class="s1">&#39;object&#39;</span><span class="p">]:</span>
            <span class="n">categories</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">feature</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
            <span class="n">cat_features</span><span class="p">[</span><span class="n">feature</span><span class="p">]</span> <span class="o">=</span> <span class="n">categories</span>

    <span class="c1"># Extract all unique categories for the top n features</span>
    <span class="n">unique_categories</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span><span class="o">.</span><span class="n">union</span><span class="p">(</span><span class="o">*</span><span class="n">cat_features</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
    <span class="n">num_categories</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">unique_categories</span><span class="p">)</span>
    <span class="n">cmap_grey</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">get_cmap</span><span class="p">(</span><span class="s1">&#39;Set1&#39;</span><span class="p">)</span>
    <span class="n">category_colors</span> <span class="o">=</span> <span class="n">cmap_grey</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">num_categories</span><span class="p">))</span>

    <span class="c1"># Create a dictionary to map each category to a distinct marker</span>
    <span class="n">category_marker_dictionary</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">category_markers</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;s&#39;</span><span class="p">,</span> <span class="s1">&#39;D&#39;</span><span class="p">,</span> <span class="s1">&#39;P&#39;</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">,</span> <span class="s1">&#39;^&#39;</span><span class="p">,</span> <span class="s1">&#39;v&#39;</span><span class="p">,</span> <span class="s1">&#39;&lt;&#39;</span><span class="p">,</span> <span class="s1">&#39;&gt;&#39;</span><span class="p">,</span> <span class="s1">&#39;H&#39;</span><span class="p">,</span> <span class="s1">&#39;h&#39;</span><span class="p">,</span> <span class="s1">&#39;+&#39;</span><span class="p">,</span> <span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="s1">&#39;p&#39;</span><span class="p">,</span> <span class="s1">&#39;d&#39;</span><span class="p">,</span> <span class="s1">&#39;1&#39;</span><span class="p">,</span> <span class="s1">&#39;2&#39;</span><span class="p">,</span> <span class="s1">&#39;3&#39;</span><span class="p">,</span> <span class="s1">&#39;4&#39;</span><span class="p">,</span> <span class="s1">&#39;|&#39;</span><span class="p">,</span> <span class="s1">&#39;_&#39;</span><span class="p">,</span> <span class="s1">&#39;,&#39;</span><span class="p">,</span> <span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="s1">&#39;8&#39;</span><span class="p">]</span>

    <span class="k">for</span> <span class="n">category</span> <span class="ow">in</span> <span class="n">unique_categories</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">category_markers</span><span class="p">:</span>
            <span class="n">category_marker_dictionary</span><span class="p">[</span><span class="n">category</span><span class="p">]</span> <span class="o">=</span> <span class="n">category_markers</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Warning: Not enough markers available.&quot;</span><span class="p">)</span>
            <span class="k">break</span>

    <span class="c1"># Calculate the height based on the number of rows</span>
    <span class="n">height</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">top_n</span><span class="p">)]))</span>
    <span class="n">max_height</span> <span class="o">=</span> <span class="mi">65535</span> <span class="o">/</span> <span class="mi">72</span>  <span class="c1"># Convert pixels to inches</span>
    <span class="k">if</span> <span class="n">height</span> <span class="o">&gt;</span> <span class="n">max_height</span><span class="p">:</span>
        <span class="n">height</span> <span class="o">=</span> <span class="n">max_height</span>

    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">height</span><span class="p">))</span>
    <span class="n">cmap</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">get_cmap</span><span class="p">(</span><span class="s1">&#39;bwr&#39;</span><span class="p">)</span>

    <span class="n">displayed_categories</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
    <span class="n">legend_handles</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">legend_labels</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sorted_indices</span><span class="p">):</span>
        <span class="n">feature_shap_values</span> <span class="o">=</span> <span class="n">shap_values</span><span class="p">[:,</span> <span class="n">idx</span><span class="p">]</span>
        <span class="n">feature_values</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="n">idx</span><span class="p">]</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">feature_names</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="ow">in</span> <span class="n">cat_features</span><span class="p">:</span>
            <span class="c1"># Handle categorical features</span>
            <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">category</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">unique_categories</span><span class="p">):</span>
                <span class="n">mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">feature_names</span><span class="p">[</span><span class="n">idx</span><span class="p">]]</span> <span class="o">==</span> <span class="n">category</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">jitter_values</span> <span class="o">=</span> <span class="n">jitter</span> <span class="o">*</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">mask</span><span class="p">))</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">)</span>
                    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">feature_shap_values</span><span class="p">[</span><span class="n">mask</span><span class="p">],</span>
                               <span class="p">[</span><span class="n">top_n</span> <span class="o">-</span> <span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span> <span class="o">+</span> <span class="n">jitter_values</span><span class="p">,</span>
                               <span class="n">facecolors</span><span class="o">=</span><span class="n">category_colors</span><span class="p">[</span><span class="n">j</span> <span class="o">%</span> <span class="n">num_categories</span><span class="p">],</span>
                               <span class="n">edgecolors</span><span class="o">=</span><span class="s1">&#39;grey&#39;</span><span class="p">,</span>
                               <span class="n">marker</span><span class="o">=</span><span class="n">category_marker_dictionary</span><span class="p">[</span><span class="n">category</span><span class="p">],</span> 
                               <span class="n">s</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span>
                               <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

                    <span class="k">if</span> <span class="n">category</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">displayed_categories</span><span class="p">:</span>
                        <span class="n">legend_handles</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">plt</span><span class="o">.</span><span class="n">Line2D</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">],</span> 
                                                         <span class="n">marker</span><span class="o">=</span><span class="n">category_marker_dictionary</span><span class="p">[</span><span class="n">category</span><span class="p">],</span> 
                                                         <span class="n">color</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">,</span>
                                                         <span class="n">markerfacecolor</span><span class="o">=</span><span class="n">category_colors</span><span class="p">[</span><span class="n">j</span> <span class="o">%</span> <span class="n">num_categories</span><span class="p">],</span> 
                                                         <span class="n">markeredgecolor</span><span class="o">=</span><span class="s1">&#39;grey&#39;</span><span class="p">,</span> 
                                                         <span class="n">markersize</span><span class="o">=</span><span class="mi">5</span><span class="p">))</span>
                        <span class="n">legend_labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">category</span><span class="p">)</span>
                        <span class="n">displayed_categories</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">category</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Handle numerical features</span>
            <span class="n">numeric_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">feature_values</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
            <span class="n">missing_mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">numeric_values</span><span class="p">)</span>  <span class="c1"># Handle missing values</span>

            <span class="c1"># Plot missing values in grey</span>
            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">missing_mask</span><span class="p">):</span>
                <span class="n">jitter_values_missing</span> <span class="o">=</span> <span class="n">jitter</span> <span class="o">*</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">missing_mask</span><span class="p">))</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">)</span>
                <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">feature_shap_values</span><span class="p">[</span><span class="n">missing_mask</span><span class="p">],</span> 
                        <span class="p">[</span><span class="n">top_n</span> <span class="o">-</span> <span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">missing_mask</span><span class="p">)</span> <span class="o">+</span> <span class="n">jitter_values_missing</span><span class="p">,</span>
                        <span class="n">c</span><span class="o">=</span><span class="s1">&#39;grey&#39;</span><span class="p">,</span> 
                        <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> 
                        <span class="n">edgecolors</span><span class="o">=</span><span class="s1">&#39;grey&#39;</span><span class="p">,</span>
                        <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span>
                        <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Missing&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span>
                       <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
            
            <span class="n">normalized_values</span> <span class="o">=</span> <span class="n">QuantileTransformer</span><span class="p">(</span><span class="n">output_distribution</span><span class="o">=</span><span class="s1">&#39;uniform&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">numeric_values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
            <span class="n">jitter_values</span> <span class="o">=</span> <span class="n">jitter</span> <span class="o">*</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">feature_shap_values</span><span class="p">))</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">feature_shap_values</span><span class="p">,</span> 
                       <span class="p">[</span><span class="n">top_n</span> <span class="o">-</span> <span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">feature_shap_values</span><span class="p">)</span> <span class="o">+</span> <span class="n">jitter_values</span><span class="p">,</span>
                       <span class="n">c</span><span class="o">=</span><span class="n">normalized_values</span><span class="p">,</span>
                       <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">,</span>
                       <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;o&quot;</span><span class="p">,</span>
                       <span class="n">edgecolors</span><span class="o">=</span><span class="s1">&#39;grey&#39;</span><span class="p">,</span>
                       <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span>
                       <span class="n">s</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span>
                       <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>


    <span class="c1"># Set y-axis ticks and labels</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">top_n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">([</span><span class="n">feature_names</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">sorted_indices</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]],</span> <span class="n">rotation</span><span class="o">=</span><span class="s1">&#39;horizontal&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>

    <span class="c1"># Set x-axis label</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;SHAP values&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>

    <span class="c1"># Add colorbar for numerical features</span>
    <span class="n">sm</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">ScalarMappable</span><span class="p">(</span><span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">)</span>
    <span class="n">sm</span><span class="o">.</span><span class="n">set_array</span><span class="p">([])</span>
    <span class="n">cbar</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">sm</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">orientation</span><span class="o">=</span><span class="s1">&#39;vertical&#39;</span><span class="p">)</span>
    <span class="n">cbar</span><span class="o">.</span><span class="n">ax</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;both&#39;</span><span class="p">,</span> <span class="n">labelsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>

    <span class="c1"># Add legend for categorical features</span>
    <span class="k">if</span> <span class="n">legend_handles</span><span class="p">:</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">legend_handles</span><span class="p">,</span> <span class="n">legend_labels</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="s1">&#39;lower right&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>

    <span class="c1"># Add a midline</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="n">cbar</span><span class="o">.</span><span class="n">set_label</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;Feature value&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s1">&#39;font.size&#39;</span><span class="p">:</span> <span class="mi">8</span><span class="p">})</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;:&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">labelsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;top&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;left&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;right&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">fig</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="qlattice-model">
<h4>QLattice model<a class="headerlink" href="#qlattice-model" title="Link to this heading">#</a></h4>
<p>The QLattice, integrated into the Feyn Python library, represents a cutting-edge approach to supervised machine learning known as symbolic regression. It specializes in identifying the most suitable mathematical models to describe complex datasets. Through an iterative process of training, the QLattice prioritizes simplicity while maintaining high performance.</p>
<p>More information: <a class="reference external" href="https://docs.abzu.ai/docs/guides/getting_started/qlattice">https://docs.abzu.ai/docs/guides/getting_started/qlattice</a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="s2">&quot;QLattice_mdl&quot;</span> <span class="ow">in</span> <span class="n">models_to_include</span><span class="p">:</span>
    <span class="n">fold_results_QLattice</span><span class="p">,</span> <span class="n">aggregated_results_QLattice</span><span class="p">,</span> <span class="n">opt_threshold_QLattice</span><span class="p">,</span> <span class="n">FI_QLattice</span><span class="p">,</span> <span class="n">treeFI_QLattice</span><span class="p">,</span> <span class="n">shap_QLattice</span><span class="p">,</span> <span class="n">fold_results_plt_Qlattice</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">missclassified_samples_QLattice</span><span class="p">,</span> <span class="n">y_fold</span><span class="p">,</span> <span class="n">pp_fold_QLattice</span> <span class="o">=</span> <span class="n">cross_validate_model</span><span class="p">(</span><span class="n">model_class</span><span class="o">=</span><span class="s1">&#39;QLattice&#39;</span><span class="p">,</span>
                                                                                                                <span class="n">X</span><span class="o">=</span><span class="n">X_train_imputed</span><span class="p">,</span>
                                                                                                                <span class="n">y</span><span class="o">=</span><span class="n">y_train</span><span class="p">,</span>
                                                                                                                <span class="n">sample_weights</span><span class="o">=</span><span class="n">sample_weights</span><span class="p">,</span>
                                                                                                                <span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">,</span>
                                                                                                                <span class="n">use_default_threshold</span><span class="o">=</span><span class="n">use_default_threshold</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="s2">&quot;QLattice_mdl&quot;</span> <span class="ow">in</span> <span class="n">models_to_include</span><span class="p">:</span>
    <span class="c1"># plot permutation-based feature importance</span>
    <span class="n">plot_PFI</span><span class="p">(</span><span class="n">PFI_folds</span><span class="o">=</span><span class="n">FI_QLattice</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">X_train</span><span class="p">,</span> <span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;QLattice&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="s2">&quot;QLattice_mdl&quot;</span> <span class="ow">in</span> <span class="n">models_to_include</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">export_missclassified</span><span class="p">:</span>
        <span class="n">misclassified_ids</span> <span class="o">=</span> <span class="n">mydata_backup</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">missclassified_samples_QLattice</span><span class="p">,</span> <span class="s1">&#39;ID&#39;</span><span class="p">]</span>
        
        <span class="n">misclassified_ids_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">misclassified_ids</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Misclassified_IDs&#39;</span><span class="p">])</span>
        <span class="n">misclassified_ids_df</span><span class="o">.</span><span class="n">to_excel</span><span class="p">(</span><span class="s1">&#39;misclassified_ids_QLattice.xlsx&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cat_features</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="gaussian-naive-bayes">
<h4>Gaussian Naive Bayes<a class="headerlink" href="#gaussian-naive-bayes" title="Link to this heading">#</a></h4>
<p>Gaussian Naive Bayes (GaussianNB) is a classification algorithm implemented in Python’s scikit-learn library. It assumes that the likelihood of features follows a Gaussian distribution. The algorithm estimates parameters using maximum likelihood. In practice, GaussianNB is commonly used for classification tasks when dealing with continuous data.</p>
<p>Read more here: <a class="reference external" href="https://scikit-learn.org/stable/modules/naive_bayes.html">https://scikit-learn.org/stable/modules/naive_bayes.html</a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="s2">&quot;NaiveBayes_mdl&quot;</span> <span class="ow">in</span> <span class="n">models_to_include</span><span class="p">:</span>
    <span class="n">fold_results_NB</span><span class="p">,</span> <span class="n">aggregated_results_NB</span><span class="p">,</span> <span class="n">opt_threshold_NB</span><span class="p">,</span> <span class="n">fi_NB</span><span class="p">,</span> <span class="n">treeFI_NB</span><span class="p">,</span> <span class="n">shap_NB</span><span class="p">,</span> <span class="n">fold_results_plt_NB</span><span class="p">,</span> <span class="n">fold_data_NB</span><span class="p">,</span> <span class="n">missclassified_samples_NB</span><span class="p">,</span> <span class="n">y_fold</span><span class="p">,</span> <span class="n">pp_fold_NB</span> <span class="o">=</span> <span class="n">cross_validate_model</span><span class="p">(</span><span class="n">model_class</span><span class="o">=</span><span class="n">GaussianNB</span><span class="p">,</span>
                                                                                                <span class="n">X</span><span class="o">=</span><span class="n">X_train_OHE</span><span class="p">,</span>
                                                                                                <span class="n">y</span><span class="o">=</span><span class="n">y_train</span><span class="p">,</span>
                                                                                                <span class="n">sample_weights</span><span class="o">=</span><span class="n">sample_weights</span><span class="p">,</span>
                                                                                                <span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">,</span>
                                                                                                <span class="n">use_default_threshold</span><span class="o">=</span><span class="n">use_default_threshold</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="s2">&quot;NaiveBayes_mdl&quot;</span> <span class="ow">in</span> <span class="n">models_to_include</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">export_missclassified</span><span class="p">:</span>
        <span class="n">misclassified_ids</span> <span class="o">=</span> <span class="n">mydata_backup</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">missclassified_samples_NB</span><span class="p">,</span> <span class="s1">&#39;ID&#39;</span><span class="p">]</span>
        
        <span class="n">misclassified_ids_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">misclassified_ids</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Misclassified_IDs&#39;</span><span class="p">])</span>
        <span class="n">misclassified_ids_df</span><span class="o">.</span><span class="n">to_excel</span><span class="p">(</span><span class="s1">&#39;misclassified_ids_NB.xlsx&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="s2">&quot;NaiveBayes_mdl&quot;</span> <span class="ow">in</span> <span class="n">models_to_include</span><span class="p">:</span>
    <span class="c1"># plot permutation-based feature importance</span>
    <span class="n">plot_PFI</span><span class="p">(</span><span class="n">PFI_folds</span><span class="o">=</span><span class="n">fi_NB</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">X_train_OHE</span><span class="p">,</span> <span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;NB&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="s2">&quot;NaiveBayes_mdl&quot;</span> <span class="ow">in</span> <span class="n">models_to_include</span><span class="p">:</span>
    <span class="n">shap_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">fold</span><span class="o">.</span><span class="n">values</span> <span class="k">for</span> <span class="n">fold</span> <span class="ow">in</span> <span class="n">shap_NB</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="c1"># Concatenate SHAP values and DataFrames</span>
    <span class="n">all_columns</span> <span class="o">=</span> <span class="n">fold_data_NB</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">columns</span>
    <span class="n">fold_data_all</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">fold</span> <span class="k">for</span> <span class="n">fold</span> <span class="ow">in</span> <span class="n">fold_data_NB</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">fold_data_all</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="n">all_columns</span>
    <span class="c1"># SHAP summary plot based on the cross validation results</span>
    <span class="n">shap_summary_plot</span><span class="p">(</span><span class="n">shap_values</span><span class="o">=</span><span class="n">shap_values</span><span class="p">[:,:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">data</span><span class="o">=</span><span class="n">fold_data_all</span><span class="p">,</span> <span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;NB&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="s2">&quot;NaiveBayes_mdl&quot;</span> <span class="ow">in</span> <span class="n">models_to_include</span><span class="p">:</span>
    
    <span class="n">PFI_median</span> <span class="o">=</span> <span class="n">PFI_median_wrap</span><span class="p">(</span><span class="n">fi_NB</span><span class="p">)</span>
    <span class="n">PFI_median</span> <span class="o">=</span> <span class="n">PFI_median</span><span class="p">[[</span><span class="s1">&#39;Feature&#39;</span><span class="p">,</span> <span class="s1">&#39;Importance&#39;</span><span class="p">]]</span>
    
    <span class="c1"># a DataFrame with SHAP values for positive class predictions</span>
    <span class="n">shap_df_positive</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">shap_values</span><span class="p">[:,:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">columns</span><span class="o">=</span><span class="n">fold_data_NB</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>

    <span class="c1"># Calculate the median absolute SHAP value across folds for each feature</span>
    <span class="n">median_abs_shap_positive</span> <span class="o">=</span> <span class="n">shap_df_positive</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span><span class="o">.</span><span class="n">median</span><span class="p">()</span>

    <span class="c1"># Sort features by their median absolute SHAP value</span>
    <span class="n">sorted_features_positive</span> <span class="o">=</span> <span class="n">median_abs_shap_positive</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">index</span>

    <span class="c1"># Take absolute values of SHAP dataframe</span>
    <span class="c1"># Reorder SHAP dataframe based on sorted features</span>
    <span class="n">shap_df_sorted_positive</span> <span class="o">=</span> <span class="n">shap_df_positive</span><span class="p">[</span><span class="n">sorted_features_positive</span><span class="p">]</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span>
    <span class="c1"># Take absolute values of SHAP dataframe</span>
    <span class="n">shap_df_sorted_positive_T</span> <span class="o">=</span> <span class="n">shap_df_sorted_positive</span><span class="o">.</span><span class="n">T</span>

    <span class="c1"># Calculate the median importance across samples</span>
    <span class="n">SHAPFI_median</span> <span class="o">=</span> <span class="n">shap_df_sorted_positive_T</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">SHAPFI_median</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;Feature&#39;</span><span class="p">:</span> <span class="n">SHAPFI_median</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="s1">&#39;Importance&#39;</span><span class="p">:</span> <span class="n">SHAPFI_median</span><span class="o">.</span><span class="n">values</span><span class="p">})</span>
    <span class="c1"># normalization</span>
    <span class="n">SHAPFI_median</span><span class="p">[</span><span class="s1">&#39;Importance&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">minmax_scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">SHAPFI_median</span><span class="p">[[</span><span class="s1">&#39;Importance&#39;</span><span class="p">]])</span>

    <span class="c1"># Merge PFI_median, SHAPFI_median, and TFI_median dataframes by &quot;Feature&quot;</span>
    <span class="n">FI_merged_df</span> <span class="o">=</span> <span class="n">PFI_median</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">SHAPFI_median</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="s2">&quot;Feature&quot;</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s1">&#39;outer&#39;</span><span class="p">,</span> <span class="n">suffixes</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;_PFI&#39;</span><span class="p">,</span> <span class="s1">&#39;_SHAP&#39;</span><span class="p">))</span>

    <span class="c1"># Take the mean of importance values across different methods</span>
    <span class="n">FI_merged_df</span><span class="p">[</span><span class="s1">&#39;Normalized_Mean_Importance&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">FI_merged_df</span><span class="p">[[</span><span class="s1">&#39;Importance_PFI&#39;</span><span class="p">,</span> <span class="s1">&#39;Importance_SHAP&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># Sort features by their mean importance</span>
    <span class="n">FI_merged_df</span> <span class="o">=</span> <span class="n">FI_merged_df</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s2">&quot;Normalized_Mean_Importance&quot;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">FI_merged_df</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="s2">&quot;LogisticRegression_mdl&quot;</span> <span class="ow">in</span> <span class="n">models_to_include</span><span class="p">:</span>
    <span class="n">fold_results_LR</span><span class="p">,</span> <span class="n">aggregated_results_LR</span><span class="p">,</span> <span class="n">opt_threshold_LR</span><span class="p">,</span> <span class="n">FI_LR</span><span class="p">,</span> <span class="n">treeFI_LR</span><span class="p">,</span> <span class="n">shap_LR</span><span class="p">,</span> <span class="n">fold_results_plt_LR</span><span class="p">,</span> <span class="n">fold_data_LR</span><span class="p">,</span> <span class="n">missclassified_samples_LR</span><span class="p">,</span> <span class="n">y_fold</span><span class="p">,</span> <span class="n">pp_fold_LR</span> <span class="o">=</span> <span class="n">cross_validate_model</span><span class="p">(</span><span class="n">model_class</span><span class="o">=</span><span class="n">LogisticRegression</span><span class="p">,</span>
                                                                                                <span class="n">X</span><span class="o">=</span><span class="n">X_train_OHE</span><span class="p">,</span>
                                                                                                <span class="n">y</span><span class="o">=</span><span class="n">y_train</span><span class="p">,</span>
                                                                                                <span class="n">sample_weights</span><span class="o">=</span><span class="n">sample_weights</span><span class="p">,</span>
                                                                                                <span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">,</span>
                                                                                                <span class="n">use_default_threshold</span><span class="o">=</span><span class="n">use_default_threshold</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="s2">&quot;LogisticRegression_mdl&quot;</span> <span class="ow">in</span> <span class="n">models_to_include</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">export_missclassified</span><span class="p">:</span>
        <span class="n">misclassified_ids</span> <span class="o">=</span> <span class="n">mydata_backup</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">missclassified_samples_LR</span><span class="p">,</span> <span class="s1">&#39;ID&#39;</span><span class="p">]</span>
        
        <span class="n">misclassified_ids_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">misclassified_ids</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Misclassified_IDs&#39;</span><span class="p">])</span>
        <span class="n">misclassified_ids_df</span><span class="o">.</span><span class="n">to_excel</span><span class="p">(</span><span class="s1">&#39;misclassified_ids_LR.xlsx&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="s2">&quot;LogisticRegression_mdl&quot;</span> <span class="ow">in</span> <span class="n">models_to_include</span><span class="p">:</span>
    <span class="c1"># plot permutation-based feature importance</span>
    <span class="n">plot_PFI</span><span class="p">(</span><span class="n">PFI_folds</span><span class="o">=</span><span class="n">FI_LR</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">X_train_OHE</span><span class="p">,</span> <span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;LR&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="s2">&quot;LogisticRegression_mdl&quot;</span> <span class="ow">in</span> <span class="n">models_to_include</span><span class="p">:</span>
    <span class="c1"># Concatenate SHAP values and DataFrames</span>
    <span class="n">all_columns</span> <span class="o">=</span> <span class="n">fold_data_LR</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">columns</span>
    <span class="n">fold_data_all</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">fold</span> <span class="k">for</span> <span class="n">fold</span> <span class="ow">in</span> <span class="n">fold_data_LR</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">fold_data_all</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="n">all_columns</span>
    <span class="n">shap_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">fold</span> <span class="k">for</span> <span class="n">fold</span> <span class="ow">in</span> <span class="n">shap_LR</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="c1"># SHAP summary plot based on the cross validation results</span>
    <span class="n">shap_summary_plot</span><span class="p">(</span><span class="n">shap_values</span><span class="o">=</span><span class="n">shap_values</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">fold_data_all</span><span class="p">,</span> <span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;LR&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="s2">&quot;LogisticRegression_mdl&quot;</span> <span class="ow">in</span> <span class="n">models_to_include</span><span class="p">:</span>
    
    <span class="c1"># permutation-based feature importance</span>
    <span class="n">PFI_median</span> <span class="o">=</span> <span class="n">PFI_median_wrap</span><span class="p">(</span><span class="n">FI_LR</span><span class="p">)</span>
    <span class="n">PFI_median</span> <span class="o">=</span> <span class="n">PFI_median</span><span class="p">[[</span><span class="s1">&#39;Feature&#39;</span><span class="p">,</span> <span class="s1">&#39;Importance&#39;</span><span class="p">]]</span>
    <span class="c1"># Create a DataFrame with SHAP values for positive class predictions</span>
    <span class="n">shap_df_positive</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">shap_values</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">fold_data_LR</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>

    <span class="c1"># Calculate the median absolute SHAP value across folds for each feature</span>
    <span class="n">median_abs_shap_positive</span> <span class="o">=</span> <span class="n">shap_df_positive</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span><span class="o">.</span><span class="n">median</span><span class="p">()</span>

    <span class="c1"># Sort features by their median absolute SHAP value</span>
    <span class="n">sorted_features_positive</span> <span class="o">=</span> <span class="n">median_abs_shap_positive</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">index</span>

    <span class="c1"># Take absolute values of SHAP dataframe</span>
    <span class="c1"># Reorder SHAP dataframe based on sorted features</span>
    <span class="n">shap_df_sorted_positive</span> <span class="o">=</span> <span class="n">shap_df_positive</span><span class="p">[</span><span class="n">sorted_features_positive</span><span class="p">]</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span>
    <span class="c1"># Take absolute values of SHAP dataframe</span>
    <span class="n">shap_df_sorted_positive_T</span> <span class="o">=</span> <span class="n">shap_df_sorted_positive</span><span class="o">.</span><span class="n">T</span>

    <span class="c1"># Calculate the median importance across samples</span>
    <span class="n">SHAPFI_median</span> <span class="o">=</span> <span class="n">shap_df_sorted_positive_T</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">SHAPFI_median</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;Feature&#39;</span><span class="p">:</span> <span class="n">SHAPFI_median</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="s1">&#39;Importance&#39;</span><span class="p">:</span> <span class="n">SHAPFI_median</span><span class="o">.</span><span class="n">values</span><span class="p">})</span>
    <span class="c1"># normalization</span>
    <span class="n">SHAPFI_median</span><span class="p">[</span><span class="s1">&#39;Importance&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">minmax_scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">SHAPFI_median</span><span class="p">[[</span><span class="s1">&#39;Importance&#39;</span><span class="p">]])</span>

    <span class="c1"># Merge PFI_median, SHAPFI_median, and TFI_median dataframes by &quot;Feature&quot;</span>
    <span class="n">FI_merged_df</span> <span class="o">=</span> <span class="n">PFI_median</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">SHAPFI_median</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="s2">&quot;Feature&quot;</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s1">&#39;outer&#39;</span><span class="p">,</span> <span class="n">suffixes</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;_PFI&#39;</span><span class="p">,</span> <span class="s1">&#39;_SHAP&#39;</span><span class="p">))</span>

    <span class="c1"># Take the mean of importance values across different methods</span>
    <span class="n">FI_merged_df</span><span class="p">[</span><span class="s1">&#39;Normalized_Mean_Importance&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">FI_merged_df</span><span class="p">[[</span><span class="s1">&#39;Importance_PFI&#39;</span><span class="p">,</span> <span class="s1">&#39;Importance_SHAP&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># Sort features by their mean importance</span>
    <span class="n">FI_merged_df</span> <span class="o">=</span> <span class="n">FI_merged_df</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s2">&quot;Normalized_Mean_Importance&quot;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">FI_merged_df</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="random-forest-classifier-rf">
<h4>Random Forest Classifier (RF)<a class="headerlink" href="#random-forest-classifier-rf" title="Link to this heading">#</a></h4>
<p>The <code class="docutils literal notranslate"><span class="pre">RandomForestClassifier</span></code>, part of the <code class="docutils literal notranslate"><span class="pre">sklearn.ensemble</span></code> module in scikit-learn, is a versatile and powerful tool for classification tasks. It operates as a meta estimator that fits multiple decision tree classifiers on various sub-samples of the dataset, using averaging to enhance predictive accuracy and mitigate overfitting. By default, the classifier uses bootstrap sampling (<code class="docutils literal notranslate"><span class="pre">bootstrap=True</span></code>), and each tree is built using a random subset of features (<code class="docutils literal notranslate"><span class="pre">max_features='sqrt'</span></code>).</p>
<p>Key parameters include:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">n_estimators</span></code>: Number of trees in the forest.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">criterion</span></code>: Function to measure the quality of a split (<code class="docutils literal notranslate"><span class="pre">'gini'</span></code> or <code class="docutils literal notranslate"><span class="pre">'entropy'</span></code>).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">max_depth</span></code>: Maximum depth of the trees.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">min_samples_split</span></code>: Minimum number of samples required to split an internal node.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">min_samples_leaf</span></code>: Minimum number of samples required to be at a leaf node.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">class_weight</span></code>: Adjusts weights inversely proportional to class frequencies to handle imbalanced datasets.</p></li>
</ul>
<p>The <code class="docutils literal notranslate"><span class="pre">RandomForestClassifier</span></code> is highly customizable, allowing for fine-tuning to suit specific datasets and classification challenges. It provides robust performance, especially in scenarios where feature interactions are complex or when the dataset contains a mix of categorical and numerical features.</p>
<p>Read more here: <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html">scikit-learn RandomForestClassifier</a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="s2">&quot;RandomForest_mdl&quot;</span> <span class="ow">in</span> <span class="n">models_to_include</span><span class="p">:</span>
    <span class="n">fold_results_rf</span><span class="p">,</span> <span class="n">aggregated_results_rf</span><span class="p">,</span> <span class="n">opt_threshold_rf</span><span class="p">,</span> <span class="n">FI_rf</span><span class="p">,</span> <span class="n">treeFI_rf</span><span class="p">,</span> <span class="n">shap_rf</span><span class="p">,</span> <span class="n">fold_results_plt_rf</span><span class="p">,</span> <span class="n">fold_data_rf</span><span class="p">,</span> <span class="n">missclassified_samples_rf</span><span class="p">,</span> <span class="n">y_fold</span><span class="p">,</span> <span class="n">pp_fold_rf</span> <span class="o">=</span> <span class="n">cross_validate_model</span><span class="p">(</span><span class="n">model_class</span><span class="o">=</span><span class="n">RandomForestClassifier</span><span class="p">,</span>
                                                                                                    <span class="n">X</span> <span class="o">=</span> <span class="n">X_train_OHE</span><span class="p">,</span>
                                                                                                    <span class="n">y</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">,</span>
                                                                                                    <span class="n">sample_weights</span> <span class="o">=</span> <span class="n">sample_weights</span><span class="p">,</span>
                                                                                                    <span class="n">random_state</span> <span class="o">=</span> <span class="n">SEED</span><span class="p">,</span>
                                                                                                    <span class="n">use_default_threshold</span><span class="o">=</span><span class="n">use_default_threshold</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="s2">&quot;RandomForest_mdl&quot;</span> <span class="ow">in</span> <span class="n">models_to_include</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">export_missclassified</span><span class="p">:</span>
        <span class="n">misclassified_ids</span> <span class="o">=</span> <span class="n">mydata_backup</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">missclassified_samples_rf</span><span class="p">,</span> <span class="s1">&#39;ID&#39;</span><span class="p">]</span>
        
        <span class="n">misclassified_ids_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">misclassified_ids</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Misclassified_IDs&#39;</span><span class="p">])</span>
        <span class="n">misclassified_ids_df</span><span class="o">.</span><span class="n">to_excel</span><span class="p">(</span><span class="s1">&#39;misclassified_ids_rf.xlsx&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="s2">&quot;RandomForest_mdl&quot;</span> <span class="ow">in</span> <span class="n">models_to_include</span><span class="p">:</span>
    <span class="c1"># plot permutation-based feature importance</span>
    <span class="n">plot_PFI</span><span class="p">(</span><span class="n">PFI_folds</span><span class="o">=</span><span class="n">FI_rf</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">X_train_OHE</span><span class="p">,</span> <span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;RF&quot;</span><span class="p">)</span>
    
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="s2">&quot;RandomForest_mdl&quot;</span> <span class="ow">in</span> <span class="n">models_to_include</span><span class="p">:</span>
    <span class="c1"># plot tree-based feature importance</span>
    <span class="n">plot_TFI</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X_train_OHE</span><span class="p">,</span> <span class="n">tree_FI</span><span class="o">=</span><span class="n">treeFI_rf</span><span class="p">,</span> <span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;RF&quot;</span><span class="p">)</span>
    
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="s2">&quot;RandomForest_mdl&quot;</span> <span class="ow">in</span> <span class="n">models_to_include</span><span class="p">:</span>
    <span class="c1"># Concatenate SHAP values and DataFrames</span>
    <span class="n">shap_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">fold</span><span class="p">[:,:,</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">fold</span> <span class="ow">in</span> <span class="n">shap_rf</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">all_columns</span> <span class="o">=</span> <span class="n">fold_data_rf</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">columns</span>
    <span class="n">fold_data_all</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">fold</span> <span class="k">for</span> <span class="n">fold</span> <span class="ow">in</span> <span class="n">fold_data_rf</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">fold_data_all</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="n">all_columns</span>
    <span class="c1"># SHAP summary plot based on the cross validation results</span>
    <span class="n">shap_summary_plot</span><span class="p">(</span><span class="n">shap_values</span><span class="o">=</span><span class="n">shap_values</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">fold_data_all</span><span class="p">,</span> <span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;RF&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="s2">&quot;RandomForest_mdl&quot;</span> <span class="ow">in</span> <span class="n">models_to_include</span><span class="p">:</span>
    
    <span class="c1"># permutation-based feature importance</span>
    <span class="n">PFI_median</span> <span class="o">=</span> <span class="n">PFI_median_wrap</span><span class="p">(</span><span class="n">FI_rf</span><span class="p">)</span>
    <span class="n">PFI_median</span> <span class="o">=</span> <span class="n">PFI_median</span><span class="p">[[</span><span class="s1">&#39;Feature&#39;</span><span class="p">,</span> <span class="s1">&#39;Importance&#39;</span><span class="p">]]</span>
    
    <span class="c1"># Extract feature names from X_train_OHE</span>
    <span class="n">feature_names</span> <span class="o">=</span> <span class="n">X_train_OHE</span><span class="o">.</span><span class="n">columns</span>
    
    <span class="c1"># a DataFrame with SHAP values for positive class predictions</span>
    <span class="n">shap_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">shap_values</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">feature_names</span><span class="p">)</span>

    <span class="n">shap_df_sorted_positive_T</span> <span class="o">=</span> <span class="n">shap_df</span><span class="o">.</span><span class="n">T</span>
    
    <span class="c1"># Calculate the median importance across samples</span>
    <span class="n">SHAPFI_median</span> <span class="o">=</span> <span class="n">shap_df_sorted_positive_T</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">SHAPFI_median</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;Feature&#39;</span><span class="p">:</span> <span class="n">SHAPFI_median</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="s1">&#39;Importance&#39;</span><span class="p">:</span> <span class="n">SHAPFI_median</span><span class="o">.</span><span class="n">values</span><span class="p">})</span>
    <span class="c1"># normalization</span>
    <span class="n">SHAPFI_median</span><span class="p">[</span><span class="s1">&#39;Importance&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">minmax_scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">SHAPFI_median</span><span class="p">[[</span><span class="s1">&#39;Importance&#39;</span><span class="p">]])</span>

    <span class="c1"># Combine feature importances from all folds into a single DataFrame TFI: tree-based feature importance</span>
    <span class="n">TFI</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;Feature&#39;</span><span class="p">:</span> <span class="n">feature_names</span><span class="p">,</span> <span class="s1">&#39;Importance&#39;</span><span class="p">:</span> <span class="n">fold</span><span class="p">})</span> <span class="k">for</span> <span class="n">fold</span> <span class="ow">in</span> <span class="n">treeFI_rf</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">ignore_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># Calculate the median importance across folds for each feature</span>
    <span class="n">TFI_median</span> <span class="o">=</span> <span class="n">TFI</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">&quot;Feature&quot;</span><span class="p">)[</span><span class="s2">&quot;Importance&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">median</span><span class="p">()</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>

    <span class="c1"># Sort features by their median importance</span>
    <span class="n">TFI_median</span> <span class="o">=</span> <span class="n">TFI_median</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s2">&quot;Importance&quot;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">TFI_median</span><span class="p">[</span><span class="s1">&#39;Importance&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">minmax_scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">TFI_median</span><span class="p">[[</span><span class="s1">&#39;Importance&#39;</span><span class="p">]])</span>
    <span class="c1"># Rename the &#39;Importance&#39; column in TFI_median to &#39;Importance_TFI&#39;</span>
    <span class="n">TFI_median</span> <span class="o">=</span> <span class="n">TFI_median</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;Importance&#39;</span><span class="p">:</span> <span class="s1">&#39;Importance_TFI&#39;</span><span class="p">})</span>
    <span class="c1"># Merge PFI_median, SHAPFI_median, and TFI_median dataframes by &quot;Feature&quot;</span>
    <span class="n">FI_merged_df</span> <span class="o">=</span> <span class="n">PFI_median</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">SHAPFI_median</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="s2">&quot;Feature&quot;</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s1">&#39;outer&#39;</span><span class="p">,</span> <span class="n">suffixes</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;_PFI&#39;</span><span class="p">,</span> <span class="s1">&#39;_SHAP&#39;</span><span class="p">))</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">TFI_median</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="s2">&quot;Feature&quot;</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s1">&#39;outer&#39;</span><span class="p">)</span>

    <span class="c1"># Take the mean of importance values across different methods</span>
    <span class="n">FI_merged_df</span><span class="p">[</span><span class="s1">&#39;Normalized_Mean_Importance&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">FI_merged_df</span><span class="p">[[</span><span class="s1">&#39;Importance_PFI&#39;</span><span class="p">,</span> <span class="s1">&#39;Importance_SHAP&#39;</span><span class="p">,</span> <span class="s1">&#39;Importance_TFI&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># Sort features by their mean importance</span>
    <span class="n">FI_merged_df</span> <span class="o">=</span> <span class="n">FI_merged_df</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s2">&quot;Normalized_Mean_Importance&quot;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">FI_merged_df</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="histogram-based-gradient-boosting-classification-tree-hgbc">
<h4>Histogram-based Gradient Boosting Classification Tree (HGBC)<a class="headerlink" href="#histogram-based-gradient-boosting-classification-tree-hgbc" title="Link to this heading">#</a></h4>
<p>The HistGradientBoostingClassifier, part of the scikit-learn library, offers a histogram-based approach to gradient boosting for classification tasks. Notably, it exhibits significantly faster performance on large datasets (with n_samples &gt;= 10,000) compared to the traditional GradientBoostingClassifier. The implementation of HistGradientBoostingClassifier is inspired by LightGBM and offers various parameters for customization, such as learning rate, maximum depth of trees, and early stopping criteria. This classifier is an excellent choice for classification tasks with large datasets, providing both speed and accuracy.</p>
<p>Read more here: <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.HistGradientBoostingClassifier.html">https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.HistGradientBoostingClassifier.html</a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="s2">&quot;HistGBC_mdl&quot;</span> <span class="ow">in</span> <span class="n">models_to_include</span><span class="p">:</span>
    <span class="n">fold_results_HGBC</span><span class="p">,</span> <span class="n">aggregated_results_HGBC</span><span class="p">,</span> <span class="n">opt_threshold_HGBC</span><span class="p">,</span> <span class="n">FI_HGBC</span><span class="p">,</span> <span class="n">treeFI_HGBC</span><span class="p">,</span> <span class="n">shap_HGBC</span><span class="p">,</span> <span class="n">fold_results_plt_HGBC</span><span class="p">,</span> <span class="n">fold_data_HGBC</span><span class="p">,</span> <span class="n">missclassified_samples_HGBC</span><span class="p">,</span> <span class="n">y_fold</span><span class="p">,</span> <span class="n">pp_fold_HGBC</span> <span class="o">=</span> <span class="n">cross_validate_model</span><span class="p">(</span><span class="n">model_class</span><span class="o">=</span><span class="n">HistGradientBoostingClassifier</span><span class="p">,</span>
                                                                                                        <span class="n">X</span> <span class="o">=</span> <span class="n">X_train_OHE</span><span class="p">,</span>
                                                                                                        <span class="n">y</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">,</span>
                                                                                                        <span class="n">sample_weights</span> <span class="o">=</span> <span class="n">sample_weights</span><span class="p">,</span>
                                                                                                        <span class="n">random_state</span> <span class="o">=</span> <span class="n">SEED</span><span class="p">,</span>
                                                                                                    <span class="n">use_default_threshold</span><span class="o">=</span><span class="n">use_default_threshold</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="s2">&quot;HistGBC_mdl&quot;</span> <span class="ow">in</span> <span class="n">models_to_include</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">export_missclassified</span><span class="p">:</span>
        <span class="n">misclassified_ids</span> <span class="o">=</span> <span class="n">mydata_backup</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">missclassified_samples_HGBC</span><span class="p">,</span> <span class="s1">&#39;ID&#39;</span><span class="p">]</span>
        
        <span class="n">misclassified_ids_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">misclassified_ids</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Misclassified_IDs&#39;</span><span class="p">])</span>
        <span class="n">misclassified_ids_df</span><span class="o">.</span><span class="n">to_excel</span><span class="p">(</span><span class="s1">&#39;misclassified_ids_HGBC.xlsx&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="s2">&quot;HistGBC_mdl&quot;</span> <span class="ow">in</span> <span class="n">models_to_include</span><span class="p">:</span>
    <span class="c1"># plot permutation-based feature importance</span>
    <span class="n">plot_PFI</span><span class="p">(</span><span class="n">PFI_folds</span><span class="o">=</span><span class="n">FI_HGBC</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">X_train_OHE</span><span class="p">,</span> <span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;HGBC&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="s2">&quot;HistGBC_mdl&quot;</span> <span class="ow">in</span> <span class="n">models_to_include</span><span class="p">:</span>
    <span class="n">shap_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">fold</span> <span class="k">for</span> <span class="n">fold</span> <span class="ow">in</span> <span class="n">shap_HGBC</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">all_columns</span> <span class="o">=</span> <span class="n">fold_data_HGBC</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">columns</span>
    <span class="n">fold_data_all</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">fold</span> <span class="k">for</span> <span class="n">fold</span> <span class="ow">in</span> <span class="n">fold_data_HGBC</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">fold_data_all</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="n">all_columns</span>
    <span class="c1"># SHAP summary plot based on the cross validation results</span>
    <span class="n">shap_summary_plot</span><span class="p">(</span><span class="n">shap_values</span><span class="o">=</span><span class="n">shap_values</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">fold_data_all</span><span class="p">,</span> <span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;HGBC&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="s2">&quot;HistGBC_mdl&quot;</span> <span class="ow">in</span> <span class="n">models_to_include</span><span class="p">:</span>
    
    <span class="c1"># permutation-based feature importance</span>
    <span class="n">PFI_median</span> <span class="o">=</span> <span class="n">PFI_median_wrap</span><span class="p">(</span><span class="n">FI_HGBC</span><span class="p">)</span>
    <span class="n">PFI_median</span> <span class="o">=</span> <span class="n">PFI_median</span><span class="p">[[</span><span class="s1">&#39;Feature&#39;</span><span class="p">,</span> <span class="s1">&#39;Importance&#39;</span><span class="p">]]</span>
    <span class="n">shap_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">shap_values</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">feature_names</span><span class="p">)</span>

    <span class="n">shap_df_sorted_positive_T</span> <span class="o">=</span> <span class="n">shap_df</span><span class="o">.</span><span class="n">T</span>
    
    <span class="c1"># Calculate the median importance across samples</span>
    <span class="n">SHAPFI_median</span> <span class="o">=</span> <span class="n">shap_df_sorted_positive_T</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">SHAPFI_median</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;Feature&#39;</span><span class="p">:</span> <span class="n">SHAPFI_median</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="s1">&#39;Importance&#39;</span><span class="p">:</span> <span class="n">SHAPFI_median</span><span class="o">.</span><span class="n">values</span><span class="p">})</span>
    <span class="c1"># normalization</span>
    <span class="n">SHAPFI_median</span><span class="p">[</span><span class="s1">&#39;Importance&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">minmax_scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">SHAPFI_median</span><span class="p">[[</span><span class="s1">&#39;Importance&#39;</span><span class="p">]])</span>

    <span class="c1"># Merge PFI_median, SHAPFI_median, and TFI_median dataframes by &quot;Feature&quot;</span>
    <span class="n">FI_merged_df</span> <span class="o">=</span> <span class="n">PFI_median</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">SHAPFI_median</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="s2">&quot;Feature&quot;</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s1">&#39;outer&#39;</span><span class="p">,</span> <span class="n">suffixes</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;_PFI&#39;</span><span class="p">,</span> <span class="s1">&#39;_SHAP&#39;</span><span class="p">))</span>

    <span class="c1"># Take the mean of importance values across different methods</span>
    <span class="n">FI_merged_df</span><span class="p">[</span><span class="s1">&#39;Normalized_Mean_Importance&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">FI_merged_df</span><span class="p">[[</span><span class="s1">&#39;Importance_PFI&#39;</span><span class="p">,</span> <span class="s1">&#39;Importance_SHAP&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># Sort features by their mean importance</span>
    <span class="n">FI_merged_df</span> <span class="o">=</span> <span class="n">FI_merged_df</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s2">&quot;Normalized_Mean_Importance&quot;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">FI_merged_df</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="light-gradient-boosting-machine-lightgbm">
<h4>Light gradient-boosting machine (LightGBM)<a class="headerlink" href="#light-gradient-boosting-machine-lightgbm" title="Link to this heading">#</a></h4>
<p>LightGBM represents an open-source, distributed, and high-performance gradient boosting framework, engineered by Microsoft, to tackle machine learning challenges with precision and efficiency. It operates on decision trees, finely tuned to optimize model efficiency while minimizing memory consumption. A key innovation is the Gradient-based One-Side Sampling (GOSS) method, which intelligently retains instances with significant gradients during training, thereby optimizing memory usage and training duration. Additionally, LightGBM employs histogram-based algorithms for rapid and resource-efficient tree construction. These advanced techniques, alongside optimizations such as leaf-wise tree growth and streamlined data storage formats, collectively contribute to LightGBM’s remarkable efficiency and competitive edge in the realm of gradient boosting frameworks.</p>
<p>Read more here: <a class="reference external" href="https://lightgbm.readthedocs.io/en/stable/">https://lightgbm.readthedocs.io/en/stable/</a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="s2">&quot;LightGBM_mdl&quot;</span> <span class="ow">in</span> <span class="n">models_to_include</span><span class="p">:</span>
    <span class="n">fold_results_LGBM</span><span class="p">,</span> <span class="n">aggregated_results_LGBM</span><span class="p">,</span> <span class="n">opt_threshold_LGBM</span><span class="p">,</span> <span class="n">FI_LGBM</span><span class="p">,</span> <span class="n">treeFI_LGBM</span><span class="p">,</span> <span class="n">shap_LGBM</span><span class="p">,</span> <span class="n">fold_results_plt_LGBM</span><span class="p">,</span> <span class="n">fold_data_LGBM</span><span class="p">,</span> <span class="n">missclassified_samples_LGBM</span><span class="p">,</span> <span class="n">y_fold</span><span class="p">,</span> <span class="n">pp_fold_LGBM</span> <span class="o">=</span> <span class="n">cross_validate_model</span><span class="p">(</span><span class="n">model_class</span><span class="o">=</span><span class="n">lgb</span><span class="o">.</span><span class="n">LGBMClassifier</span><span class="p">,</span>
                                                                                                        <span class="n">X</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">,</span>
                                                                                                        <span class="n">y</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">,</span>
                                                                                                        <span class="n">sample_weights</span> <span class="o">=</span> <span class="n">sample_weights</span><span class="p">,</span>
                                                                                                        <span class="n">random_state</span> <span class="o">=</span> <span class="n">SEED</span><span class="p">,</span>
                                                                                                        <span class="n">use_default_threshold</span><span class="o">=</span><span class="n">use_default_threshold</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="s2">&quot;LightGBM_mdl&quot;</span> <span class="ow">in</span> <span class="n">models_to_include</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">export_missclassified</span><span class="p">:</span>
        <span class="n">misclassified_ids</span> <span class="o">=</span> <span class="n">mydata_backup</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">missclassified_samples_LGBM</span><span class="p">,</span> <span class="s1">&#39;ID&#39;</span><span class="p">]</span>
        
        <span class="n">misclassified_ids_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">misclassified_ids</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Misclassified_IDs&#39;</span><span class="p">])</span>
        <span class="n">misclassified_ids_df</span><span class="o">.</span><span class="n">to_excel</span><span class="p">(</span><span class="s1">&#39;misclassified_ids_LGBM.xlsx&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="s2">&quot;LightGBM_mdl&quot;</span> <span class="ow">in</span> <span class="n">models_to_include</span><span class="p">:</span>
    <span class="c1"># plot permutation-based feature importance</span>
    <span class="n">plot_PFI</span><span class="p">(</span><span class="n">PFI_folds</span><span class="o">=</span><span class="n">FI_LGBM</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">X_train</span><span class="p">,</span> <span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;LGBM&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="s2">&quot;LightGBM_mdl&quot;</span> <span class="ow">in</span> <span class="n">models_to_include</span><span class="p">:</span>
    <span class="c1"># plot tree-based feature importance</span>
    <span class="n">plot_TFI</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X_train</span><span class="p">,</span> <span class="n">tree_FI</span><span class="o">=</span><span class="n">treeFI_LGBM</span><span class="p">,</span> <span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;LGBM&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="s2">&quot;LightGBM_mdl&quot;</span> <span class="ow">in</span> <span class="n">models_to_include</span><span class="p">:</span>
    <span class="c1"># each fold contains two arrays: one for the SHAP values of the negative class predictions (index 0) and one for the SHAP values of the positive class predictions (index 1). </span>
    <span class="c1"># Therefore, to extract the arrays for the positive class predictions, you should use index 1.</span>
    <span class="n">shap_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">fold</span> <span class="k">for</span> <span class="n">fold</span> <span class="ow">in</span> <span class="n">shap_LGBM</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">all_columns</span> <span class="o">=</span> <span class="n">fold_data_LGBM</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">columns</span>
    <span class="n">fold_data_all</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">fold</span> <span class="k">for</span> <span class="n">fold</span> <span class="ow">in</span> <span class="n">fold_data_LGBM</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">fold_data_all</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="n">all_columns</span>
    <span class="c1"># SHAP summary plot based on the cross validation results</span>
    <span class="n">shap_summary_plot</span><span class="p">(</span><span class="n">shap_values</span><span class="o">=</span><span class="n">shap_values</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">fold_data_all</span><span class="p">,</span> <span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;LGBM&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="s2">&quot;LightGBM_mdl&quot;</span> <span class="ow">in</span> <span class="n">models_to_include</span><span class="p">:</span>
    
    <span class="c1"># permutation-based feature importance</span>
    <span class="n">PFI_median</span> <span class="o">=</span> <span class="n">PFI_median_wrap</span><span class="p">(</span><span class="n">FI_LGBM</span><span class="p">)</span>
    <span class="n">PFI_median</span> <span class="o">=</span> <span class="n">PFI_median</span><span class="p">[[</span><span class="s1">&#39;Feature&#39;</span><span class="p">,</span> <span class="s1">&#39;Importance&#39;</span><span class="p">]]</span>
    <span class="n">shap_values_positive</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">fold</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">fold</span> <span class="ow">in</span> <span class="n">shap_LGBM</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">feature_names</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">columns</span>

    <span class="n">shap_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">shap_values</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">feature_names</span><span class="p">)</span>

    <span class="n">shap_df_sorted_positive_T</span> <span class="o">=</span> <span class="n">shap_df</span><span class="o">.</span><span class="n">T</span>
    
    <span class="c1"># Calculate the median importance across samples</span>
    <span class="n">SHAPFI_median</span> <span class="o">=</span> <span class="n">shap_df_sorted_positive_T</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">SHAPFI_median</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;Feature&#39;</span><span class="p">:</span> <span class="n">SHAPFI_median</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="s1">&#39;Importance&#39;</span><span class="p">:</span> <span class="n">SHAPFI_median</span><span class="o">.</span><span class="n">values</span><span class="p">})</span>
    <span class="c1"># normalization</span>
    <span class="n">SHAPFI_median</span><span class="p">[</span><span class="s1">&#39;Importance&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">minmax_scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">SHAPFI_median</span><span class="p">[[</span><span class="s1">&#39;Importance&#39;</span><span class="p">]])</span>

    <span class="c1"># Extract feature names from X_train</span>
    <span class="n">feature_names</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">columns</span>

    <span class="c1"># Combine feature importances from all folds into a single DataFrame TFI: tree-based feature importance</span>
    <span class="n">TFI</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;Feature&#39;</span><span class="p">:</span> <span class="n">feature_names</span><span class="p">,</span> <span class="s1">&#39;Importance&#39;</span><span class="p">:</span> <span class="n">fold</span><span class="p">})</span> <span class="k">for</span> <span class="n">fold</span> <span class="ow">in</span> <span class="n">treeFI_LGBM</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">ignore_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># Calculate the median importance across folds for each feature</span>
    <span class="n">TFI_median</span> <span class="o">=</span> <span class="n">TFI</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">&quot;Feature&quot;</span><span class="p">)[</span><span class="s2">&quot;Importance&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">median</span><span class="p">()</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>

    <span class="c1"># Sort features by their median importance</span>
    <span class="n">TFI_median</span> <span class="o">=</span> <span class="n">TFI_median</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s2">&quot;Importance&quot;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">TFI_median</span><span class="p">[</span><span class="s1">&#39;Importance&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">minmax_scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">TFI_median</span><span class="p">[[</span><span class="s1">&#39;Importance&#39;</span><span class="p">]])</span>
    <span class="c1"># Rename the &#39;Importance&#39; column in TFI_median to &#39;Importance_TFI&#39;</span>
    <span class="n">TFI_median</span> <span class="o">=</span> <span class="n">TFI_median</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;Importance&#39;</span><span class="p">:</span> <span class="s1">&#39;Importance_TFI&#39;</span><span class="p">})</span>
    <span class="c1"># Merge PFI_median, SHAPFI_median, and TFI_median dataframes by &quot;Feature&quot;</span>
    <span class="n">FI_merged_df</span> <span class="o">=</span> <span class="n">PFI_median</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">SHAPFI_median</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="s2">&quot;Feature&quot;</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s1">&#39;outer&#39;</span><span class="p">,</span> <span class="n">suffixes</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;_PFI&#39;</span><span class="p">,</span> <span class="s1">&#39;_SHAP&#39;</span><span class="p">))</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">TFI_median</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="s2">&quot;Feature&quot;</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s1">&#39;outer&#39;</span><span class="p">)</span>

    <span class="c1"># Take the mean of importance values across different methods</span>
    <span class="n">FI_merged_df</span><span class="p">[</span><span class="s1">&#39;Normalized_Mean_Importance&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">FI_merged_df</span><span class="p">[[</span><span class="s1">&#39;Importance_PFI&#39;</span><span class="p">,</span> <span class="s1">&#39;Importance_SHAP&#39;</span><span class="p">,</span> <span class="s1">&#39;Importance_TFI&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># Sort features by their mean importance</span>
    <span class="n">FI_merged_df</span> <span class="o">=</span> <span class="n">FI_merged_df</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s2">&quot;Normalized_Mean_Importance&quot;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">FI_merged_df</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="categorical-boosting-catboost">
<h4>Categorical boosting (CATBoost)<a class="headerlink" href="#categorical-boosting-catboost" title="Link to this heading">#</a></h4>
<p>CatBoost is a supervised machine learning method utilized for classification and regression tasks, particularly useful for handling categorical data without the need for extensive preprocessing. Employing gradient boosting, CatBoost iteratively constructs decision trees to refine predictions, achieving enhanced accuracy over time. Notably, CatBoost employs ordered encoding to effectively handle categorical features, utilizing target statistics from all rows to inform encoding decisions. Additionally, it introduces symmetric trees, ensuring uniformity in split conditions at each depth level. Compared to similar methods like XGBoost, CatBoost have often demonstrates superior performance across datasets of varying sizes, retaining key features such as cross-validation, regularization, and support for missing values.</p>
<p>Read more here: <a class="reference external" href="https://catboost.ai/docs/features/categorical-features">https://catboost.ai/docs/features/categorical-features</a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cat_features</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">cat_features</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cat_features</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="s2">&quot;CatBoost_mdl&quot;</span> <span class="ow">in</span> <span class="n">models_to_include</span><span class="p">:</span>
    <span class="n">fold_results_CB</span><span class="p">,</span> <span class="n">aggregated_results_CB</span><span class="p">,</span> <span class="n">opt_threshold_CB</span><span class="p">,</span> <span class="n">FI_CB</span><span class="p">,</span> <span class="n">treeFI_CB</span><span class="p">,</span> <span class="n">shap_CB</span><span class="p">,</span> <span class="n">fold_results_plt_CB</span><span class="p">,</span> <span class="n">fold_data_CB</span><span class="p">,</span> <span class="n">missclassified_samples_CB</span><span class="p">,</span> <span class="n">y_fold</span><span class="p">,</span> <span class="n">pp_fold_CB</span> <span class="o">=</span> <span class="n">cross_validate_model</span><span class="p">(</span><span class="n">model_class</span><span class="o">=</span> <span class="n">cb</span><span class="o">.</span><span class="n">CatBoostClassifier</span><span class="p">,</span>
                                                                                                <span class="n">X</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">,</span>
                                                                                                <span class="n">y</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">,</span>
                                                                                                <span class="n">sample_weights</span> <span class="o">=</span> <span class="n">sample_weights</span><span class="p">,</span>
                                                                                                <span class="n">random_state</span> <span class="o">=</span> <span class="n">SEED</span><span class="p">,</span>
                                                                                                <span class="n">cat_features</span> <span class="o">=</span> <span class="n">cat_features</span><span class="p">,</span>
                                                                                                <span class="n">use_default_threshold</span> <span class="o">=</span> <span class="n">use_default_threshold</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="s2">&quot;CatBoost_mdl&quot;</span> <span class="ow">in</span> <span class="n">models_to_include</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">export_missclassified</span><span class="p">:</span>
        <span class="n">misclassified_ids</span> <span class="o">=</span> <span class="n">mydata_backup</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">missclassified_samples_CB</span><span class="p">,</span> <span class="s1">&#39;ID&#39;</span><span class="p">]</span>
        
        <span class="n">misclassified_ids_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">misclassified_ids</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Misclassified_IDs&#39;</span><span class="p">])</span>
        <span class="n">misclassified_ids_df</span><span class="o">.</span><span class="n">to_excel</span><span class="p">(</span><span class="s1">&#39;misclassified_ids_CB.xlsx&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="s2">&quot;CatBoost_mdl&quot;</span> <span class="ow">in</span> <span class="n">models_to_include</span><span class="p">:</span>
    <span class="c1"># plot permutation-based feature importance</span>
    <span class="n">plot_PFI</span><span class="p">(</span><span class="n">PFI_folds</span><span class="o">=</span><span class="n">FI_CB</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">X_train</span><span class="p">,</span> <span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;CB&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="s2">&quot;CatBoost_mdl&quot;</span> <span class="ow">in</span> <span class="n">models_to_include</span><span class="p">:</span>
    <span class="c1"># plot tree-based feature importance</span>
    <span class="n">plot_TFI</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X_train</span><span class="p">,</span> <span class="n">tree_FI</span><span class="o">=</span><span class="n">treeFI_CB</span><span class="p">,</span> <span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;CB&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="s2">&quot;CatBoost_mdl&quot;</span> <span class="ow">in</span> <span class="n">models_to_include</span><span class="p">:</span>
    <span class="n">shap_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">fold</span> <span class="k">for</span> <span class="n">fold</span> <span class="ow">in</span> <span class="n">shap_CB</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">all_columns</span> <span class="o">=</span> <span class="n">fold_data_CB</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">columns</span>
    <span class="n">fold_data_all</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">fold</span> <span class="k">for</span> <span class="n">fold</span> <span class="ow">in</span> <span class="n">fold_data_CB</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">fold_data_all</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="n">all_columns</span>
    <span class="c1"># SHAP summary plot based on the cross validation results</span>
    <span class="n">shap_summary_plot</span><span class="p">(</span><span class="n">shap_values</span><span class="o">=</span><span class="n">shap_values</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">fold_data_all</span><span class="p">,</span> <span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;CB&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="s2">&quot;CatBoost_mdl&quot;</span> <span class="ow">in</span> <span class="n">models_to_include</span><span class="p">:</span>
    
    <span class="c1"># permutation-based feature importance</span>
    <span class="n">PFI_median</span> <span class="o">=</span> <span class="n">PFI_median_wrap</span><span class="p">(</span><span class="n">FI_CB</span><span class="p">)</span>
    <span class="n">PFI_median</span> <span class="o">=</span> <span class="n">PFI_median</span><span class="p">[[</span><span class="s1">&#39;Feature&#39;</span><span class="p">,</span> <span class="s1">&#39;Importance&#39;</span><span class="p">]]</span>
    <span class="n">shap_values_positive</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">fold</span> <span class="k">for</span> <span class="n">fold</span> <span class="ow">in</span> <span class="n">shap_CB</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">feature_names</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">columns</span>
    <span class="n">shap_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">shap_values</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">feature_names</span><span class="p">)</span>

    <span class="n">shap_df_sorted_positive_T</span> <span class="o">=</span> <span class="n">shap_df</span><span class="o">.</span><span class="n">T</span>
    
    <span class="c1"># Calculate the median importance across samples</span>
    <span class="n">SHAPFI_median</span> <span class="o">=</span> <span class="n">shap_df_sorted_positive_T</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">SHAPFI_median</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;Feature&#39;</span><span class="p">:</span> <span class="n">SHAPFI_median</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="s1">&#39;Importance&#39;</span><span class="p">:</span> <span class="n">SHAPFI_median</span><span class="o">.</span><span class="n">values</span><span class="p">})</span>
    <span class="c1"># normalization</span>
    <span class="n">SHAPFI_median</span><span class="p">[</span><span class="s1">&#39;Importance&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">minmax_scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">SHAPFI_median</span><span class="p">[[</span><span class="s1">&#39;Importance&#39;</span><span class="p">]])</span>

    <span class="c1"># Extract feature names from X_train</span>
    <span class="n">feature_names</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">columns</span>

    <span class="c1"># Combine feature importances from all folds into a single DataFrame TFI: tree-based feature importance</span>
    <span class="n">TFI</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;Feature&#39;</span><span class="p">:</span> <span class="n">feature_names</span><span class="p">,</span> <span class="s1">&#39;Importance&#39;</span><span class="p">:</span> <span class="n">fold</span><span class="p">})</span> <span class="k">for</span> <span class="n">fold</span> <span class="ow">in</span> <span class="n">treeFI_CB</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">ignore_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># Calculate the median importance across folds for each feature</span>
    <span class="n">TFI_median</span> <span class="o">=</span> <span class="n">TFI</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">&quot;Feature&quot;</span><span class="p">)[</span><span class="s2">&quot;Importance&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">median</span><span class="p">()</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>

    <span class="c1"># Sort features by their median importance</span>
    <span class="n">TFI_median</span> <span class="o">=</span> <span class="n">TFI_median</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s2">&quot;Importance&quot;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">TFI_median</span><span class="p">[</span><span class="s1">&#39;Importance&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">minmax_scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">TFI_median</span><span class="p">[[</span><span class="s1">&#39;Importance&#39;</span><span class="p">]])</span>
    <span class="c1"># Rename the &#39;Importance&#39; column in TFI_median to &#39;Importance_TFI&#39;</span>
    <span class="n">TFI_median</span> <span class="o">=</span> <span class="n">TFI_median</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;Importance&#39;</span><span class="p">:</span> <span class="s1">&#39;Importance_TFI&#39;</span><span class="p">})</span>
    <span class="c1"># Merge PFI_median, SHAPFI_median, and TFI_median dataframes by &quot;Feature&quot;</span>
    <span class="n">FI_merged_df</span> <span class="o">=</span> <span class="n">PFI_median</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">SHAPFI_median</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="s2">&quot;Feature&quot;</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s1">&#39;outer&#39;</span><span class="p">,</span> <span class="n">suffixes</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;_PFI&#39;</span><span class="p">,</span> <span class="s1">&#39;_SHAP&#39;</span><span class="p">))</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">TFI_median</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="s2">&quot;Feature&quot;</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s1">&#39;outer&#39;</span><span class="p">)</span>

    <span class="c1"># Take the mean of importance values across different methods</span>
    <span class="n">FI_merged_df</span><span class="p">[</span><span class="s1">&#39;Normalized_Mean_Importance&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">FI_merged_df</span><span class="p">[[</span><span class="s1">&#39;Importance_PFI&#39;</span><span class="p">,</span> <span class="s1">&#39;Importance_SHAP&#39;</span><span class="p">,</span> <span class="s1">&#39;Importance_TFI&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># Sort features by their mean importance</span>
    <span class="n">FI_merged_df</span> <span class="o">=</span> <span class="n">FI_merged_df</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s2">&quot;Normalized_Mean_Importance&quot;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">FI_merged_df</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_fold_all</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">fold</span> <span class="k">for</span> <span class="n">fold</span> <span class="ow">in</span> <span class="n">y_fold</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="summary-of-the-cross-validation-results">
<h4>summary of the cross validation results<a class="headerlink" href="#summary-of-the-cross-validation-results" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define the available models and their corresponding DataFrames</span>
<span class="n">models_dict</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">if</span> <span class="s2">&quot;QLattice_mdl&quot;</span> <span class="ow">in</span> <span class="n">models_to_include</span><span class="p">:</span>
    <span class="n">models_dict</span><span class="p">[</span><span class="s2">&quot;QLattice_mdl&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">aggregated_results_QLattice</span>
<span class="k">if</span> <span class="s2">&quot;RandomForest_mdl&quot;</span> <span class="ow">in</span> <span class="n">models_to_include</span><span class="p">:</span>
    <span class="n">models_dict</span><span class="p">[</span><span class="s2">&quot;RandomForest_mdl&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">aggregated_results_rf</span>
<span class="k">if</span> <span class="s2">&quot;LightGBM_mdl&quot;</span> <span class="ow">in</span> <span class="n">models_to_include</span><span class="p">:</span>
    <span class="n">models_dict</span><span class="p">[</span><span class="s2">&quot;LightGBM_mdl&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">aggregated_results_LGBM</span>
<span class="k">if</span> <span class="s2">&quot;NaiveBayes_mdl&quot;</span> <span class="ow">in</span> <span class="n">models_to_include</span><span class="p">:</span>
    <span class="n">models_dict</span><span class="p">[</span><span class="s2">&quot;NaiveBayes_mdl&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">aggregated_results_NB</span>
<span class="k">if</span> <span class="s2">&quot;CatBoost_mdl&quot;</span> <span class="ow">in</span> <span class="n">models_to_include</span><span class="p">:</span>
    <span class="n">models_dict</span><span class="p">[</span><span class="s2">&quot;CatBoost_mdl&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">aggregated_results_CB</span>
<span class="k">if</span> <span class="s2">&quot;LogisticRegression_mdl&quot;</span> <span class="ow">in</span> <span class="n">models_to_include</span><span class="p">:</span>
    <span class="n">models_dict</span><span class="p">[</span><span class="s2">&quot;LogisticRegression_mdl&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">aggregated_results_LR</span>
<span class="k">if</span> <span class="s2">&quot;HistGBC_mdl&quot;</span> <span class="ow">in</span> <span class="n">models_to_include</span><span class="p">:</span>
    <span class="n">models_dict</span><span class="p">[</span><span class="s2">&quot;HistGBC_mdl&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">aggregated_results_HGBC</span>

<span class="c1"># Initialize an empty list to store selected models&#39; DataFrames</span>
<span class="n">selected_models</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Select the DataFrames based on user&#39;s choice</span>
<span class="k">for</span> <span class="n">model_name</span> <span class="ow">in</span> <span class="n">models_to_include</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">model_name</span> <span class="ow">in</span> <span class="n">models_dict</span><span class="p">:</span>
        <span class="n">selected_models</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">models_dict</span><span class="p">[</span><span class="n">model_name</span><span class="p">])</span>

<span class="c1"># Set &#39;Metric&#39; as the index for each model&#39;s DataFrame</span>
<span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">selected_models</span><span class="p">:</span>
    <span class="n">model</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s1">&#39;Metric&#39;</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Concatenate the DataFrames along the columns</span>
<span class="n">aggregated_results_all</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">selected_models</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Set the column names based on the selected models</span>
<span class="n">aggregated_results_all</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="n">models_to_include</span>


<span class="nb">print</span><span class="p">(</span><span class="n">aggregated_results_all</span><span class="p">)</span>

<span class="c1"># Save the results to an Excel file</span>
<span class="n">aggregated_results_all</span><span class="o">.</span><span class="n">to_excel</span><span class="p">(</span><span class="s1">&#39;aggregated_results_all.xlsx&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Function to extract mean values from strings</span>
<span class="k">def</span> <span class="nf">extract_mean</span><span class="p">(</span><span class="n">value</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Extract the mean value from a string.</span>

<span class="sd">    This function uses regular expressions to search for a decimal number in the input string.</span>
<span class="sd">    If a match is found, it returns the extracted value as a float. Otherwise, it returns None.</span>

<span class="sd">    Parameters:</span>
<span class="sd">        value (str): The input string to extract the mean value from.</span>

<span class="sd">    ## Returns</span>
<span class="sd">        float or None: The extracted mean value as a float, or None if no match is found.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">mean</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;(\d+\.\d+)&#39;</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">mean</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="n">mean</span><span class="o">.</span><span class="n">group</span><span class="p">())</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">None</span>

<span class="c1"># Extracting mean values from the DataFrame</span>
<span class="n">mean_values</span> <span class="o">=</span> <span class="n">aggregated_results_all</span><span class="o">.</span><span class="n">applymap</span><span class="p">(</span><span class="n">extract_mean</span><span class="p">)</span>

<span class="c1"># Calculate mean values for MCC, ROCAUC, and PRAUC for each model</span>
<span class="n">mean_values_per_model</span> <span class="o">=</span> <span class="n">mean_values</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">level</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

<span class="c1"># Calculate the average of MCC, ROCAUC, and PRAUC for each model</span>
<span class="n">mean_values_per_model</span><span class="p">[</span><span class="s1">&#39;MRPAvg&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">mean_values_per_model</span><span class="p">[[</span><span class="s1">&#39;MCC&#39;</span><span class="p">,</span> <span class="s1">&#39;ROCAUC&#39;</span><span class="p">,</span> <span class="s1">&#39;PRAUC&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">mean_values_per_model</span><span class="p">)</span>

<span class="c1"># Find the model with the highest average of MCC, ROCAUC, and PRAUC (termed as MRPavg)</span>
<span class="n">best_model</span> <span class="o">=</span> <span class="n">mean_values_per_model</span><span class="p">[</span><span class="s1">&#39;MRPAvg&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">idxmax</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create a dictionary to map model abbreviations to full names</span>
<span class="n">model_names</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;RandomForest_mdl&#39;</span><span class="p">:</span> <span class="s1">&#39;rf&#39;</span><span class="p">,</span>
    <span class="s1">&#39;HistGBC_mdl&#39;</span><span class="p">:</span> <span class="s1">&#39;HGBC&#39;</span><span class="p">,</span>
    <span class="s1">&#39;LogisticRegression_mdl&#39;</span><span class="p">:</span> <span class="s1">&#39;LR&#39;</span><span class="p">,</span>
    <span class="s1">&#39;CatBoost_mdl&#39;</span><span class="p">:</span> <span class="s1">&#39;CB&#39;</span><span class="p">,</span>
    <span class="s1">&#39;NaiveBayes_mdl&#39;</span><span class="p">:</span> <span class="s1">&#39;NB&#39;</span><span class="p">,</span>
    <span class="s1">&#39;LightGBM_mdl&#39;</span><span class="p">:</span> <span class="s1">&#39;LGBM&#39;</span><span class="p">,</span>
    <span class="s1">&#39;QLattice_mdl&#39;</span> <span class="p">:</span> <span class="s1">&#39;QLattice&#39;</span>
<span class="p">}</span>

<span class="c1"># Get the full name of the best model</span>
<span class="n">best_model_name</span> <span class="o">=</span> <span class="n">model_names</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">best_model</span><span class="p">)</span>

<span class="c1"># Print the best model</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Model with the highest average of MCC, ROCAUC, and PRAUC: </span><span class="si">{</span><span class="n">best_model_name</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="n">best_model</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="statistical-test-to-compare-the-performance-of-the-models-on-cross-validation">
<h4>Statistical test to compare the performance of the models on cross validation<a class="headerlink" href="#statistical-test-to-compare-the-performance-of-the-models-on-cross-validation" title="Link to this heading">#</a></h4>
<p>Note: this is done only for AUC but can be extended for other measures.</p>
<p>Using the Kruskal-Wallis test allows you to compare the mean AUC values of multiple models without relying on the assumptions of normality and homogeneity of variances. It provides a robust nonparametric approach to assess whether there are significant differences between the models in terms of their performance.</p>
<p>The Kruskal-Wallis test is a nonparametric equivalent of the ANOVA test and is suitable when the assumptions of normality and homogeneity of variances are not met.</p>
<p>Here’s an outline of the steps to perform a Kruskal-Wallis test:</p>
<p>Null Hypothesis (H0): The mean AUC values of all models are equal.
Alternative Hypothesis (HA): At least one mean AUC value is significantly different from the others.</p>
<p>Collect the mean AUC values of each model obtained from cross-validation.</p>
<p>Perform a Kruskal-Wallis test, which tests for differences in the distribution of a continuous variable (AUC) among multiple groups (models).</p>
<p>Calculate the test statistic (H-statistic) and obtain the corresponding p-value.</p>
<p>Interpret the results:</p>
<p>If the p-value is less than a predetermined significance level (e.g., 0.05), reject the null hypothesis. It suggests that at least one model’s mean AUC value is significantly different from the others.
If the p-value is greater than the significance level, fail to reject the null hypothesis. It indicates that there is no significant difference between the mean AUC values of the models.
If the null hypothesis is rejected (i.e., significant differences exist), you can perform post-hoc tests to determine which specific models are significantly different from each other. Common post-hoc tests for nonparametric data include the Dunn test or the Bonferroni correction.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># a dictionary to map model names to their corresponding AUC values</span>
<span class="c1"># Define the available models and their corresponding fold results</span>
<span class="n">model_auc_dict</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">if</span> <span class="s2">&quot;QLattice_mdl&quot;</span> <span class="ow">in</span> <span class="n">models_to_include</span><span class="p">:</span>
    <span class="n">model_auc_dict</span><span class="p">[</span><span class="s1">&#39;QLattice_mdl&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">fold_results_QLattice</span><span class="p">[</span><span class="s1">&#39;ROCAUC&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="k">if</span> <span class="s2">&quot;RandomForest_mdl&quot;</span> <span class="ow">in</span> <span class="n">models_to_include</span><span class="p">:</span>
    <span class="n">model_auc_dict</span><span class="p">[</span><span class="s1">&#39;RandomForest_mdl&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">fold_results_rf</span><span class="p">[</span><span class="s1">&#39;ROCAUC&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="k">if</span> <span class="s2">&quot;LightGBM_mdl&quot;</span> <span class="ow">in</span> <span class="n">models_to_include</span><span class="p">:</span>
    <span class="n">model_auc_dict</span><span class="p">[</span><span class="s1">&#39;LightGBM_mdl&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">fold_results_LGBM</span><span class="p">[</span><span class="s1">&#39;ROCAUC&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="k">if</span> <span class="s2">&quot;NaiveBayes_mdl&quot;</span> <span class="ow">in</span> <span class="n">models_to_include</span><span class="p">:</span>
    <span class="n">model_auc_dict</span><span class="p">[</span><span class="s1">&#39;NaiveBayes_mdl&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">fold_results_NB</span><span class="p">[</span><span class="s1">&#39;ROCAUC&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="k">if</span> <span class="s2">&quot;CatBoost_mdl&quot;</span> <span class="ow">in</span> <span class="n">models_to_include</span><span class="p">:</span>
    <span class="n">model_auc_dict</span><span class="p">[</span><span class="s1">&#39;CatBoost_mdl&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">fold_results_CB</span><span class="p">[</span><span class="s1">&#39;ROCAUC&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="k">if</span> <span class="s2">&quot;LogisticRegression_mdl&quot;</span> <span class="ow">in</span> <span class="n">models_to_include</span><span class="p">:</span>
    <span class="n">model_auc_dict</span><span class="p">[</span><span class="s1">&#39;LogisticRegression_mdl&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">fold_results_LR</span><span class="p">[</span><span class="s1">&#39;ROCAUC&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="k">if</span> <span class="s2">&quot;HistGBC_mdl&quot;</span> <span class="ow">in</span> <span class="n">models_to_include</span><span class="p">:</span>
    <span class="n">model_auc_dict</span><span class="p">[</span><span class="s1">&#39;HistGBC_mdl&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">fold_results_HGBC</span><span class="p">[</span><span class="s1">&#39;ROCAUC&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>

<span class="c1"># Initialize an empty list to store selected AUC values</span>
<span class="n">selected_auc_values</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Select the AUC values based on user&#39;s choice</span>
<span class="k">for</span> <span class="n">model_name</span> <span class="ow">in</span> <span class="n">models_to_include</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">model_name</span> <span class="ow">in</span> <span class="n">model_auc_dict</span><span class="p">:</span>
        <span class="n">selected_auc_values</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">model_auc_dict</span><span class="p">[</span><span class="n">model_name</span><span class="p">])</span>

<span class="c1"># Perform Kruskal-Wallis test</span>
<span class="n">statistic</span><span class="p">,</span> <span class="n">p_value</span> <span class="o">=</span> <span class="n">kruskal</span><span class="p">(</span><span class="o">*</span><span class="n">selected_auc_values</span><span class="p">)</span>

<span class="c1"># Interpret the results</span>
<span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.05</span>  <span class="c1"># Significance level</span>

<span class="k">if</span> <span class="n">p_value</span> <span class="o">&lt;</span> <span class="n">alpha</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;At least one model&#39;s mean AUC value is significantly different from the others.&quot;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;No significant difference between the mean AUC values of the models.&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Kruskal-Wallis test statistic: </span><span class="si">{</span><span class="n">statistic</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;P-value: </span><span class="si">{</span><span class="n">p_value</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="model-uncertainty-reduction-mur-optional">
<h3>Model Uncertainty Reduction (MUR) - optional<a class="headerlink" href="#model-uncertainty-reduction-mur-optional" title="Link to this heading">#</a></h3>
<p>The following code chunk identifies a margin around the prediction probability threshold and SHAP percentile to filter out samples where the predicted probabilities and SHAP values fall within a predefined uncertainty margin. This margin is determined through a grid search over a limited search space for SHAP percentile values and prediction probability margins in binary classification models. The approach ensures that the number of discarded samples does not exceed a specified maximum percentage, thereby balancing the trade-off between model uncertainty reduction and sample retention. This trade-off involves maintaining a high number of samples while ensuring the model has high certainty in its predictions.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">model_uncertainty_reduction</span><span class="p">:</span>
    <span class="c1"># Initialize an empty list to store selected models&#39; DataFrames</span>
    <span class="n">selected_models</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="c1"># Calculate SHAP values for the positive class</span>
    <span class="n">positive_class_index</span> <span class="o">=</span> <span class="mi">1</span>
    
    <span class="c1"># Define the probability margin around the threshold</span>
    <span class="c1"># probability_threshold = 0.5</span>
    <span class="n">margin_grid</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">]</span> <span class="c1"># Margin from the prediction probability threshold</span>
    <span class="n">SHAP_percentile_grid</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">]</span> <span class="c1"># Percentile of absolute SHAP values</span>
    <span class="n">max_sample_loss_perc</span> <span class="o">=</span> <span class="mi">20</span> <span class="c1"># Maximum percentage of samples that can be discarded</span>

    <span class="n">aggregated_CV_results_filtered_mdl</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
    <span class="c1"># Iterate over the combinations of margin and SHAP_percentile</span>
    <span class="k">for</span> <span class="n">margin</span> <span class="ow">in</span> <span class="n">margin_grid</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">SHAP_percentile</span> <span class="ow">in</span> <span class="n">SHAP_percentile_grid</span><span class="p">:</span>

            <span class="k">for</span> <span class="n">selected_model</span> <span class="ow">in</span> <span class="n">models_to_include</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">selected_model</span><span class="o">==</span><span class="s2">&quot;HistGBC_mdl&quot;</span><span class="p">:</span>
                    <span class="n">fold_data_all_OHE</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">fold</span> <span class="k">for</span> <span class="n">fold</span> <span class="ow">in</span> <span class="n">fold_data_HGBC</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                    <span class="n">shap_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">fold</span> <span class="k">for</span> <span class="n">fold</span> <span class="ow">in</span> <span class="n">shap_HGBC</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                    <span class="n">predicted_probabilities</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">fold</span> <span class="k">for</span> <span class="n">fold</span> <span class="ow">in</span> <span class="n">pp_fold_HGBC</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                    <span class="n">shap_sum</span> <span class="o">=</span> <span class="n">shap_values</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
                    <span class="n">shap_sum_abs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">shap_sum</span><span class="p">)</span>
                    <span class="n">SHAP_thr_HGBC</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">shap_sum_abs</span><span class="p">,</span> <span class="n">SHAP_percentile</span><span class="p">)</span>

                    <span class="n">X_train_filtered_shap</span> <span class="o">=</span> <span class="n">fold_data_all_OHE</span><span class="p">[(</span><span class="n">shap_sum_abs</span> <span class="o">&gt;</span> <span class="n">SHAP_thr_HGBC</span><span class="p">)</span> <span class="o">&amp;</span> 
                                                        <span class="p">((</span><span class="n">predicted_probabilities</span> <span class="o">&lt;</span> <span class="p">(</span><span class="n">opt_threshold_HGBC</span> <span class="o">-</span> <span class="n">margin</span><span class="p">))</span> <span class="o">|</span> 
                                                        <span class="p">(</span><span class="n">predicted_probabilities</span> <span class="o">&gt;</span> <span class="p">(</span><span class="n">opt_threshold_HGBC</span> <span class="o">+</span> <span class="n">margin</span><span class="p">)))]</span>
                    <span class="n">y_train_filtered_shap</span> <span class="o">=</span> <span class="n">y_fold_all</span><span class="p">[(</span><span class="n">shap_sum_abs</span> <span class="o">&gt;</span> <span class="n">SHAP_thr_HGBC</span><span class="p">)</span> <span class="o">&amp;</span> 
                                                    <span class="p">((</span><span class="n">predicted_probabilities</span> <span class="o">&lt;</span> <span class="p">(</span><span class="n">opt_threshold_HGBC</span> <span class="o">-</span> <span class="n">margin</span><span class="p">))</span> <span class="o">|</span> 
                                                        <span class="p">(</span><span class="n">predicted_probabilities</span> <span class="o">&gt;</span> <span class="p">(</span><span class="n">opt_threshold_HGBC</span> <span class="o">+</span> <span class="n">margin</span><span class="p">)))]</span>
                    <span class="n">pp_filtered</span> <span class="o">=</span> <span class="n">predicted_probabilities</span><span class="p">[(</span><span class="n">shap_sum_abs</span> <span class="o">&gt;</span> <span class="n">SHAP_thr_HGBC</span><span class="p">)</span> <span class="o">&amp;</span> 
                                                    <span class="p">((</span><span class="n">predicted_probabilities</span> <span class="o">&lt;</span> <span class="p">(</span><span class="n">opt_threshold_HGBC</span> <span class="o">-</span> <span class="n">margin</span><span class="p">))</span> <span class="o">|</span> 
                                                        <span class="p">(</span><span class="n">predicted_probabilities</span> <span class="o">&gt;</span> <span class="p">(</span><span class="n">opt_threshold_HGBC</span> <span class="o">+</span> <span class="n">margin</span><span class="p">)))]</span>
                    <span class="n">pc_filtered</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">pp_filtered</span> <span class="o">&gt;=</span> <span class="n">opt_threshold_HGBC</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
                        
                <span class="k">elif</span> <span class="n">selected_model</span><span class="o">==</span><span class="s2">&quot;RandomForest_mdl&quot;</span><span class="p">:</span>
                    <span class="n">fold_data_all_OHE</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">fold</span> <span class="k">for</span> <span class="n">fold</span> <span class="ow">in</span> <span class="n">fold_data_rf</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                    <span class="n">shap_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">fold</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">fold</span> <span class="ow">in</span> <span class="n">shap_rf</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                    <span class="n">predicted_probabilities</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">fold</span> <span class="k">for</span> <span class="n">fold</span> <span class="ow">in</span> <span class="n">pp_fold_rf</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                    <span class="n">shap_sum</span> <span class="o">=</span> <span class="n">shap_values</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
                    <span class="n">shap_sum_abs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">shap_sum</span><span class="p">)</span>
                    <span class="n">SHAP_thr_rf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">shap_sum_abs</span><span class="p">,</span> <span class="n">SHAP_percentile</span><span class="p">)</span>

                    <span class="n">X_train_filtered_shap</span> <span class="o">=</span> <span class="n">fold_data_all_OHE</span><span class="p">[(</span><span class="n">shap_sum_abs</span> <span class="o">&gt;</span> <span class="n">SHAP_thr_rf</span><span class="p">)</span> <span class="o">&amp;</span> 
                                                        <span class="p">((</span><span class="n">predicted_probabilities</span> <span class="o">&lt;</span> <span class="p">(</span><span class="n">opt_threshold_rf</span> <span class="o">-</span> <span class="n">margin</span><span class="p">))</span> <span class="o">|</span> 
                                                        <span class="p">(</span><span class="n">predicted_probabilities</span> <span class="o">&gt;</span> <span class="p">(</span><span class="n">opt_threshold_rf</span> <span class="o">+</span> <span class="n">margin</span><span class="p">)))]</span>
                    <span class="n">y_train_filtered_shap</span> <span class="o">=</span> <span class="n">y_fold_all</span><span class="p">[(</span><span class="n">shap_sum_abs</span> <span class="o">&gt;</span> <span class="n">SHAP_thr_rf</span><span class="p">)</span> <span class="o">&amp;</span> 
                                                    <span class="p">((</span><span class="n">predicted_probabilities</span> <span class="o">&lt;</span> <span class="p">(</span><span class="n">opt_threshold_rf</span> <span class="o">-</span> <span class="n">margin</span><span class="p">))</span> <span class="o">|</span> 
                                                        <span class="p">(</span><span class="n">predicted_probabilities</span> <span class="o">&gt;</span> <span class="p">(</span><span class="n">opt_threshold_rf</span> <span class="o">+</span> <span class="n">margin</span><span class="p">)))]</span>
                    <span class="n">pp_filtered</span> <span class="o">=</span> <span class="n">predicted_probabilities</span><span class="p">[(</span><span class="n">shap_sum_abs</span> <span class="o">&gt;</span> <span class="n">SHAP_thr_rf</span><span class="p">)</span> <span class="o">&amp;</span> 
                                                    <span class="p">((</span><span class="n">predicted_probabilities</span> <span class="o">&lt;</span> <span class="p">(</span><span class="n">opt_threshold_rf</span> <span class="o">-</span> <span class="n">margin</span><span class="p">))</span> <span class="o">|</span> 
                                                        <span class="p">(</span><span class="n">predicted_probabilities</span> <span class="o">&gt;</span> <span class="p">(</span><span class="n">opt_threshold_rf</span> <span class="o">+</span> <span class="n">margin</span><span class="p">)))]</span>
                    <span class="n">pc_filtered</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">pp_filtered</span> <span class="o">&gt;=</span> <span class="n">opt_threshold_rf</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
                    
                <span class="k">elif</span> <span class="n">selected_model</span><span class="o">==</span><span class="s2">&quot;CatBoost_mdl&quot;</span><span class="p">:</span>
                    <span class="n">fold_data_all</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">fold</span> <span class="k">for</span> <span class="n">fold</span> <span class="ow">in</span> <span class="n">fold_data_CB</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                    <span class="n">shap_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">fold</span> <span class="k">for</span> <span class="n">fold</span> <span class="ow">in</span> <span class="n">shap_CB</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                    <span class="n">shap_sum</span> <span class="o">=</span> <span class="n">shap_values</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
                    <span class="n">shap_sum_abs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">shap_sum</span><span class="p">)</span>
                    <span class="n">SHAP_thr_CB</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">shap_sum_abs</span><span class="p">,</span> <span class="n">SHAP_percentile</span><span class="p">)</span>
                    <span class="n">predicted_probabilities</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">fold</span> <span class="k">for</span> <span class="n">fold</span> <span class="ow">in</span> <span class="n">pp_fold_CB</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

                    <span class="n">X_train_filtered_shap</span> <span class="o">=</span> <span class="n">fold_data_all</span><span class="p">[(</span><span class="n">shap_sum_abs</span> <span class="o">&gt;</span> <span class="n">SHAP_thr_CB</span><span class="p">)</span> <span class="o">&amp;</span> 
                                                    <span class="p">((</span><span class="n">predicted_probabilities</span> <span class="o">&lt;</span> <span class="p">(</span><span class="n">opt_threshold_CB</span> <span class="o">-</span> <span class="n">margin</span><span class="p">))</span> <span class="o">|</span> 
                                                    <span class="p">(</span><span class="n">predicted_probabilities</span> <span class="o">&gt;</span> <span class="p">(</span><span class="n">opt_threshold_CB</span> <span class="o">+</span> <span class="n">margin</span><span class="p">)))]</span>
                    <span class="n">y_train_filtered_shap</span> <span class="o">=</span> <span class="n">y_fold_all</span><span class="p">[(</span><span class="n">shap_sum_abs</span> <span class="o">&gt;</span> <span class="n">SHAP_thr_CB</span><span class="p">)</span> <span class="o">&amp;</span> 
                                                    <span class="p">((</span><span class="n">predicted_probabilities</span> <span class="o">&lt;</span> <span class="p">(</span><span class="n">opt_threshold_CB</span> <span class="o">-</span> <span class="n">margin</span><span class="p">))</span> <span class="o">|</span> 
                                                        <span class="p">(</span><span class="n">predicted_probabilities</span> <span class="o">&gt;</span> <span class="p">(</span><span class="n">opt_threshold_CB</span> <span class="o">+</span> <span class="n">margin</span><span class="p">)))]</span>
                    <span class="n">pp_filtered</span> <span class="o">=</span> <span class="n">predicted_probabilities</span><span class="p">[(</span><span class="n">shap_sum_abs</span> <span class="o">&gt;</span> <span class="n">SHAP_thr_CB</span><span class="p">)</span> <span class="o">&amp;</span> 
                                                    <span class="p">((</span><span class="n">predicted_probabilities</span> <span class="o">&lt;</span> <span class="p">(</span><span class="n">opt_threshold_CB</span> <span class="o">-</span> <span class="n">margin</span><span class="p">))</span> <span class="o">|</span> 
                                                        <span class="p">(</span><span class="n">predicted_probabilities</span> <span class="o">&gt;</span> <span class="p">(</span><span class="n">opt_threshold_CB</span> <span class="o">+</span> <span class="n">margin</span><span class="p">)))]</span>
                    <span class="n">pc_filtered</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">pp_filtered</span> <span class="o">&gt;=</span> <span class="n">opt_threshold_CB</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
                    
                <span class="k">elif</span> <span class="n">selected_model</span><span class="o">==</span><span class="s2">&quot;LightGBM_mdl&quot;</span><span class="p">:</span>
                    <span class="n">fold_data_all</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">fold</span> <span class="k">for</span> <span class="n">fold</span> <span class="ow">in</span> <span class="n">fold_data_LGBM</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                    <span class="n">shap_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">fold</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">fold</span> <span class="ow">in</span> <span class="n">shap_LGBM</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                    <span class="n">shap_sum</span> <span class="o">=</span> <span class="n">shap_values</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
                    <span class="n">shap_sum_abs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">shap_sum</span><span class="p">)</span>
                    <span class="n">SHAP_thr_LGBM</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">shap_sum_abs</span><span class="p">,</span> <span class="n">SHAP_percentile</span><span class="p">)</span>
                    <span class="n">predicted_probabilities</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">fold</span> <span class="k">for</span> <span class="n">fold</span> <span class="ow">in</span> <span class="n">pp_fold_LGBM</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                    <span class="n">X_train_filtered_shap</span> <span class="o">=</span> <span class="n">fold_data_all</span><span class="p">[(</span><span class="n">shap_sum_abs</span> <span class="o">&gt;</span> <span class="n">SHAP_thr_LGBM</span><span class="p">)</span> <span class="o">&amp;</span> 
                                                        <span class="p">((</span><span class="n">predicted_probabilities</span> <span class="o">&lt;</span> <span class="p">(</span><span class="n">opt_threshold_LGBM</span> <span class="o">-</span> <span class="n">margin</span><span class="p">))</span> <span class="o">|</span> 
                                                        <span class="p">(</span><span class="n">predicted_probabilities</span> <span class="o">&gt;</span> <span class="p">(</span><span class="n">opt_threshold_LGBM</span> <span class="o">+</span> <span class="n">margin</span><span class="p">)))]</span>
                    <span class="n">y_train_filtered_shap</span> <span class="o">=</span> <span class="n">y_fold_all</span><span class="p">[(</span><span class="n">shap_sum_abs</span> <span class="o">&gt;</span> <span class="n">SHAP_thr_LGBM</span><span class="p">)</span> <span class="o">&amp;</span> 
                                                    <span class="p">((</span><span class="n">predicted_probabilities</span> <span class="o">&lt;</span> <span class="p">(</span><span class="n">opt_threshold_LGBM</span> <span class="o">-</span> <span class="n">margin</span><span class="p">))</span> <span class="o">|</span> 
                                                        <span class="p">(</span><span class="n">predicted_probabilities</span> <span class="o">&gt;</span> <span class="p">(</span><span class="n">opt_threshold_LGBM</span> <span class="o">+</span> <span class="n">margin</span><span class="p">)))]</span>
                    <span class="n">pp_filtered</span> <span class="o">=</span> <span class="n">predicted_probabilities</span><span class="p">[(</span><span class="n">shap_sum_abs</span> <span class="o">&gt;</span> <span class="n">SHAP_thr_LGBM</span><span class="p">)</span> <span class="o">&amp;</span> 
                                                    <span class="p">((</span><span class="n">predicted_probabilities</span> <span class="o">&lt;</span> <span class="p">(</span><span class="n">opt_threshold_LGBM</span> <span class="o">-</span> <span class="n">margin</span><span class="p">))</span> <span class="o">|</span> 
                                                        <span class="p">(</span><span class="n">predicted_probabilities</span> <span class="o">&gt;</span> <span class="p">(</span><span class="n">opt_threshold_LGBM</span> <span class="o">+</span> <span class="n">margin</span><span class="p">)))]</span>
                    <span class="n">pc_filtered</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">pp_filtered</span> <span class="o">&gt;=</span> <span class="n">opt_threshold_LGBM</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
                    
                <span class="k">elif</span> <span class="n">selected_model</span><span class="o">==</span><span class="s2">&quot;LogisticRegression_mdl&quot;</span><span class="p">:</span>
                    <span class="n">fold_data_all_OHE</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">fold</span> <span class="k">for</span> <span class="n">fold</span> <span class="ow">in</span> <span class="n">fold_data_LR</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                    <span class="n">shap_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">fold</span> <span class="k">for</span> <span class="n">fold</span> <span class="ow">in</span> <span class="n">shap_LR</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                    <span class="n">predicted_probabilities</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">fold</span> <span class="k">for</span> <span class="n">fold</span> <span class="ow">in</span> <span class="n">pp_fold_LR</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                    <span class="n">shap_sum</span> <span class="o">=</span> <span class="n">shap_values</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
                    <span class="n">shap_sum_abs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">shap_sum</span><span class="p">)</span>
                    <span class="n">SHAP_thr_LR</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">shap_sum_abs</span><span class="p">,</span> <span class="n">SHAP_percentile</span><span class="p">)</span>

                    <span class="n">X_train_filtered_shap</span> <span class="o">=</span> <span class="n">fold_data_all_OHE</span><span class="p">[(</span><span class="n">shap_sum_abs</span> <span class="o">&gt;</span> <span class="n">SHAP_thr_LR</span><span class="p">)</span> <span class="o">&amp;</span> 
                                                        <span class="p">((</span><span class="n">predicted_probabilities</span> <span class="o">&lt;</span> <span class="p">(</span><span class="n">opt_threshold_LR</span> <span class="o">-</span> <span class="n">margin</span><span class="p">))</span> <span class="o">|</span> 
                                                        <span class="p">(</span><span class="n">predicted_probabilities</span> <span class="o">&gt;</span> <span class="p">(</span><span class="n">opt_threshold_LR</span> <span class="o">+</span> <span class="n">margin</span><span class="p">)))]</span>
                    <span class="n">y_train_filtered_shap</span> <span class="o">=</span> <span class="n">y_fold_all</span><span class="p">[(</span><span class="n">shap_sum_abs</span> <span class="o">&gt;</span> <span class="n">SHAP_thr_LR</span><span class="p">)</span> <span class="o">&amp;</span> 
                                                    <span class="p">((</span><span class="n">predicted_probabilities</span> <span class="o">&lt;</span> <span class="p">(</span><span class="n">opt_threshold_LR</span> <span class="o">-</span> <span class="n">margin</span><span class="p">))</span> <span class="o">|</span> 
                                                        <span class="p">(</span><span class="n">predicted_probabilities</span> <span class="o">&gt;</span> <span class="p">(</span><span class="n">opt_threshold_LR</span> <span class="o">+</span> <span class="n">margin</span><span class="p">)))]</span>
                    <span class="n">pp_filtered</span> <span class="o">=</span> <span class="n">predicted_probabilities</span><span class="p">[(</span><span class="n">shap_sum_abs</span> <span class="o">&gt;</span> <span class="n">SHAP_thr_LR</span><span class="p">)</span> <span class="o">&amp;</span> 
                                                    <span class="p">((</span><span class="n">predicted_probabilities</span> <span class="o">&lt;</span> <span class="p">(</span><span class="n">opt_threshold_LR</span> <span class="o">-</span> <span class="n">margin</span><span class="p">))</span> <span class="o">|</span> 
                                                        <span class="p">(</span><span class="n">predicted_probabilities</span> <span class="o">&gt;</span> <span class="p">(</span><span class="n">opt_threshold_LR</span> <span class="o">+</span> <span class="n">margin</span><span class="p">)))]</span>
                    <span class="n">pc_filtered</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">pp_filtered</span> <span class="o">&gt;=</span> <span class="n">opt_threshold_LR</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>                   
                   
                <span class="k">elif</span> <span class="n">selected_model</span><span class="o">==</span><span class="s2">&quot;NaiveBayes_mdl&quot;</span><span class="p">:</span>
                    <span class="n">fold_data_all_OHE</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">fold</span> <span class="k">for</span> <span class="n">fold</span> <span class="ow">in</span> <span class="n">fold_data_NB</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                    <span class="n">shap_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">fold</span><span class="o">.</span><span class="n">values</span> <span class="k">for</span> <span class="n">fold</span> <span class="ow">in</span> <span class="n">shap_NB</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                    <span class="n">predicted_probabilities</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">fold</span> <span class="k">for</span> <span class="n">fold</span> <span class="ow">in</span> <span class="n">pp_fold_NB</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                    <span class="n">shap_sum</span> <span class="o">=</span> <span class="n">shap_values</span><span class="p">[:,:,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
                    <span class="n">shap_sum_abs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">shap_sum</span><span class="p">)</span>
                    <span class="n">SHAP_thr_NB</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">shap_sum_abs</span><span class="p">,</span> <span class="n">SHAP_percentile</span><span class="p">)</span>

                    <span class="n">X_train_filtered_shap</span> <span class="o">=</span> <span class="n">fold_data_all_OHE</span><span class="p">[(</span><span class="n">shap_sum_abs</span> <span class="o">&gt;</span> <span class="n">SHAP_thr_NB</span><span class="p">)</span> <span class="o">&amp;</span> 
                                                        <span class="p">((</span><span class="n">predicted_probabilities</span> <span class="o">&lt;</span> <span class="p">(</span><span class="n">opt_threshold_NB</span> <span class="o">-</span> <span class="n">margin</span><span class="p">))</span> <span class="o">|</span> 
                                                        <span class="p">(</span><span class="n">predicted_probabilities</span> <span class="o">&gt;</span> <span class="p">(</span><span class="n">opt_threshold_NB</span> <span class="o">+</span> <span class="n">margin</span><span class="p">)))]</span>
                    <span class="n">y_train_filtered_shap</span> <span class="o">=</span> <span class="n">y_fold_all</span><span class="p">[(</span><span class="n">shap_sum_abs</span> <span class="o">&gt;</span> <span class="n">SHAP_thr_NB</span><span class="p">)</span> <span class="o">&amp;</span> 
                                                    <span class="p">((</span><span class="n">predicted_probabilities</span> <span class="o">&lt;</span> <span class="p">(</span><span class="n">opt_threshold_NB</span> <span class="o">-</span> <span class="n">margin</span><span class="p">))</span> <span class="o">|</span> 
                                                        <span class="p">(</span><span class="n">predicted_probabilities</span> <span class="o">&gt;</span> <span class="p">(</span><span class="n">opt_threshold_NB</span> <span class="o">+</span> <span class="n">margin</span><span class="p">)))]</span>
                    <span class="n">pp_filtered</span> <span class="o">=</span> <span class="n">predicted_probabilities</span><span class="p">[(</span><span class="n">shap_sum_abs</span> <span class="o">&gt;</span> <span class="n">SHAP_thr_NB</span><span class="p">)</span> <span class="o">&amp;</span> 
                                                    <span class="p">((</span><span class="n">predicted_probabilities</span> <span class="o">&lt;</span> <span class="p">(</span><span class="n">opt_threshold_NB</span> <span class="o">-</span> <span class="n">margin</span><span class="p">))</span> <span class="o">|</span> 
                                                        <span class="p">(</span><span class="n">predicted_probabilities</span> <span class="o">&gt;</span> <span class="p">(</span><span class="n">opt_threshold_NB</span> <span class="o">+</span> <span class="n">margin</span><span class="p">)))]</span>
                    <span class="n">pc_filtered</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">pp_filtered</span> <span class="o">&gt;=</span> <span class="n">opt_threshold_NB</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
                    
                <span class="k">elif</span> <span class="n">selected_model</span><span class="o">==</span><span class="s2">&quot;QLattice_mdl&quot;</span><span class="p">:</span>
                    <span class="n">fold_data_all_OHE</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">fold</span> <span class="k">for</span> <span class="n">fold</span> <span class="ow">in</span> <span class="n">fold_data_QLattice</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                    <span class="n">predicted_probabilities</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">fold</span> <span class="k">for</span> <span class="n">fold</span> <span class="ow">in</span> <span class="n">pp_fold_QLattice</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                    <span class="n">X_train_filtered_shap</span> <span class="o">=</span> <span class="n">fold_data_all_OHE</span><span class="p">[((</span><span class="n">predicted_probabilities</span> <span class="o">&lt;</span> <span class="p">(</span><span class="n">opt_threshold_QLattice</span> <span class="o">-</span> <span class="n">margin</span><span class="p">))</span> <span class="o">|</span> 
                                                    <span class="p">(</span><span class="n">predicted_probabilities</span> <span class="o">&gt;</span> <span class="p">(</span><span class="n">opt_threshold_QLattice</span> <span class="o">+</span> <span class="n">margin</span><span class="p">)))]</span>
                    <span class="n">y_train_filtered_shap</span> <span class="o">=</span> <span class="n">y_fold_all</span><span class="p">[((</span><span class="n">predicted_probabilities</span> <span class="o">&lt;</span> <span class="p">(</span><span class="n">opt_threshold_QLattice</span> <span class="o">-</span> <span class="n">margin</span><span class="p">))</span> <span class="o">|</span> 
                                                        <span class="p">(</span><span class="n">predicted_probabilities</span> <span class="o">&gt;</span> <span class="p">(</span><span class="n">opt_threshold_QLattice</span> <span class="o">+</span> <span class="n">margin</span><span class="p">)))]</span>
                    <span class="n">pp_filtered</span> <span class="o">=</span> <span class="n">predicted_probabilities</span><span class="p">[((</span><span class="n">predicted_probabilities</span> <span class="o">&lt;</span> <span class="p">(</span><span class="n">opt_threshold_QLattice</span> <span class="o">-</span> <span class="n">margin</span><span class="p">))</span> <span class="o">|</span> <span class="p">(</span><span class="n">predicted_probabilities</span> <span class="o">&gt;</span> <span class="p">(</span><span class="n">opt_threshold_QLattice</span> <span class="o">+</span> <span class="n">margin</span><span class="p">)))]</span>
                    <span class="n">pc_filtered</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">pp_filtered</span> <span class="o">&gt;=</span> <span class="n">opt_threshold_QLattice</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>

                <span class="n">CV_results_filtered_mdl</span> <span class="o">=</span> <span class="n">calculate_metrics</span><span class="p">(</span><span class="n">y_true</span> <span class="o">=</span> <span class="n">y_train_filtered_shap</span><span class="p">,</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="n">pc_filtered</span><span class="p">,</span> <span class="n">y_pred_proba</span> <span class="o">=</span> <span class="n">pp_filtered</span><span class="p">)</span>
                <span class="n">CV_results_filtered_mdl</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">CV_results_filtered_mdl</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
                <span class="c1"># Add the model name to the results</span>
                <span class="n">CV_results_filtered_mdl</span><span class="p">[</span><span class="s1">&#39;Model&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">selected_model</span>
                <span class="n">CV_results_filtered_mdl</span><span class="p">[</span><span class="s1">&#39;Margin&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">margin</span>
                <span class="n">CV_results_filtered_mdl</span><span class="p">[</span><span class="s1">&#39;SHAP_percentile&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">SHAP_percentile</span>
                <span class="n">CV_results_filtered_mdl</span><span class="p">[</span><span class="s1">&#39;Sample_size&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_train_filtered_shap</span><span class="p">)</span>
                <span class="n">CV_results_filtered_mdl</span><span class="p">[</span><span class="s1">&#39;Sample_loss&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">100</span><span class="o">-</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y_train_filtered_shap</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">y_fold_all</span><span class="p">))</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
                <span class="c1"># Append results</span>
                <span class="n">aggregated_CV_results_filtered_mdl</span> <span class="o">=</span> <span class="n">aggregated_CV_results_filtered_mdl</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">CV_results_filtered_mdl</span><span class="p">,</span> <span class="n">ignore_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="c1"># Save the results to an Excel file</span>
                
    <span class="c1"># Save the aggregated results to an Excel file</span>
    <span class="n">aggregated_CV_results_filtered_mdl</span><span class="o">.</span><span class="n">to_excel</span><span class="p">(</span><span class="s1">&#39;agg_results.xlsx&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="c1"># Define a filter for sample loss</span>
    <span class="n">sample_loss_filter</span> <span class="o">=</span> <span class="n">aggregated_CV_results_filtered_mdl</span><span class="p">[</span><span class="s2">&quot;Sample_loss&quot;</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">max_sample_loss_perc</span>

    <span class="c1"># Find the maximum values for ROCAUC, PRAUC, and MCC under the sample loss filter</span>
    <span class="n">max_rocauc</span> <span class="o">=</span> <span class="n">aggregated_CV_results_filtered_mdl</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">sample_loss_filter</span><span class="p">,</span> <span class="s2">&quot;ROCAUC&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
    <span class="n">max_prauc</span> <span class="o">=</span> <span class="n">aggregated_CV_results_filtered_mdl</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">sample_loss_filter</span><span class="p">,</span> <span class="s2">&quot;PRAUC&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
    <span class="n">max_mcc</span> <span class="o">=</span> <span class="n">aggregated_CV_results_filtered_mdl</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">sample_loss_filter</span><span class="p">,</span> <span class="s2">&quot;MCC&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>

    <span class="c1"># Filter the DataFrame based on the maximum values and sample loss filter</span>
    <span class="n">best_combination</span> <span class="o">=</span> <span class="n">aggregated_CV_results_filtered_mdl</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span>
        <span class="n">sample_loss_filter</span> <span class="o">&amp;</span>
        <span class="p">(</span><span class="n">aggregated_CV_results_filtered_mdl</span><span class="p">[</span><span class="s2">&quot;ROCAUC&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="n">max_rocauc</span><span class="p">)</span> <span class="o">&amp;</span>
        <span class="p">(</span><span class="n">aggregated_CV_results_filtered_mdl</span><span class="p">[</span><span class="s2">&quot;PRAUC&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="n">max_prauc</span><span class="p">)</span> <span class="o">&amp;</span>
        <span class="p">(</span><span class="n">aggregated_CV_results_filtered_mdl</span><span class="p">[</span><span class="s2">&quot;MCC&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="n">max_mcc</span><span class="p">)</span>
    <span class="p">]</span>
    <span class="c1"># Filter the DataFrame based on sample loss</span>
    <span class="n">filtered_df</span> <span class="o">=</span> <span class="n">aggregated_CV_results_filtered_mdl</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">sample_loss_filter</span><span class="p">]</span>

    <span class="c1"># Filter the DataFrame based on the maximum values and sample loss filter</span>
    <span class="n">best_combination</span> <span class="o">=</span> <span class="n">filtered_df</span><span class="p">[</span>
        <span class="p">(</span><span class="n">filtered_df</span><span class="p">[</span><span class="s2">&quot;ROCAUC&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="n">max_rocauc</span><span class="p">)</span> <span class="o">&amp;</span>
        <span class="p">(</span><span class="n">filtered_df</span><span class="p">[</span><span class="s2">&quot;PRAUC&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="n">max_prauc</span><span class="p">)</span> <span class="o">&amp;</span>
        <span class="p">(</span><span class="n">filtered_df</span><span class="p">[</span><span class="s2">&quot;MCC&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="n">max_mcc</span><span class="p">)</span>
    <span class="p">]</span>
    <span class="c1"># Check if best_combination is empty</span>
    <span class="k">if</span> <span class="n">best_combination</span><span class="o">.</span><span class="n">empty</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;No exact match found. Finding the closest combination.&quot;</span><span class="p">)</span>

        <span class="c1"># Define a closeness metric: using inverse of distance to the maximum values</span>
        <span class="n">filtered_df</span><span class="p">[</span><span class="s1">&#39;Closeness&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">filtered_df</span><span class="p">[</span><span class="s2">&quot;ROCAUC&quot;</span><span class="p">]</span> <span class="o">-</span> <span class="n">max_rocauc</span><span class="p">)</span> <span class="o">+</span>
            <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">filtered_df</span><span class="p">[</span><span class="s2">&quot;PRAUC&quot;</span><span class="p">]</span> <span class="o">-</span> <span class="n">max_prauc</span><span class="p">)</span> <span class="o">+</span>
            <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">filtered_df</span><span class="p">[</span><span class="s2">&quot;MCC&quot;</span><span class="p">]</span> <span class="o">-</span> <span class="n">max_mcc</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="c1"># Find the row with the smallest closeness value</span>
        <span class="n">closest_combination</span> <span class="o">=</span> <span class="n">filtered_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">filtered_df</span><span class="p">[</span><span class="s1">&#39;Closeness&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">idxmin</span><span class="p">()]</span>

        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Closest combination found:&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">closest_combination</span><span class="p">)</span>
        <span class="n">best_combination</span> <span class="o">=</span> <span class="n">closest_combination</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best combination found:&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">best_combination</span><span class="p">)</span>
        <span class="n">best_combination</span> <span class="o">=</span> <span class="n">best_combination</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Sample_loss&quot;</span><span class="p">,</span> <span class="s2">&quot;Margin&quot;</span><span class="p">,</span> <span class="s2">&quot;SHAP_percentile&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    

    <span class="n">best_margin</span> <span class="o">=</span> <span class="n">best_combination</span><span class="p">[</span><span class="s2">&quot;Margin&quot;</span><span class="p">]</span>
    <span class="n">best_SHAP_percentile</span> <span class="o">=</span> <span class="n">best_combination</span><span class="p">[</span><span class="s2">&quot;SHAP_percentile&quot;</span><span class="p">]</span>
    <span class="n">best_model</span> <span class="o">=</span> <span class="n">best_combination</span><span class="p">[</span><span class="s2">&quot;Model&quot;</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The best margin is </span><span class="si">{</span><span class="n">best_margin</span><span class="si">}</span><span class="s2"> and the best SHAP_percentile is </span><span class="si">{</span><span class="n">best_SHAP_percentile</span><span class="si">}</span><span class="s2"> and the best model is </span><span class="si">{</span><span class="n">best_model</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">model_uncertainty_reduction</span><span class="p">:</span>
    <span class="n">best_combination_agg_perf_df</span> <span class="o">=</span> <span class="n">aggregated_CV_results_filtered_mdl</span><span class="o">.</span><span class="n">loc</span><span class="p">[(</span><span class="n">aggregated_CV_results_filtered_mdl</span><span class="p">[</span><span class="s2">&quot;Margin&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="n">best_margin</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">aggregated_CV_results_filtered_mdl</span><span class="p">[</span><span class="s2">&quot;SHAP_percentile&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="n">best_SHAP_percentile</span><span class="p">)]</span>
    <span class="c1"># List of columns to be rounded</span>
    <span class="n">columns_to_round</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s2">&quot;PPV&quot;</span><span class="p">,</span> <span class="s2">&quot;NPV&quot;</span><span class="p">,</span> <span class="s2">&quot;Sensitivity&quot;</span><span class="p">,</span> <span class="s2">&quot;Specificity&quot;</span><span class="p">,</span> 
        <span class="s2">&quot;Balanced Accuracy&quot;</span><span class="p">,</span> <span class="s2">&quot;MCC&quot;</span><span class="p">,</span> <span class="s2">&quot;ROCAUC&quot;</span><span class="p">,</span> 
        <span class="s2">&quot;PRAUC&quot;</span><span class="p">,</span> <span class="s2">&quot;Brier Score&quot;</span><span class="p">,</span> <span class="s2">&quot;F1 Score&quot;</span>
    <span class="p">]</span>

    <span class="c1"># Round the selected columns to 2 decimal places</span>
    <span class="n">best_combination_agg_perf_df</span><span class="p">[</span><span class="n">columns_to_round</span><span class="p">]</span> <span class="o">=</span> <span class="n">best_combination_agg_perf_df</span><span class="p">[</span><span class="n">columns_to_round</span><span class="p">]</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="n">best_combination_agg_perf_df</span><span class="p">)</span>
    <span class="c1"># Save the aggregated results to an Excel file</span>
    <span class="n">best_combination_agg_perf_df</span><span class="o">.</span><span class="n">to_excel</span><span class="p">(</span><span class="s1">&#39;best_combination_agg_perf_df.xlsx&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    
    <span class="c1"># reassign the best model after applying the MUR approach</span>
    <span class="n">selected_model</span> <span class="o">=</span> <span class="n">best_model</span>
    
    <span class="c1"># Get the full name of the best model</span>
    <span class="n">best_model_name</span> <span class="o">=</span> <span class="n">model_names</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">best_model</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="stopping-if-there-is-no-data-split">
<h3>Stopping if there is no data split<a class="headerlink" href="#stopping-if-there-is-no-data-split" title="Link to this heading">#</a></h3>
<p>If data split is not done then the following code should stop the pipeline here.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="ow">not</span> <span class="n">data_split</span><span class="p">:</span>
    <span class="k">class</span> <span class="nc">IpyExit</span><span class="p">(</span><span class="ne">SystemExit</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Exit Exception for IPython.</span>
<span class="sd">        This defines a custom exception class named `IpyExit`, which inherits from Python&#39;s built-in `SystemExit` class. This custom exception is used to handle the exit mechanism in IPython environments when the `data_split` variable is not set.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">            </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            This defines the constructor (`__init__`) and destructor (`__del__`) methods for the `IpyExit` custom exception class.</span>
<span class="sd">            &quot;&quot;&quot;</span>
            <span class="n">sys</span><span class="o">.</span><span class="n">stderr</span> <span class="o">=</span> <span class="n">StringIO</span><span class="p">()</span>

        <span class="k">def</span> <span class="fm">__del__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">            </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            The `__del__` method closes the captured output buffer and restores it to its original value, ensuring proper cleanup when exiting.</span>
<span class="sd">            &quot;&quot;&quot;</span>
            <span class="n">sys</span><span class="o">.</span><span class="n">stderr</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
            <span class="n">sys</span><span class="o">.</span><span class="n">stderr</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">__stderr__</span>

    <span class="k">def</span> <span class="nf">ipy_exit</span><span class="p">():</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This function raises an exception to terminate the execution of a Jupyter Notebook or IPython environment. When raised, it creates an instance of `SystemExit` which is handled by Python&#39;s built-in exit mechanism.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="n">IpyExit</span>

    <span class="k">if</span> <span class="n">get_ipython</span><span class="p">():</span>    <span class="c1"># If running in IPython (e.g., Jupyter)</span>
        <span class="n">exit</span> <span class="o">=</span> <span class="n">ipy_exit</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">exit</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">exit</span>

    <span class="n">exit</span><span class="p">()</span>  <span class="c1"># Stop the execution</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="prediction-block-for-binary-classification-models">
<h3>Prediction block for binary classification models<a class="headerlink" href="#prediction-block-for-binary-classification-models" title="Link to this heading">#</a></h3>
<p>The following blocks are for the case that there is an independent dataset that can be used to validate a trained model (external validation).</p>
<section id="id1">
<h4>QLattice model<a class="headerlink" href="#id1" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">test_only_best_cvmodel</span> <span class="ow">and</span> <span class="n">best_model_name</span> <span class="o">!=</span> <span class="s2">&quot;QLattice&quot;</span><span class="p">:</span>
    <span class="k">pass</span>
<span class="k">else</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">hp_tuning</span><span class="p">:</span>
            
        <span class="n">best_composite_score</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">best_parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;n_epochs&#39;</span><span class="p">:</span> <span class="mi">50</span><span class="p">,</span> <span class="s1">&#39;max_complexity&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
    
        <span class="k">def</span> <span class="nf">evaluate_params</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">,</span> <span class="n">max_complexity</span><span class="p">):</span>
<span class="w">            </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Evaluate a composite model by tuning hyperparameters using the Feyn framework.</span>

<span class="sd">            Parameters:</span>
<span class="sd">                n_epochs (int): Number of epochs for training the model.</span>
<span class="sd">                max_complexity (int): Maximum complexity of the model.</span>

<span class="sd">            ## Returns</span>
<span class="sd">                tuple: The composite score (mean of AUC and AP) and the best parameters used to achieve this score.</span>

<span class="sd">            Notes:</span>
<span class="sd">                This function uses the Feyn framework to perform a hyperparameter tuning search.</span>
<span class="sd">                It assumes that `mydata_imputed_nocv`, `outcome_var`, `y_train`, `stypes`, `sample_weights` are defined elsewhere in the code.</span>
<span class="sd">                The `random_seed` parameter is set to `SEED` for reproducibility.</span>

<span class="sd">            Steps:</span>
<span class="sd">                1. Initialize a QLattice object with a random seed.</span>
<span class="sd">                2. Use `auto_run` to perform a hyperparameter tuning search.</span>
<span class="sd">                    - The model is run on the training data (`mydata_imputed_nocv`) for `n_epochs` epochs.</span>
<span class="sd">                    - The criterion used for hyperparameter selection is AIC (Akaike information criterion).</span>
<span class="sd">                    - The loss function used for classification is binary cross-entropy.</span>
<span class="sd">                3. Select the best model from the set of models generated by `auto_run`.</span>
<span class="sd">                4. Use this best model to make predictions on the training data.</span>
<span class="sd">                5. Calculate the composite score, which is the mean of AUC (Receiver Operating Characteristic) and AP (Area Under the Precision-Recall Curve).</span>
<span class="sd">            &quot;&quot;&quot;</span>
            <span class="n">ql</span> <span class="o">=</span> <span class="n">feyn</span><span class="o">.</span><span class="n">QLattice</span><span class="p">(</span><span class="n">random_seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
            <span class="n">models</span> <span class="o">=</span> <span class="n">ql</span><span class="o">.</span><span class="n">auto_run</span><span class="p">(</span>
                <span class="n">data</span><span class="o">=</span><span class="n">mydata_imputed_nocv</span><span class="p">,</span>
                <span class="n">output_name</span><span class="o">=</span><span class="n">outcome_var</span><span class="p">,</span>
                <span class="n">kind</span><span class="o">=</span><span class="s1">&#39;classification&#39;</span><span class="p">,</span>
                <span class="n">n_epochs</span><span class="o">=</span><span class="n">n_epochs</span><span class="p">,</span>
                <span class="n">stypes</span><span class="o">=</span><span class="n">stypes</span><span class="p">,</span>
                <span class="n">criterion</span><span class="o">=</span><span class="s2">&quot;aic&quot;</span><span class="p">,</span>
                <span class="n">loss_function</span><span class="o">=</span><span class="s1">&#39;binary_cross_entropy&#39;</span><span class="p">,</span>
                <span class="n">max_complexity</span><span class="o">=</span><span class="n">max_complexity</span><span class="p">,</span>
                <span class="n">sample_weights</span><span class="o">=</span><span class="n">sample_weights</span>
            <span class="p">)</span>
            <span class="n">best_model</span> <span class="o">=</span> <span class="n">models</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            
            <span class="n">predictions_proba</span> <span class="o">=</span> <span class="n">best_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">mydata_imputed_nocv</span><span class="p">)</span>
            <span class="n">QL_composite_score</span> <span class="o">=</span> <span class="p">(</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_true</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_score</span> <span class="o">=</span> <span class="n">predictions_proba</span><span class="p">)</span> <span class="o">+</span> <span class="n">average_precision_score</span><span class="p">(</span><span class="n">y_true</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_score</span> <span class="o">=</span> <span class="n">predictions_proba</span><span class="p">))</span><span class="o">/</span><span class="mi">2</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">QL_composite_score</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">QL_composite_score</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;n_epochs&#39;</span><span class="p">:</span> <span class="n">n_epochs</span><span class="p">,</span> <span class="s1">&#39;max_complexity&#39;</span><span class="p">:</span> <span class="n">max_complexity</span><span class="p">}</span>
    
        <span class="n">results</span> <span class="o">=</span> <span class="n">Parallel</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=</span><span class="n">n_cpu_for_tuning</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="s1">&#39;loky&#39;</span><span class="p">)(</span>
            <span class="n">delayed</span><span class="p">(</span><span class="n">evaluate_params</span><span class="p">)(</span><span class="n">n_epochs</span><span class="p">,</span> <span class="n">max_complexity</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">n_epochs</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">max_complexity</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">]</span>
        <span class="p">)</span>
    
        <span class="k">for</span> <span class="n">QL_composite_score</span><span class="p">,</span> <span class="n">params</span> <span class="ow">in</span> <span class="n">results</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">QL_composite_score</span> <span class="o">&gt;</span> <span class="n">best_composite_score</span><span class="p">:</span>
                <span class="n">best_composite_score</span> <span class="o">=</span> <span class="n">QL_composite_score</span>
                <span class="n">best_parameters</span> <span class="o">=</span> <span class="n">params</span>
        
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best Parameters:&quot;</span><span class="p">,</span> <span class="n">best_parameters</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best composite score:&quot;</span><span class="p">,</span> <span class="n">best_composite_score</span><span class="p">)</span>
        <span class="c1"># Use the best parameters from the grid search</span>
        <span class="n">best_n_epochs</span> <span class="o">=</span> <span class="n">best_parameters</span><span class="p">[</span><span class="s1">&#39;n_epochs&#39;</span><span class="p">]</span>
        <span class="n">best_max_complexity</span> <span class="o">=</span> <span class="n">best_parameters</span><span class="p">[</span><span class="s1">&#39;max_complexity&#39;</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">best_n_epochs</span> <span class="o">=</span> <span class="mi">50</span>
        <span class="n">best_max_complexity</span> <span class="o">=</span> <span class="mi">10</span>
            
    <span class="c1"># Train the final model with the best parameters</span>
    <span class="n">ql</span> <span class="o">=</span> <span class="n">feyn</span><span class="o">.</span><span class="n">QLattice</span><span class="p">(</span><span class="n">random_seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
    <span class="n">models</span> <span class="o">=</span> <span class="n">ql</span><span class="o">.</span><span class="n">auto_run</span><span class="p">(</span>
        <span class="n">data</span><span class="o">=</span><span class="n">mydata_imputed_nocv</span><span class="p">,</span>
        <span class="n">output_name</span><span class="o">=</span><span class="n">outcome_var</span><span class="p">,</span>
        <span class="n">kind</span><span class="o">=</span><span class="s1">&#39;classification&#39;</span><span class="p">,</span>
        <span class="n">n_epochs</span><span class="o">=</span><span class="n">best_n_epochs</span><span class="p">,</span>
        <span class="n">stypes</span><span class="o">=</span><span class="n">stypes</span><span class="p">,</span>
        <span class="n">criterion</span><span class="o">=</span><span class="s2">&quot;aic&quot;</span><span class="p">,</span>
        <span class="n">loss_function</span><span class="o">=</span><span class="s1">&#39;binary_cross_entropy&#39;</span><span class="p">,</span>
        <span class="n">max_complexity</span><span class="o">=</span><span class="n">best_max_complexity</span><span class="p">,</span>
        <span class="n">sample_weights</span><span class="o">=</span><span class="n">sample_weights</span>
    <span class="p">)</span>

    <span class="n">best_model</span> <span class="o">=</span> <span class="n">models</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">test_only_best_cvmodel</span> <span class="ow">and</span> <span class="n">best_model_name</span> <span class="o">!=</span> <span class="s2">&quot;QLattice&quot;</span><span class="p">:</span>
    <span class="k">pass</span>
<span class="k">else</span><span class="p">:</span>
    <span class="k">if</span> <span class="s2">&quot;QLattice_mdl&quot;</span> <span class="ow">in</span> <span class="n">models_to_include</span><span class="p">:</span>
        <span class="n">best_model</span><span class="o">.</span><span class="n">plot_signal</span><span class="p">(</span><span class="n">mydata_imputed_nocv</span><span class="p">,</span><span class="n">corr_func</span><span class="o">=</span><span class="s1">&#39;spearman&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">test_only_best_cvmodel</span> <span class="ow">and</span> <span class="n">best_model_name</span> <span class="o">!=</span> <span class="s2">&quot;QLattice&quot;</span><span class="p">:</span>
    <span class="k">pass</span>
<span class="k">else</span><span class="p">:</span>
    <span class="k">if</span> <span class="s2">&quot;QLattice_mdl&quot;</span> <span class="ow">in</span> <span class="n">models_to_include</span><span class="p">:</span>
        <span class="n">best_model</span><span class="o">.</span><span class="n">plot_signal</span><span class="p">(</span><span class="n">testset_imputed</span><span class="p">,</span><span class="n">corr_func</span><span class="o">=</span><span class="s1">&#39;spearman&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">test_only_best_cvmodel</span> <span class="ow">and</span> <span class="n">best_model_name</span> <span class="o">!=</span> <span class="s2">&quot;QLattice&quot;</span><span class="p">:</span>
    <span class="k">pass</span>
<span class="k">else</span><span class="p">:</span>
    <span class="k">if</span> <span class="s2">&quot;QLattice_mdl&quot;</span> <span class="ow">in</span> <span class="n">models_to_include</span><span class="p">:</span>
        <span class="n">best_model</span><span class="o">.</span><span class="n">plot_signal</span><span class="p">(</span><span class="n">mydata_imputed_nocv</span><span class="p">,</span><span class="n">corr_func</span><span class="o">=</span><span class="s1">&#39;mutual_information&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">test_only_best_cvmodel</span> <span class="ow">and</span> <span class="n">best_model_name</span> <span class="o">!=</span> <span class="s2">&quot;QLattice&quot;</span><span class="p">:</span>
    <span class="k">pass</span>
<span class="k">else</span><span class="p">:</span>
    <span class="k">if</span> <span class="s2">&quot;QLattice_mdl&quot;</span> <span class="ow">in</span> <span class="n">models_to_include</span><span class="p">:</span>
        <span class="n">best_model</span><span class="o">.</span><span class="n">plot_signal</span><span class="p">(</span><span class="n">testset_imputed</span><span class="p">,</span><span class="n">corr_func</span><span class="o">=</span><span class="s1">&#39;mutual_information&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">test_only_best_cvmodel</span> <span class="ow">and</span> <span class="n">best_model_name</span> <span class="o">!=</span> <span class="s2">&quot;QLattice&quot;</span><span class="p">:</span>
    <span class="k">pass</span>
<span class="k">else</span><span class="p">:</span>
    <span class="k">if</span> <span class="s2">&quot;QLattice_mdl&quot;</span> <span class="ow">in</span> <span class="n">models_to_include</span><span class="p">:</span>
        <span class="n">results_df_QLattice</span><span class="p">,</span> <span class="n">missclassified_samples</span> <span class="o">=</span> <span class="n">evaluate_and_plot_model</span><span class="p">(</span><span class="n">model</span> <span class="o">=</span> <span class="n">best_model</span><span class="p">,</span>
                                                    <span class="n">threshold</span> <span class="o">=</span> <span class="n">opt_threshold_QLattice</span><span class="p">,</span>
                                                    <span class="n">testset</span> <span class="o">=</span> <span class="n">testset_imputed</span><span class="p">,</span>
                                                    <span class="n">y_test</span> <span class="o">=</span> <span class="n">y_test</span><span class="p">,</span>
                                                    <span class="n">filename</span><span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;ROC_CM_QLattice.</span><span class="si">{</span><span class="n">fig_file_format</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">external_val</span><span class="p">:</span>
            <span class="c1"># Reorder extval_data_imputed columns to match testset_imputed</span>
            <span class="n">extval_data_imputed</span> <span class="o">=</span> <span class="n">extval_data_imputed</span><span class="p">[</span><span class="n">testset_imputed</span><span class="o">.</span><span class="n">columns</span><span class="p">]</span>
            <span class="n">results_df_QLattice_extval</span><span class="p">,</span> <span class="n">missclassified_samples_external</span> <span class="o">=</span> <span class="n">evaluate_and_plot_model</span><span class="p">(</span><span class="n">model</span> <span class="o">=</span> <span class="n">best_model</span><span class="p">,</span>
                                                        <span class="n">threshold</span> <span class="o">=</span> <span class="n">opt_threshold_QLattice</span><span class="p">,</span>
                                                        <span class="n">testset</span> <span class="o">=</span> <span class="n">extval_data_imputed</span><span class="p">,</span>
                                                        <span class="n">y_test</span> <span class="o">=</span> <span class="n">y_extval_data</span><span class="p">,</span>
                                                        <span class="n">filename</span><span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;ROC_CM_QLattice_extval.</span><span class="si">{</span><span class="n">fig_file_format</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    
        <span class="k">if</span> <span class="n">export_missclassified</span><span class="p">:</span> <span class="c1"># extend the code if you have external validation set and want to check this </span>
            <span class="n">misclassified_ids</span> <span class="o">=</span> <span class="n">mydata_backup</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">missclassified_samples</span><span class="p">,</span> <span class="s1">&#39;ID&#39;</span><span class="p">]</span>
            
            <span class="n">misclassified_ids_df</span><span class="o">.</span><span class="n">to_excel</span><span class="p">(</span><span class="s1">&#39;testset_misclassified_ids_QLattice.xlsx&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">test_only_best_cvmodel</span> <span class="ow">and</span> <span class="n">best_model_name</span> <span class="o">!=</span> <span class="s2">&quot;QLattice&quot;</span><span class="p">:</span>
    <span class="k">pass</span>
<span class="k">else</span><span class="p">:</span>
    <span class="k">if</span> <span class="s2">&quot;QLattice_mdl&quot;</span> <span class="ow">in</span> <span class="n">models_to_include</span><span class="p">:</span>
        <span class="n">init_printing</span><span class="p">()</span>
        <span class="n">display</span><span class="p">(</span><span class="n">best_model</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">mydata_imputed_nocv</span><span class="p">,</span> <span class="n">testset_imputed</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">test_only_best_cvmodel</span> <span class="ow">and</span> <span class="n">best_model_name</span> <span class="o">!=</span> <span class="s2">&quot;QLattice&quot;</span><span class="p">:</span>
    <span class="k">pass</span>
<span class="k">else</span><span class="p">:</span>
    <span class="k">if</span> <span class="s2">&quot;QLattice_mdl&quot;</span> <span class="ow">in</span> <span class="n">models_to_include</span><span class="p">:</span>
        <span class="c1"># feature selected by the model</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">best_model</span><span class="o">.</span><span class="n">features</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># distribution of model predicted probabilities for each class</span>
<span class="k">if</span> <span class="n">test_only_best_cvmodel</span> <span class="ow">and</span> <span class="n">best_model_name</span> <span class="o">!=</span> <span class="s2">&quot;QLattice&quot;</span><span class="p">:</span>
    <span class="k">pass</span>
<span class="k">else</span><span class="p">:</span>
    <span class="k">if</span> <span class="s2">&quot;QLattice_mdl&quot;</span> <span class="ow">in</span> <span class="n">models_to_include</span><span class="p">:</span>
        <span class="n">best_model</span><span class="o">.</span><span class="n">plot_probability_scores</span><span class="p">(</span><span class="n">testset_imputed</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># model representation as a closed-form expression</span>
<span class="k">if</span> <span class="n">test_only_best_cvmodel</span> <span class="ow">and</span> <span class="n">best_model_name</span> <span class="o">!=</span> <span class="s2">&quot;QLattice&quot;</span><span class="p">:</span>
    <span class="k">pass</span>
<span class="k">else</span><span class="p">:</span>
    <span class="k">if</span> <span class="s2">&quot;QLattice_mdl&quot;</span> <span class="ow">in</span> <span class="n">models_to_include</span><span class="p">:</span>
        <span class="n">init_printing</span><span class="p">()</span>
        <span class="n">sympy_model</span> <span class="o">=</span> <span class="n">best_model</span><span class="o">.</span><span class="n">sympify</span><span class="p">(</span><span class="n">symbolic_lr</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">include_weights</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="n">display</span><span class="p">(</span><span class="n">sympy_model</span><span class="o">.</span><span class="n">as_expr</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">test_only_best_cvmodel</span> <span class="ow">and</span> <span class="n">best_model_name</span> <span class="o">!=</span> <span class="s2">&quot;QLattice&quot;</span><span class="p">:</span>
    <span class="k">pass</span>
<span class="k">else</span><span class="p">:</span>
    <span class="k">if</span> <span class="s2">&quot;QLattice_mdl&quot;</span> <span class="ow">in</span> <span class="n">models_to_include</span><span class="p">:</span>
        <span class="c1"># Save a model to a file</span>
        <span class="n">best_model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;QLattice_model.json&#39;</span><span class="p">)</span>
        
        <span class="c1"># to load the model use the following script</span>
        <span class="c1"># from feyn import Model</span>
        <span class="c1"># model = Model.load(&#39;QLattice_model.json&#39;)</span>
        <span class="c1"># prediction = model.predict(testset_imputed)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="test-dummy-models">
<h4>Test dummy models<a class="headerlink" href="#test-dummy-models" title="Link to this heading">#</a></h4>
<p>See how dummy models (models that are not trained on the data) perform. This is done to estimate the performance level of dummy models as compared with the models that are trained.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Train Dummy Classifier</span>
<span class="n">dummy_classifier</span> <span class="o">=</span> <span class="n">DummyClassifier</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s1">&#39;most_frequent&#39;</span><span class="p">)</span>  <span class="c1"># you can choose different strategies based on your requirements</span>
<span class="n">dummy_classifier</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_OHE_nocv</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weights</span><span class="p">)</span>

<span class="n">results_df_dummy</span><span class="p">,</span> <span class="n">missclassified_samples</span> <span class="o">=</span> <span class="n">evaluate_and_plot_model</span><span class="p">(</span><span class="n">model</span> <span class="o">=</span> <span class="n">dummy_classifier</span><span class="p">,</span>
                                        <span class="n">threshold</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
                                        <span class="n">testset</span> <span class="o">=</span> <span class="n">X_test_OHE</span><span class="p">,</span>
                                        <span class="n">y_test</span> <span class="o">=</span> <span class="n">y_test</span><span class="p">,</span>
                                        <span class="n">filename</span><span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;ROC_CM_dummy_most_frequent.</span><span class="si">{</span><span class="n">fig_file_format</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Train Dummy Classifier with &#39;stratified&#39; strategy</span>
<span class="n">dummy_classifier</span> <span class="o">=</span> <span class="n">DummyClassifier</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s1">&#39;stratified&#39;</span><span class="p">)</span>
<span class="n">dummy_classifier</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_OHE_nocv</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weights</span><span class="p">)</span>

<span class="n">results_df_dummy</span><span class="p">,</span> <span class="n">missclassified_samples</span> <span class="o">=</span> <span class="n">evaluate_and_plot_model</span><span class="p">(</span><span class="n">model</span> <span class="o">=</span> <span class="n">dummy_classifier</span><span class="p">,</span>
                                        <span class="n">threshold</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
                                        <span class="n">testset</span> <span class="o">=</span> <span class="n">X_test_OHE</span><span class="p">,</span>
                                        <span class="n">y_test</span> <span class="o">=</span> <span class="n">y_test</span><span class="p">,</span>
                                        <span class="n">filename</span><span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;ROC_CM_dummy_stratified.</span><span class="si">{</span><span class="n">fig_file_format</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="id2">
<h4>Gaussian Naive Bayes<a class="headerlink" href="#id2" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">test_only_best_cvmodel</span> <span class="ow">and</span> <span class="n">best_model_name</span> <span class="o">!=</span> <span class="s2">&quot;NB&quot;</span><span class="p">:</span>
    <span class="k">pass</span>
<span class="k">else</span><span class="p">:</span>
    <span class="k">if</span> <span class="s2">&quot;NaiveBayes_mdl&quot;</span> <span class="ow">in</span> <span class="n">models_to_include</span><span class="p">:</span>
        <span class="c1"># Train Naive Bayes</span>
        <span class="n">nb_classifier</span> <span class="o">=</span> <span class="n">GaussianNB</span><span class="p">()</span>
        <span class="n">nb_classifier</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_OHE_nocv</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weights</span><span class="p">)</span>

        <span class="n">results_df_NB</span><span class="p">,</span> <span class="n">missclassified_samples</span> <span class="o">=</span> <span class="n">evaluate_and_plot_model</span><span class="p">(</span><span class="n">model</span> <span class="o">=</span> <span class="n">nb_classifier</span><span class="p">,</span>
                                                <span class="n">threshold</span> <span class="o">=</span> <span class="n">opt_threshold_NB</span><span class="p">,</span>
                                                <span class="n">testset</span> <span class="o">=</span> <span class="n">X_test_OHE</span><span class="p">,</span>
                                                <span class="n">y_test</span> <span class="o">=</span> <span class="n">y_test</span><span class="p">,</span>
                                                <span class="n">filename</span><span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;ROC_CM_NB.</span><span class="si">{</span><span class="n">fig_file_format</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">external_val</span><span class="p">:</span>
            <span class="c1"># Reorder X_extval_data_OHE columns to match X_test_OHE</span>
            <span class="n">X_extval_data_OHE</span> <span class="o">=</span> <span class="n">X_extval_data_OHE</span><span class="p">[</span><span class="n">X_test_OHE</span><span class="o">.</span><span class="n">columns</span><span class="p">]</span>
            <span class="n">results_df_NB_extval</span><span class="p">,</span> <span class="n">missclassified_samples_external</span> <span class="o">=</span> <span class="n">evaluate_and_plot_model</span><span class="p">(</span><span class="n">model</span> <span class="o">=</span> <span class="n">nb_classifier</span><span class="p">,</span>
                                                    <span class="n">threshold</span> <span class="o">=</span> <span class="n">opt_threshold_NB</span><span class="p">,</span>
                                                    <span class="n">testset</span> <span class="o">=</span> <span class="n">X_extval_data_OHE</span><span class="p">,</span>
                                                    <span class="n">y_test</span> <span class="o">=</span> <span class="n">y_extval_data</span><span class="p">,</span>
                                                    <span class="n">filename</span><span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;ROC_CM_NB_extval.</span><span class="si">{</span><span class="n">fig_file_format</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    
        <span class="k">if</span> <span class="n">export_missclassified</span><span class="p">:</span> <span class="c1"># extend the code if you have external validation set and want to check this </span>
            <span class="n">misclassified_ids</span> <span class="o">=</span> <span class="n">mydata_backup</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">missclassified_samples</span><span class="p">,</span> <span class="s1">&#39;ID&#39;</span><span class="p">]</span>
            
            <span class="n">misclassified_ids_df</span><span class="o">.</span><span class="n">to_excel</span><span class="p">(</span><span class="s1">&#39;testset_misclassified_ids_NB.xlsx&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="logistic-regression">
<h4>Logistic Regression<a class="headerlink" href="#logistic-regression" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">test_only_best_cvmodel</span> <span class="ow">and</span> <span class="n">best_model_name</span> <span class="o">!=</span> <span class="s2">&quot;LR&quot;</span><span class="p">:</span>
    <span class="k">pass</span>
<span class="k">else</span><span class="p">:</span>
    <span class="k">if</span> <span class="s2">&quot;LogisticRegression_mdl&quot;</span> <span class="ow">in</span> <span class="n">models_to_include</span><span class="p">:</span>
        <span class="c1"># Calculate necessary information for adjusting hyperparameters</span>
        <span class="n">n_rows</span> <span class="o">=</span> <span class="n">X_train_OHE_nocv</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">n_cols</span> <span class="o">=</span> <span class="n">X_train_OHE_nocv</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">class_proportion</span> <span class="o">=</span> <span class="n">y_train</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>  <span class="c1"># binary classification</span>
        <span class="n">rf_params</span><span class="p">,</span> <span class="n">lgbm_params</span><span class="p">,</span> <span class="n">hgbc_params</span><span class="p">,</span> <span class="n">cb_params</span><span class="p">,</span> <span class="n">lr_params</span> <span class="o">=</span> <span class="n">set_parameters</span><span class="p">(</span><span class="n">n_rows</span><span class="p">,</span> <span class="n">n_cols</span><span class="p">,</span> <span class="n">class_proportion</span><span class="p">)</span>
        <span class="c1"># Create a Logistic Regression instance</span>
        <span class="n">lr</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">penalty</span><span class="o">=</span><span class="s1">&#39;l1&#39;</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s2">&quot;liblinear&quot;</span><span class="p">,</span> <span class="o">**</span><span class="n">lr_params</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">hp_tuning</span><span class="p">:</span>
        
            <span class="c1"># Adjust hyperparameters based on the training data in this fold</span>
            <span class="n">rf_param_dist</span><span class="p">,</span> <span class="n">lgbm_param_dist</span><span class="p">,</span> <span class="n">hgbc_param_dist</span><span class="p">,</span> <span class="n">cb_param_dist</span><span class="p">,</span> <span class="n">lr_param_dist</span> <span class="o">=</span> <span class="n">adjust_hyperparameters</span><span class="p">(</span><span class="n">n_rows</span><span class="p">,</span> <span class="n">n_cols</span><span class="p">)</span>
            <span class="c1"># a RandomizedSearchCV instance</span>
            <span class="n">random_search</span> <span class="o">=</span> <span class="n">RandomizedSearchCV</span><span class="p">(</span>
                <span class="n">estimator</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span>
                <span class="n">param_distributions</span><span class="o">=</span><span class="n">lr_param_dist</span><span class="p">,</span>
                <span class="n">n_iter</span><span class="o">=</span><span class="n">n_iter_hptuning</span><span class="p">,</span>
                <span class="n">scoring</span><span class="o">=</span> <span class="n">custom_scorer</span><span class="p">,</span> 
                <span class="n">cv</span><span class="o">=</span><span class="n">cv_folds_hptuning</span><span class="p">,</span>
                <span class="n">refit</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
                <span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">,</span>
                <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_cpu_for_tuning</span>
            <span class="p">)</span>

            <span class="c1"># Perform the random search on the training data</span>
            <span class="n">random_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_OHE_nocv</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weights</span><span class="p">)</span>

            <span class="c1"># Get the best parameters and best estimator</span>
            <span class="n">best_params</span> <span class="o">=</span> <span class="n">random_search</span><span class="o">.</span><span class="n">best_params_</span>
            <span class="n">lr</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">penalty</span><span class="o">=</span><span class="s1">&#39;l1&#39;</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s2">&quot;liblinear&quot;</span><span class="p">,</span> <span class="o">**</span><span class="n">best_params</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">lr</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">penalty</span><span class="o">=</span><span class="s1">&#39;l1&#39;</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s2">&quot;liblinear&quot;</span><span class="p">,</span> <span class="o">**</span><span class="n">lr_params</span><span class="p">)</span>

        <span class="c1"># Fit the best estimator on the entire training data</span>
        <span class="n">lr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_OHE_nocv</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weights</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">test_only_best_cvmodel</span> <span class="ow">and</span> <span class="n">best_model_name</span> <span class="o">!=</span> <span class="s2">&quot;LR&quot;</span><span class="p">:</span>
    <span class="k">pass</span>
<span class="k">else</span><span class="p">:</span>
    <span class="k">if</span> <span class="s2">&quot;LogisticRegression_mdl&quot;</span> <span class="ow">in</span> <span class="n">models_to_include</span><span class="p">:</span>
        <span class="n">results_df_LR</span><span class="p">,</span> <span class="n">missclassified_samples</span> <span class="o">=</span> <span class="n">evaluate_and_plot_model</span><span class="p">(</span><span class="n">model</span> <span class="o">=</span> <span class="n">lr</span><span class="p">,</span>
                                                <span class="n">threshold</span> <span class="o">=</span> <span class="n">opt_threshold_LR</span><span class="p">,</span>
                                                <span class="n">testset</span> <span class="o">=</span> <span class="n">X_test_OHE</span><span class="p">,</span>
                                                <span class="n">y_test</span> <span class="o">=</span> <span class="n">y_test</span><span class="p">,</span>
                                                <span class="n">filename</span><span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;ROC_CM_LR.</span><span class="si">{</span><span class="n">fig_file_format</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">external_val</span><span class="p">:</span>
            <span class="c1"># Reorder X_extval_data_OHE columns to match X_test_OHE</span>
            <span class="n">X_extval_data_OHE</span> <span class="o">=</span> <span class="n">X_extval_data_OHE</span><span class="p">[</span><span class="n">X_test_OHE</span><span class="o">.</span><span class="n">columns</span><span class="p">]</span>
            <span class="n">results_df_LR_extval</span><span class="p">,</span> <span class="n">missclassified_samples_external</span> <span class="o">=</span> <span class="n">evaluate_and_plot_model</span><span class="p">(</span><span class="n">model</span> <span class="o">=</span> <span class="n">lr</span><span class="p">,</span>
                                                <span class="n">threshold</span> <span class="o">=</span> <span class="n">opt_threshold_LR</span><span class="p">,</span>
                                                <span class="n">testset</span> <span class="o">=</span> <span class="n">X_extval_data_OHE</span><span class="p">,</span>
                                                <span class="n">y_test</span> <span class="o">=</span> <span class="n">y_extval_data</span><span class="p">,</span>
                                                <span class="n">filename</span><span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;ROC_CM_LR_extval.</span><span class="si">{</span><span class="n">fig_file_format</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
            
        <span class="k">if</span> <span class="n">export_missclassified</span><span class="p">:</span> <span class="c1"># extend the code if you have external validation set and want to check this </span>
            <span class="n">misclassified_ids</span> <span class="o">=</span> <span class="n">mydata_backup</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">missclassified_samples</span><span class="p">,</span> <span class="s1">&#39;ID&#39;</span><span class="p">]</span>
            
            <span class="n">misclassified_ids_df</span><span class="o">.</span><span class="n">to_excel</span><span class="p">(</span><span class="s1">&#39;testset_misclassified_ids_LR.xlsx&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="histgbc">
<h4>HistGBC<a class="headerlink" href="#histgbc" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">test_only_best_cvmodel</span> <span class="ow">and</span> <span class="n">best_model_name</span> <span class="o">!=</span> <span class="s2">&quot;HGBC&quot;</span><span class="p">:</span>
    <span class="k">pass</span>
<span class="k">else</span><span class="p">:</span>
    <span class="k">if</span> <span class="s2">&quot;HistGBC_mdl&quot;</span> <span class="ow">in</span> <span class="n">models_to_include</span><span class="p">:</span>
        <span class="c1"># Calculate necessary information for adjusting hyperparameters</span>
        <span class="n">n_rows</span> <span class="o">=</span> <span class="n">X_train_OHE_nocv</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">n_cols</span> <span class="o">=</span> <span class="n">X_train_OHE_nocv</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">class_proportion</span> <span class="o">=</span> <span class="n">y_train</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>  <span class="c1"># binary classification</span>
        <span class="n">rf_params</span><span class="p">,</span> <span class="n">lgbm_params</span><span class="p">,</span> <span class="n">hgbc_params</span><span class="p">,</span> <span class="n">cb_params</span><span class="p">,</span> <span class="n">lr_params</span> <span class="o">=</span> <span class="n">set_parameters</span><span class="p">(</span><span class="n">n_rows</span><span class="p">,</span> <span class="n">n_cols</span><span class="p">,</span> <span class="n">class_proportion</span><span class="p">)</span>
        <span class="c1"># a HistGradientBoostingClassifier instance</span>
        <span class="n">HGBC</span> <span class="o">=</span> <span class="n">HistGradientBoostingClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">,</span> <span class="n">early_stopping</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">hgbc_params</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">hp_tuning</span><span class="p">:</span>
        
            <span class="c1"># Adjust hyperparameters based on the training data in this fold</span>
            <span class="n">rf_param_dist</span><span class="p">,</span> <span class="n">lgbm_param_dist</span><span class="p">,</span> <span class="n">hgbc_param_dist</span><span class="p">,</span> <span class="n">cb_param_dist</span><span class="p">,</span> <span class="n">lr_param_dist</span> <span class="o">=</span> <span class="n">adjust_hyperparameters</span><span class="p">(</span><span class="n">n_rows</span><span class="p">,</span> <span class="n">n_cols</span><span class="p">)</span>
            <span class="c1"># a RandomizedSearchCV instance</span>
            <span class="n">random_search</span> <span class="o">=</span> <span class="n">RandomizedSearchCV</span><span class="p">(</span>
                <span class="n">estimator</span><span class="o">=</span><span class="n">HGBC</span><span class="p">,</span> 
                <span class="n">param_distributions</span><span class="o">=</span><span class="n">hgbc_param_dist</span><span class="p">,</span> 
                <span class="n">n_iter</span><span class="o">=</span><span class="n">n_iter_hptuning</span><span class="p">,</span>
                <span class="n">scoring</span><span class="o">=</span> <span class="n">custom_scorer</span><span class="p">,</span> 
                <span class="n">cv</span><span class="o">=</span><span class="n">cv_folds_hptuning</span><span class="p">,</span>
                <span class="n">refit</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
                <span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">,</span>
                <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                <span class="n">n_jobs</span> <span class="o">=</span> <span class="n">n_cpu_for_tuning</span><span class="p">)</span>

            <span class="c1"># Perform the random search on the training data</span>
            <span class="n">random_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_OHE_nocv</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weights</span><span class="p">)</span>

            <span class="c1"># Get the best parameters and best estimator</span>
            <span class="n">best_params</span> <span class="o">=</span> <span class="n">random_search</span><span class="o">.</span><span class="n">best_params_</span>
            <span class="n">HGBC</span> <span class="o">=</span> <span class="n">HistGradientBoostingClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">,</span> <span class="n">early_stopping</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">best_params</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">HGBC</span> <span class="o">=</span> <span class="n">HistGradientBoostingClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">,</span> <span class="n">early_stopping</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">hgbc_params</span><span class="p">)</span>

        <span class="c1"># Fit the best estimator on the entire training data</span>
        <span class="n">HGBC</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_OHE_nocv</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weights</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">test_only_best_cvmodel</span> <span class="ow">and</span> <span class="n">best_model_name</span> <span class="o">!=</span> <span class="s2">&quot;HGBC&quot;</span><span class="p">:</span>
    <span class="k">pass</span>
<span class="k">else</span><span class="p">:</span>
    <span class="k">if</span> <span class="s2">&quot;HistGBC_mdl&quot;</span> <span class="ow">in</span> <span class="n">models_to_include</span><span class="p">:</span>
        <span class="n">results_df_HGBC</span><span class="p">,</span> <span class="n">missclassified_samples</span> <span class="o">=</span> <span class="n">evaluate_and_plot_model</span><span class="p">(</span><span class="n">model</span> <span class="o">=</span> <span class="n">HGBC</span><span class="p">,</span>
                                                <span class="n">threshold</span> <span class="o">=</span> <span class="n">opt_threshold_HGBC</span><span class="p">,</span>
                                                <span class="n">testset</span> <span class="o">=</span> <span class="n">X_test_OHE</span><span class="p">,</span>
                                                <span class="n">y_test</span> <span class="o">=</span> <span class="n">y_test</span><span class="p">,</span>
                                                <span class="n">filename</span><span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;ROC_CM_HGBC.</span><span class="si">{</span><span class="n">fig_file_format</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">external_val</span><span class="p">:</span>
            <span class="c1"># Reorder X_extval_data_OHE columns to match X_test_OHE</span>
            <span class="n">X_extval_data_OHE</span> <span class="o">=</span> <span class="n">X_extval_data_OHE</span><span class="p">[</span><span class="n">X_test_OHE</span><span class="o">.</span><span class="n">columns</span><span class="p">]</span>
            <span class="n">results_df_HGBC_extval</span><span class="p">,</span> <span class="n">missclassified_samples_external</span> <span class="o">=</span> <span class="n">evaluate_and_plot_model</span><span class="p">(</span><span class="n">model</span> <span class="o">=</span> <span class="n">HGBC</span><span class="p">,</span>
                                                <span class="n">threshold</span> <span class="o">=</span> <span class="n">opt_threshold_HGBC</span><span class="p">,</span>
                                                <span class="n">testset</span> <span class="o">=</span> <span class="n">X_extval_data_OHE</span><span class="p">,</span>
                                                <span class="n">y_test</span> <span class="o">=</span> <span class="n">y_extval_data</span><span class="p">,</span>
                                                <span class="n">filename</span><span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;ROC_CM_HGBC_extval.</span><span class="si">{</span><span class="n">fig_file_format</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    
        <span class="k">if</span> <span class="n">export_missclassified</span><span class="p">:</span> <span class="c1"># extend the code if you have external validation set and want to check this </span>
            <span class="n">misclassified_ids</span> <span class="o">=</span> <span class="n">mydata_backup</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">missclassified_samples</span><span class="p">,</span> <span class="s1">&#39;ID&#39;</span><span class="p">]</span>
            
            <span class="n">misclassified_ids_df</span><span class="o">.</span><span class="n">to_excel</span><span class="p">(</span><span class="s1">&#39;testset_misclassified_ids_HGBC.xlsx&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="random-forest-rf">
<h4>Random Forest (RF)<a class="headerlink" href="#random-forest-rf" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">test_only_best_cvmodel</span> <span class="ow">and</span> <span class="n">best_model_name</span> <span class="o">!=</span> <span class="s2">&quot;rf&quot;</span><span class="p">:</span>
    <span class="k">pass</span>
<span class="k">else</span><span class="p">:</span>
    <span class="k">if</span> <span class="s2">&quot;RandomForest_mdl&quot;</span> <span class="ow">in</span> <span class="n">models_to_include</span><span class="p">:</span>
        <span class="c1"># Calculate necessary information for adjusting hyperparameters</span>
        <span class="n">n_rows</span> <span class="o">=</span> <span class="n">X_train_OHE_nocv</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">n_cols</span> <span class="o">=</span> <span class="n">X_train_OHE_nocv</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">class_proportion</span> <span class="o">=</span> <span class="n">y_train</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>  <span class="c1"># binary classification</span>
        <span class="n">rf_params</span><span class="p">,</span> <span class="n">lgbm_params</span><span class="p">,</span> <span class="n">hgbc_params</span><span class="p">,</span> <span class="n">cb_params</span><span class="p">,</span> <span class="n">lr_params</span> <span class="o">=</span> <span class="n">set_parameters</span><span class="p">(</span><span class="n">n_rows</span><span class="p">,</span> <span class="n">n_cols</span><span class="p">,</span> <span class="n">class_proportion</span><span class="p">)</span>
        <span class="n">rf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_cpu_model_training</span><span class="p">,</span> <span class="o">**</span><span class="n">rf_params</span><span class="p">)</span> <span class="c1"># , class_weight= &quot;balanced&quot;</span>
        <span class="c1"># rf = RandomForestClassifier(random_state=SEED, sampling_strategy=&#39;all&#39;, n_jobs=n_cpu_model_training, **rf_params)</span>
        <span class="k">if</span> <span class="n">hp_tuning</span><span class="p">:</span>      
            <span class="c1"># Adjust hyperparameters based on the training data in this fold</span>
            <span class="n">rf_param_dist</span><span class="p">,</span> <span class="n">lgbm_param_dist</span><span class="p">,</span> <span class="n">hgbc_param_dist</span><span class="p">,</span> <span class="n">cb_param_dist</span><span class="p">,</span> <span class="n">lr_param_dist</span> <span class="o">=</span> <span class="n">adjust_hyperparameters</span><span class="p">(</span><span class="n">n_rows</span><span class="p">,</span> <span class="n">n_cols</span><span class="p">)</span>
            <span class="c1"># Create RandomizedSearchCV object with balanced accuracy as the scoring metric</span>
            <span class="n">random_search</span> <span class="o">=</span> <span class="n">RandomizedSearchCV</span><span class="p">(</span>
                <span class="n">estimator</span><span class="o">=</span><span class="n">rf</span><span class="p">,</span> 
                <span class="n">param_distributions</span><span class="o">=</span><span class="n">rf_param_dist</span><span class="p">,</span> 
                <span class="n">n_iter</span><span class="o">=</span><span class="n">n_iter_hptuning</span><span class="p">,</span>
                <span class="n">scoring</span><span class="o">=</span> <span class="n">custom_scorer</span><span class="p">,</span> 
                <span class="n">cv</span><span class="o">=</span><span class="n">cv_folds_hptuning</span><span class="p">,</span>
                <span class="n">refit</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
                <span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">,</span>
                <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="n">n_jobs</span> <span class="o">=</span> <span class="n">n_cpu_for_tuning</span><span class="p">)</span>

            <span class="c1"># Fit the RandomizedSearchCV object to the data</span>
            <span class="n">random_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_OHE_nocv</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weights</span><span class="p">)</span>

            <span class="c1"># Get the best parameters and best estimator from the random search</span>
            <span class="n">best_params</span> <span class="o">=</span> <span class="n">random_search</span><span class="o">.</span><span class="n">best_params_</span>

            <span class="c1"># Reinitialize a new rf model with the best parameters</span>
            <span class="n">rf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">,</span> <span class="n">class_weight</span><span class="o">=</span> <span class="s2">&quot;balanced&quot;</span><span class="p">,</span><span class="n">n_jobs</span><span class="o">=</span><span class="n">n_cpu_model_training</span><span class="p">,</span> <span class="o">**</span><span class="n">best_params</span><span class="p">)</span>
            <span class="c1"># Print the best parameters</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best Parameters:&quot;</span><span class="p">,</span> <span class="n">best_params</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">rf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">,</span> <span class="n">class_weight</span><span class="o">=</span> <span class="s2">&quot;balanced&quot;</span><span class="p">,</span><span class="n">n_jobs</span><span class="o">=</span><span class="n">n_cpu_model_training</span><span class="p">,</span> <span class="o">**</span><span class="n">rf_params</span><span class="p">)</span>
            <span class="c1"># Print the best parameters</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best Parameters:&quot;</span><span class="p">,</span> <span class="n">best_params</span><span class="p">)</span>
        <span class="c1"># Train the new model on the training data</span>
        <span class="n">rf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_OHE_nocv</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weights</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">test_only_best_cvmodel</span> <span class="ow">and</span> <span class="n">best_model_name</span> <span class="o">!=</span> <span class="s2">&quot;rf&quot;</span><span class="p">:</span>
    <span class="k">pass</span>
<span class="k">else</span><span class="p">:</span>
    <span class="k">if</span> <span class="s2">&quot;RandomForest_mdl&quot;</span> <span class="ow">in</span> <span class="n">models_to_include</span><span class="p">:</span>
        <span class="n">results_df_rf</span><span class="p">,</span> <span class="n">missclassified_samples</span> <span class="o">=</span> <span class="n">evaluate_and_plot_model</span><span class="p">(</span><span class="n">model</span> <span class="o">=</span> <span class="n">rf</span><span class="p">,</span> <span class="n">threshold</span> <span class="o">=</span> <span class="n">opt_threshold_rf</span><span class="p">,</span> <span class="n">testset</span> <span class="o">=</span> <span class="n">X_test_OHE</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">filename</span><span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;ROC_CM_rf.</span><span class="si">{</span><span class="n">fig_file_format</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">external_val</span><span class="p">:</span>
            <span class="c1"># Reorder X_extval_data_OHE columns to match X_test_OHE</span>
            <span class="n">X_extval_data_OHE</span> <span class="o">=</span> <span class="n">X_extval_data_OHE</span><span class="p">[</span><span class="n">X_test_OHE</span><span class="o">.</span><span class="n">columns</span><span class="p">]</span>
            <span class="n">results_df_rf_extval</span><span class="p">,</span> <span class="n">missclassified_samples_external</span> <span class="o">=</span> <span class="n">evaluate_and_plot_model</span><span class="p">(</span><span class="n">model</span> <span class="o">=</span> <span class="n">rf</span><span class="p">,</span>
                                                            <span class="n">threshold</span> <span class="o">=</span> <span class="n">opt_threshold_rf</span><span class="p">,</span>
                                                            <span class="n">testset</span> <span class="o">=</span> <span class="n">X_extval_data_OHE</span><span class="p">,</span>
                                                            <span class="n">y_test</span> <span class="o">=</span> <span class="n">y_extval_data</span><span class="p">,</span>
                                                            <span class="n">filename</span><span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;ROC_CM_rf_extval.</span><span class="si">{</span><span class="n">fig_file_format</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">export_missclassified</span><span class="p">:</span> <span class="c1"># extend the code if you have external validation set and want to check this </span>
            <span class="n">misclassified_ids</span> <span class="o">=</span> <span class="n">mydata_backup</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">missclassified_samples</span><span class="p">,</span> <span class="s1">&#39;ID&#39;</span><span class="p">]</span>
            
            <span class="n">misclassified_ids_df</span><span class="o">.</span><span class="n">to_excel</span><span class="p">(</span><span class="s1">&#39;testset_misclassified_ids_rf.xlsx&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="lightgbm">
<h4>LightGBM<a class="headerlink" href="#lightgbm" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">test_only_best_cvmodel</span> <span class="ow">and</span> <span class="n">best_model_name</span> <span class="o">!=</span> <span class="s2">&quot;LGBM&quot;</span><span class="p">:</span>
    <span class="k">pass</span>
<span class="k">else</span><span class="p">:</span>
    <span class="k">if</span> <span class="s2">&quot;LightGBM_mdl&quot;</span> <span class="ow">in</span> <span class="n">models_to_include</span><span class="p">:</span>
        <span class="c1"># Calculate necessary information for adjusting hyperparameters</span>
        <span class="n">n_rows</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">n_cols</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">class_proportion</span> <span class="o">=</span> <span class="n">y_train</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>  <span class="c1"># binary classification</span>
        <span class="n">rf_params</span><span class="p">,</span> <span class="n">lgbm_params</span><span class="p">,</span> <span class="n">hgbc_params</span><span class="p">,</span> <span class="n">cb_params</span><span class="p">,</span> <span class="n">lr_params</span> <span class="o">=</span> <span class="n">set_parameters</span><span class="p">(</span><span class="n">n_rows</span><span class="p">,</span> <span class="n">n_cols</span><span class="p">,</span> <span class="n">class_proportion</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">lgbm_params</span><span class="p">)</span>
        <span class="c1"># Define the classifier</span>
        <span class="k">if</span> <span class="n">GPU_avail</span><span class="p">:</span>
            <span class="n">lgbm</span> <span class="o">=</span> <span class="n">lgb</span><span class="o">.</span><span class="n">LGBMClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_cpu_model_training</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;gpu&quot;</span><span class="p">,</span> <span class="o">**</span><span class="n">lgbm_params</span><span class="p">)</span> 
        <span class="k">else</span><span class="p">:</span>
            <span class="n">lgbm</span> <span class="o">=</span> <span class="n">lgb</span><span class="o">.</span><span class="n">LGBMClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_cpu_model_training</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="o">**</span><span class="n">lgbm_params</span><span class="p">)</span> 

        <span class="k">if</span> <span class="n">hp_tuning</span><span class="p">:</span>
            
            <span class="c1"># Adjust hyperparameters based on the training data in this fold</span>
            <span class="n">rf_param_dist</span><span class="p">,</span> <span class="n">lgbm_param_dist</span><span class="p">,</span> <span class="n">hgbc_param_dist</span><span class="p">,</span> <span class="n">cb_param_dist</span><span class="p">,</span> <span class="n">lr_param_dist</span> <span class="o">=</span> <span class="n">adjust_hyperparameters</span><span class="p">(</span><span class="n">n_rows</span><span class="p">,</span> <span class="n">n_cols</span><span class="p">)</span>
            
            <span class="c1"># Define the search strategy and scoring metric</span>
            <span class="c1"># a RandomizedSearchCV instance</span>
            <span class="n">random_search</span> <span class="o">=</span> <span class="n">RandomizedSearchCV</span><span class="p">(</span>
                <span class="n">estimator</span><span class="o">=</span><span class="n">lgbm</span><span class="p">,</span> 
                <span class="n">param_distributions</span><span class="o">=</span><span class="n">lgbm_param_dist</span><span class="p">,</span> 
                <span class="n">n_iter</span><span class="o">=</span><span class="n">n_iter_hptuning</span><span class="p">,</span>
                <span class="n">scoring</span><span class="o">=</span> <span class="n">custom_scorer</span><span class="p">,</span> 
                <span class="n">cv</span><span class="o">=</span><span class="n">cv_folds_hptuning</span><span class="p">,</span>
                <span class="n">refit</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
                <span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">,</span>
                <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                <span class="n">n_jobs</span> <span class="o">=</span> <span class="n">n_cpu_for_tuning</span><span class="p">)</span>

            <span class="c1"># Perform the random search on the data</span>
            <span class="n">random_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weights</span><span class="p">)</span>

            <span class="c1"># Get the best parameters and best model</span>
            <span class="n">best_params</span> <span class="o">=</span> <span class="n">random_search</span><span class="o">.</span><span class="n">best_params_</span>

            <span class="c1"># Print the best parameters</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best Hyperparameters:&quot;</span><span class="p">,</span> <span class="n">best_params</span><span class="p">)</span>

            <span class="c1"># Reinitialize a new lgbm model with the best parameters</span>
            <span class="k">if</span> <span class="n">GPU_avail</span><span class="p">:</span>
                <span class="n">lgbm</span> <span class="o">=</span> <span class="n">lgb</span><span class="o">.</span><span class="n">LGBMClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_cpu_model_training</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;gpu&quot;</span><span class="p">,</span> <span class="o">**</span><span class="n">best_params</span><span class="p">)</span> 
            <span class="k">else</span><span class="p">:</span>
                <span class="n">lgbm</span> <span class="o">=</span> <span class="n">lgb</span><span class="o">.</span><span class="n">LGBMClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_cpu_model_training</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="o">**</span><span class="n">best_params</span><span class="p">)</span> 

        <span class="c1"># Train the new model on the training data</span>
        <span class="n">lgbm</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weights</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">test_only_best_cvmodel</span> <span class="ow">and</span> <span class="n">best_model_name</span> <span class="o">!=</span> <span class="s2">&quot;LGBM&quot;</span><span class="p">:</span>
    <span class="k">pass</span>
<span class="k">else</span><span class="p">:</span>
    <span class="k">if</span> <span class="s2">&quot;LightGBM_mdl&quot;</span> <span class="ow">in</span> <span class="n">models_to_include</span><span class="p">:</span>
        <span class="n">results_df_LGBM</span><span class="p">,</span> <span class="n">missclassified_samples</span> <span class="o">=</span> <span class="n">evaluate_and_plot_model</span><span class="p">(</span><span class="n">model</span> <span class="o">=</span> <span class="n">lgbm</span><span class="p">,</span>
                                                <span class="n">threshold</span> <span class="o">=</span> <span class="n">opt_threshold_LGBM</span><span class="p">,</span>
                                                <span class="n">testset</span> <span class="o">=</span> <span class="n">X_test</span><span class="p">,</span>
                                                <span class="n">y_test</span> <span class="o">=</span> <span class="n">y_test</span><span class="p">,</span>
                                                <span class="n">filename</span><span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;ROC_CM_LGBM.</span><span class="si">{</span><span class="n">fig_file_format</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">external_val</span><span class="p">:</span>
            <span class="c1"># Reorder X_extval_data columns to match X_test</span>
            <span class="n">X_extval_data</span> <span class="o">=</span> <span class="n">X_extval_data</span><span class="p">[</span><span class="n">X_test</span><span class="o">.</span><span class="n">columns</span><span class="p">]</span>
            <span class="n">results_df_LGBM_extval</span><span class="p">,</span> <span class="n">missclassified_samples_external</span> <span class="o">=</span> <span class="n">evaluate_and_plot_model</span><span class="p">(</span><span class="n">model</span> <span class="o">=</span> <span class="n">lgbm</span><span class="p">,</span>
                                            <span class="n">threshold</span> <span class="o">=</span> <span class="n">opt_threshold_LGBM</span><span class="p">,</span>
                                            <span class="n">testset</span> <span class="o">=</span> <span class="n">X_extval_data</span><span class="p">,</span>
                                            <span class="n">y_test</span> <span class="o">=</span> <span class="n">y_extval_data</span><span class="p">,</span>
                                            <span class="n">filename</span><span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;ROC_CM_LGBM_extval.</span><span class="si">{</span><span class="n">fig_file_format</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">export_missclassified</span><span class="p">:</span> <span class="c1"># extend the code if you have external validation set and want to check this </span>
            <span class="n">misclassified_ids</span> <span class="o">=</span> <span class="n">mydata_backup</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">missclassified_samples</span><span class="p">,</span> <span class="s1">&#39;ID&#39;</span><span class="p">]</span>
            
            <span class="n">misclassified_ids_df</span><span class="o">.</span><span class="n">to_excel</span><span class="p">(</span><span class="s1">&#39;testset_misclassified_ids_LGBM.xlsx&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="catboost">
<h4>CatBoost<a class="headerlink" href="#catboost" title="Link to this heading">#</a></h4>
<p>It may generate some unimportant warning messages about that can be ignored and cleaned up after running the pipeline.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">test_only_best_cvmodel</span> <span class="ow">and</span> <span class="n">best_model_name</span> <span class="o">!=</span> <span class="s2">&quot;CB&quot;</span><span class="p">:</span>
    <span class="k">pass</span>
<span class="k">else</span><span class="p">:</span>
    <span class="k">if</span> <span class="s2">&quot;CatBoost_mdl&quot;</span> <span class="ow">in</span> <span class="n">models_to_include</span><span class="p">:</span>
        <span class="c1"># Calculate necessary information for adjusting hyperparameters</span>
        <span class="n">n_rows</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">n_cols</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">class_proportion</span> <span class="o">=</span> <span class="n">y_train</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>  <span class="c1"># binary classification</span>
        <span class="n">rf_params</span><span class="p">,</span> <span class="n">lgbm_params</span><span class="p">,</span> <span class="n">hgbc_params</span><span class="p">,</span> <span class="n">cb_params</span><span class="p">,</span> <span class="n">lr_params</span> <span class="o">=</span> <span class="n">set_parameters</span><span class="p">(</span><span class="n">n_rows</span><span class="p">,</span> <span class="n">n_cols</span><span class="p">,</span> <span class="n">class_proportion</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">hp_tuning</span><span class="p">:</span>
            <span class="c1"># Adjust hyperparameters based on the training data in this fold</span>
            <span class="n">rf_param_dist</span><span class="p">,</span> <span class="n">lgbm_param_dist</span><span class="p">,</span> <span class="n">hgbc_param_dist</span><span class="p">,</span> <span class="n">cb_param_dist</span><span class="p">,</span> <span class="n">lr_param_dist</span> <span class="o">=</span> <span class="n">adjust_hyperparameters</span><span class="p">(</span><span class="n">n_rows</span><span class="p">,</span> <span class="n">n_cols</span><span class="p">)</span>
            <span class="n">catb</span> <span class="o">=</span> <span class="n">cb</span><span class="o">.</span><span class="n">CatBoostClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">,</span> <span class="n">cat_features</span><span class="o">=</span><span class="n">cat_features</span><span class="p">,</span> <span class="n">silent</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="c1"># , logging_level=&#39;Silent&#39; verbose=0, </span>

            <span class="c1"># Perform random search</span>
            <span class="n">random_search</span> <span class="o">=</span> <span class="n">RandomizedSearchCV</span><span class="p">(</span>
                <span class="n">estimator</span><span class="o">=</span><span class="n">catb</span><span class="p">,</span> 
                <span class="n">param_distributions</span><span class="o">=</span><span class="n">cb_param_dist</span><span class="p">,</span> 
                <span class="n">n_iter</span><span class="o">=</span><span class="n">n_iter_hptuning</span><span class="p">,</span>
                <span class="n">scoring</span><span class="o">=</span> <span class="n">custom_scorer</span><span class="p">,</span> 
                <span class="n">cv</span><span class="o">=</span><span class="n">cv_folds_hptuning</span><span class="p">,</span>
                <span class="n">refit</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
                <span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">,</span>
                <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_cpu_for_tuning</span>
            <span class="p">)</span>

            <span class="c1"># Fit the random search on your data</span>
            <span class="n">random_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weights</span><span class="p">)</span>

            <span class="c1"># Get the best parameters and best model</span>
            <span class="n">best_params</span> <span class="o">=</span> <span class="n">random_search</span><span class="o">.</span><span class="n">best_params_</span>
            
            <span class="n">catb</span> <span class="o">=</span> <span class="n">cb</span><span class="o">.</span><span class="n">CatBoostClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">,</span> <span class="n">cat_features</span><span class="o">=</span><span class="n">cat_features</span><span class="p">,</span> <span class="n">silent</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">best_params</span><span class="p">)</span> 
        <span class="k">else</span><span class="p">:</span>
            <span class="n">catb</span> <span class="o">=</span> <span class="n">cb</span><span class="o">.</span><span class="n">CatBoostClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">,</span> <span class="n">cat_features</span><span class="o">=</span><span class="n">cat_features</span><span class="p">,</span> <span class="n">silent</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">cb_params</span><span class="p">)</span> 
            
        <span class="c1"># Train the new model on the training data</span>
        <span class="n">catb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weights</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">test_only_best_cvmodel</span> <span class="ow">and</span> <span class="n">best_model_name</span> <span class="o">!=</span> <span class="s2">&quot;CB&quot;</span><span class="p">:</span>
    <span class="k">pass</span>
<span class="k">else</span><span class="p">:</span>
    <span class="k">if</span> <span class="s2">&quot;CatBoost_mdl&quot;</span> <span class="ow">in</span> <span class="n">models_to_include</span><span class="p">:</span>
        <span class="n">results_df_CB</span><span class="p">,</span> <span class="n">missclassified_samples</span> <span class="o">=</span> <span class="n">evaluate_and_plot_model</span><span class="p">(</span><span class="n">model</span> <span class="o">=</span> <span class="n">catb</span><span class="p">,</span>
                                                <span class="n">threshold</span> <span class="o">=</span> <span class="n">opt_threshold_CB</span><span class="p">,</span>
                                                <span class="n">testset</span> <span class="o">=</span> <span class="n">X_test</span><span class="p">,</span>
                                                <span class="n">y_test</span> <span class="o">=</span> <span class="n">y_test</span><span class="p">,</span>
                                                <span class="n">filename</span><span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;ROC_CM_CB.</span><span class="si">{</span><span class="n">fig_file_format</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">external_val</span><span class="p">:</span>
            <span class="c1"># Reorder X_extval_data columns to match X_test</span>
            <span class="n">X_extval_data</span> <span class="o">=</span> <span class="n">X_extval_data</span><span class="p">[</span><span class="n">X_test</span><span class="o">.</span><span class="n">columns</span><span class="p">]</span>
            <span class="n">results_df_CB_extval</span><span class="p">,</span> <span class="n">missclassified_samples_external</span> <span class="o">=</span> <span class="n">evaluate_and_plot_model</span><span class="p">(</span><span class="n">model</span> <span class="o">=</span> <span class="n">catb</span><span class="p">,</span>
                                            <span class="n">threshold</span> <span class="o">=</span> <span class="n">opt_threshold_CB</span><span class="p">,</span>
                                            <span class="n">testset</span> <span class="o">=</span> <span class="n">X_extval_data</span><span class="p">,</span>
                                            <span class="n">y_test</span> <span class="o">=</span> <span class="n">y_extval_data</span><span class="p">,</span>
                                            <span class="n">filename</span><span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;ROC_CM_CB_extval.</span><span class="si">{</span><span class="n">fig_file_format</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">export_missclassified</span><span class="p">:</span> <span class="c1"># extend the code if you have external validation set and want to check this </span>
            <span class="n">misclassified_ids</span> <span class="o">=</span> <span class="n">mydata_backup</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">missclassified_samples</span><span class="p">,</span> <span class="s1">&#39;ID&#39;</span><span class="p">]</span>
            
            <span class="n">misclassified_ids_df</span><span class="o">.</span><span class="n">to_excel</span><span class="p">(</span><span class="s1">&#39;testset_misclassified_ids_CB.xlsx&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="model-interpretation-for-the-best-performing-model">
<h4>Model interpretation for the best performing model<a class="headerlink" href="#model-interpretation-for-the-best-performing-model" title="Link to this heading">#</a></h4>
<p>The best performing model is chosen based on the performance of the models on cross validation as the model with the highest mean of MCC, AUC, and PRAUC. This model may not necessarily have the best performance on the test set, especially if the models perform closely similar on the cross validation. Since most of the data is used in cross validation, the model that is chosen based on that is prefered to the best performing model based only on the test set.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">best_model_name</span> <span class="o">!=</span> <span class="s2">&quot;QLattice&quot;</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">test_only_best_cvmodel</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">best_model_name</span> <span class="o">==</span> <span class="s2">&quot;rf&quot;</span><span class="p">:</span>
            <span class="n">selected_model</span> <span class="o">=</span> <span class="n">rf</span>
        <span class="k">elif</span> <span class="n">best_model_name</span> <span class="o">==</span> <span class="s2">&quot;LGBM&quot;</span><span class="p">:</span>
            <span class="n">selected_model</span> <span class="o">=</span> <span class="n">lgbm</span>
        <span class="k">elif</span> <span class="n">best_model_name</span> <span class="o">==</span> <span class="s2">&quot;NB&quot;</span><span class="p">:</span>
            <span class="n">selected_model</span> <span class="o">=</span> <span class="n">nb_classifier</span>
        <span class="k">elif</span> <span class="n">best_model_name</span> <span class="o">==</span> <span class="s2">&quot;CB&quot;</span><span class="p">:</span>
            <span class="n">selected_model</span> <span class="o">=</span> <span class="n">catb</span>
        <span class="k">elif</span> <span class="n">best_model_name</span> <span class="o">==</span> <span class="s2">&quot;LR&quot;</span><span class="p">:</span>
            <span class="n">selected_model</span> <span class="o">=</span> <span class="n">lr</span>
        <span class="k">elif</span> <span class="n">best_model_name</span> <span class="o">==</span> <span class="s2">&quot;HGBC&quot;</span><span class="p">:</span>
            <span class="n">selected_model</span> <span class="o">=</span> <span class="n">HGBC</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">selected_model</span> <span class="o">=</span> <span class="n">model_dictionary</span><span class="p">[</span><span class="n">best_model_name</span><span class="p">]</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">skip_block</span> <span class="o">=</span> <span class="kc">True</span>
    
    <span class="c1"># raise Exception(&quot;QLattice is already explained - Stopping code execution&quot;)</span>
</pre></div>
</div>
</div>
</div>
<section id="shap-values-association-with-predicted-probabilities">
<h5>SHAP values association with predicted probabilities<a class="headerlink" href="#shap-values-association-with-predicted-probabilities" title="Link to this heading">#</a></h5>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="ow">not</span> <span class="n">skip_block</span><span class="p">:</span>
    <span class="c1"># Calculate SHAP values for the positive class</span>
    <span class="n">positive_class_index</span> <span class="o">=</span> <span class="mi">1</span> 

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">selected_model</span><span class="p">,</span> <span class="p">(</span><span class="n">HistGradientBoostingClassifier</span><span class="p">,</span> <span class="n">RandomForestClassifier</span><span class="p">)):</span>
        <span class="n">explainer</span> <span class="o">=</span> <span class="n">shap</span><span class="o">.</span><span class="n">TreeExplainer</span><span class="p">(</span><span class="n">selected_model</span><span class="p">)</span>
        <span class="n">shap_values</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">shap_values</span><span class="p">(</span><span class="n">X_test_OHE</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">selected_model</span><span class="p">,</span> <span class="n">RandomForestClassifier</span><span class="p">):</span>
            <span class="c1"># shap_values = shap_values[positive_class_index]</span>
            <span class="n">shap_values</span> <span class="o">=</span> <span class="n">shap_values</span><span class="p">[:,:,</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">selected_model</span><span class="p">,</span> <span class="n">cb</span><span class="o">.</span><span class="n">CatBoostClassifier</span><span class="p">):</span>
        <span class="n">explainer</span> <span class="o">=</span> <span class="n">shap</span><span class="o">.</span><span class="n">TreeExplainer</span><span class="p">(</span><span class="n">selected_model</span><span class="p">)</span>
        <span class="n">shap_values</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">shap_values</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">selected_model</span><span class="p">,</span> <span class="n">LogisticRegression</span><span class="p">):</span>
        <span class="n">explainer</span> <span class="o">=</span> <span class="n">shap</span><span class="o">.</span><span class="n">LinearExplainer</span><span class="p">(</span><span class="n">selected_model</span><span class="p">,</span> <span class="n">X_train_OHE_nocv</span><span class="p">)</span>
        <span class="n">shap_values</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">shap_values</span><span class="p">(</span><span class="n">X_test_OHE</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">selected_model</span><span class="p">,</span> <span class="n">GaussianNB</span><span class="p">):</span>  
        <span class="n">explainer</span> <span class="o">=</span> <span class="n">shap</span><span class="o">.</span><span class="n">Explainer</span><span class="p">(</span><span class="n">selected_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">,</span> <span class="n">X_train_OHE_nocv</span><span class="p">)</span>
        <span class="n">shap_values</span> <span class="o">=</span> <span class="n">explainer</span><span class="p">(</span><span class="n">X_test_OHE</span><span class="p">)</span>
        <span class="n">shap_values</span> <span class="o">=</span> <span class="n">shap_values</span><span class="o">.</span><span class="n">values</span>
        <span class="n">shap_values</span> <span class="o">=</span> <span class="n">shap_values</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">explainer</span> <span class="o">=</span> <span class="n">shap</span><span class="o">.</span><span class="n">TreeExplainer</span><span class="p">(</span><span class="n">selected_model</span><span class="p">)</span>
        <span class="n">shap_values</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">shap_values</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
        <span class="c1"># shap_values = shap_values[positive_class_index]</span>

    <span class="c1"># Calculate the sum of SHAP values for each sample</span>
    <span class="n">shap_sum</span> <span class="o">=</span> <span class="n">shap_values</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># Get the predicted probabilities of the model</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">selected_model</span><span class="p">,</span> <span class="p">(</span><span class="n">HistGradientBoostingClassifier</span><span class="p">,</span> <span class="n">RandomForestClassifier</span><span class="p">)):</span>
        <span class="n">predicted_probabilities</span> <span class="o">=</span> <span class="n">selected_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test_OHE</span><span class="p">)[:,</span> <span class="n">positive_class_index</span><span class="p">]</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">selected_model</span><span class="p">,</span> <span class="n">cb</span><span class="o">.</span><span class="n">CatBoostClassifier</span><span class="p">):</span>
        <span class="n">predicted_probabilities</span> <span class="o">=</span> <span class="n">selected_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="n">positive_class_index</span><span class="p">]</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">selected_model</span><span class="p">,</span> <span class="p">(</span><span class="n">LogisticRegression</span><span class="p">,</span> <span class="n">GaussianNB</span><span class="p">)):</span>
        <span class="n">predicted_probabilities</span> <span class="o">=</span> <span class="n">selected_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test_OHE</span><span class="p">)[:,</span> <span class="n">positive_class_index</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">predicted_probabilities</span> <span class="o">=</span> <span class="n">selected_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="n">positive_class_index</span><span class="p">]</span>

    <span class="c1"># Plot the SHAP sum against the predicted probabilities</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">shap_sum</span><span class="p">,</span> <span class="n">predicted_probabilities</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;sum of SHAP values&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;predicted probability&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;sum of SHAP values vs. predicted probability&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;:&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;font.family&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;sans-serif&#39;</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;font.size&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">8</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;both&#39;</span><span class="p">,</span> <span class="n">labelsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span> 
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">set_facecolor</span><span class="p">(</span><span class="s1">&#39;white&#39;</span><span class="p">)</span>
    <span class="c1"># display grid lines</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">&#39;both&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;grey&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">&#39;minor&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">&#39;major&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="ow">not</span> <span class="n">skip_block</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">model_uncertainty_reduction</span><span class="p">:</span>

        <span class="c1"># Calculate SHAP values for the positive class</span>
        <span class="n">positive_class_index</span> <span class="o">=</span> <span class="mi">1</span> 
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">selected_model</span><span class="p">,</span> <span class="n">HistGradientBoostingClassifier</span><span class="p">):</span>
            <span class="n">explainer</span> <span class="o">=</span> <span class="n">shap</span><span class="o">.</span><span class="n">TreeExplainer</span><span class="p">(</span><span class="n">selected_model</span><span class="p">)</span>
            <span class="n">shap_values</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">shap_values</span><span class="p">(</span><span class="n">X_test_OHE</span><span class="p">)</span>
            <span class="n">predicted_probabilities</span> <span class="o">=</span> <span class="n">selected_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test_OHE</span><span class="p">)[:,</span> <span class="n">positive_class_index</span><span class="p">]</span>
            <span class="n">shap_sum</span> <span class="o">=</span> <span class="n">shap_values</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">shap_sum_abs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">shap_sum</span><span class="p">)</span>
            <span class="n">SHAP_thr_HGBC</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">shap_sum_abs</span><span class="p">,</span> <span class="n">best_SHAP_percentile</span><span class="p">)</span>
            <span class="n">opt_threshold_selectedmodel</span> <span class="o">=</span> <span class="n">opt_threshold_HGBC</span>

            <span class="n">X_test_filtered_shap</span> <span class="o">=</span> <span class="n">X_test_OHE</span><span class="p">[(</span><span class="n">shap_sum_abs</span> <span class="o">&gt;</span> <span class="n">SHAP_thr_HGBC</span><span class="p">)</span> <span class="o">&amp;</span> 
                                                <span class="p">((</span><span class="n">predicted_probabilities</span> <span class="o">&lt;</span> <span class="p">(</span><span class="n">opt_threshold_HGBC</span> <span class="o">-</span> <span class="n">best_margin</span><span class="p">))</span> <span class="o">|</span> 
                                                <span class="p">(</span><span class="n">predicted_probabilities</span> <span class="o">&gt;</span> <span class="p">(</span><span class="n">opt_threshold_HGBC</span> <span class="o">+</span> <span class="n">best_margin</span><span class="p">)))]</span>
            <span class="n">y_test_filtered_shap</span> <span class="o">=</span> <span class="n">y_test</span><span class="p">[(</span><span class="n">shap_sum_abs</span> <span class="o">&gt;</span> <span class="n">SHAP_thr_HGBC</span><span class="p">)</span> <span class="o">&amp;</span> 
                                            <span class="p">((</span><span class="n">predicted_probabilities</span> <span class="o">&lt;</span> <span class="p">(</span><span class="n">opt_threshold_HGBC</span> <span class="o">-</span> <span class="n">best_margin</span><span class="p">))</span> <span class="o">|</span> 
                                                <span class="p">(</span><span class="n">predicted_probabilities</span> <span class="o">&gt;</span> <span class="p">(</span><span class="n">opt_threshold_HGBC</span> <span class="o">+</span> <span class="n">best_margin</span><span class="p">)))]</span>
            <span class="n">pp_filtered</span> <span class="o">=</span> <span class="n">predicted_probabilities</span><span class="p">[(</span><span class="n">shap_sum_abs</span> <span class="o">&gt;</span> <span class="n">SHAP_thr_HGBC</span><span class="p">)</span> <span class="o">&amp;</span> 
                                            <span class="p">((</span><span class="n">predicted_probabilities</span> <span class="o">&lt;</span> <span class="p">(</span><span class="n">opt_threshold_HGBC</span> <span class="o">-</span> <span class="n">best_margin</span><span class="p">))</span> <span class="o">|</span> 
                                                <span class="p">(</span><span class="n">predicted_probabilities</span> <span class="o">&gt;</span> <span class="p">(</span><span class="n">opt_threshold_HGBC</span> <span class="o">+</span> <span class="n">best_margin</span><span class="p">)))]</span>
            <span class="n">pc_filtered</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">pp_filtered</span> <span class="o">&gt;=</span> <span class="n">opt_threshold_HGBC</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
            
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">selected_model</span><span class="p">,</span> <span class="n">RandomForestClassifier</span><span class="p">):</span>
            <span class="n">explainer</span> <span class="o">=</span> <span class="n">shap</span><span class="o">.</span><span class="n">TreeExplainer</span><span class="p">(</span><span class="n">selected_model</span><span class="p">)</span>
            <span class="n">shap_values</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">shap_values</span><span class="p">(</span><span class="n">X_test_OHE</span><span class="p">)</span>
            <span class="n">shap_values</span> <span class="o">=</span> <span class="n">shap_values</span><span class="p">[:,:,</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">predicted_probabilities</span> <span class="o">=</span> <span class="n">selected_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test_OHE</span><span class="p">)[:,</span> <span class="n">positive_class_index</span><span class="p">]</span>
            <span class="n">shap_sum</span> <span class="o">=</span> <span class="n">shap_values</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">shap_sum_abs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">shap_sum</span><span class="p">)</span>
            <span class="n">SHAP_thr_rf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">shap_sum_abs</span><span class="p">,</span> <span class="n">best_SHAP_percentile</span><span class="p">)</span>
            <span class="n">opt_threshold_selectedmodel</span> <span class="o">=</span> <span class="n">opt_threshold_rf</span>
            <span class="n">X_test_filtered_shap</span> <span class="o">=</span> <span class="n">X_test_OHE</span><span class="p">[(</span><span class="n">shap_sum_abs</span> <span class="o">&gt;</span> <span class="n">SHAP_thr_rf</span><span class="p">)</span> <span class="o">&amp;</span> 
                                                <span class="p">((</span><span class="n">predicted_probabilities</span> <span class="o">&lt;</span> <span class="p">(</span><span class="n">opt_threshold_rf</span> <span class="o">-</span> <span class="n">best_margin</span><span class="p">))</span> <span class="o">|</span> 
                                                <span class="p">(</span><span class="n">predicted_probabilities</span> <span class="o">&gt;</span> <span class="p">(</span><span class="n">opt_threshold_rf</span> <span class="o">+</span> <span class="n">best_margin</span><span class="p">)))]</span>
            <span class="n">y_test_filtered_shap</span> <span class="o">=</span> <span class="n">y_test</span><span class="p">[(</span><span class="n">shap_sum_abs</span> <span class="o">&gt;</span> <span class="n">SHAP_thr_rf</span><span class="p">)</span> <span class="o">&amp;</span> 
                                            <span class="p">((</span><span class="n">predicted_probabilities</span> <span class="o">&lt;</span> <span class="p">(</span><span class="n">opt_threshold_rf</span> <span class="o">-</span> <span class="n">best_margin</span><span class="p">))</span> <span class="o">|</span> 
                                                <span class="p">(</span><span class="n">predicted_probabilities</span> <span class="o">&gt;</span> <span class="p">(</span><span class="n">opt_threshold_rf</span> <span class="o">+</span> <span class="n">best_margin</span><span class="p">)))]</span>
            <span class="n">pp_filtered</span> <span class="o">=</span> <span class="n">predicted_probabilities</span><span class="p">[(</span><span class="n">shap_sum_abs</span> <span class="o">&gt;</span> <span class="n">SHAP_thr_rf</span><span class="p">)</span> <span class="o">&amp;</span> 
                                            <span class="p">((</span><span class="n">predicted_probabilities</span> <span class="o">&lt;</span> <span class="p">(</span><span class="n">opt_threshold_rf</span> <span class="o">-</span> <span class="n">best_margin</span><span class="p">))</span> <span class="o">|</span> 
                                                <span class="p">(</span><span class="n">predicted_probabilities</span> <span class="o">&gt;</span> <span class="p">(</span><span class="n">opt_threshold_rf</span> <span class="o">+</span> <span class="n">best_margin</span><span class="p">)))]</span>
            <span class="n">pc_filtered</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">pp_filtered</span> <span class="o">&gt;=</span> <span class="n">opt_threshold_rf</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
            
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">selected_model</span><span class="p">,</span> <span class="n">cb</span><span class="o">.</span><span class="n">CatBoostClassifier</span><span class="p">):</span>
            <span class="n">explainer</span> <span class="o">=</span> <span class="n">shap</span><span class="o">.</span><span class="n">TreeExplainer</span><span class="p">(</span><span class="n">selected_model</span><span class="p">)</span>
            <span class="n">shap_values</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">shap_values</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
            <span class="n">shap_sum</span> <span class="o">=</span> <span class="n">shap_values</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">shap_sum_abs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">shap_sum</span><span class="p">)</span>
            <span class="n">SHAP_thr_CB</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">shap_sum_abs</span><span class="p">,</span> <span class="n">best_SHAP_percentile</span><span class="p">)</span>
            <span class="n">opt_threshold_selectedmodel</span> <span class="o">=</span> <span class="n">opt_threshold_CB</span>
            <span class="n">predicted_probabilities</span> <span class="o">=</span> <span class="n">selected_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="n">positive_class_index</span><span class="p">]</span>
            <span class="n">X_test_filtered_shap</span> <span class="o">=</span> <span class="n">X_test</span><span class="p">[(</span><span class="n">shap_sum_abs</span> <span class="o">&gt;</span> <span class="n">SHAP_thr_CB</span><span class="p">)</span> <span class="o">&amp;</span> 
                                            <span class="p">((</span><span class="n">predicted_probabilities</span> <span class="o">&lt;</span> <span class="p">(</span><span class="n">opt_threshold_CB</span> <span class="o">-</span> <span class="n">best_margin</span><span class="p">))</span> <span class="o">|</span> 
                                            <span class="p">(</span><span class="n">predicted_probabilities</span> <span class="o">&gt;</span> <span class="p">(</span><span class="n">opt_threshold_CB</span> <span class="o">+</span> <span class="n">best_margin</span><span class="p">)))]</span>
            <span class="n">y_test_filtered_shap</span> <span class="o">=</span> <span class="n">y_test</span><span class="p">[(</span><span class="n">shap_sum_abs</span> <span class="o">&gt;</span> <span class="n">SHAP_thr_CB</span><span class="p">)</span> <span class="o">&amp;</span> 
                                            <span class="p">((</span><span class="n">predicted_probabilities</span> <span class="o">&lt;</span> <span class="p">(</span><span class="n">opt_threshold_CB</span> <span class="o">-</span> <span class="n">best_margin</span><span class="p">))</span> <span class="o">|</span> 
                                                <span class="p">(</span><span class="n">predicted_probabilities</span> <span class="o">&gt;</span> <span class="p">(</span><span class="n">opt_threshold_CB</span> <span class="o">+</span> <span class="n">best_margin</span><span class="p">)))]</span>
            <span class="n">pp_filtered</span> <span class="o">=</span> <span class="n">predicted_probabilities</span><span class="p">[(</span><span class="n">shap_sum_abs</span> <span class="o">&gt;</span> <span class="n">SHAP_thr_CB</span><span class="p">)</span> <span class="o">&amp;</span> 
                                            <span class="p">((</span><span class="n">predicted_probabilities</span> <span class="o">&lt;</span> <span class="p">(</span><span class="n">opt_threshold_CB</span> <span class="o">-</span> <span class="n">best_margin</span><span class="p">))</span> <span class="o">|</span> 
                                                <span class="p">(</span><span class="n">predicted_probabilities</span> <span class="o">&gt;</span> <span class="p">(</span><span class="n">opt_threshold_CB</span> <span class="o">+</span> <span class="n">best_margin</span><span class="p">)))]</span>
            <span class="n">pc_filtered</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">pp_filtered</span> <span class="o">&gt;=</span> <span class="n">opt_threshold_CB</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
            
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">selected_model</span><span class="p">,</span> <span class="n">LogisticRegression</span><span class="p">):</span>
            <span class="n">opt_threshold_selectedmodel</span> <span class="o">=</span> <span class="n">opt_threshold_LR</span>
            <span class="n">explainer</span> <span class="o">=</span> <span class="n">shap</span><span class="o">.</span><span class="n">LinearExplainer</span><span class="p">(</span><span class="n">selected_model</span><span class="p">,</span> <span class="n">X_train_OHE_nocv</span><span class="p">)</span>
            <span class="n">shap_values</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">shap_values</span><span class="p">(</span><span class="n">X_test_OHE</span><span class="p">)</span>
            <span class="n">predicted_probabilities</span> <span class="o">=</span> <span class="n">selected_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test_OHE</span><span class="p">)[:,</span> <span class="n">positive_class_index</span><span class="p">]</span>
            <span class="n">shap_sum</span> <span class="o">=</span> <span class="n">shap_values</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">shap_sum_abs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">shap_sum</span><span class="p">)</span>
            <span class="n">SHAP_thr_LR</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">shap_sum_abs</span><span class="p">,</span> <span class="n">best_SHAP_percentile</span><span class="p">)</span>

            <span class="n">X_test_filtered_shap</span> <span class="o">=</span> <span class="n">X_test_OHE</span><span class="p">[(</span><span class="n">shap_sum_abs</span> <span class="o">&gt;</span> <span class="n">SHAP_thr_LR</span><span class="p">)</span> <span class="o">&amp;</span> 
                                                <span class="p">((</span><span class="n">predicted_probabilities</span> <span class="o">&lt;</span> <span class="p">(</span><span class="n">opt_threshold_LR</span> <span class="o">-</span> <span class="n">best_margin</span><span class="p">))</span> <span class="o">|</span> 
                                                <span class="p">(</span><span class="n">predicted_probabilities</span> <span class="o">&gt;</span> <span class="p">(</span><span class="n">opt_threshold_LR</span> <span class="o">+</span> <span class="n">best_margin</span><span class="p">)))]</span>
            <span class="n">y_test_filtered_shap</span> <span class="o">=</span> <span class="n">y_test</span><span class="p">[(</span><span class="n">shap_sum_abs</span> <span class="o">&gt;</span> <span class="n">SHAP_thr_LR</span><span class="p">)</span> <span class="o">&amp;</span> 
                                            <span class="p">((</span><span class="n">predicted_probabilities</span> <span class="o">&lt;</span> <span class="p">(</span><span class="n">opt_threshold_LR</span> <span class="o">-</span> <span class="n">best_margin</span><span class="p">))</span> <span class="o">|</span> 
                                                <span class="p">(</span><span class="n">predicted_probabilities</span> <span class="o">&gt;</span> <span class="p">(</span><span class="n">opt_threshold_LR</span> <span class="o">+</span> <span class="n">best_margin</span><span class="p">)))]</span>
            <span class="n">pp_filtered</span> <span class="o">=</span> <span class="n">predicted_probabilities</span><span class="p">[(</span><span class="n">shap_sum_abs</span> <span class="o">&gt;</span> <span class="n">SHAP_thr_LR</span><span class="p">)</span> <span class="o">&amp;</span> 
                                            <span class="p">((</span><span class="n">predicted_probabilities</span> <span class="o">&lt;</span> <span class="p">(</span><span class="n">opt_threshold_LR</span> <span class="o">-</span> <span class="n">best_margin</span><span class="p">))</span> <span class="o">|</span> 
                                                <span class="p">(</span><span class="n">predicted_probabilities</span> <span class="o">&gt;</span> <span class="p">(</span><span class="n">opt_threshold_LR</span> <span class="o">+</span> <span class="n">best_margin</span><span class="p">)))]</span>
            <span class="n">pc_filtered</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">pp_filtered</span> <span class="o">&gt;=</span> <span class="n">opt_threshold_LR</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
            
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">selected_model</span><span class="p">,</span> <span class="n">GaussianNB</span><span class="p">):</span>  
            <span class="n">explainer</span> <span class="o">=</span> <span class="n">shap</span><span class="o">.</span><span class="n">Explainer</span><span class="p">(</span><span class="n">selected_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">,</span> <span class="n">X_train_OHE_nocv</span><span class="p">)</span>
            <span class="n">opt_threshold_selectedmodel</span> <span class="o">=</span> <span class="n">opt_threshold_NB</span>
            <span class="n">shap_values</span> <span class="o">=</span> <span class="n">explainer</span><span class="p">(</span><span class="n">X_test_OHE</span><span class="p">)</span>  
            <span class="n">shap_values</span> <span class="o">=</span> <span class="n">shap_values</span><span class="o">.</span><span class="n">values</span><span class="p">[:,:,</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">predicted_probabilities</span> <span class="o">=</span> <span class="n">selected_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test_OHE</span><span class="p">)[:,</span> <span class="n">positive_class_index</span><span class="p">]</span>
            <span class="n">shap_sum</span> <span class="o">=</span> <span class="n">shap_values</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">shap_sum_abs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">shap_sum</span><span class="p">)</span>
            <span class="n">SHAP_thr_NB</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">shap_sum_abs</span><span class="p">,</span> <span class="n">best_SHAP_percentile</span><span class="p">)</span>

            <span class="n">X_test_filtered_shap</span> <span class="o">=</span> <span class="n">X_test_OHE</span><span class="p">[(</span><span class="n">shap_sum_abs</span> <span class="o">&gt;</span> <span class="n">SHAP_thr_NB</span><span class="p">)</span> <span class="o">&amp;</span> 
                                                <span class="p">((</span><span class="n">predicted_probabilities</span> <span class="o">&lt;</span> <span class="p">(</span><span class="n">opt_threshold_NB</span> <span class="o">-</span> <span class="n">best_margin</span><span class="p">))</span> <span class="o">|</span> 
                                                <span class="p">(</span><span class="n">predicted_probabilities</span> <span class="o">&gt;</span> <span class="p">(</span><span class="n">opt_threshold_NB</span> <span class="o">+</span> <span class="n">best_margin</span><span class="p">)))]</span>
            <span class="n">y_test_filtered_shap</span> <span class="o">=</span> <span class="n">y_test</span><span class="p">[(</span><span class="n">shap_sum_abs</span> <span class="o">&gt;</span> <span class="n">SHAP_thr_NB</span><span class="p">)</span> <span class="o">&amp;</span> 
                                            <span class="p">((</span><span class="n">predicted_probabilities</span> <span class="o">&lt;</span> <span class="p">(</span><span class="n">opt_threshold_NB</span> <span class="o">-</span> <span class="n">best_margin</span><span class="p">))</span> <span class="o">|</span> 
                                                <span class="p">(</span><span class="n">predicted_probabilities</span> <span class="o">&gt;</span> <span class="p">(</span><span class="n">opt_threshold_NB</span> <span class="o">+</span> <span class="n">best_margin</span><span class="p">)))]</span>
            <span class="n">pp_filtered</span> <span class="o">=</span> <span class="n">predicted_probabilities</span><span class="p">[(</span><span class="n">shap_sum_abs</span> <span class="o">&gt;</span> <span class="n">SHAP_thr_NB</span><span class="p">)</span> <span class="o">&amp;</span> 
                                            <span class="p">((</span><span class="n">predicted_probabilities</span> <span class="o">&lt;</span> <span class="p">(</span><span class="n">opt_threshold_NB</span> <span class="o">-</span> <span class="n">best_margin</span><span class="p">))</span> <span class="o">|</span> 
                                                <span class="p">(</span><span class="n">predicted_probabilities</span> <span class="o">&gt;</span> <span class="p">(</span><span class="n">opt_threshold_NB</span> <span class="o">+</span> <span class="n">best_margin</span><span class="p">)))]</span>
            <span class="n">pc_filtered</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">pp_filtered</span> <span class="o">&gt;=</span> <span class="n">opt_threshold_NB</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
            
        <span class="k">else</span><span class="p">:</span> <span class="c1"># LGBM</span>
            <span class="n">opt_threshold_selectedmodel</span> <span class="o">=</span> <span class="n">opt_threshold_LGBM</span>
            <span class="n">explainer</span> <span class="o">=</span> <span class="n">shap</span><span class="o">.</span><span class="n">TreeExplainer</span><span class="p">(</span><span class="n">selected_model</span><span class="p">)</span>
            <span class="n">shap_values</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">shap_values</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
            <span class="c1"># shap_values = shap_values[positive_class_index]</span>
            <span class="n">shap_sum</span> <span class="o">=</span> <span class="n">shap_values</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">shap_sum_abs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">shap_sum</span><span class="p">)</span>
            <span class="n">SHAP_thr_LGBM</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">shap_sum_abs</span><span class="p">,</span> <span class="n">best_SHAP_percentile</span><span class="p">)</span>
            <span class="n">predicted_probabilities</span> <span class="o">=</span> <span class="n">selected_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="n">positive_class_index</span><span class="p">]</span>
            <span class="n">X_test_filtered_shap</span> <span class="o">=</span> <span class="n">X_test</span><span class="p">[(</span><span class="n">shap_sum_abs</span> <span class="o">&gt;</span> <span class="n">SHAP_thr_LGBM</span><span class="p">)</span> <span class="o">&amp;</span> 
                                                <span class="p">((</span><span class="n">predicted_probabilities</span> <span class="o">&lt;</span> <span class="p">(</span><span class="n">opt_threshold_LGBM</span> <span class="o">-</span> <span class="n">best_margin</span><span class="p">))</span> <span class="o">|</span> 
                                                <span class="p">(</span><span class="n">predicted_probabilities</span> <span class="o">&gt;</span> <span class="p">(</span><span class="n">opt_threshold_LGBM</span> <span class="o">+</span> <span class="n">best_margin</span><span class="p">)))]</span>
            <span class="n">y_test_filtered_shap</span> <span class="o">=</span> <span class="n">y_test</span><span class="p">[(</span><span class="n">shap_sum_abs</span> <span class="o">&gt;</span> <span class="n">SHAP_thr_LGBM</span><span class="p">)</span> <span class="o">&amp;</span> 
                                            <span class="p">((</span><span class="n">predicted_probabilities</span> <span class="o">&lt;</span> <span class="p">(</span><span class="n">opt_threshold_LGBM</span> <span class="o">-</span> <span class="n">best_margin</span><span class="p">))</span> <span class="o">|</span> 
                                                <span class="p">(</span><span class="n">predicted_probabilities</span> <span class="o">&gt;</span> <span class="p">(</span><span class="n">opt_threshold_LGBM</span> <span class="o">+</span> <span class="n">best_margin</span><span class="p">)))]</span>
            <span class="n">pp_filtered</span> <span class="o">=</span> <span class="n">predicted_probabilities</span><span class="p">[(</span><span class="n">shap_sum_abs</span> <span class="o">&gt;</span> <span class="n">SHAP_thr_LGBM</span><span class="p">)</span> <span class="o">&amp;</span> 
                                            <span class="p">((</span><span class="n">predicted_probabilities</span> <span class="o">&lt;</span> <span class="p">(</span><span class="n">opt_threshold_LGBM</span> <span class="o">-</span> <span class="n">best_margin</span><span class="p">))</span> <span class="o">|</span> 
                                                <span class="p">(</span><span class="n">predicted_probabilities</span> <span class="o">&gt;</span> <span class="p">(</span><span class="n">opt_threshold_LGBM</span> <span class="o">+</span> <span class="n">best_margin</span><span class="p">)))]</span>
            <span class="n">pc_filtered</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">pp_filtered</span> <span class="o">&gt;=</span> <span class="n">opt_threshold_LGBM</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>

        <span class="c1"># Plot the SHAP sum against the predicted probabilities</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">shap_sum_abs</span><span class="p">,</span> <span class="n">predicted_probabilities</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X_test_filtered_shap</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">X_test</span><span class="p">),</span><span class="mi">2</span><span class="p">))</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Sum of absolute SHAP values&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Predicted probability&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Sum of absolute SHAP values vs. Predicted probability&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;:&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;font.family&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;sans-serif&#39;</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;font.size&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">8</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;both&#39;</span><span class="p">,</span> <span class="n">labelsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span> 
        <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">set_facecolor</span><span class="p">(</span><span class="s1">&#39;white&#39;</span><span class="p">)</span>
        <span class="c1"># display grid lines</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">&#39;both&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;grey&quot;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">&#39;minor&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">&#39;major&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="ow">not</span> <span class="n">skip_block</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">model_uncertainty_reduction</span><span class="p">:</span>
        <span class="n">results_df_selected_model</span><span class="p">,</span> <span class="n">missclassified_samples_selected_model</span> <span class="o">=</span> <span class="n">evaluate_and_plot_model</span><span class="p">(</span><span class="n">model</span> <span class="o">=</span> <span class="n">selected_model</span><span class="p">,</span>
                                                        <span class="n">threshold</span> <span class="o">=</span> <span class="n">opt_threshold_selectedmodel</span><span class="p">,</span>
                                                        <span class="n">testset</span> <span class="o">=</span> <span class="n">X_test_filtered_shap</span><span class="p">,</span>
                                                        <span class="n">y_test</span> <span class="o">=</span> <span class="n">y_test_filtered_shap</span><span class="p">,</span>
                                                        <span class="n">filename</span><span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;ROC_CM_selected_model.</span><span class="si">{</span><span class="n">fig_file_format</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">selected_model</span><span class="p">,</span> <span class="p">(</span><span class="n">LogisticRegression</span><span class="p">,</span> <span class="n">GaussianNB</span><span class="p">,</span> <span class="n">HistGradientBoostingClassifier</span><span class="p">,</span> <span class="n">RandomForestClassifier</span><span class="p">)):</span> <span class="c1"># then we discard samples that will have uncertain predictions</span>
            <span class="n">X_test_OHE</span> <span class="o">=</span> <span class="n">X_test_filtered_shap</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">X_test</span> <span class="o">=</span> <span class="n">X_test_filtered_shap</span>
            
        <span class="n">y_test</span> <span class="o">=</span> <span class="n">y_test_filtered_shap</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="ow">not</span> <span class="n">skip_block</span><span class="p">:</span>
    <span class="c1"># Calculate SHAP values for the positive class</span>
    <span class="n">positive_class_index</span> <span class="o">=</span> <span class="mi">1</span> 

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">selected_model</span><span class="p">,</span> <span class="p">(</span><span class="n">HistGradientBoostingClassifier</span><span class="p">,</span> <span class="n">RandomForestClassifier</span><span class="p">)):</span>
        <span class="n">explainer</span> <span class="o">=</span> <span class="n">shap</span><span class="o">.</span><span class="n">TreeExplainer</span><span class="p">(</span><span class="n">selected_model</span><span class="p">)</span>
        <span class="n">shap_values</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">shap_values</span><span class="p">(</span><span class="n">X_test_OHE</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">selected_model</span><span class="p">,</span> <span class="n">RandomForestClassifier</span><span class="p">):</span>
            <span class="n">shap_values</span> <span class="o">=</span> <span class="n">shap_values</span><span class="p">[:,:,</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">selected_model</span><span class="p">,</span> <span class="n">cb</span><span class="o">.</span><span class="n">CatBoostClassifier</span><span class="p">):</span>
        <span class="n">explainer</span> <span class="o">=</span> <span class="n">shap</span><span class="o">.</span><span class="n">TreeExplainer</span><span class="p">(</span><span class="n">selected_model</span><span class="p">)</span>
        <span class="n">shap_values</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">shap_values</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">selected_model</span><span class="p">,</span> <span class="n">LogisticRegression</span><span class="p">):</span>
        <span class="n">explainer</span> <span class="o">=</span> <span class="n">shap</span><span class="o">.</span><span class="n">LinearExplainer</span><span class="p">(</span><span class="n">selected_model</span><span class="p">,</span> <span class="n">X_train_OHE_nocv</span><span class="p">)</span>
        <span class="n">shap_values</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">shap_values</span><span class="p">(</span><span class="n">X_test_OHE</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">selected_model</span><span class="p">,</span> <span class="n">GaussianNB</span><span class="p">):</span>  
        <span class="n">explainer</span> <span class="o">=</span> <span class="n">shap</span><span class="o">.</span><span class="n">Explainer</span><span class="p">(</span><span class="n">selected_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">,</span> <span class="n">X_train_OHE_nocv</span><span class="p">)</span>
        <span class="n">shap_values</span> <span class="o">=</span> <span class="n">explainer</span><span class="p">(</span><span class="n">X_test_OHE</span><span class="p">)</span>  
        <span class="n">shap_values</span> <span class="o">=</span> <span class="n">shap_values</span><span class="o">.</span><span class="n">values</span><span class="p">[:,:,</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">explainer</span> <span class="o">=</span> <span class="n">shap</span><span class="o">.</span><span class="n">TreeExplainer</span><span class="p">(</span><span class="n">selected_model</span><span class="p">)</span>
        <span class="n">shap_values</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">shap_values</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
        <span class="c1"># shap_values = shap_values[positive_class_index]</span>

    <span class="c1"># Calculate the sum of SHAP values for each sample</span>
    <span class="n">shap_sum</span> <span class="o">=</span> <span class="n">shap_values</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># Get the predicted probabilities of the model</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">selected_model</span><span class="p">,</span> <span class="p">(</span><span class="n">HistGradientBoostingClassifier</span><span class="p">,</span> <span class="n">RandomForestClassifier</span><span class="p">)):</span>
        <span class="n">predicted_probabilities</span> <span class="o">=</span> <span class="n">selected_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test_OHE</span><span class="p">)[:,</span> <span class="n">positive_class_index</span><span class="p">]</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">selected_model</span><span class="p">,</span> <span class="n">cb</span><span class="o">.</span><span class="n">CatBoostClassifier</span><span class="p">):</span>
        <span class="n">predicted_probabilities</span> <span class="o">=</span> <span class="n">selected_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="n">positive_class_index</span><span class="p">]</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">selected_model</span><span class="p">,</span> <span class="p">(</span><span class="n">LogisticRegression</span><span class="p">,</span> <span class="n">GaussianNB</span><span class="p">)):</span>
        <span class="n">predicted_probabilities</span> <span class="o">=</span> <span class="n">selected_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test_OHE</span><span class="p">)[:,</span> <span class="n">positive_class_index</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">predicted_probabilities</span> <span class="o">=</span> <span class="n">selected_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="n">positive_class_index</span><span class="p">]</span>

    <span class="c1"># Plot the SHAP sum against the predicted probabilities</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">shap_sum</span><span class="p">,</span> <span class="n">predicted_probabilities</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;sum of SHAP values&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;predicted probability&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;sum of SHAP values vs. predicted probability&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;:&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;font.family&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;sans-serif&#39;</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;font.size&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">8</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;both&#39;</span><span class="p">,</span> <span class="n">labelsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span> 
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">set_facecolor</span><span class="p">(</span><span class="s1">&#39;white&#39;</span><span class="p">)</span>
    <span class="c1"># display grid lines</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">&#39;both&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;grey&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">&#39;minor&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">&#39;major&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="interpret-the-model-based-on-shap-analysis">
<h5>Interpret the model based on SHAP analysis<a class="headerlink" href="#interpret-the-model-based-on-shap-analysis" title="Link to this heading">#</a></h5>
</section>
<section id="shap-summary-plot">
<h5>SHAP summary plot<a class="headerlink" href="#shap-summary-plot" title="Link to this heading">#</a></h5>
<p>Note: the plot cannot show categorical features in color codes and thus they are plotted in grey (not mistaken with missing values)
In the case of having categorical features, two SHAP plots are displayed, once with categories shown and once using the original SHAP plot that does not show the categories</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="ow">not</span> <span class="n">skip_block</span><span class="p">:</span>
    <span class="c1"># Determine which features to use based on the model type</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">selected_model</span><span class="p">,</span> <span class="p">(</span><span class="n">HistGradientBoostingClassifier</span><span class="p">,</span> <span class="n">RandomForestClassifier</span><span class="p">,</span> <span class="n">LogisticRegression</span><span class="p">,</span> <span class="n">GaussianNB</span><span class="p">)):</span>
        <span class="n">feature_names_with_shapvalues</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">data_dictionary</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">feature</span><span class="p">,</span> <span class="n">feature</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
            <span class="k">for</span> <span class="n">feature</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">X_test_OHE</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">shap_values</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span> 
        <span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">feature_names_with_shapvalues</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">data_dictionary</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">feature</span><span class="p">,</span> <span class="n">feature</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
            <span class="k">for</span> <span class="n">feature</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">X_test</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">shap_values</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span> 
        <span class="p">]</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">selected_model</span><span class="p">,</span> <span class="p">(</span><span class="n">HistGradientBoostingClassifier</span><span class="p">,</span> <span class="n">RandomForestClassifier</span><span class="p">,</span> <span class="n">LogisticRegression</span><span class="p">,</span> <span class="n">GaussianNB</span><span class="p">)):</span>
        <span class="n">shap_summary_plot</span><span class="p">(</span><span class="n">shap_values</span><span class="o">=</span><span class="n">shap_values</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">X_test_OHE</span><span class="p">,</span> <span class="n">model_name</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;finalmodel_</span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">selected_model</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">shap_summary_plot</span><span class="p">(</span><span class="n">shap_values</span><span class="o">=</span><span class="n">shap_values</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">X_test</span><span class="p">,</span> <span class="n">model_name</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;finalmodel_</span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">selected_model</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="significance-of-features">
<h5>Significance of features<a class="headerlink" href="#significance-of-features" title="Link to this heading">#</a></h5>
<p>Sometimes it is favorable to point out significant features, like statistical analysis, and here we so far had a list of most important (impactful in terms of SHAP values). SHAP summary gives an idea on both population-based importance and individual-based importance of features.
To have more emphasize on population-based importance (global importance in explainable AI) we apply the following approach based on bootstrap testing.</p>
<p>The significance test is based on the subsampling method (with replication), where if the IQR crosses zero less than 5% of the time (95% confidence) via subsample_iqr_test function, the feature is marked as significant. The results will be depicted as boxplots with indication of significant features with light green color (as oppposed to light red color for non-significant features) and an “*” in front of the feature name via f_imp_shapboxplot function. This is similarly done for survival models.</p>
<p>Derivation and interpretation:</p>
<p>Data-driven threshold: By using the sum of absolute SHAP values and defining the threshold based on the 1st percentile, you’re taking into account the overall contribution of each feature across all instances. Features with lower total contributions are compared against this data-derived threshold, rather than simply comparing them against zero.</p>
<p>Significance Test: For each feature, you conduct a subsampling test to see how often the IQR of the SHAP values crosses this threshold. If it crosses less than 5% of the time, the feature is considered significant and marked with an asterisk.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># significant features found from this method are denoted by &quot;*&quot; and shown in light green color</span>
<span class="k">def</span> <span class="nf">subsample_iqr_test</span><span class="p">(</span><span class="n">shap_values</span><span class="p">,</span> <span class="n">num_subsamples</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">confidence_level</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span> <span class="n">random_seed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Perform subsampling and check if the IQR crosses zero in the SHAP values.</span>
<span class="sd">    </span>
<span class="sd">    Parameters:</span>
<span class="sd">    - shap_values: Array of SHAP values for a given feature</span>
<span class="sd">    - num_subsamples: Number of subsamples to generate</span>
<span class="sd">    - threshold: Threshold to determine significance (default None means use zero)</span>
<span class="sd">    - confidence_level: Threshold for determining significance (default 95%)</span>
<span class="sd">    - random_seed: Seed for reproducibility of random sampling</span>
<span class="sd">    </span>
<span class="sd">    ## Returns</span>
<span class="sd">    - proportion_crossing_zero: The proportion of subsamples where the IQR crosses zero</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">shap_values</span><span class="p">)</span>
    <span class="n">zero_crossings</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># Counter for IQR crossing zero</span>

    <span class="c1"># Set the random seed if provided</span>
    <span class="k">if</span> <span class="n">random_seed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">random_seed</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_subsamples</span><span class="p">):</span>
        <span class="c1"># Subsample with replacement</span>
        <span class="n">subsample</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">shap_values</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">lower_iqr</span><span class="p">,</span> <span class="n">upper_iqr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">subsample</span><span class="p">,</span> <span class="p">[</span><span class="mi">25</span><span class="p">,</span> <span class="mi">75</span><span class="p">])</span>
        
        <span class="c1"># Check if IQR crosses a threshold</span>
        <span class="k">if</span> <span class="n">lower_iqr</span> <span class="o">&lt;=</span> <span class="n">threshold</span><span class="p">:</span>
            <span class="n">zero_crossings</span> <span class="o">+=</span> <span class="mi">1</span>
    
    <span class="c1"># Proportion of times the IQR crosses zero</span>
    <span class="n">proportion_crossing_zero</span> <span class="o">=</span> <span class="n">zero_crossings</span> <span class="o">/</span> <span class="n">num_subsamples</span>
    <span class="k">return</span> <span class="n">proportion_crossing_zero</span>

<span class="k">def</span> <span class="nf">f_imp_shapboxplot</span><span class="p">(</span><span class="n">shap_values</span><span class="p">,</span> <span class="n">X_test_OHE</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">selected_model</span><span class="p">,</span> <span class="n">data_dictionary</span><span class="p">,</span> <span class="n">num_features</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">num_subsamples</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">random_seed</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">apply_threshold</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Plot the SHAP values for the top N most important features.</span>

<span class="sd">    This function uses the SHAP (SHapley Additive exPlanations) method to explain the contribution of each feature to a model&#39;s predictions.</span>
<span class="sd">    It plots a boxplot of the absolute SHAP values for the top N features, with colors indicating significance based on the IQR crossing test.</span>
<span class="sd">    </span>
<span class="sd">    Parameters:</span>
<span class="sd">        shap_values (np.array): The SHAP values for the input data.</span>
<span class="sd">        X_test_OHE (pd.DataFrame): The one-hot encoded test data.</span>
<span class="sd">        X_test (pd.DataFrame): The raw test data.</span>
<span class="sd">        selected_model (class): The model used to select the top N most important features.</span>
<span class="sd">        data_dictionary (dict): A dictionary mapping feature names to their corresponding indices in the dataset.</span>
<span class="sd">        num_features (int, optional): The number of top features to plot. Defaults to 20.</span>
<span class="sd">        num_subsamples (int, optional): The number of subsamples to use for the IQR crossing test. Defaults to 1000.</span>
<span class="sd">        random_seed (int, optional): The seed used for randomization. Defaults to None.</span>
<span class="sd">        apply_threshold (bool, optional): Whether to apply a threshold to the sum of SHAP values before performing the IQR crossing test. Defaults to False.</span>
<span class="sd">    </span>
<span class="sd">    ## Returns</span>
<span class="sd">        pd.DataFrame: A DataFrame containing the top N most important features, including their median absolute SHAP value, lower and upper quantiles, and subsample proportion crossing zero.</span>
<span class="sd">        plt: The plot of the boxplot of absolute SHAP values for the top N features.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Use absolute SHAP values for median and quantiles</span>
    <span class="n">abs_shap_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">shap_values</span><span class="p">)</span>
    <span class="n">median_abs_shap_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">abs_shap_values</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">lower_quantiles</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">abs_shap_values</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># 25th percentile of absolute values</span>
    <span class="n">upper_quantiles</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">abs_shap_values</span><span class="p">,</span> <span class="mi">75</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># 75th percentile of absolute values</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">selected_model</span><span class="p">,</span> <span class="p">(</span><span class="n">HistGradientBoostingClassifier</span><span class="p">,</span> <span class="n">RandomForestClassifier</span><span class="p">,</span> <span class="n">LogisticRegression</span><span class="p">,</span> <span class="n">GaussianNB</span><span class="p">)):</span>
        <span class="n">feature_importance_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
            <span class="s1">&#39;Feature&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">data_dictionary</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">feature</span><span class="p">,</span> <span class="n">feature</span><span class="p">)</span> <span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="n">X_test_OHE</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">tolist</span><span class="p">()],</span>
            <span class="s1">&#39;Median_SHAP&#39;</span><span class="p">:</span> <span class="n">median_abs_shap_values</span><span class="p">,</span>
            <span class="s1">&#39;Lower_Quantile&#39;</span><span class="p">:</span> <span class="n">lower_quantiles</span><span class="p">,</span>
            <span class="s1">&#39;Upper_Quantile&#39;</span><span class="p">:</span> <span class="n">upper_quantiles</span>
        <span class="p">})</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">feature_importance_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
            <span class="s1">&#39;Feature&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">data_dictionary</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">feature</span><span class="p">,</span> <span class="n">feature</span><span class="p">)</span> <span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="n">X_test</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">tolist</span><span class="p">()],</span>
            <span class="s1">&#39;Median_SHAP&#39;</span><span class="p">:</span> <span class="n">median_abs_shap_values</span><span class="p">,</span>
            <span class="s1">&#39;Lower_Quantile&#39;</span><span class="p">:</span> <span class="n">lower_quantiles</span><span class="p">,</span>
            <span class="s1">&#39;Upper_Quantile&#39;</span><span class="p">:</span> <span class="n">upper_quantiles</span>
        <span class="p">})</span>

    <span class="c1"># Sort the features by median absolute SHAP values in descending order</span>
    <span class="n">feature_importance_df</span> <span class="o">=</span> <span class="n">feature_importance_df</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">&#39;Median_SHAP&#39;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">apply_threshold</span><span class="p">:</span>
        <span class="c1"># Compute the sum of SHAP values for instance</span>
        <span class="n">sum_shap_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">shap_values</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">sum_shap_values</span><span class="p">))</span>

        <span class="c1"># Define threshold as the 1st percentile of the sum of SHAP values</span>
        <span class="n">shap_threshold</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">sum_shap_values</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">shap_threshold</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">shap_threshold</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># Select the top N most important features</span>
    <span class="n">top_features</span> <span class="o">=</span> <span class="n">feature_importance_df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="n">num_features</span><span class="p">)</span>

    <span class="c1"># Initialize lists to store subsample results</span>
    <span class="n">subsample_results</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">is_significant</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">top_features</span><span class="o">.</span><span class="n">index</span><span class="p">:</span>
        <span class="n">feature_shap_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">shap_values</span><span class="p">[:,</span> <span class="n">i</span><span class="p">])</span>
        <span class="c1"># Perform the IQR crossing test with subsamples</span>
        <span class="n">proportion_crossing_zero</span> <span class="o">=</span> <span class="n">subsample_iqr_test</span><span class="p">(</span><span class="n">feature_shap_values</span><span class="p">,</span> <span class="n">num_subsamples</span><span class="o">=</span><span class="n">num_subsamples</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="n">shap_threshold</span><span class="p">,</span> <span class="n">random_seed</span><span class="o">=</span><span class="n">random_seed</span><span class="p">)</span>
        
        <span class="c1"># A feature is significant if less than (1 - confidence_level)% of the subsamples cross zero</span>
        <span class="n">significant</span> <span class="o">=</span> <span class="n">proportion_crossing_zero</span> <span class="o">&lt;=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="mf">0.95</span><span class="p">)</span>
        <span class="n">is_significant</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">significant</span><span class="p">)</span>
        
        <span class="n">subsample_results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">proportion_crossing_zero</span><span class="p">)</span>

    <span class="c1"># Add the subsample results and significance to the DataFrame</span>
    <span class="n">top_features</span><span class="p">[</span><span class="s1">&#39;Subsample_Proportion_Crossing_Zero&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">subsample_results</span>
    <span class="n">top_features</span><span class="p">[</span><span class="s1">&#39;Significant&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">is_significant</span>
    
    <span class="c1"># Mark significant features with an asterisk</span>
    <span class="n">top_features</span><span class="p">[</span><span class="s1">&#39;Feature&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">top_features</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">row</span><span class="p">:</span> <span class="n">row</span><span class="p">[</span><span class="s1">&#39;Feature&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="s1">&#39;*&#39;</span> <span class="k">if</span> <span class="n">row</span><span class="p">[</span><span class="s1">&#39;Significant&#39;</span><span class="p">]</span> <span class="k">else</span> <span class="s1">&#39;&#39;</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="c1"># Prepare colors based on significance: light green for significant, light red for non-significant</span>
    <span class="n">colors</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;lightgreen&#39;</span> <span class="k">if</span> <span class="n">sig</span> <span class="k">else</span> <span class="s1">&#39;lightcoral&#39;</span> <span class="k">for</span> <span class="n">sig</span> <span class="ow">in</span> <span class="n">top_features</span><span class="p">[</span><span class="s1">&#39;Significant&#39;</span><span class="p">]]</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">num_features</span><span class="p">)]))))</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">shap_values</span><span class="p">[:,</span> <span class="n">top_features</span><span class="o">.</span><span class="n">index</span><span class="p">[:</span><span class="n">num_features</span><span class="p">]]),</span> <span class="n">orient</span><span class="o">=</span><span class="s1">&#39;h&#39;</span><span class="p">,</span> <span class="n">whis</span><span class="o">=</span><span class="p">[</span><span class="mi">25</span><span class="p">,</span> <span class="mi">75</span><span class="p">],</span> 
                <span class="n">width</span><span class="o">=</span><span class="mf">.5</span><span class="p">,</span> <span class="n">flierprops</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;marker&quot;</span><span class="p">:</span> <span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="s2">&quot;alpha&quot;</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">},</span> <span class="n">palette</span><span class="o">=</span><span class="n">colors</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>

    <span class="c1"># Customize the plot</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">num_features</span><span class="p">),</span> <span class="n">top_features</span><span class="p">[</span><span class="s1">&#39;Feature&#39;</span><span class="p">],</span> <span class="n">size</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;:&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Absolute SHAP value&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Feature&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Distribution of absolute SHAP values for all available features&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">top_features</span><span class="p">,</span> <span class="n">plt</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="ow">not</span> <span class="n">skip_block</span><span class="p">:</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">selected_model</span><span class="p">,</span> <span class="p">(</span><span class="n">HistGradientBoostingClassifier</span><span class="p">,</span> <span class="n">RandomForestClassifier</span><span class="p">,</span> <span class="n">LogisticRegression</span><span class="p">,</span> <span class="n">GaussianNB</span><span class="p">)):</span>
        <span class="n">f_imp_shapboxplot_fn</span> <span class="o">=</span> <span class="n">X_test_OHE</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">f_imp_shapboxplot_fn</span> <span class="o">=</span> <span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        
    <span class="n">f_imp_shap_table_testset</span><span class="p">,</span> <span class="n">f_imp_shapboxplot_testset</span> <span class="o">=</span> <span class="n">f_imp_shapboxplot</span><span class="p">(</span><span class="n">shap_values</span><span class="p">,</span> <span class="n">X_test_OHE</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">selected_model</span><span class="p">,</span> <span class="n">data_dictionary</span><span class="p">,</span> <span class="n">num_features</span><span class="o">=</span><span class="n">f_imp_shapboxplot_fn</span><span class="p">,</span> <span class="n">random_seed</span><span class="o">=</span> <span class="n">SEED</span><span class="p">,</span> <span class="n">apply_threshold</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">f_imp_shapboxplot_testset</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">f_imp_shapboxplot_testset</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s2">&quot;f_imp_shapboxplot_testset.tif&quot;</span><span class="p">,</span> <span class="n">bbox_inches</span><span class="o">=</span><span class="s1">&#39;tight&#39;</span><span class="p">)</span> 
    <span class="n">f_imp_shapboxplot_testset</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">f_imp_shap_table_testset</span><span class="p">)</span>
    <span class="n">f_imp_shap_table_testset</span><span class="o">.</span><span class="n">to_excel</span><span class="p">(</span><span class="s1">&#39;f_imp_shap_table_testset.xlsx&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="ow">not</span> <span class="n">skip_block</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">external_val</span><span class="p">:</span>
        <span class="c1"># Calculate SHAP values for the positive class</span>
        <span class="n">positive_class_index</span> <span class="o">=</span> <span class="mi">1</span> 

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">selected_model</span><span class="p">,</span> <span class="p">(</span><span class="n">HistGradientBoostingClassifier</span><span class="p">,</span> <span class="n">RandomForestClassifier</span><span class="p">)):</span>
            <span class="n">explainer</span> <span class="o">=</span> <span class="n">shap</span><span class="o">.</span><span class="n">TreeExplainer</span><span class="p">(</span><span class="n">selected_model</span><span class="p">)</span>
            <span class="n">shap_values_extval</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">shap_values</span><span class="p">(</span><span class="n">X_extval_OHE</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">selected_model</span><span class="p">,</span> <span class="n">RandomForestClassifier</span><span class="p">):</span>
                <span class="n">shap_values</span> <span class="o">=</span> <span class="n">shap_values</span><span class="p">[:,:,</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">selected_model</span><span class="p">,</span> <span class="n">cb</span><span class="o">.</span><span class="n">CatBoostClassifier</span><span class="p">):</span>
            <span class="n">explainer</span> <span class="o">=</span> <span class="n">shap</span><span class="o">.</span><span class="n">TreeExplainer</span><span class="p">(</span><span class="n">selected_model</span><span class="p">)</span>
            <span class="n">shap_values_extval</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">shap_values</span><span class="p">(</span><span class="n">X_extval_data</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">selected_model</span><span class="p">,</span> <span class="n">LogisticRegression</span><span class="p">):</span>
            <span class="n">explainer</span> <span class="o">=</span> <span class="n">shap</span><span class="o">.</span><span class="n">LinearExplainer</span><span class="p">(</span><span class="n">selected_model</span><span class="p">,</span> <span class="n">X_train_OHE_nocv</span><span class="p">)</span>
            <span class="n">shap_values_extval</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">shap_values</span><span class="p">(</span><span class="n">X_extval_OHE</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">selected_model</span><span class="p">,</span> <span class="n">GaussianNB</span><span class="p">):</span>  
            <span class="n">explainer</span> <span class="o">=</span> <span class="n">shap</span><span class="o">.</span><span class="n">Explainer</span><span class="p">(</span><span class="n">selected_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">,</span> <span class="n">X_train_OHE_nocv</span><span class="p">)</span>
            <span class="n">shap_values_extval</span> <span class="o">=</span> <span class="n">explainer</span><span class="p">(</span><span class="n">X_extval_OHE</span><span class="p">)</span>  
            <span class="n">shap_values_extval</span> <span class="o">=</span> <span class="n">shap_values_extval</span><span class="o">.</span><span class="n">values</span><span class="p">[:,:,</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">explainer</span> <span class="o">=</span> <span class="n">shap</span><span class="o">.</span><span class="n">TreeExplainer</span><span class="p">(</span><span class="n">selected_model</span><span class="p">)</span>
            <span class="n">shap_values_extval</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">shap_values</span><span class="p">(</span><span class="n">X_extval_data</span><span class="p">)</span>
            
        <span class="c1"># Determine which features to use based on the model type</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">selected_model</span><span class="p">,</span> <span class="p">(</span><span class="n">HistGradientBoostingClassifier</span><span class="p">,</span> <span class="n">RandomForestClassifier</span><span class="p">,</span> <span class="n">LogisticRegression</span><span class="p">,</span> <span class="n">GaussianNB</span><span class="p">)):</span>
            <span class="n">feature_names_with_shapvalues</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">data_dictionary</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">feature</span><span class="p">,</span> <span class="n">feature</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
                <span class="k">for</span> <span class="n">feature</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">X_extval_OHE</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">shap_values_extval</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span> 
            <span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">feature_names_with_shapvalues</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">data_dictionary</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">feature</span><span class="p">,</span> <span class="n">feature</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
                <span class="k">for</span> <span class="n">feature</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">X_test</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">shap_values_extval</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span> 
            <span class="p">]</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">selected_model</span><span class="p">,</span> <span class="p">(</span><span class="n">HistGradientBoostingClassifier</span><span class="p">,</span> <span class="n">RandomForestClassifier</span><span class="p">,</span> <span class="n">LogisticRegression</span><span class="p">,</span> <span class="n">GaussianNB</span><span class="p">)):</span>
            <span class="n">shap_summary_plot</span><span class="p">(</span><span class="n">shap_values</span><span class="o">=</span><span class="n">shap_values_extval</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">X_extval_OHE</span><span class="p">,</span> <span class="n">model_name</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;finalmodel_extval_</span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">selected_model</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">shap_summary_plot</span><span class="p">(</span><span class="n">shap_values</span><span class="o">=</span><span class="n">shap_values_extval</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">X_extval_data</span><span class="p">,</span> <span class="n">model_name</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;finalmodel_extval_</span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">selected_model</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="ow">not</span> <span class="n">skip_block</span><span class="p">:</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">selected_model</span><span class="p">,</span> <span class="p">(</span><span class="n">HistGradientBoostingClassifier</span><span class="p">,</span> <span class="n">RandomForestClassifier</span><span class="p">,</span> <span class="n">LogisticRegression</span><span class="p">,</span> <span class="n">GaussianNB</span><span class="p">)):</span>

        <span class="n">predictions</span> <span class="o">=</span> <span class="n">selected_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test_OHE</span><span class="p">)</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="n">predictions</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">selected_model</span><span class="p">,</span> <span class="p">(</span><span class="n">HistGradientBoostingClassifier</span><span class="p">)):</span>
            <span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="kc">True</span> <span class="k">if</span> <span class="n">x</span> <span class="o">&gt;=</span> <span class="n">opt_threshold_HGBC</span> <span class="k">else</span> <span class="kc">False</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">predictions</span><span class="p">]</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">selected_model</span><span class="p">,</span> <span class="p">(</span><span class="n">RandomForestClassifier</span><span class="p">)):</span>
            <span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="kc">True</span> <span class="k">if</span> <span class="n">x</span> <span class="o">&gt;=</span> <span class="n">opt_threshold_rf</span> <span class="k">else</span> <span class="kc">False</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">predictions</span><span class="p">]</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">selected_model</span><span class="p">,</span> <span class="p">(</span><span class="n">LogisticRegression</span><span class="p">)):</span>
            <span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="kc">True</span> <span class="k">if</span> <span class="n">x</span> <span class="o">&gt;=</span> <span class="n">opt_threshold_LR</span> <span class="k">else</span> <span class="kc">False</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">predictions</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="kc">True</span> <span class="k">if</span> <span class="n">x</span> <span class="o">&gt;=</span> <span class="n">opt_threshold_NB</span> <span class="k">else</span> <span class="kc">False</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">predictions</span><span class="p">]</span>
        
        <span class="n">misclassified</span> <span class="o">=</span> <span class="n">y_pred</span> <span class="o">!=</span> <span class="n">y_test</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">selected_model</span><span class="p">,</span> <span class="p">(</span><span class="n">cb</span><span class="o">.</span><span class="n">CatBoostClassifier</span><span class="p">)):</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="n">selected_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="n">predictions</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span>
        <span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="kc">True</span> <span class="k">if</span> <span class="n">x</span> <span class="o">&gt;=</span> <span class="n">opt_threshold_CB</span> <span class="k">else</span> <span class="kc">False</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">predictions</span><span class="p">]</span>
        <span class="n">misclassified</span> <span class="o">=</span> <span class="n">y_pred</span> <span class="o">!=</span> <span class="n">y_test</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">selected_model</span><span class="p">,</span> <span class="p">(</span><span class="n">lgb</span><span class="o">.</span><span class="n">LGBMClassifier</span><span class="p">)):</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="n">selected_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="n">predictions</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span>
        <span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="kc">True</span> <span class="k">if</span> <span class="n">x</span> <span class="o">&gt;=</span> <span class="n">opt_threshold_LGBM</span> <span class="k">else</span> <span class="kc">False</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">predictions</span><span class="p">]</span>
        <span class="n">misclassified</span> <span class="o">=</span> <span class="n">y_pred</span> <span class="o">!=</span> <span class="n">y_test</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="model-interpretation-only-based-on-correctly-classified-samples">
<h5>Model interpretation only based on correctly classified samples<a class="headerlink" href="#model-interpretation-only-based-on-correctly-classified-samples" title="Link to this heading">#</a></h5>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="ow">not</span> <span class="n">skip_block</span><span class="p">:</span>
    <span class="n">shap_values_CorrectClassified</span> <span class="o">=</span> <span class="n">shap_values</span><span class="p">[</span><span class="n">misclassified</span> <span class="o">==</span> <span class="kc">False</span><span class="p">]</span>
    <span class="c1"># Retrieve feature names from the data dictionary</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">selected_model</span><span class="p">,</span> <span class="p">(</span><span class="n">HistGradientBoostingClassifier</span><span class="p">,</span> <span class="n">RandomForestClassifier</span><span class="p">,</span><span class="n">LogisticRegression</span><span class="p">,</span> <span class="n">GaussianNB</span><span class="p">)):</span>
        <span class="n">X_test_CorrectClassified_OHE</span> <span class="o">=</span> <span class="n">X_test_OHE</span><span class="p">[</span><span class="n">misclassified</span> <span class="o">==</span> <span class="kc">False</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">X_test_CorrectClassified</span> <span class="o">=</span> <span class="n">X_test</span><span class="p">[</span><span class="n">misclassified</span> <span class="o">==</span> <span class="kc">False</span><span class="p">]</span>
        
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">selected_model</span><span class="p">,</span> <span class="p">(</span><span class="n">HistGradientBoostingClassifier</span><span class="p">,</span> <span class="n">RandomForestClassifier</span><span class="p">,</span> <span class="n">LogisticRegression</span><span class="p">,</span> <span class="n">GaussianNB</span><span class="p">)):</span>
        <span class="n">shap_summary_plot</span><span class="p">(</span><span class="n">shap_values</span><span class="o">=</span><span class="n">shap_values_CorrectClassified</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">X_test_CorrectClassified_OHE</span><span class="p">,</span> <span class="n">model_name</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;finalmodel_</span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">selected_model</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">shap_summary_plot</span><span class="p">(</span><span class="n">shap_values</span><span class="o">=</span><span class="n">shap_values_CorrectClassified</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">X_test_CorrectClassified</span><span class="p">,</span> <span class="n">model_name</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;finalmodel_</span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">selected_model</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="feature-interactions-based-on-shap-method">
<h5>Feature interactions based on SHAP method<a class="headerlink" href="#feature-interactions-based-on-shap-method" title="Link to this heading">#</a></h5>
<p>The below code generates a heatmap visualization representing the interaction between features using SHAP (SHapley Additive exPlanations) values. First, it computes the sum of absolute SHAP values for each pair of features, averaging them over all samples. These interaction scores are stored in an interaction matrix. Next, the interaction matrix is converted into a dataframe for easier plotting, with features as both rows and columns. A mask is created to hide the upper triangle of the heatmap, to eliminate redundant information. Finally, the heatmap is plotted using Seaborn, with feature names on both axes and interaction scores as annotations, providing a visual representation of feature interactions in the model predictions.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="ow">not</span> <span class="n">skip_block</span><span class="p">:</span>
    <span class="c1"># Separate SHAP values and y_test into two classes</span>
    <span class="n">class_0_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y_test</span> <span class="o">==</span> <span class="kc">False</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">class_1_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y_test</span> <span class="o">==</span> <span class="kc">True</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

    <span class="n">shap_values_class_0</span> <span class="o">=</span> <span class="n">shap_values</span><span class="p">[</span><span class="n">class_0_indices</span><span class="p">]</span>
    <span class="n">shap_values_class_1</span> <span class="o">=</span> <span class="n">shap_values</span><span class="p">[</span><span class="n">class_1_indices</span><span class="p">]</span>

    <span class="c1"># Get the number of features</span>
    <span class="n">num_samples</span><span class="p">,</span> <span class="n">num_features</span> <span class="o">=</span> <span class="n">shap_values</span><span class="o">.</span><span class="n">shape</span>

    <span class="c1"># Initialize matrices to store the median, min, and max SHAP values for each pair of features</span>
    <span class="n">interaction_matrix_median</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">num_features</span><span class="p">,</span> <span class="n">num_features</span><span class="p">))</span>
    <span class="n">interaction_matrix_min</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">num_features</span><span class="p">,</span> <span class="n">num_features</span><span class="p">))</span>
    <span class="n">interaction_matrix_max</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">num_features</span><span class="p">,</span> <span class="n">num_features</span><span class="p">))</span>

    <span class="c1"># Calculate the median, min, and max SHAP values for each pair of features</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_features</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">num_features</span><span class="p">):</span>
            <span class="n">pairwise_shap_values</span> <span class="o">=</span> <span class="n">shap_values</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">shap_values</span><span class="p">[:,</span> <span class="n">j</span><span class="p">]</span>
            <span class="n">interaction_matrix_median</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">pairwise_shap_values</span><span class="p">)</span>
            <span class="n">interaction_matrix_median</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">interaction_matrix_median</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span>
            <span class="n">interaction_matrix_min</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">pairwise_shap_values</span><span class="p">)</span>
            <span class="n">interaction_matrix_min</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">interaction_matrix_min</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span>
            <span class="n">interaction_matrix_max</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">pairwise_shap_values</span><span class="p">)</span>
            <span class="n">interaction_matrix_max</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">interaction_matrix_max</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span>

    <span class="c1"># Select appropriate test dataset based on the model type</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">selected_model</span><span class="p">,</span> <span class="p">(</span><span class="n">HistGradientBoostingClassifier</span><span class="p">,</span> <span class="n">RandomForestClassifier</span><span class="p">,</span> <span class="n">LogisticRegression</span><span class="p">,</span> <span class="n">GaussianNB</span><span class="p">)):</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">X_test_OHE</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">X_test</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

    <span class="c1"># DataFrames from the interaction matrices for easier plotting</span>
    <span class="n">interaction_df_median</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">interaction_matrix_median</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
    <span class="n">interaction_df_min</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">interaction_matrix_min</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
    <span class="n">interaction_df_max</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">interaction_matrix_max</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>

    <span class="c1"># a mask for the upper triangle excluding the diagonal</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">triu</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">interaction_df_median</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">))</span>

    <span class="n">height</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">interaction_df_median</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span><span class="p">)]))</span> 
    <span class="c1"># Ensure height does not exceed the maximum allowed dimension</span>
    <span class="n">max_height</span> <span class="o">=</span> <span class="mi">20000</span> <span class="o">/</span> <span class="mi">72</span>  <span class="c1"># Convert pixels to inches</span>
    <span class="k">if</span> <span class="n">height</span> <span class="o">&gt;</span> <span class="n">max_height</span><span class="p">:</span>
        <span class="n">height</span> <span class="o">=</span> <span class="n">max_height</span>

    <span class="c1"># Plot heatmaps for median, min, and max interactions</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">height</span><span class="o">*</span><span class="mi">3</span><span class="p">))</span>

    <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">interaction_df_median</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="n">mask</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;coolwarm&#39;</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s2">&quot;.1f&quot;</span><span class="p">,</span> <span class="n">annot_kws</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;size&quot;</span><span class="p">:</span> <span class="mi">8</span><span class="p">},</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Feature interaction heatmap based on median SHAP values&#39;</span><span class="p">)</span>

    <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">interaction_df_min</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="n">mask</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;coolwarm&#39;</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s2">&quot;.1f&quot;</span><span class="p">,</span> <span class="n">annot_kws</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;size&quot;</span><span class="p">:</span> <span class="mi">8</span><span class="p">},</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Feature interaction heatmap based on minimum SHAP values&#39;</span><span class="p">)</span>

    <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">interaction_df_max</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="n">mask</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;coolwarm&#39;</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s2">&quot;.1f&quot;</span><span class="p">,</span> <span class="n">annot_kws</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;size&quot;</span><span class="p">:</span> <span class="mi">8</span><span class="p">},</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Feature interaction heatmap based on maximum SHAP values&#39;</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;f_interaction_heatmap.tif&#39;</span><span class="p">,</span> <span class="n">bbox_inches</span><span class="o">=</span><span class="s1">&#39;tight&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

    <span class="c1"># a box plot to show the distribution of interactions for each feature pair</span>
    <span class="n">interaction_values</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">feature_pairs</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_features</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">num_features</span><span class="p">):</span>
            <span class="n">pairwise_shap_values</span> <span class="o">=</span> <span class="n">shap_values</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">shap_values</span><span class="p">[:,</span> <span class="n">j</span><span class="p">]</span>
            <span class="n">interaction_values</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">pairwise_shap_values</span><span class="p">)</span>
            <span class="n">feature_pairs</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s2"> &amp; </span><span class="si">{</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="n">num_samples</span><span class="p">)</span>

    <span class="n">interaction_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;Feature Pair&#39;</span><span class="p">:</span> <span class="n">feature_pairs</span><span class="p">,</span> <span class="s1">&#39;Interaction Value&#39;</span><span class="p">:</span> <span class="n">interaction_values</span><span class="p">})</span>

    <span class="c1"># Calculate median SHAP values for each feature pair</span>
    <span class="n">median_values</span> <span class="o">=</span> <span class="n">interaction_df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;Feature Pair&#39;</span><span class="p">)[</span><span class="s1">&#39;Interaction Value&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">median</span><span class="p">()</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="c1"># Determine the cutoff values for the top 10% and lowest 10%</span>
    <span class="n">top_10_percent_threshold</span> <span class="o">=</span> <span class="n">median_values</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="mf">0.99</span><span class="p">)</span>
    <span class="n">bottom_10_percent_threshold</span> <span class="o">=</span> <span class="n">median_values</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>

    <span class="c1"># Identify the feature pairs within the top 10% and lowest 10%</span>
    <span class="n">top_10_percent_pairs</span> <span class="o">=</span> <span class="n">median_values</span><span class="p">[</span><span class="n">median_values</span> <span class="o">&gt;=</span> <span class="n">top_10_percent_threshold</span><span class="p">]</span><span class="o">.</span><span class="n">index</span>
    <span class="n">bottom_10_percent_pairs</span> <span class="o">=</span> <span class="n">median_values</span><span class="p">[</span><span class="n">median_values</span> <span class="o">&lt;=</span> <span class="n">bottom_10_percent_threshold</span><span class="p">]</span><span class="o">.</span><span class="n">index</span>

    <span class="c1"># Combine the top and bottom feature pairs</span>
    <span class="n">selected_pairs</span> <span class="o">=</span> <span class="n">top_10_percent_pairs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">bottom_10_percent_pairs</span><span class="p">)</span>

    <span class="c1"># Filter the DataFrame to include only the selected feature pairs</span>
    <span class="n">interaction_df_filtered</span> <span class="o">=</span> <span class="n">interaction_df</span><span class="p">[</span><span class="n">interaction_df</span><span class="p">[</span><span class="s1">&#39;Feature Pair&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">selected_pairs</span><span class="p">)]</span>

    <span class="c1"># Determine figure size based on the number of variables</span>
    <span class="n">height</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">interaction_df_filtered</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span><span class="p">)]))</span> 

    <span class="c1"># Ensure height does not exceed the maximum allowed dimension</span>
    <span class="n">max_height</span> <span class="o">=</span> <span class="mi">20000</span> <span class="o">/</span> <span class="mi">72</span>  <span class="c1"># Convert pixels to inches</span>
    <span class="k">if</span> <span class="n">height</span> <span class="o">&gt;</span> <span class="n">max_height</span><span class="p">:</span>
        <span class="n">height</span> <span class="o">=</span> <span class="n">max_height</span>

    <span class="c1"># Plot the box plot with the filtered data</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="n">height</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;Feature Pair&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;Interaction Value&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">interaction_df_filtered</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="n">selected_pairs</span><span class="p">)</span>
    <span class="c1"># Enable autoscaling</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">autoscale</span><span class="p">(</span><span class="n">enable</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="s1">&#39;both&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Box plot of feature interaction values for top and bottom 1% median SHAP values&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;f_interaction_filtered_bplot.tif&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>The following script generates several plots to visualize the feature interactions based on SHAP (SHapley Additive exPlanations) values for different classes in a binary classification problem. The specific plots created are:</p>
<ol class="arabic">
<li><p><strong>Heatmaps of Feature Interactions:</strong></p>
<ul class="simple">
<li><p><strong>Median SHAP values</strong>: A heatmap showing the median SHAP interaction values between each pair of features.</p></li>
<li><p><strong>Minimum SHAP values</strong>: A heatmap displaying the minimum SHAP interaction values for each pair of features.</p></li>
<li><p><strong>Maximum SHAP values</strong>: A heatmap depicting the maximum SHAP interaction values for each pair of features.</p></li>
</ul>
<p>These heatmaps are created separately for each class (<code class="docutils literal notranslate"><span class="pre">False</span></code> and <code class="docutils literal notranslate"><span class="pre">True</span></code>). The upper triangle of the heatmap (excluding the diagonal) is masked to avoid redundant information.</p>
</li>
<li><p><strong>Box Plots of Feature Interactions:</strong></p>
<ul class="simple">
<li><p><strong>Top and Bottom 10% feature pairs</strong>: A box plot highlighting the feature pairs that fall within the top 10% and bottom 10% of median SHAP interaction values. This helps identify the most and least significant interactions.</p></li>
</ul>
</li>
</ol>
<p>Each type of plot is generated for both classes, resulting in comprehensive visualizations that facilitate the understanding of how different features interact and contribute to the model’s predictions. The plots are saved as TIFF files for further analysis and presentation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="ow">not</span> <span class="n">skip_block</span><span class="p">:</span>
    <span class="c1"># Define the classes</span>
    <span class="n">classes</span> <span class="o">=</span> <span class="p">[</span><span class="kc">False</span><span class="p">,</span> <span class="kc">True</span><span class="p">]</span>

    <span class="k">for</span> <span class="n">current_class</span> <span class="ow">in</span> <span class="n">classes</span><span class="p">:</span>
        <span class="c1"># Get the indices for the current class</span>
        <span class="n">class_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y_test</span> <span class="o">==</span> <span class="n">current_class</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        
        <span class="c1"># Extract SHAP values for the current class</span>
        <span class="n">shap_values_class</span> <span class="o">=</span> <span class="n">shap_values</span><span class="p">[</span><span class="n">class_indices</span><span class="p">]</span>
        
        <span class="c1"># Get the number of features</span>
        <span class="n">num_samples</span><span class="p">,</span> <span class="n">num_features</span> <span class="o">=</span> <span class="n">shap_values_class</span><span class="o">.</span><span class="n">shape</span>

        <span class="c1"># Initialize matrices to store the median, min, and max SHAP values for each pair of features</span>
        <span class="n">interaction_matrix_median</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">num_features</span><span class="p">,</span> <span class="n">num_features</span><span class="p">))</span>
        <span class="n">interaction_matrix_min</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">num_features</span><span class="p">,</span> <span class="n">num_features</span><span class="p">))</span>
        <span class="n">interaction_matrix_max</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">num_features</span><span class="p">,</span> <span class="n">num_features</span><span class="p">))</span>

        <span class="c1"># Calculate the median, min, and max SHAP values for each pair of features</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_features</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">num_features</span><span class="p">):</span>
                <span class="n">pairwise_shap_values</span> <span class="o">=</span> <span class="n">shap_values_class</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">shap_values_class</span><span class="p">[:,</span> <span class="n">j</span><span class="p">]</span>
                <span class="n">interaction_matrix_median</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">pairwise_shap_values</span><span class="p">)</span>
                <span class="n">interaction_matrix_median</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">interaction_matrix_median</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span>
                <span class="n">interaction_matrix_min</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">pairwise_shap_values</span><span class="p">)</span>
                <span class="n">interaction_matrix_min</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">interaction_matrix_min</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span>
                <span class="n">interaction_matrix_max</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">pairwise_shap_values</span><span class="p">)</span>
                <span class="n">interaction_matrix_max</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">interaction_matrix_max</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span>

        <span class="c1"># Select appropriate test dataset based on the model type</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">selected_model</span><span class="p">,</span> <span class="p">(</span><span class="n">HistGradientBoostingClassifier</span><span class="p">,</span> <span class="n">RandomForestClassifier</span><span class="p">,</span> <span class="n">LogisticRegression</span><span class="p">,</span> <span class="n">GaussianNB</span><span class="p">)):</span>
            <span class="n">df</span> <span class="o">=</span> <span class="n">X_test_OHE</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">df</span> <span class="o">=</span> <span class="n">X_test</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

        <span class="c1"># DataFrames from the interaction matrices for easier plotting</span>
        <span class="n">interaction_df_median</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">interaction_matrix_median</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
        <span class="n">interaction_df_min</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">interaction_matrix_min</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
        <span class="n">interaction_df_max</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">interaction_matrix_max</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>

        <span class="c1"># a mask for the upper triangle excluding the diagonal</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">triu</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">interaction_df_median</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">))</span>
        <span class="n">height</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">interaction_df_median</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span><span class="p">)]))</span> 
        <span class="c1"># Ensure height does not exceed the maximum allowed dimension</span>
        <span class="n">max_height</span> <span class="o">=</span> <span class="mi">20000</span> <span class="o">/</span> <span class="mi">72</span>  <span class="c1"># Convert pixels to inches</span>
        <span class="k">if</span> <span class="n">height</span> <span class="o">&gt;</span> <span class="n">max_height</span><span class="p">:</span>
            <span class="n">height</span> <span class="o">=</span> <span class="n">max_height</span>

        <span class="c1"># Plot heatmaps for median, min, and max interactions</span>
        <span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">height</span><span class="o">*</span><span class="mi">3</span><span class="p">))</span>

        <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">interaction_df_median</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="n">mask</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;coolwarm&#39;</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s2">&quot;.1f&quot;</span><span class="p">,</span> <span class="n">annot_kws</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;size&quot;</span><span class="p">:</span> <span class="mi">8</span><span class="p">},</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Feature interaction heatmap based on median SHAP values for class </span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="n">current_class</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

        <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">interaction_df_min</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="n">mask</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;coolwarm&#39;</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s2">&quot;.1f&quot;</span><span class="p">,</span> <span class="n">annot_kws</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;size&quot;</span><span class="p">:</span> <span class="mi">8</span><span class="p">},</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Feature interaction heatmap based on minimum SHAP values for class </span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="n">current_class</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

        <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">interaction_df_max</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="n">mask</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;coolwarm&#39;</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s2">&quot;.1f&quot;</span><span class="p">,</span> <span class="n">annot_kws</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;size&quot;</span><span class="p">:</span> <span class="mi">8</span><span class="p">},</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
        <span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Feature interaction heatmap based on maximum SHAP values for class </span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="n">current_class</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

        <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;f_interaction_heatmap_</span><span class="si">{</span><span class="n">current_class</span><span class="si">}</span><span class="s1">.tif&#39;</span><span class="p">,</span> <span class="n">bbox_inches</span><span class="o">=</span><span class="s1">&#39;tight&#39;</span><span class="p">)</span>
        <span class="c1"># plt.show()</span>

        <span class="c1"># Create a box plot to show the distribution of interactions for each feature pair</span>
        <span class="n">interaction_values</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">feature_pairs</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_features</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">num_features</span><span class="p">):</span>
                <span class="n">pairwise_shap_values</span> <span class="o">=</span> <span class="n">shap_values_class</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">shap_values_class</span><span class="p">[:,</span> <span class="n">j</span><span class="p">]</span>
                <span class="n">interaction_values</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">pairwise_shap_values</span><span class="p">)</span>
                <span class="n">feature_pairs</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s2"> &amp; </span><span class="si">{</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="n">num_samples</span><span class="p">)</span>

        <span class="n">interaction_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;Feature Pair&#39;</span><span class="p">:</span> <span class="n">feature_pairs</span><span class="p">,</span> <span class="s1">&#39;Interaction Value&#39;</span><span class="p">:</span> <span class="n">interaction_values</span><span class="p">})</span>
        
        <span class="c1"># Remove feature pairs where a feature interacts with itself</span>
        <span class="n">interaction_df</span> <span class="o">=</span> <span class="n">interaction_df</span><span class="p">[</span><span class="o">~</span><span class="n">interaction_df</span><span class="p">[</span><span class="s1">&#39;Feature Pair&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39; &amp; &#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">x</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39; &amp; &#39;</span><span class="p">)[</span><span class="mi">1</span><span class="p">])]</span>

        <span class="c1"># Calculate median SHAP values for each feature pair</span>
        <span class="n">median_values</span> <span class="o">=</span> <span class="n">interaction_df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;Feature Pair&#39;</span><span class="p">)[</span><span class="s1">&#39;Interaction Value&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">median</span><span class="p">()</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="c1"># Determine the cutoff values for the top 10% and lowest 10%</span>
        <span class="n">top_10_percent_threshold</span> <span class="o">=</span> <span class="n">median_values</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="mf">0.90</span><span class="p">)</span>
        <span class="n">bottom_10_percent_threshold</span> <span class="o">=</span> <span class="n">median_values</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="mf">0.10</span><span class="p">)</span>

        <span class="c1"># Identify the feature pairs within the top 10% and lowest 10%</span>
        <span class="n">top_10_percent_pairs</span> <span class="o">=</span> <span class="n">median_values</span><span class="p">[</span><span class="n">median_values</span> <span class="o">&gt;=</span> <span class="n">top_10_percent_threshold</span><span class="p">]</span><span class="o">.</span><span class="n">index</span>
        <span class="n">bottom_10_percent_pairs</span> <span class="o">=</span> <span class="n">median_values</span><span class="p">[</span><span class="n">median_values</span> <span class="o">&lt;=</span> <span class="n">bottom_10_percent_threshold</span><span class="p">]</span><span class="o">.</span><span class="n">index</span>

        <span class="c1"># Combine the top and bottom feature pairs</span>
        <span class="n">selected_pairs</span> <span class="o">=</span> <span class="n">top_10_percent_pairs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">bottom_10_percent_pairs</span><span class="p">)</span>

        <span class="c1"># Filter the DataFrame to include only the selected feature pairs</span>
        <span class="n">interaction_df_filtered</span> <span class="o">=</span> <span class="n">interaction_df</span><span class="p">[</span><span class="n">interaction_df</span><span class="p">[</span><span class="s1">&#39;Feature Pair&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">selected_pairs</span><span class="p">)]</span>

        <span class="c1"># Determine figure size based on the number of variables</span>
        <span class="n">height</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">interaction_df_filtered</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span><span class="p">)]))</span> 

        <span class="c1"># Ensure height does not exceed the maximum allowed dimension</span>
        <span class="n">max_height</span> <span class="o">=</span> <span class="mi">20000</span> <span class="o">/</span> <span class="mi">72</span>  <span class="c1"># Convert pixels to inches</span>
        <span class="k">if</span> <span class="n">height</span> <span class="o">&gt;</span> <span class="n">max_height</span><span class="p">:</span>
            <span class="n">height</span> <span class="o">=</span> <span class="n">max_height</span>

        <span class="c1"># Plot the box plot with the filtered data</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="n">height</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
        <span class="n">sns</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;Feature Pair&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;Interaction Value&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">interaction_df_filtered</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="n">selected_pairs</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Box plot of feature interaction values for top and bottom 10% median SHAP values for class </span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="n">current_class</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;f_interaction_filtered_bplot_</span><span class="si">{</span><span class="n">current_class</span><span class="si">}</span><span class="s1">.tif&#39;</span><span class="p">,</span> <span class="n">dpi</span> <span class="o">=</span> <span class="mi">300</span><span class="p">)</span>
        <span class="c1"># plt.show()</span>
</pre></div>
</div>
</div>
</div>
<p>In this context, “interaction” refers to the combined effect of two features on the model’s prediction, as measured by their SHAP values. SHAP (SHapley Additive exPlanations) values provide a way to interpret the contribution of each feature to the prediction of a machine learning model. Here, the interaction between two features is quantified by combining their SHAP values and assessing how these combined values influence the prediction.</p>
<p>Specifically:</p>
<ol class="arabic simple">
<li><p><strong>Pairwise SHAP Values</strong>: The interaction between two features ( i ) and ( j ) is evaluated by summing their individual SHAP values for each sample. This summed value represents the joint contribution of both features to the prediction for that sample.</p></li>
<li><p><strong>Interaction Metrics</strong>:</p>
<ul class="simple">
<li><p><strong>Median Interaction</strong>: The median of the pairwise SHAP values across all samples for a given class.</p></li>
<li><p><strong>Minimum Interaction</strong>: The minimum of the pairwise SHAP values across all samples for a given class.</p></li>
<li><p><strong>Maximum Interaction</strong>: The maximum of the pairwise SHAP values across all samples for a given class.</p></li>
</ul>
</li>
</ol>
<p>These metrics are calculated for each pair of features, resulting in matrices that summarize the interactions. The script then visualizes these interactions through heatmaps and box plots to provide insights into how pairs of features work together to influence the model’s predictions for different classes.</p>
</section>
</section>
</section>
<section id="additional-analyses-on-model-interpretation-and-evaluation">
<h3>Additional analyses on model interpretation and evaluation:<a class="headerlink" href="#additional-analyses-on-model-interpretation-and-evaluation" title="Link to this heading">#</a></h3>
<ol class="arabic simple">
<li><p><strong>Heatmaps</strong>:</p>
<ul class="simple">
<li><p><strong>Median SHAP Interaction Heatmap</strong>: Shows the median combined effect of feature pairs.</p></li>
<li><p><strong>Minimum SHAP Interaction Heatmap</strong>: Shows the smallest combined effect of feature pairs.</p></li>
<li><p><strong>Maximum SHAP Interaction Heatmap</strong>: Shows the largest combined effect of feature pairs.</p></li>
</ul>
</li>
<li><p><strong>Box Plots</strong>:</p>
<ul class="simple">
<li><p><strong>Top and Bottom 10% Feature Pairs Box Plot</strong>: Highlights the feature pairs with the most and least significant interactions, based on the median SHAP values.</p></li>
</ul>
</li>
</ol>
<section id="feature-interactions-based-on-feature-permutation-method-for-feature-pairs">
<h4>Feature interactions based on feature permutation method for feature pairs<a class="headerlink" href="#feature-interactions-based-on-feature-permutation-method-for-feature-pairs" title="Link to this heading">#</a></h4>
<p>this code provides insight into the interaction effects between pairs of features in the machine learning model, helping identify which combinations of features contribute significantly to the model’s performance.</p>
<ul class="simple">
<li><p>The <code class="docutils literal notranslate"><span class="pre">permute_feature_pairs</span></code> function calculates the permutation importances for pairs of features.</p></li>
<li><p>It converts the binary target variable to numeric format and calculates the baseline score using ROC AUC.</p></li>
<li><p>For each pair of features, it shuffles their values multiple times and computes the change in ROC AUC compared to the baseline. The average change in ROC AUC is stored as the importance score for that feature pair.</p></li>
<li><p>It generates all possible pairs of features from the input feature set.</p></li>
<li><p>It computes the permutation importances for pairs of features using the defined function.</p></li>
<li><p>The results are stored in a DataFrame, where each row represents a feature pair along with its importance score.</p></li>
<li><p>The DataFrame is sorted based on importance in descending order and printed to display the importance of feature pairs.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="ow">not</span> <span class="n">skip_block</span><span class="p">:</span>
    <span class="c1"># Function to permute pairs of features</span>
    <span class="k">if</span> <span class="n">find_interacting_feature_permutation</span><span class="p">:</span>
        <span class="k">def</span> <span class="nf">permute_feature_pairs</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">pairs</span><span class="p">,</span> <span class="n">n_repeats</span><span class="p">,</span> <span class="n">random_state</span><span class="p">,</span> <span class="n">scoring</span><span class="p">,</span> <span class="n">n_jobs</span><span class="p">):</span>
<span class="w">            </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Computes the permutation importance of pairs of features in a given model.This function computes the permutation importance of pairs of features in a given machine learning model. It takes as input:</span>

<span class="sd">            *   The model to be used</span>
<span class="sd">            *   The input data `X`</span>
<span class="sd">            *   The target variable `y`</span>
<span class="sd">            *   A list of tuples, where each tuple contains two feature indices `pairs`</span>
<span class="sd">            *   The number of times to repeat the permutation for each pair `n_repeats`</span>
<span class="sd">            *   The random seed for reproducibility `random_state`</span>
<span class="sd">            *   A function to evaluate the model&#39;s performance on a given split of data `scoring`</span>
<span class="sd">            *   The number of CPU cores to use for parallel computation `n_jobs`</span>

<span class="sd">            The function returns a dictionary where the keys are tuples of feature indices and the values are the average permutation importances for each pair. This allows users to easily identify which pairs of features have the most significant impact on the model&#39;s performance.</span>

<span class="sd">            In this specific implementation, the function is used to compute the permutation importance of all pairs of features in the test data `X_test_OHE` (or `X_test` if the model can handle missing values). The results are then stored in a pandas DataFrame for easy visualization and analysis.</span>

<span class="sd">            Parameters:</span>
<span class="sd">                model (object): The machine learning model to be used.</span>
<span class="sd">                X (pandas DataFrame or numpy array): The input data.</span>
<span class="sd">                y (pandas Series): The target variable.</span>
<span class="sd">                pairs (list): A list of tuples, where each tuple contains two feature indices.</span>
<span class="sd">                n_repeats (int): The number of times to repeat the permutation for each pair.</span>
<span class="sd">                random_state (int): The random seed for reproducibility.</span>
<span class="sd">                scoring (function): A function to evaluate the model&#39;s performance on a given split of data.</span>
<span class="sd">                n_jobs (int): The number of CPU cores to use for parallel computation.</span>

<span class="sd">            ## Returns</span>
<span class="sd">                dict: A dictionary where the keys are tuples of feature indices and the values are the average permutation importances for each pair.</span>
<span class="sd">            &quot;&quot;&quot;</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">replace</span><span class="p">({</span><span class="n">class_1</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="n">class_0</span><span class="p">:</span> <span class="mi">0</span><span class="p">})</span>
            <span class="n">baseline_score</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">])</span>
            <span class="n">importance_dict</span> <span class="o">=</span> <span class="p">{}</span>

            <span class="k">for</span> <span class="n">feature1</span><span class="p">,</span> <span class="n">feature2</span> <span class="ow">in</span> <span class="n">pairs</span><span class="p">:</span>
                <span class="n">importances</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_repeats</span><span class="p">):</span>
                    <span class="n">X_permuted</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
                    <span class="n">X_permuted</span><span class="p">[[</span><span class="n">feature1</span><span class="p">,</span> <span class="n">feature2</span><span class="p">]]</span> <span class="o">=</span> <span class="n">X_permuted</span><span class="p">[[</span><span class="n">feature1</span><span class="p">,</span> <span class="n">feature2</span><span class="p">]]</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">frac</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">)</span><span class="o">.</span><span class="n">values</span>
                    <span class="n">permuted_score</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_permuted</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">])</span>
                    <span class="n">importances</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">baseline_score</span> <span class="o">-</span> <span class="n">permuted_score</span><span class="p">)</span>
                
                <span class="n">importance_dict</span><span class="p">[(</span><span class="n">feature1</span><span class="p">,</span> <span class="n">feature2</span><span class="p">)]</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">importances</span><span class="p">)</span> <span class="o">/</span> <span class="n">n_repeats</span>  <span class="c1"># Average importance over n_repeats</span>
            
            <span class="k">return</span> <span class="n">importance_dict</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">selected_model</span><span class="p">,</span> <span class="p">(</span><span class="n">HistGradientBoostingClassifier</span><span class="p">,</span> <span class="n">RandomForestClassifier</span><span class="p">,</span><span class="n">LogisticRegression</span><span class="p">,</span> <span class="n">GaussianNB</span><span class="p">)):</span>
            <span class="n">df</span> <span class="o">=</span> <span class="n">X_test_OHE</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">df</span> <span class="o">=</span> <span class="n">X_test</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

        <span class="c1"># Define the features</span>
        <span class="n">features</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
        <span class="n">pairs</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">itertools</span><span class="o">.</span><span class="n">combinations</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>

        <span class="c1"># Calculate the permutation importances for pairs of features</span>
        <span class="n">pair_importances</span> <span class="o">=</span> <span class="n">permute_feature_pairs</span><span class="p">(</span>
            <span class="n">selected_model</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">pairs</span><span class="p">,</span> <span class="n">n_repeats</span> <span class="o">=</span> <span class="n">n_rep_feature_permutation</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="n">SEED</span><span class="p">,</span> <span class="n">scoring</span> <span class="o">=</span> <span class="n">custom_scorer</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_cpu_model_training</span>
        <span class="p">)</span>

        <span class="c1"># a DataFrame to store the results</span>
        <span class="n">pair_importance_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
            <span class="p">{</span><span class="s2">&quot;feature pair&quot;</span><span class="p">:</span> <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">pair</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2"> + </span><span class="si">{</span><span class="n">pair</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">pair</span> <span class="ow">in</span> <span class="n">pair_importances</span><span class="o">.</span><span class="n">keys</span><span class="p">()],</span>
            <span class="s2">&quot;importance&quot;</span><span class="p">:</span> <span class="n">pair_importances</span><span class="o">.</span><span class="n">values</span><span class="p">()}</span>
        <span class="p">)</span>

        <span class="c1"># Sort by importance</span>
        <span class="n">pair_importance_df</span> <span class="o">=</span> <span class="n">pair_importance_df</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s2">&quot;importance&quot;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">pair_importance_df</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="shap-decision-plot">
<h4>SHAP decision plot<a class="headerlink" href="#shap-decision-plot" title="Link to this heading">#</a></h4>
<p>The SHAP decision plot centers around the <code class="docutils literal notranslate"><span class="pre">explainer.expected_value</span></code> on the x-axis, with colored lines representing predictions for each observation. Moving upwards, these lines intersect the x-axis at the prediction specific to each observation, depicted in varying colors on a gradient scale. The plot integrates SHAP values for each feature, illustrating their contributions to the overall prediction relative to the model’s baseline value. At the plot’s bottom, observations converge at <code class="docutils literal notranslate"><span class="pre">explainer.expected_value</span></code>.</p>
<ol class="arabic simple">
<li><p><strong>Demonstrating feature effects:</strong></p>
<ul class="simple">
<li><p>Visualizes the impact of multiple features on predictions and their individual contributions.</p></li>
</ul>
</li>
<li><p><strong>Revealing interaction effects:</strong></p>
<ul class="simple">
<li><p>shows how interactions between features influence predictions by incorporating SHAP values.</p></li>
</ul>
</li>
<li><p><strong>Exploring feature effects across values:</strong></p>
<ul class="simple">
<li><p>Enables exploration of feature effects by showcasing prediction variations across different feature values.</p></li>
</ul>
</li>
<li><p><strong>Identifying outliers:</strong></p>
<ul class="simple">
<li><p>Enables outlier detection by pinpointing observations deviating significantly from expected values or prediction trends.</p></li>
</ul>
</li>
<li><p><strong>Understanding prediction paths:</strong></p>
<ul class="simple">
<li><p>Facilitates the identification of common prediction patterns, offering insight into model behavior.</p></li>
</ul>
</li>
<li><p><strong>Model comparison:</strong></p>
<ul class="simple">
<li><p>Allows comparing predictions across multiple models.</p></li>
</ul>
</li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="ow">not</span> <span class="n">skip_block</span><span class="p">:</span>
    <span class="c1"># Plot the SHAP decision plot with only significant features</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">selected_model</span><span class="p">,</span> <span class="p">(</span><span class="n">HistGradientBoostingClassifier</span><span class="p">)):</span>
        <span class="n">shap</span><span class="o">.</span><span class="n">decision_plot</span><span class="p">(</span><span class="n">explainer</span><span class="o">.</span><span class="n">expected_value</span><span class="p">,</span> 
                        <span class="n">shap_values</span><span class="p">,</span>
                        <span class="n">X_test_OHE</span><span class="p">,</span>
                        <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> 
                        <span class="n">feature_names</span><span class="o">=</span><span class="n">feature_names_with_shapvalues</span><span class="p">,</span>
                        <span class="n">link</span><span class="o">=</span><span class="s1">&#39;logit&#39;</span><span class="p">,</span>
                        <span class="n">highlight</span><span class="o">=</span><span class="n">misclassified</span><span class="p">,</span>
                        <span class="n">ignore_warnings</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                        <span class="n">feature_order</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">selected_model</span><span class="p">,</span> <span class="p">(</span><span class="n">RandomForestClassifier</span><span class="p">)):</span>
        <span class="n">shap</span><span class="o">.</span><span class="n">decision_plot</span><span class="p">(</span><span class="n">explainer</span><span class="o">.</span><span class="n">expected_value</span><span class="p">[</span><span class="n">positive_class_index</span><span class="p">],</span> 
                        <span class="n">shap_values</span><span class="p">,</span>
                        <span class="n">X_test_OHE</span><span class="p">,</span>
                        <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> 
                        <span class="n">feature_names</span><span class="o">=</span><span class="n">feature_names_with_shapvalues</span><span class="p">,</span>
                        <span class="n">link</span><span class="o">=</span><span class="s1">&#39;logit&#39;</span><span class="p">,</span>
                        <span class="n">highlight</span><span class="o">=</span><span class="n">misclassified</span><span class="p">,</span>
                        <span class="n">ignore_warnings</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                        <span class="n">feature_order</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">selected_model</span><span class="p">,</span> <span class="p">(</span><span class="n">LogisticRegression</span><span class="p">)):</span>
        <span class="n">shap</span><span class="o">.</span><span class="n">decision_plot</span><span class="p">(</span><span class="n">explainer</span><span class="o">.</span><span class="n">expected_value</span><span class="p">,</span> 
                        <span class="n">shap_values</span><span class="p">,</span>
                        <span class="n">X_test_OHE</span><span class="p">,</span>
                        <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> 
                        <span class="n">feature_names</span><span class="o">=</span><span class="n">feature_names_with_shapvalues</span><span class="p">,</span>
                        <span class="n">link</span><span class="o">=</span><span class="s1">&#39;logit&#39;</span><span class="p">,</span>
                        <span class="n">highlight</span><span class="o">=</span><span class="n">misclassified</span><span class="p">,</span>
                        <span class="n">ignore_warnings</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                        <span class="n">feature_order</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">selected_model</span><span class="p">,</span> <span class="p">(</span><span class="n">cb</span><span class="o">.</span><span class="n">CatBoostClassifier</span><span class="p">)):</span>
        <span class="n">shap</span><span class="o">.</span><span class="n">decision_plot</span><span class="p">(</span><span class="n">explainer</span><span class="o">.</span><span class="n">expected_value</span><span class="p">,</span> 
                        <span class="n">shap_values</span><span class="p">,</span>
                        <span class="n">X_test</span><span class="p">,</span>
                        <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> 
                        <span class="n">feature_names</span><span class="o">=</span><span class="n">feature_names_with_shapvalues</span><span class="p">,</span>
                        <span class="n">link</span><span class="o">=</span><span class="s1">&#39;logit&#39;</span><span class="p">,</span>
                        <span class="n">highlight</span><span class="o">=</span><span class="n">misclassified</span><span class="p">,</span>
                        <span class="n">ignore_warnings</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                        <span class="n">feature_order</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">selected_model</span><span class="p">,</span> <span class="p">(</span><span class="n">GaussianNB</span><span class="p">)):</span>
        <span class="n">shap_values_NB</span> <span class="o">=</span> <span class="n">explainer</span><span class="p">(</span><span class="n">X_test_OHE</span><span class="p">)</span>
        <span class="n">shap</span><span class="o">.</span><span class="n">decision_plot</span><span class="p">(</span><span class="n">base_value</span> <span class="o">=</span> <span class="n">shap_values_NB</span><span class="o">.</span><span class="n">base_values</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span>
                        <span class="n">shap_values</span> <span class="o">=</span> <span class="n">shap_values</span><span class="p">,</span>
                        <span class="n">features</span> <span class="o">=</span> <span class="n">X_test_OHE</span><span class="p">,</span>
                        <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> 
                        <span class="n">feature_names</span><span class="o">=</span><span class="n">feature_names_with_shapvalues</span><span class="p">,</span>
                        <span class="n">link</span><span class="o">=</span><span class="s1">&#39;logit&#39;</span><span class="p">,</span>
                        <span class="n">highlight</span><span class="o">=</span><span class="n">misclassified</span><span class="p">,</span> 
                        <span class="n">ignore_warnings</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                        <span class="n">feature_order</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">shap</span><span class="o">.</span><span class="n">decision_plot</span><span class="p">(</span><span class="n">explainer</span><span class="o">.</span><span class="n">expected_value</span><span class="p">,</span> 
                        <span class="n">shap_values</span><span class="p">,</span>
                        <span class="n">X_test</span><span class="p">,</span>
                        <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> 
                        <span class="n">feature_names</span><span class="o">=</span><span class="n">feature_names_with_shapvalues</span><span class="p">,</span>
                        <span class="n">link</span><span class="o">=</span><span class="s1">&#39;logit&#39;</span><span class="p">,</span>
                        <span class="n">highlight</span><span class="o">=</span><span class="n">misclassified</span><span class="p">,</span> 
                        <span class="n">ignore_warnings</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                        <span class="n">feature_order</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">set_facecolor</span><span class="p">(</span><span class="s1">&#39;white&#39;</span><span class="p">)</span>  
    <span class="c1"># display grid lines</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">&#39;both&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;grey&quot;</span><span class="p">)</span>
    <span class="c1"># modify grid lines</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">&#39;minor&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">&#39;major&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;shap_decision_allfeats_plot.tif&#39;</span><span class="p">,</span> <span class="n">bbox_inches</span><span class="o">=</span><span class="s1">&#39;tight&#39;</span><span class="p">)</span>

    <span class="c1"># Close the extra figure</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="c1"># show the plot</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="shap-dependence-plots">
<h4>SHAP dependence plots<a class="headerlink" href="#shap-dependence-plots" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="ow">not</span> <span class="n">skip_block</span><span class="p">:</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="s2">&quot;ticks&quot;</span><span class="p">)</span>

    <span class="c1"># Set the background color to white</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">set_style</span><span class="p">(</span><span class="s2">&quot;white&quot;</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s2">&quot;figure.figsize&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>

    <span class="c1"># Compute median absolute SHAP values for each feature</span>
    <span class="n">median_abs_shap_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">shap_values</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="c1"># Sort features by median absolute SHAP values in descending order</span>
    <span class="n">sorted_features</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">median_abs_shap_values</span><span class="p">)[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

    <span class="c1"># Calculate the number of features to plot</span>
    <span class="c1"># num_features_to_plot = min(np.sum(median_abs_shap_values &gt; 0), top_n_f)</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">selected_model</span><span class="p">,</span> <span class="p">(</span><span class="n">HistGradientBoostingClassifier</span><span class="p">,</span> <span class="n">RandomForestClassifier</span><span class="p">,</span> <span class="n">LogisticRegression</span><span class="p">,</span> <span class="n">GaussianNB</span><span class="p">)):</span>
        <span class="n">num_features_to_plot</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">top_n_f</span><span class="p">,</span><span class="n">X_test_OHE</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">num_features_to_plot</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">top_n_f</span><span class="p">,</span><span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

    <span class="c1"># Set the number of columns for subplots</span>
    <span class="n">num_cols</span> <span class="o">=</span> <span class="mi">4</span>

    <span class="c1"># Calculate the number of rows for subplots</span>
    <span class="n">num_rows</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">num_features_to_plot</span> <span class="o">/</span> <span class="n">num_cols</span><span class="p">))</span>

    <span class="c1"># Initialize a subplot</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">num_rows</span><span class="p">,</span> <span class="n">num_cols</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">5</span><span class="o">*</span><span class="n">num_rows</span><span class="p">))</span>
    <span class="n">axs</span> <span class="o">=</span> <span class="n">axs</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>

    <span class="c1"># Track the current subplot index</span>
    <span class="n">current_subplot</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># Iterate over the top features</span>
    <span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="n">sorted_features</span><span class="p">[:</span><span class="n">num_features_to_plot</span><span class="p">]:</span>
        <span class="c1"># Get feature name</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">selected_model</span><span class="p">,</span> <span class="p">(</span><span class="n">HistGradientBoostingClassifier</span><span class="p">,</span> <span class="n">RandomForestClassifier</span><span class="p">,</span> <span class="n">LogisticRegression</span><span class="p">,</span> <span class="n">GaussianNB</span><span class="p">)):</span>
            <span class="n">feature_name</span> <span class="o">=</span> <span class="n">X_test_OHE</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">feature</span><span class="p">]</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">X_test_OHE</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="n">feature</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">feature_name</span> <span class="o">=</span> <span class="n">X_test</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">feature</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">X_test</span><span class="p">[</span><span class="n">feature_name</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;category&#39;</span><span class="p">:</span>
                <span class="c1"># Convert categorical feature to numerical using LabelEncoder</span>
                <span class="n">encoder</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
                <span class="n">X_test_encoded</span> <span class="o">=</span> <span class="n">X_test</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
                <span class="n">X_test_encoded</span><span class="p">[</span><span class="n">feature_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">[</span><span class="n">feature_name</span><span class="p">])</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">X_test_encoded</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="n">feature</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">X_test</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="n">feature</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
        
        <span class="c1"># Handle missing values in feature values and SHAP values</span>
        <span class="n">mask_x</span> <span class="o">=</span> <span class="o">~</span><span class="n">pd</span><span class="o">.</span><span class="n">isnull</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">mask_shap</span> <span class="o">=</span> <span class="o">~</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">shap_values</span><span class="p">[:,</span> <span class="n">feature</span><span class="p">])</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">mask_x</span> <span class="o">&amp;</span> <span class="n">mask_shap</span>
        
        <span class="n">x_filtered</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span>
        <span class="n">shap_values_filtered</span> <span class="o">=</span> <span class="n">shap_values</span><span class="p">[:,</span> <span class="n">feature</span><span class="p">][</span><span class="n">mask</span><span class="p">]</span>
        <span class="n">predictions_filtered</span> <span class="o">=</span> <span class="n">predictions</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span>
        <span class="n">misclassified_filtered</span> <span class="o">=</span> <span class="n">misclassified</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span>
        
        <span class="c1"># Check if all x values are identical</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">x_filtered</span><span class="p">))</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Skipped feature </span><span class="si">{</span><span class="n">feature_name</span><span class="si">}</span><span class="s2"> because all x values are identical.&quot;</span><span class="p">)</span>
            <span class="k">continue</span>
        
        <span class="c1"># Calculate Spearman correlation coefficient and p-value</span>
        <span class="n">correlation</span><span class="p">,</span> <span class="n">p_value</span> <span class="o">=</span> <span class="n">spearmanr</span><span class="p">(</span><span class="n">x_filtered</span><span class="p">,</span> <span class="n">shap_values_filtered</span><span class="p">,</span> <span class="n">nan_policy</span><span class="o">=</span><span class="s1">&#39;omit&#39;</span><span class="p">)</span>
        
        <span class="c1"># Create scatter plot in the current subplot</span>
        <span class="n">scatter</span> <span class="o">=</span> <span class="n">axs</span><span class="p">[</span><span class="n">current_subplot</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x_filtered</span><span class="p">,</span> <span class="n">shap_values_filtered</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">predictions_filtered</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
        <span class="n">axs</span><span class="p">[</span><span class="n">current_subplot</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="n">feature_name</span><span class="p">)</span>
        <span class="n">axs</span><span class="p">[</span><span class="n">current_subplot</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;SHAP Value&quot;</span><span class="p">)</span>
        
        <span class="c1"># Add correlation line</span>
        <span class="n">slope</span><span class="p">,</span> <span class="n">intercept</span><span class="p">,</span> <span class="n">r_value</span><span class="p">,</span> <span class="n">p_value_corr</span><span class="p">,</span> <span class="n">std_err</span> <span class="o">=</span> <span class="n">linregress</span><span class="p">(</span><span class="n">x_filtered</span><span class="p">,</span> <span class="n">shap_values_filtered</span><span class="p">)</span>
        <span class="n">axs</span><span class="p">[</span><span class="n">current_subplot</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_filtered</span><span class="p">,</span> <span class="n">slope</span> <span class="o">*</span> <span class="n">x_filtered</span> <span class="o">+</span> <span class="n">intercept</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">)</span>
        
        <span class="c1"># Mark misclassified samples with &#39;x&#39;</span>
        <span class="n">axs</span><span class="p">[</span><span class="n">current_subplot</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x_filtered</span><span class="p">[</span><span class="n">misclassified_filtered</span><span class="p">],</span> <span class="n">shap_values_filtered</span><span class="p">[</span><span class="n">misclassified_filtered</span><span class="p">],</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
        
        <span class="c1"># Customize colorbar</span>
        <span class="n">cbar</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">scatter</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="n">current_subplot</span><span class="p">])</span>
        <span class="n">cbar</span><span class="o">.</span><span class="n">set_label</span><span class="p">(</span><span class="s2">&quot;Predicted Probability&quot;</span><span class="p">)</span>
        
        <span class="c1"># Check if correlation is statistically significant</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">correlation</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">p_value_corr</span><span class="p">):</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">p_value_corr_test</span> <span class="o">=</span> <span class="n">ttest_rel</span><span class="p">(</span><span class="n">x_filtered</span><span class="p">,</span> <span class="n">shap_values_filtered</span><span class="p">)</span>
            <span class="n">p_value_text</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;p &lt; 0.05&quot;</span> <span class="k">if</span> <span class="n">p_value_corr_test</span> <span class="o">&lt;</span> <span class="mf">0.05</span> <span class="k">else</span> <span class="sa">f</span><span class="s2">&quot;p = </span><span class="si">{</span><span class="n">p_value_corr_test</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="n">axs</span><span class="p">[</span><span class="n">current_subplot</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">feature_name</span><span class="si">}</span><span class="s2"> vs. SHAP Value</span><span class="se">\n</span><span class="s2">Spearman Correlation: </span><span class="si">{</span><span class="n">correlation</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">p_value_text</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">axs</span><span class="p">[</span><span class="n">current_subplot</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">feature_name</span><span class="si">}</span><span class="s2"> vs. SHAP Value</span><span class="se">\n</span><span class="s2">Correlation: N/A&quot;</span><span class="p">)</span>
        
        <span class="c1"># Increment the current subplot index</span>
        <span class="n">current_subplot</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="c1"># Hide any remaining empty subplots</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">current_subplot</span><span class="p">,</span> <span class="n">num_rows</span> <span class="o">*</span> <span class="n">num_cols</span><span class="p">):</span>
        <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>

    <span class="c1"># Adjust the spacing between subplots</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;shap_dependence_plot.tif&#39;</span><span class="p">,</span> <span class="n">bbox_inches</span><span class="o">=</span><span class="s1">&#39;tight&#39;</span><span class="p">)</span>

    <span class="c1"># Show the plot</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="shap-clustering">
<h4>SHAP clustering<a class="headerlink" href="#shap-clustering" title="Link to this heading">#</a></h4>
<p>In the context of precision medicine, SHAP clustering serves to uncover patient subgroups with distinct patterns, leading to differential model behavior. These subgroups often manifest as low or high-risk clusters, with a potential third cluster exhibiting less decisive model behavior. Identifying these clusters aids in profiling patient subgroups, offering valuable insights for model application to new patients.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="ow">not</span> <span class="n">skip_block</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">find_feature_clusters</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">shap_values</span><span class="p">,</span> <span class="n">selected_model</span><span class="p">,</span> <span class="n">data_dictionary</span><span class="p">,</span> <span class="n">top_n_f</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This function analyzes SHAP values to identify feature clusters and instance clusters using hierarchical clustering. The goal is to visualize the relationships between features and instances in the dataset.</span>

<span class="sd">        ### Parameters</span>

<span class="sd">        *   `X`: A pandas DataFrame containing the feature data.</span>
<span class="sd">        *   `shap_values`: A numpy array of shape `(n_samples, n_features)` containing SHAP values for each instance and feature.</span>
<span class="sd">        *   `selected_model`: The model used to select features (not used in this function).</span>
<span class="sd">        *   `data_dictionary`: Not used in this function (possibly used elsewhere in the codebase).</span>
<span class="sd">        *   `top_n_f`: An integer specifying the number of top clusters to display for features.</span>

<span class="sd">        ### Returns</span>

<span class="sd">        A tuple containing three elements:</span>

<span class="sd">        1.  A dictionary (`top_n_col_clusters_info`) where keys are cluster indices and values are lists of feature names within each cluster, ordered by the number of features in descending order.</span>
<span class="sd">        2.  A dictionary (`row_clusters_info`) where keys are cluster indices and values are lists of instance indices within each cluster, ordered by the number of instances in descending order.</span>
<span class="sd">        3.  A DataFrame (`shap_df`) containing SHAP values with feature names as columns.</span>

<span class="sd">        ### Functionality</span>

<span class="sd">        1.  The function first creates a clustermap plot showing relationships between features and instances using SHAP values.</span>
<span class="sd">        2.  It then performs hierarchical clustering on the column (feature) data to identify clusters and groups them into `top_n_f` top clusters based on the number of features in each cluster.</span>
<span class="sd">        3.  Next, it determines the best number of clusters for row (instance) data using the silhouette score and plots a graph showing the relationship between the number of clusters and the silhouette scores.</span>
<span class="sd">        4.  After finding the optimal number of clusters for rows, it performs hierarchical clustering on the row data with the chosen number of clusters and groups instances into `best_num_clusters` top clusters based on the number of instances in each cluster.</span>
<span class="sd">        5.  Finally, the function returns three dictionaries and a DataFrame containing SHAP values: one for feature clusters, one for instance clusters, and one for the original SHAP value DataFrame.</span>

<span class="sd">        ### Notes</span>

<span class="sd">        *   This function assumes that the input data is properly formatted and does not contain any errors or inconsistencies.</span>
<span class="sd">        *   The best number of clusters for row data can be manually adjusted by modifying the range in the `silhouette_scores` loop (currently set to 3-5).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># a DataFrame for SHAP values with feature names as columns</span>
        <span class="n">shap_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">shap_values</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>

        <span class="c1"># Plot clustermap for both rows and columns</span>
        <span class="n">cluster_grid</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">clustermap</span><span class="p">(</span><span class="n">shap_df</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Clustermap for Features and Instances&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
        
        <span class="c1"># Perform hierarchical clustering on columns (features)</span>
        <span class="n">col_clusters</span> <span class="o">=</span> <span class="n">AgglomerativeClustering</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">shap_values</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>

        <span class="c1"># Group columns into clusters</span>
        <span class="n">features_in_clusters</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="p">:</span> <span class="p">[]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">)}</span>

        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">cluster_idx</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">col_clusters</span><span class="p">):</span>
            <span class="n">features_in_clusters</span><span class="p">[</span><span class="n">cluster_idx</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>

        <span class="c1"># Get top N clusters for features</span>
        <span class="n">top_n_col_clusters</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">features_in_clusters</span><span class="o">.</span><span class="n">keys</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">features_in_clusters</span><span class="p">[</span><span class="n">x</span><span class="p">]),</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)[:</span><span class="n">top_n_f</span><span class="p">]</span>
        <span class="n">top_n_col_clusters_info</span> <span class="o">=</span> <span class="p">{</span><span class="n">cluster</span><span class="p">:</span> <span class="n">features_in_clusters</span><span class="p">[</span><span class="n">cluster</span><span class="p">]</span> <span class="k">for</span> <span class="n">cluster</span> <span class="ow">in</span> <span class="n">top_n_col_clusters</span><span class="p">}</span>

        <span class="c1"># Determine the best number of clusters for rows (instances) using silhouette score</span>
        <span class="n">best_num_clusters</span> <span class="o">=</span> <span class="mi">3</span>
        <span class="n">best_silhouette_score</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="n">silhouette_scores</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">n_clusters</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">):</span>
            <span class="n">row_clusters</span> <span class="o">=</span> <span class="n">AgglomerativeClustering</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">n_clusters</span><span class="p">)</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">shap_values</span><span class="p">)</span>
            <span class="n">silhouette_avg</span> <span class="o">=</span> <span class="n">silhouette_score</span><span class="p">(</span><span class="n">shap_values</span><span class="p">,</span> <span class="n">row_clusters</span><span class="p">)</span>
            <span class="n">silhouette_scores</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">n_clusters</span><span class="p">,</span> <span class="n">silhouette_avg</span><span class="p">))</span>
            <span class="k">if</span> <span class="n">silhouette_avg</span> <span class="o">&gt;</span> <span class="n">best_silhouette_score</span><span class="p">:</span>
                <span class="n">best_silhouette_score</span> <span class="o">=</span> <span class="n">silhouette_avg</span>
                <span class="n">best_num_clusters</span> <span class="o">=</span> <span class="n">n_clusters</span>

        <span class="c1"># Plot silhouette scores</span>
        <span class="n">cluster_counts</span><span class="p">,</span> <span class="n">scores</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">silhouette_scores</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">cluster_counts</span><span class="p">,</span> <span class="n">scores</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Silhouette Score vs. Number of Clusters&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Number of Clusters&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Silhouette Score&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

        <span class="c1"># Perform hierarchical clustering on rows (instances) with the best number of clusters</span>
        <span class="n">row_clusters</span> <span class="o">=</span> <span class="n">AgglomerativeClustering</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">best_num_clusters</span><span class="p">)</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">shap_values</span><span class="p">)</span>

        <span class="c1"># Group rows into clusters</span>
        <span class="n">instances_in_clusters</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="p">:</span> <span class="p">[]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">best_num_clusters</span><span class="p">)}</span>

        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">cluster_idx</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">row_clusters</span><span class="p">):</span>
            <span class="n">instances_in_clusters</span><span class="p">[</span><span class="n">cluster_idx</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>

        <span class="c1"># Get top N clusters for instances</span>
        <span class="n">top_N_row_clusters</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">instances_in_clusters</span><span class="o">.</span><span class="n">keys</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">instances_in_clusters</span><span class="p">[</span><span class="n">x</span><span class="p">]),</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)[:</span><span class="n">best_num_clusters</span><span class="p">]</span>
        <span class="n">row_clusters_info</span> <span class="o">=</span> <span class="p">{</span><span class="n">cluster</span><span class="p">:</span> <span class="n">instances_in_clusters</span><span class="p">[</span><span class="n">cluster</span><span class="p">]</span> <span class="k">for</span> <span class="n">cluster</span> <span class="ow">in</span> <span class="n">top_N_row_clusters</span><span class="p">}</span>

        <span class="k">return</span> <span class="n">top_n_col_clusters_info</span><span class="p">,</span> <span class="n">row_clusters_info</span><span class="p">,</span> <span class="n">shap_df</span>


    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">selected_model</span><span class="p">,</span> <span class="p">(</span><span class="n">HistGradientBoostingClassifier</span><span class="p">,</span> <span class="n">RandomForestClassifier</span><span class="p">,</span><span class="n">LogisticRegression</span><span class="p">,</span> <span class="n">GaussianNB</span><span class="p">)):</span>
        <span class="n">top_n_col_clusters_info</span><span class="p">,</span> <span class="n">row_clusters_info</span><span class="p">,</span> <span class="n">shap_df</span> <span class="o">=</span> <span class="n">find_feature_clusters</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X_test_OHE</span><span class="p">,</span> 
                                                                                    <span class="n">shap_values</span><span class="o">=</span><span class="n">shap_values</span><span class="p">,</span>
                                                                                    <span class="n">selected_model</span><span class="o">=</span><span class="n">selected_model</span><span class="p">,</span> 
                                                                                    <span class="n">data_dictionary</span><span class="o">=</span><span class="n">data_dictionary</span><span class="p">,</span> 
                                                                                    <span class="n">top_n_f</span><span class="o">=</span><span class="n">top_n_f</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">selected_model</span><span class="p">,</span> <span class="p">(</span><span class="n">cb</span><span class="o">.</span><span class="n">CatBoostClassifier</span><span class="p">,</span> <span class="n">lgb</span><span class="o">.</span><span class="n">LGBMClassifier</span><span class="p">)):</span>
        <span class="n">top_n_col_clusters_info</span><span class="p">,</span> <span class="n">row_clusters_info</span><span class="p">,</span> <span class="n">shap_df</span> <span class="o">=</span> <span class="n">find_feature_clusters</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X_test</span><span class="p">,</span> 
                                                                                    <span class="n">shap_values</span><span class="o">=</span><span class="n">shap_values</span><span class="p">,</span>
                                                                                    <span class="n">selected_model</span><span class="o">=</span><span class="n">selected_model</span><span class="p">,</span> 
                                                                                    <span class="n">data_dictionary</span><span class="o">=</span><span class="n">data_dictionary</span><span class="p">,</span> 
                                                                                    <span class="n">top_n_f</span><span class="o">=</span><span class="n">top_n_f</span><span class="p">)</span>
        
      
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;cluster_info.txt&#39;</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;Top N clusters for features:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">cluster</span><span class="p">,</span> <span class="n">features</span> <span class="ow">in</span> <span class="n">top_n_col_clusters_info</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Cluster </span><span class="si">{</span><span class="n">cluster</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">features</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
        
        <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Top N clusters for instances:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">cluster</span><span class="p">,</span> <span class="n">instances</span> <span class="ow">in</span> <span class="n">row_clusters_info</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Cluster </span><span class="si">{</span><span class="n">cluster</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">instances</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Cluster information has been saved to &#39;cluster_info.txt&#39;&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="ow">not</span> <span class="n">skip_block</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">plot_confusion_matrix_for_clusters</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cluster_info</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">shap_values</span><span class="p">,</span> <span class="n">top_n</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Plots a confusion matrix for each cluster in the test data and visualizes the feature importance using SHAP values.</span>

<span class="sd">        Parameters:</span>
<span class="sd">            X (pandas DataFrame or numpy array): The input data.</span>
<span class="sd">            y (pandas Series): The target variable.</span>
<span class="sd">            cluster_info (dict): A dictionary indicating the instances in each cluster.</span>
<span class="sd">            model (object): The machine learning model to be used.</span>
<span class="sd">            shap_values (numpy array): The SHAP values for the given model and data.</span>
<span class="sd">            top_n (int): The number of features to display.</span>

<span class="sd">        This function:</span>
<span class="sd">        1.  Iterates over each unique cluster.</span>
<span class="sd">        2.  Subset the test data and target variable for the current cluster.</span>
<span class="sd">        3.  Computes the predicted labels using the selected model on the subsetted data.</span>
<span class="sd">        4.  Calculates the confusion matrix between the actual labels and predicted labels.</span>
<span class="sd">        5.  Plots a heatmap of the confusion matrix with actual label names.</span>
<span class="sd">        6.  Displays the feature importance for the current cluster using SHAP values.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Get unique class labels from your data</span>
        <span class="n">unique_labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

        <span class="c1"># Get unique cluster labels</span>
        <span class="n">unique_clusters</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">cluster_info</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>

        <span class="c1"># Iterate over each cluster</span>
        <span class="k">for</span> <span class="n">cluster</span> <span class="ow">in</span> <span class="n">unique_clusters</span><span class="p">:</span>
            <span class="c1"># Subset the test data for the current cluster</span>
            <span class="n">cluster_indices</span> <span class="o">=</span> <span class="n">cluster_info</span><span class="p">[</span><span class="n">cluster</span><span class="p">]</span>
            <span class="n">X_cluster</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">cluster_indices</span><span class="p">]</span>
            <span class="n">y_cluster</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">cluster_indices</span><span class="p">]</span>
            <span class="n">shap_values_cluster</span> <span class="o">=</span> <span class="n">shap_values</span><span class="p">[</span><span class="n">cluster_indices</span><span class="p">]</span>

            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="p">(</span><span class="n">RandomForestClassifier</span><span class="p">)):</span>
                <span class="n">predictions_proba_cluster</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_cluster</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
                <span class="n">model_opt_threshold</span> <span class="o">=</span> <span class="n">opt_threshold_rf</span>
            <span class="k">elif</span> <span class="n">model</span> <span class="o">==</span> <span class="s1">&#39;QLattice&#39;</span><span class="p">:</span>
                <span class="n">predictions_proba_cluster</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_cluster</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="p">(</span><span class="n">HistGradientBoostingClassifier</span><span class="p">)):</span>
                <span class="n">predictions_proba_cluster</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_cluster</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
                <span class="n">model_opt_threshold</span> <span class="o">=</span> <span class="n">opt_threshold_HGBC</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="p">(</span><span class="n">lgb</span><span class="o">.</span><span class="n">LGBMClassifier</span><span class="p">)):</span>
                <span class="n">predictions_proba_cluster</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_cluster</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
                <span class="n">model_opt_threshold</span> <span class="o">=</span> <span class="n">opt_threshold_LGBM</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="p">(</span><span class="n">cb</span><span class="o">.</span><span class="n">CatBoostClassifier</span><span class="p">)):</span>
                <span class="n">predictions_proba_cluster</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_cluster</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
                <span class="n">model_opt_threshold</span> <span class="o">=</span> <span class="n">opt_threshold_CB</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="p">(</span><span class="n">LogisticRegression</span><span class="p">)):</span>
                <span class="n">predictions_proba_cluster</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_cluster</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
                <span class="n">model_opt_threshold</span> <span class="o">=</span> <span class="n">opt_threshold_LR</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="p">(</span><span class="n">GaussianNB</span><span class="p">)):</span>
                <span class="n">predictions_proba_cluster</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_cluster</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
                <span class="n">model_opt_threshold</span> <span class="o">=</span> <span class="n">opt_threshold_NB</span>
            
            <span class="n">predictions_class_cluster</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">predictions_proba_cluster</span> <span class="o">&gt;=</span> <span class="n">model_opt_threshold</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>

            <span class="c1"># Compute confusion matrix</span>
            <span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_cluster</span><span class="p">,</span> <span class="n">predictions_class_cluster</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="kc">False</span><span class="p">,</span> <span class="kc">True</span><span class="p">])</span>

            <span class="c1"># Plot confusion matrix with actual label names</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
            <span class="n">myheatmap</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s2">&quot;d&quot;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;Blues&quot;</span><span class="p">,</span> <span class="n">cbar</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">xticklabels</span><span class="o">=</span><span class="n">class_labels_display</span><span class="p">,</span> <span class="n">yticklabels</span><span class="o">=</span><span class="n">class_labels_display</span><span class="p">,</span> <span class="n">annot_kws</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;size&quot;</span><span class="p">:</span> <span class="mi">8</span><span class="p">})</span>  <span class="c1"># Adjust annot_kws to change annotation font size</span>
            <span class="n">myheatmap</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">()</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Confusion Matrix for Cluster </span><span class="si">{</span><span class="n">cluster</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Predicted Label&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;True Label&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span> 
            <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>  
            <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

            <span class="c1"># Call categorical_shap_plot for the current cluster</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">selected_model</span><span class="p">,</span> <span class="p">(</span><span class="n">HistGradientBoostingClassifier</span><span class="p">,</span> <span class="n">RandomForestClassifier</span><span class="p">,</span> <span class="n">LogisticRegression</span><span class="p">,</span> <span class="n">GaussianNB</span><span class="p">)):</span>
                <span class="n">shap</span><span class="o">.</span><span class="n">summary_plot</span><span class="p">(</span><span class="n">shap_values_cluster</span><span class="p">,</span> <span class="n">X_cluster</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span> <span class="n">max_display</span><span class="o">=</span><span class="n">top_n_f</span><span class="p">)</span>
            <span class="k">elif</span> <span class="nb">any</span><span class="p">(</span><span class="n">X_test</span><span class="p">[</span><span class="n">column</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="s1">&#39;category&#39;</span> <span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">X_test</span><span class="o">.</span><span class="n">columns</span><span class="p">):</span>
                <span class="n">categorical_shap_plot</span><span class="p">(</span><span class="n">shap_values</span><span class="o">=</span><span class="n">shap_values_cluster</span><span class="p">,</span> 
                                            <span class="n">data</span><span class="o">=</span><span class="n">X_cluster</span><span class="p">,</span>
                                            <span class="n">top_n</span><span class="o">=</span><span class="nb">min</span><span class="p">(</span><span class="n">top_n</span><span class="p">,</span> <span class="n">X_cluster</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span>
                                            <span class="n">jitter</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span> <span class="c1"># it could be a LGBM or CATBoost model based on only numerical features </span>
                <span class="n">shap</span><span class="o">.</span><span class="n">summary_plot</span><span class="p">(</span><span class="n">shap_values_cluster</span><span class="p">,</span> <span class="n">X_cluster</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span> <span class="n">max_display</span><span class="o">=</span><span class="n">top_n_f</span><span class="p">)</span>

    <span class="c1"># based on the assumption that cluster_info is the dictionary indicating the instances in each cluster</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">selected_model</span><span class="p">,</span> <span class="p">(</span><span class="n">HistGradientBoostingClassifier</span><span class="p">,</span> <span class="n">RandomForestClassifier</span><span class="p">,</span><span class="n">LogisticRegression</span><span class="p">,</span> <span class="n">GaussianNB</span><span class="p">)):</span>
        <span class="n">plot_confusion_matrix_for_clusters</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X_test_OHE</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span> <span class="n">cluster_info</span><span class="o">=</span><span class="n">row_clusters_info</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">selected_model</span><span class="p">,</span> <span class="n">shap_values</span><span class="o">=</span><span class="n">shap_values</span><span class="p">,</span> <span class="n">top_n</span><span class="o">=</span><span class="n">top_n_f</span><span class="p">)</span>

    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">selected_model</span><span class="p">,</span> <span class="p">(</span><span class="n">cb</span><span class="o">.</span><span class="n">CatBoostClassifier</span><span class="p">,</span> <span class="n">lgb</span><span class="o">.</span><span class="n">LGBMClassifier</span><span class="p">)):</span>
        <span class="n">plot_confusion_matrix_for_clusters</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span> <span class="n">cluster_info</span><span class="o">=</span><span class="n">row_clusters_info</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">selected_model</span><span class="p">,</span> <span class="n">shap_values</span><span class="o">=</span><span class="n">shap_values</span><span class="p">,</span> <span class="n">top_n</span><span class="o">=</span><span class="n">top_n_f</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="shap-force-plot-for-individuals-e-g-one-patient">
<h4>SHAP force plot for individuals (e.g., one patient)<a class="headerlink" href="#shap-force-plot-for-individuals-e-g-one-patient" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="ow">not</span> <span class="n">skip_block</span><span class="p">:</span>
    <span class="c1"># load JS visualization code to notebook</span>
    <span class="n">shap</span><span class="o">.</span><span class="n">initjs</span><span class="p">()</span>
    <span class="c1"># Function to get a sample from each class</span>
    <span class="k">def</span> <span class="nf">get_samples_per_class</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="n">samples</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">class_value</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">):</span>
            <span class="c1"># Select a sample from each class</span>
            <span class="n">class_samples</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">y</span> <span class="o">==</span> <span class="n">class_value</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">class_samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">samples</span><span class="p">[</span><span class="n">class_value</span><span class="p">]</span> <span class="o">=</span> <span class="n">class_samples</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>  <span class="c1"># Random sample</span>
        <span class="k">return</span> <span class="n">samples</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">selected_model</span><span class="p">,</span> <span class="p">(</span><span class="n">HistGradientBoostingClassifier</span><span class="p">,</span> <span class="n">RandomForestClassifier</span><span class="p">,</span> <span class="n">LogisticRegression</span><span class="p">,</span> <span class="n">GaussianNB</span><span class="p">)):</span>
        <span class="c1"># Get samples from each class</span>
        <span class="n">mysamples</span> <span class="o">=</span> <span class="n">get_samples_per_class</span><span class="p">(</span><span class="n">X_test_OHE</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">mysamples</span> <span class="o">=</span> <span class="n">get_samples_per_class</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
        
    <span class="k">try</span><span class="p">:</span>
        <span class="c1"># Generate SHAP force plots for each sample</span>
        <span class="k">for</span> <span class="n">class_value</span><span class="p">,</span> <span class="n">sample</span> <span class="ow">in</span> <span class="n">mysamples</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            
            <span class="c1"># Convert sample to appropriate format for explainer</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">selected_model</span><span class="p">,</span> <span class="p">(</span><span class="n">HistGradientBoostingClassifier</span><span class="p">,</span> <span class="n">RandomForestClassifier</span><span class="p">,</span> <span class="n">LogisticRegression</span><span class="p">,</span> <span class="n">GaussianNB</span><span class="p">)):</span>
                <span class="n">sample_predicted_prob</span> <span class="o">=</span> <span class="n">selected_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;predicted probability: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">sample_predicted_prob</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;class: </span><span class="si">{</span><span class="n">class_value</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="c1"># Get the SHAP values for the sample</span>
                <span class="n">sample_shap_values</span> <span class="o">=</span> <span class="n">explainer</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>
                <span class="c1"># Generate the force plot</span>
                <span class="n">base_value</span> <span class="o">=</span> <span class="n">sample_shap_values</span><span class="o">.</span><span class="n">base_values</span>
                <span class="c1"># shap.plots.force(base_value, sample_shap_values.values[:,:,1])</span>
                <span class="n">display</span><span class="p">(</span><span class="n">shap</span><span class="o">.</span><span class="n">plots</span><span class="o">.</span><span class="n">force</span><span class="p">(</span><span class="n">base_value</span><span class="p">,</span> <span class="n">sample_shap_values</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">plot_cmap</span><span class="o">=</span><span class="s2">&quot;RdBu&quot;</span><span class="p">,</span> <span class="n">feature_names</span><span class="o">=</span><span class="n">X_train_OHE_nocv</span><span class="o">.</span><span class="n">columns</span><span class="p">))</span>
            
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">selected_model</span><span class="p">,</span> <span class="p">(</span><span class="n">cb</span><span class="o">.</span><span class="n">CatBoostClassifier</span><span class="p">,</span> <span class="n">lgb</span><span class="o">.</span><span class="n">LGBMClassifier</span><span class="p">)):</span>
                <span class="n">sample_predicted_prob</span> <span class="o">=</span> <span class="n">selected_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;predicted probability: </span><span class="si">{</span><span class="n">sample_predicted_prob</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="c1"># Get the SHAP values for the sample</span>
                <span class="n">sample_shap_values</span> <span class="o">=</span> <span class="n">explainer</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>
                <span class="c1"># Generate the force plot</span>
                <span class="n">display</span><span class="p">(</span><span class="n">shap</span><span class="o">.</span><span class="n">plots</span><span class="o">.</span><span class="n">force</span><span class="p">(</span><span class="n">sample_shap_values</span><span class="p">,</span> <span class="n">plot_cmap</span><span class="o">=</span><span class="s2">&quot;RdBu&quot;</span><span class="p">,</span> <span class="n">feature_names</span><span class="o">=</span><span class="n">feature_names</span><span class="p">))</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;An error occurred: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">. Skipping to the next block.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="decision-curve-analysis">
<h4>Decision curve analysis<a class="headerlink" href="#decision-curve-analysis" title="Link to this heading">#</a></h4>
<p>Net benefit of the model compared to random guessing, extreme cases, and an alternative method or model. Read more here: <a class="reference external" href="https://en.wikipedia.org/wiki/Decision_curve_analysis#:~:text=Decision%20curve%20analysis%20evaluates%20a,are%20positive%20are%20also%20plotted">https://en.wikipedia.org/wiki/Decision_curve_analysis#:~:text=Decision curve analysis evaluates a,are positive are also plotted</a>.
As an alternative model we here use logistic regression model but you can modify this or import prediction probabilities for the test samples from elsewhere.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="ow">not</span> <span class="n">skip_block</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">do_decision_curve_analysis</span><span class="p">:</span>

        <span class="c1"># Calculate necessary information for adjusting hyperparameters</span>
        <span class="n">n_rows</span> <span class="o">=</span> <span class="n">X_train_OHE_nocv</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">n_cols</span> <span class="o">=</span> <span class="n">X_train_OHE_nocv</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">class_proportion</span> <span class="o">=</span> <span class="n">y_train</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>  <span class="c1"># binary classification</span>
        <span class="n">rf_params</span><span class="p">,</span> <span class="n">lgbm_params</span><span class="p">,</span> <span class="n">hgbc_params</span><span class="p">,</span> <span class="n">cb_params</span><span class="p">,</span> <span class="n">lr_params</span> <span class="o">=</span> <span class="n">set_parameters</span><span class="p">(</span><span class="n">n_rows</span><span class="p">,</span> <span class="n">n_cols</span><span class="p">,</span> <span class="n">class_proportion</span><span class="p">)</span>
        <span class="c1"># Create a Logistic Regression instance</span>
        <span class="n">lr</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">penalty</span><span class="o">=</span><span class="s1">&#39;l1&#39;</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s2">&quot;liblinear&quot;</span><span class="p">,</span> <span class="o">**</span><span class="n">lr_params</span><span class="p">)</span>
        <span class="c1"># lr = LogisticRegression(penalty=&#39;elasticnet&#39;,random_state=SEED, solver=&quot;saga&quot;)</span>
        <span class="k">if</span> <span class="n">hp_tuning</span><span class="p">:</span>
        
            <span class="c1"># Adjust hyperparameters based on the training data in this fold</span>
            <span class="n">rf_param_dist</span><span class="p">,</span> <span class="n">lgbm_param_dist</span><span class="p">,</span> <span class="n">hgbc_param_dist</span><span class="p">,</span> <span class="n">cb_param_dist</span><span class="p">,</span> <span class="n">lr_param_dist</span> <span class="o">=</span> <span class="n">adjust_hyperparameters</span><span class="p">(</span><span class="n">n_rows</span><span class="p">,</span> <span class="n">n_cols</span><span class="p">)</span>
            <span class="c1"># Create a RandomizedSearchCV instance</span>
            <span class="n">random_search</span> <span class="o">=</span> <span class="n">RandomizedSearchCV</span><span class="p">(</span>
                <span class="n">estimator</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span>
                <span class="n">param_distributions</span><span class="o">=</span><span class="n">lr_param_dist</span><span class="p">,</span>
                <span class="n">n_iter</span><span class="o">=</span><span class="n">n_iter_hptuning</span><span class="p">,</span>
                <span class="n">scoring</span><span class="o">=</span> <span class="n">custom_scorer</span><span class="p">,</span> 
                <span class="n">cv</span><span class="o">=</span><span class="n">cv_folds_hptuning</span><span class="p">,</span>
                <span class="n">refit</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
                <span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">,</span>
                <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_cpu_for_tuning</span>
            <span class="p">)</span>

            <span class="c1"># Perform the random search on the training data</span>
            <span class="n">random_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_OHE_nocv</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weights</span><span class="p">)</span>

            <span class="c1"># Get the best parameters and best estimator</span>
            <span class="n">best_params</span> <span class="o">=</span> <span class="n">random_search</span><span class="o">.</span><span class="n">best_params_</span>
            <span class="n">lr</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">penalty</span><span class="o">=</span><span class="s1">&#39;l1&#39;</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s2">&quot;liblinear&quot;</span><span class="p">,</span> <span class="o">**</span><span class="n">best_params</span><span class="p">)</span>
            <span class="c1"># lr = LogisticRegression(penalty=&#39;elasticnet&#39;,random_state=SEED, solver=&quot;saga&quot;, **best_params)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">lr</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">penalty</span><span class="o">=</span><span class="s1">&#39;l1&#39;</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s2">&quot;liblinear&quot;</span><span class="p">,</span> <span class="o">**</span><span class="n">lr_params</span><span class="p">)</span>

        <span class="c1"># Fit the best estimator on the entire training data</span>
        <span class="n">lr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_OHE_nocv</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weights</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="cost-sensitive-model-evaluation">
<h4>Cost-sensitive model evaluation<a class="headerlink" href="#cost-sensitive-model-evaluation" title="Link to this heading">#</a></h4>
<p>Here we introduce cost-sensitive net benefit where we introduce weights as coefficients for the number of TP and FP cases.
The weights are supposed to be positive values &gt;0. Use w_tp=1, w_fp=1 for true positives and false positives respectively when they are equally important (equal cost).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="ow">not</span> <span class="n">skip_block</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">do_decision_curve_analysis</span><span class="p">:</span>
        <span class="k">def</span> <span class="nf">cost_sensitive_net_benefit</span><span class="p">(</span><span class="n">tp</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">threshold</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">w_tp</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">w_fp</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="w">            </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Calculates the net benefit of a classification model under a given probability threshold.</span>
<span class="sd">            </span>
<span class="sd">            The net benefit is calculated as the weighted sum of the positive and negative classes, </span>
<span class="sd">            where the weights are based on the prior probabilities of the classes. This metric allows for </span>
<span class="sd">            cost-sensitive comparison between different models, taking into account the costs associated with </span>
<span class="sd">            false positives and false negatives.</span>
<span class="sd">            </span>
<span class="sd">            ## Parameters</span>
<span class="sd">                tp (int): True positives in the current test set.</span>
<span class="sd">                fp (int): False positives in the current test set.</span>
<span class="sd">                threshold (float): Probability threshold used to determine predicted positive classes.</span>
<span class="sd">                N (int): Total number of samples in the test set.</span>
<span class="sd">                w_tp (float, optional): Weight assigned to true positives. Defaults to 1.</span>
<span class="sd">                w_fp (float, optional): Weight assigned to false positives. Defaults to 1.</span>

<span class="sd">            ## Returns</span>
<span class="sd">                float: Net benefit of the model under the given threshold.</span>
<span class="sd">            &quot;&quot;&quot;</span>
            <span class="c1"># Calculate cost-sensitive net benefit</span>
            <span class="k">if</span> <span class="n">N</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">return</span> <span class="mi">0</span>  <span class="c1"># Prevent division by zero</span>
            <span class="n">net_benefit</span> <span class="o">=</span> <span class="p">(</span><span class="n">tp</span> <span class="o">*</span> <span class="n">w_tp</span> <span class="o">/</span> <span class="n">N</span><span class="p">)</span> <span class="o">-</span> <span class="p">(</span><span class="n">fp</span> <span class="o">*</span> <span class="n">w_fp</span> <span class="o">/</span> <span class="n">N</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">threshold</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">threshold</span><span class="p">))</span>
            <span class="k">return</span> <span class="n">net_benefit</span>
        <span class="k">def</span> <span class="nf">decision_curve_analysis</span><span class="p">(</span><span class="n">pred_probs_selected_model</span><span class="p">,</span> <span class="n">pred_probs_alternative_model</span><span class="p">,</span> <span class="n">rand_pred_probs</span><span class="p">,</span> <span class="n">w_tp</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">w_fp</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="w">            </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Performs cost-sensitive decision curve analysis on two models.</span>
<span class="sd">            </span>
<span class="sd">            The analysis plots the net benefit of each model under different probability thresholds </span>
<span class="sd">            and allows for comparison between the two models. The plot also includes a reference line </span>
<span class="sd">            representing the default threshold used in many machine learning applications.</span>
<span class="sd">            </span>
<span class="sd">            ## Parameters</span>
<span class="sd">                pred_probs_selected_model (array-like): Predicted probabilities of positive classes for the first model.</span>
<span class="sd">                pred_probs_alternative_model (array-like): Predicted probabilities of positive classes for the second model.</span>
<span class="sd">                rand_pred_probs (array-like): Randomly generated predicted probabilities for a third set of models.</span>

<span class="sd">            ## Returns</span>
<span class="sd">                None</span>
<span class="sd">            &quot;&quot;&quot;</span>
            <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span>  <span class="c1"># Total number of observations</span>
            
            <span class="c1"># Precompute TP and FP for extreme cases</span>
            <span class="n">tp_all_positive</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y_test</span><span class="o">.</span><span class="n">values</span> <span class="o">==</span> <span class="kc">True</span><span class="p">)</span>
            <span class="n">fp_all_positive</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y_test</span><span class="o">.</span><span class="n">values</span> <span class="o">==</span> <span class="kc">False</span><span class="p">)</span>
            
            <span class="c1"># Extreme cases do not vary by threshold</span>
            <span class="n">net_benefit_all_positive</span> <span class="o">=</span> <span class="p">[</span><span class="n">cost_sensitive_net_benefit</span><span class="p">(</span><span class="n">tp_all_positive</span><span class="p">,</span> <span class="n">fp_all_positive</span><span class="p">,</span> <span class="n">threshold</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">w_tp</span><span class="p">,</span> <span class="n">w_fp</span><span class="p">)</span> <span class="k">for</span> <span class="n">threshold</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">)]</span>
            <span class="n">net_benefit_all_negative</span> <span class="o">=</span> <span class="p">[</span><span class="n">cost_sensitive_net_benefit</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">threshold</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">w_tp</span><span class="p">,</span> <span class="n">w_fp</span><span class="p">)</span> <span class="k">for</span> <span class="n">threshold</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">)]</span>

            <span class="c1"># Initialize lists for storing net benefits</span>
            <span class="n">net_benefit_selected_model</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">net_benefit_alternative_model</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">net_benefit_rand</span> <span class="o">=</span> <span class="p">[]</span>

            <span class="n">threshold_range</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
            
            <span class="k">for</span> <span class="n">threshold</span> <span class="ow">in</span> <span class="n">threshold_range</span><span class="p">:</span>
                <span class="c1"># Calculate TP and FP for selected model</span>
                <span class="n">tp_selected_model</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">pred_probs_selected_model</span> <span class="o">&gt;</span> <span class="n">threshold</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">y_test</span><span class="o">.</span><span class="n">values</span> <span class="o">==</span> <span class="kc">True</span><span class="p">))</span>
                <span class="n">fp_selected_model</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">pred_probs_selected_model</span> <span class="o">&gt;</span> <span class="n">threshold</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">y_test</span><span class="o">.</span><span class="n">values</span> <span class="o">==</span> <span class="kc">False</span><span class="p">))</span>
                
                <span class="c1"># Calculate TP and FP for alternative model</span>
                <span class="n">tp_alternative_model</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">pred_probs_alternative_model</span> <span class="o">&gt;</span> <span class="n">threshold</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">y_test</span><span class="o">.</span><span class="n">values</span> <span class="o">==</span> <span class="kc">True</span><span class="p">))</span>
                <span class="n">fp_alternative_model</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">pred_probs_alternative_model</span> <span class="o">&gt;</span> <span class="n">threshold</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">y_test</span><span class="o">.</span><span class="n">values</span> <span class="o">==</span> <span class="kc">False</span><span class="p">))</span>
                
                <span class="c1"># Calculate TP and FP for random predictions</span>
                <span class="n">tp_rand</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">rand_pred_probs</span> <span class="o">&gt;</span> <span class="n">threshold</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">y_test</span><span class="o">.</span><span class="n">values</span> <span class="o">==</span> <span class="kc">True</span><span class="p">))</span>
                <span class="n">fp_rand</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">rand_pred_probs</span> <span class="o">&gt;</span> <span class="n">threshold</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">y_test</span><span class="o">.</span><span class="n">values</span> <span class="o">==</span> <span class="kc">False</span><span class="p">))</span>
                
                <span class="c1"># Calculate net benefits</span>
                <span class="n">net_benefit_selected_model</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cost_sensitive_net_benefit</span><span class="p">(</span><span class="n">tp_selected_model</span><span class="p">,</span> <span class="n">fp_selected_model</span><span class="p">,</span> <span class="n">threshold</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">w_tp</span><span class="p">,</span> <span class="n">w_fp</span><span class="p">))</span>
                <span class="n">net_benefit_alternative_model</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cost_sensitive_net_benefit</span><span class="p">(</span><span class="n">tp_alternative_model</span><span class="p">,</span> <span class="n">fp_alternative_model</span><span class="p">,</span> <span class="n">threshold</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">w_tp</span><span class="p">,</span> <span class="n">w_fp</span><span class="p">))</span>
                <span class="n">net_benefit_rand</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cost_sensitive_net_benefit</span><span class="p">(</span><span class="n">tp_rand</span><span class="p">,</span> <span class="n">fp_rand</span><span class="p">,</span> <span class="n">threshold</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">w_tp</span><span class="p">,</span> <span class="n">w_fp</span><span class="p">))</span>

            <span class="c1"># Find the maximum net benefit for y-axis limit</span>
            <span class="n">max_net_benefit</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span>
                <span class="nb">max</span><span class="p">(</span><span class="n">net_benefit_selected_model</span><span class="p">),</span>
                <span class="nb">max</span><span class="p">(</span><span class="n">net_benefit_alternative_model</span><span class="p">),</span>
                <span class="nb">max</span><span class="p">(</span><span class="n">net_benefit_rand</span><span class="p">),</span>
                <span class="nb">max</span><span class="p">(</span><span class="n">net_benefit_all_positive</span><span class="p">),</span>
                <span class="nb">max</span><span class="p">(</span><span class="n">net_benefit_all_negative</span><span class="p">)</span>
            <span class="p">)</span>

            <span class="c1"># Plot decision curve</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">threshold_range</span><span class="p">,</span> <span class="n">net_benefit_selected_model</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Selected model&#39;</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">threshold_range</span><span class="p">,</span> <span class="n">net_benefit_alternative_model</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Alternative model&#39;</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">threshold_range</span><span class="p">,</span> <span class="n">net_benefit_rand</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Random predictions&#39;</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">threshold_range</span><span class="p">,</span> <span class="n">net_benefit_all_positive</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;All positive&#39;</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">threshold_range</span><span class="p">,</span> <span class="n">net_benefit_all_negative</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;All negative&#39;</span><span class="p">)</span>

            <span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Default threshold (0.5)&#39;</span><span class="p">)</span>
            
            <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Probability threshold&#39;</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Net benefit&#39;</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Cost-sensitive decision curve analysis&#39;</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="n">bottom</span><span class="o">=-</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="n">max_net_benefit</span> <span class="o">+</span> <span class="mf">0.01</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
            
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">selected_model</span><span class="p">,</span> <span class="p">(</span><span class="n">HistGradientBoostingClassifier</span><span class="p">,</span> <span class="n">RandomForestClassifier</span><span class="p">,</span> <span class="n">LogisticRegression</span><span class="p">,</span> <span class="n">GaussianNB</span><span class="p">)):</span>
            <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">SEED</span><span class="p">)</span>
            <span class="n">rand_pred_probs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X_test_OHE</span><span class="p">))</span>
            <span class="n">predictions</span> <span class="o">=</span> <span class="n">selected_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test_OHE</span><span class="p">)</span>
            <span class="n">pred_probs_selected_model</span> <span class="o">=</span> <span class="n">predictions</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">selected_model</span><span class="p">,</span> <span class="p">(</span><span class="n">cb</span><span class="o">.</span><span class="n">CatBoostClassifier</span><span class="p">,</span> <span class="n">lgb</span><span class="o">.</span><span class="n">LGBMClassifier</span><span class="p">)):</span>
            <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">SEED</span><span class="p">)</span>
            <span class="n">rand_pred_probs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X_test</span><span class="p">))</span>
            <span class="n">predictions</span> <span class="o">=</span> <span class="n">selected_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
            <span class="n">pred_probs_selected_model</span> <span class="o">=</span> <span class="n">predictions</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span>

        <span class="c1"># pred_probs_selected_model = selected_model.predict_proba(X_test)[:, 1] </span>
        <span class="n">pred_probs_alternative_model</span> <span class="o">=</span> <span class="n">lr</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test_OHE</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>

        <span class="n">decision_curve_analysis</span><span class="p">(</span><span class="n">pred_probs_selected_model</span><span class="o">=</span><span class="n">pred_probs_selected_model</span><span class="p">,</span>
                                <span class="n">pred_probs_alternative_model</span><span class="o">=</span> <span class="n">pred_probs_alternative_model</span><span class="p">,</span>
                                <span class="n">rand_pred_probs</span><span class="o">=</span><span class="n">rand_pred_probs</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="model-calibration-and-conformal-predictions-optional">
<h4>Model calibration and conformal predictions (optional)<a class="headerlink" href="#model-calibration-and-conformal-predictions-optional" title="Link to this heading">#</a></h4>
<p>Here we applied isotonic regression as the model calibration method. Isotonic regression is a non-parametric approach used to calibrate the predicted probabilities of a classifier. Note that the calibration should be preferrebly done based on an unseen dataset (not the dataset the model is already trained).</p>
<p>The following steps are followed:</p>
<ol class="arabic simple">
<li><p>Test Set Split:</p></li>
</ol>
<p>We split the test set into a calibration set (X_calibration, y_calibration) and a new test set (X_new_test, y_new_test). The calibration set is used to compute the nonconformity scores for Conformal Prediction.</p>
<ol class="arabic simple" start="2">
<li><p>Isotonic Regression:</p></li>
</ol>
<p>We calibrate the predicted probabilities using Isotonic Regression to make the predicted probabilities more reliable.</p>
<ol class="arabic simple" start="3">
<li><p>Conformal Prediction:</p></li>
</ol>
<p>To understand conformal prediction you can refer to Shafer and Vovk, 2008. Below is the steps performed in the following code:</p>
<p><strong>conformal prediction</strong> for binary classification is based on a split-conformal approach. The goal is to provide prediction sets for each test instance, ensuring 95% coverage (i.e., that the true label is included in the prediction set for approximately 95% of instances).</p>
<p><strong>Non-conformity Scores</strong>: These scores are calculated for the calibration set based on the predicted probabilities for the true class: ( s_i = 1 - p_i ), where ( p_i ) is the predicted probability for the true class.</p>
<p><strong>Threshold Calculation</strong>: The 95th percentile of the non-conformity scores from the calibration set is used to determine the threshold for prediction sets.</p>
<p><strong>Prediction Sets</strong>: For each test instance, the non-conformity scores for both classes (class 0 and class 1) are compared to the threshold. The class(es) whose non-conformity scores fall below the threshold are included in the prediction set.</p>
<p><strong>Coverage and Metrics</strong>: The coverage, or proportion of test instances where the true label is in the prediction set, is reported. Additional metrics like Brier Score, MCC, and ROC AUC are also evaluated for confident predictions.</p>
<p>Coverage is the proportion of test instances for which the true label is included in the prediction set. In this analysis, coverage was <strong>calculated as the fraction of confident predictions</strong> made by the model:</p>
<p>The percentage of confident predictions was calculated as the fraction of predictions where the model was able to predict a single class with confidence.</p>
<ol class="arabic simple" start="4">
<li><p>Filtering Confident Predictions:</p></li>
</ol>
<p>We filter out the predictions where the p-value is less than alpha (indicating less confidence).
Only single-class prediction sets are retained, which means the model is confident enough to assign a label with a clear margin.</p>
<ol class="arabic simple" start="5">
<li><p>Evaluation:</p></li>
</ol>
<p>Various metrics like Brier Score, Matthews Correlation Coefficient (MCC), ROC AUC, and PR AUC are computed for the confident predictions only.
We also report the percentage of confident predictions, giving insight into how often the model is making confident predictions.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="ow">not</span> <span class="n">skip_block</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">calibration_and_conformal_predictions</span><span class="p">:</span>

        <span class="c1"># Step 1: Split the test data into calibration and new test sets</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">selected_model</span><span class="p">,</span> <span class="p">(</span><span class="n">HistGradientBoostingClassifier</span><span class="p">,</span> <span class="n">RandomForestClassifier</span><span class="p">,</span> <span class="n">LogisticRegression</span><span class="p">,</span> <span class="n">GaussianNB</span><span class="p">)):</span>
            <span class="n">X_calibration</span><span class="p">,</span> <span class="n">X_new_test</span><span class="p">,</span> <span class="n">y_calibration</span><span class="p">,</span> <span class="n">y_new_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
                <span class="n">X_test_OHE</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y_test</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">X_calibration</span><span class="p">,</span> <span class="n">X_new_test</span><span class="p">,</span> <span class="n">y_calibration</span><span class="p">,</span> <span class="n">y_new_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
                <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y_test</span>
            <span class="p">)</span>

        <span class="c1"># Convert y_calibration and y_new_test from True/False to 1/0</span>
        <span class="n">y_calibration</span> <span class="o">=</span> <span class="n">y_calibration</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
        <span class="n">y_new_test</span> <span class="o">=</span> <span class="n">y_new_test</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>

        <span class="c1"># Step 2: Get predicted probabilities for the calibration set</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">selected_model</span><span class="p">,</span> <span class="p">(</span><span class="n">HistGradientBoostingClassifier</span><span class="p">,</span> <span class="n">RandomForestClassifier</span><span class="p">,</span> <span class="n">LogisticRegression</span><span class="p">,</span> <span class="n">GaussianNB</span><span class="p">)):</span>
            <span class="n">calibration_probs</span> <span class="o">=</span> <span class="n">selected_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_calibration</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">selected_model</span><span class="p">,</span> <span class="p">(</span><span class="n">cb</span><span class="o">.</span><span class="n">CatBoostClassifier</span><span class="p">,</span> <span class="n">lgb</span><span class="o">.</span><span class="n">LGBMClassifier</span><span class="p">)):</span>
            <span class="n">calibration_probs</span> <span class="o">=</span> <span class="n">selected_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_calibration</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>

        <span class="c1"># Step 3: Compute nonconformity scores using the calibration set</span>
        <span class="c1"># Nonconformity scores for class 1: (1 - probability), for class 0: probability</span>
        <span class="n">nonconformity_scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y_calibration</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">calibration_probs</span><span class="p">,</span> <span class="n">calibration_probs</span><span class="p">)</span>

        <span class="c1"># Step 4: Get predicted probabilities for the new test set</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">selected_model</span><span class="p">,</span> <span class="p">(</span><span class="n">HistGradientBoostingClassifier</span><span class="p">,</span> <span class="n">RandomForestClassifier</span><span class="p">,</span> <span class="n">LogisticRegression</span><span class="p">,</span> <span class="n">GaussianNB</span><span class="p">)):</span>
            <span class="n">test_probs</span> <span class="o">=</span> <span class="n">selected_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_new_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">selected_model</span><span class="p">,</span> <span class="p">(</span><span class="n">cb</span><span class="o">.</span><span class="n">CatBoostClassifier</span><span class="p">,</span> <span class="n">lgb</span><span class="o">.</span><span class="n">LGBMClassifier</span><span class="p">)):</span>
            <span class="n">test_probs</span> <span class="o">=</span> <span class="n">selected_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_new_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>

        <span class="c1"># Step 5: Define the p-value calculation for conformal prediction</span>
        <span class="k">def</span> <span class="nf">conformal_p_value</span><span class="p">(</span><span class="n">prob</span><span class="p">,</span> <span class="n">calibration_scores</span><span class="p">,</span> <span class="n">true_label</span><span class="p">):</span>
<span class="w">            </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Calculates the p-value for conformal prediction using the calibration scores.</span>
<span class="sd">            </span>
<span class="sd">            This function estimates the proportion of calibration nonconformity scores that are greater than or equal to </span>
<span class="sd">            the test sample&#39;s nonconformity score. The p-value represents the probability that the null hypothesis of </span>
<span class="sd">            no difference between the distribution of labels and the predicted probabilities is rejected.</span>
<span class="sd">            </span>
<span class="sd">            ## Parameters</span>
<span class="sd">                prob (float): Predicted probability for the test sample.</span>
<span class="sd">                calibration_scores (array-like): Calibration scores from a conformal prediction model.</span>
<span class="sd">                true_label (int): True label of the test sample.</span>

<span class="sd">            ## Returns</span>
<span class="sd">                float: The p-value, representing the proportion of calibration nonconformity scores greater than or equal to </span>
<span class="sd">                    the test sample&#39;s nonconformity score.</span>
<span class="sd">            &quot;&quot;&quot;</span>
            <span class="c1"># Nonconformity score for the test sample</span>
            <span class="n">nonconformity</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">prob</span> <span class="k">if</span> <span class="n">true_label</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">prob</span>
            <span class="c1"># p-value is the proportion of calibration nonconformity scores that are greater than or equal to the test nonconformity</span>
            <span class="n">p_value</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">calibration_scores</span> <span class="o">&gt;=</span> <span class="n">nonconformity</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">p_value</span>

        <span class="c1"># Step 6: Conformal prediction for binary classification</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.05</span>  <span class="c1"># 95% coverage level</span>
        <span class="n">conformal_predictions</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">filtered_indices</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># Calculate conformal p-values and make predictions</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X_new_test</span><span class="p">)):</span>
            <span class="n">p_value_class_0</span> <span class="o">=</span> <span class="n">conformal_p_value</span><span class="p">(</span><span class="n">test_probs</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">nonconformity_scores</span><span class="p">,</span> <span class="n">true_label</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">p_value_class_1</span> <span class="o">=</span> <span class="n">conformal_p_value</span><span class="p">(</span><span class="n">test_probs</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">nonconformity_scores</span><span class="p">,</span> <span class="n">true_label</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

            <span class="c1"># Make confident prediction if one p-value is &gt;= alpha and the other is &lt; alpha</span>
            <span class="k">if</span> <span class="n">p_value_class_1</span> <span class="o">&gt;=</span> <span class="n">alpha</span> <span class="ow">and</span> <span class="n">p_value_class_0</span> <span class="o">&lt;</span> <span class="n">alpha</span><span class="p">:</span>
                <span class="n">conformal_predictions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">filtered_indices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">p_value_class_0</span> <span class="o">&gt;=</span> <span class="n">alpha</span> <span class="ow">and</span> <span class="n">p_value_class_1</span> <span class="o">&lt;</span> <span class="n">alpha</span><span class="p">:</span>
                <span class="n">conformal_predictions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
                <span class="n">filtered_indices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
                
        <span class="c1"># Open a file for writing</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;prediction_sets.txt&#39;</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">file</span><span class="p">:</span>
            <span class="c1"># Write the prediction sets to the file</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X_new_test</span><span class="p">)):</span>
                <span class="n">p_value_class_0</span> <span class="o">=</span> <span class="n">conformal_p_value</span><span class="p">(</span><span class="n">test_probs</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">nonconformity_scores</span><span class="p">,</span> <span class="n">true_label</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                <span class="n">p_value_class_1</span> <span class="o">=</span> <span class="n">conformal_p_value</span><span class="p">(</span><span class="n">test_probs</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">nonconformity_scores</span><span class="p">,</span> <span class="n">true_label</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
                
                <span class="n">prediction_set</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="k">if</span> <span class="n">p_value_class_0</span> <span class="o">&gt;=</span> <span class="n">alpha</span><span class="p">:</span>
                    <span class="n">prediction_set</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># Add class 0 to the prediction set</span>
                <span class="k">if</span> <span class="n">p_value_class_1</span> <span class="o">&gt;=</span> <span class="n">alpha</span><span class="p">:</span>
                    <span class="n">prediction_set</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Add class 1 to the prediction set</span>
                
                <span class="c1"># Write to file instead of printing</span>
                <span class="n">file</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Test sample </span><span class="si">{</span><span class="n">X_new_test</span><span class="o">.</span><span class="n">index</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s2">: Prediction set = </span><span class="si">{</span><span class="n">prediction_set</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Step 7: Filter the test set and report results</span>
        <span class="n">y_confident</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y_new_test</span><span class="p">)[</span><span class="n">filtered_indices</span><span class="p">]</span>
        <span class="n">confident_predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">conformal_predictions</span><span class="p">)</span>

        <span class="c1"># Evaluate Brier Score, MCC, ROC AUC, and PR AUC for both calibrated and uncalibrated probabilities</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">confident_predictions</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">brier_score_uncalibrated</span> <span class="o">=</span> <span class="n">brier_score_loss</span><span class="p">(</span><span class="n">y_new_test</span><span class="p">,</span> <span class="n">test_probs</span><span class="p">)</span>
            <span class="n">brier_score_calibrated</span> <span class="o">=</span> <span class="n">brier_score_loss</span><span class="p">(</span><span class="n">y_confident</span><span class="p">,</span> <span class="n">confident_predictions</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Brier Score (Uncalibrated):&quot;</span><span class="p">,</span> <span class="n">brier_score_uncalibrated</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Brier Score (Calibrated for confident predictions):&quot;</span><span class="p">,</span> <span class="n">brier_score_calibrated</span><span class="p">)</span>

            <span class="n">mcc_uncalibrated</span> <span class="o">=</span> <span class="n">matthews_corrcoef</span><span class="p">(</span><span class="n">y_new_test</span><span class="p">,</span> <span class="p">(</span><span class="n">test_probs</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">))</span>
            <span class="n">mcc_calibrated</span> <span class="o">=</span> <span class="n">matthews_corrcoef</span><span class="p">(</span><span class="n">y_confident</span><span class="p">,</span> <span class="n">confident_predictions</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;MCC (Uncalibrated):&quot;</span><span class="p">,</span> <span class="n">mcc_uncalibrated</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;MCC (Calibrated for confident predictions):&quot;</span><span class="p">,</span> <span class="n">mcc_calibrated</span><span class="p">)</span>

            <span class="n">roc_auc_uncalibrated</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_new_test</span><span class="p">,</span> <span class="n">test_probs</span><span class="p">)</span>
            <span class="n">roc_auc_calibrated</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_confident</span><span class="p">,</span> <span class="n">confident_predictions</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;ROC AUC (Uncalibrated):&quot;</span><span class="p">,</span> <span class="n">roc_auc_uncalibrated</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;ROC AUC (Calibrated for confident predictions):&quot;</span><span class="p">,</span> <span class="n">roc_auc_calibrated</span><span class="p">)</span>

            <span class="n">pr_auc_uncalibrated</span> <span class="o">=</span> <span class="n">average_precision_score</span><span class="p">(</span><span class="n">y_new_test</span><span class="p">,</span> <span class="n">test_probs</span><span class="p">)</span>
            <span class="n">pr_auc_calibrated</span> <span class="o">=</span> <span class="n">average_precision_score</span><span class="p">(</span><span class="n">y_confident</span><span class="p">,</span> <span class="n">confident_predictions</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;PR AUC (Uncalibrated):&quot;</span><span class="p">,</span> <span class="n">pr_auc_uncalibrated</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;PR AUC (Calibrated for confident predictions):&quot;</span><span class="p">,</span> <span class="n">pr_auc_calibrated</span><span class="p">)</span>

        <span class="c1"># Report the percentage of confident predictions</span>
        <span class="n">confident_ratio</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">confident_predictions</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_new_test</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Percentage of confident predictions (coverage): </span><span class="si">{</span><span class="n">confident_ratio</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">100</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="export-the-selected-model-to-deploy">
<h4>Export the selected model to deploy<a class="headerlink" href="#export-the-selected-model-to-deploy" title="Link to this heading">#</a></h4>
<p>The best performing model is exported (saved) on disk to be deployed.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="ow">not</span> <span class="n">skip_block</span><span class="p">:</span>
    <span class="c1"># Export the model</span>
    <span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">selected_model</span><span class="p">,</span> <span class="s1">&#39;selected_model.pkl&#39;</span><span class="p">)</span>

    <span class="c1"># Load the model</span>
    <span class="n">loaded_model</span> <span class="o">=</span> <span class="n">joblib</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;selected_model.pkl&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>
<section id="survival-models">
<h2>Survival models<a class="headerlink" href="#survival-models" title="Link to this heading">#</a></h2>
<p>This part of the pipeline is intended to be used in case the data contains a column for time-to-event information as a survival outcome variable. If so it is possible to use the following code chunks to develop a random survival forest model and a Cox proportional hazard model and compare their performance in prediction performance. For survival models we use scikit-survival package and you can read about here: <a class="reference external" href="https://scikit-survival.readthedocs.io/en/stable/#">https://scikit-survival.readthedocs.io/en/stable/#</a>
This part may require minimal modifications according to the names used for the target column and whether Cox model outperforms the survival random forest model. By default, the assumption is that the outcome variable requires formatting as follows and the random survival forest outperforms its linear alternative that is the Cox model. It is of course possible to include more models from scikit-survival package, however it is expected that the random survival model to have similar performance to its alternative ensemble models.</p>
<p>It should be noted that the survival models can work with one-hot encoded data with no missingness. So X_train_OHE and X_test_OHE are suitable for the analyses. Another thing to note is that the time-to-event column is not in X_train_OHE and X_test_OHE and so we get that column from the copy of the dataset that was initially made in the beginning of the pipeline as a back up to extract that information. In the following chunk you can see the column is called “max_time_difference_days”, and so if that is different in your dataset, you should modify it.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">survival_analysis</span><span class="p">:</span>
    <span class="c1"># X_train_OHE</span>
    <span class="n">X_train_surv</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">X_train_OHE_nocv</span><span class="p">,</span> <span class="n">mydata_copy_survival</span><span class="p">[</span><span class="n">time_to_event_column</span><span class="p">],</span> <span class="n">left_index</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">right_index</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s1">&#39;left&#39;</span><span class="p">)</span>
    <span class="n">X_test_surv</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">X_test_OHE</span><span class="p">,</span> <span class="n">mydata_copy_survival</span><span class="p">[</span><span class="n">time_to_event_column</span><span class="p">],</span> <span class="n">left_index</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">right_index</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s1">&#39;left&#39;</span><span class="p">)</span>

    <span class="n">y_train_surv</span> <span class="o">=</span> <span class="n">X_train_surv</span><span class="p">[</span><span class="n">time_to_event_column</span><span class="p">]</span>
    <span class="n">y_test_surv</span> <span class="o">=</span> <span class="n">X_test_surv</span><span class="p">[</span><span class="n">time_to_event_column</span><span class="p">]</span>
    <span class="n">X_train_surv</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="n">time_to_event_column</span><span class="p">],</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">X_test_surv</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="n">time_to_event_column</span><span class="p">],</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    
    
    <span class="k">if</span> <span class="n">external_val</span><span class="p">:</span>
        <span class="n">X_extval_surv</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">X_extval_data_OHE</span><span class="p">,</span> <span class="n">extval_data_survival</span><span class="p">[</span><span class="n">time_to_event_column</span><span class="p">],</span> <span class="n">left_index</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">right_index</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s1">&#39;left&#39;</span><span class="p">)</span>
        <span class="n">y_extval_surv</span> <span class="o">=</span> <span class="n">X_extval_surv</span><span class="p">[</span><span class="n">time_to_event_column</span><span class="p">]</span>
        <span class="n">X_extval_surv</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="n">time_to_event_column</span><span class="p">],</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        
    
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">survival_analysis</span><span class="p">:</span>
    <span class="n">contains_nan</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">y_train_surv</span><span class="o">.</span><span class="n">values</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="n">contains_nan</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">y_test_surv</span><span class="o">.</span><span class="n">values</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

    <span class="c1"># Check for NaN values</span>
    <span class="n">nan_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">y_train_surv</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>

    <span class="c1"># Replace NaN values with 0</span>
    <span class="n">y_train_surv</span><span class="p">[</span><span class="n">nan_indices</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># Check for NaN values</span>
    <span class="n">nan_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">y_test_surv</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>

    <span class="c1"># Replace NaN values with 0</span>
    <span class="n">y_test_surv</span><span class="p">[</span><span class="n">nan_indices</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">survival_analysis</span><span class="p">:</span>

    <span class="n">y_train_surv_transformed</span> <span class="o">=</span> <span class="n">Surv</span><span class="p">()</span><span class="o">.</span><span class="n">from_arrays</span><span class="p">(</span><span class="n">y_train</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">y_train_surv</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
    <span class="n">y_test_surv_transformed</span> <span class="o">=</span> <span class="n">Surv</span><span class="p">()</span><span class="o">.</span><span class="n">from_arrays</span><span class="p">(</span><span class="n">y_test</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">y_test_surv</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">external_val</span><span class="p">:</span>
        <span class="n">y_extval_surv_transformed</span> <span class="o">=</span> <span class="n">Surv</span><span class="p">()</span><span class="o">.</span><span class="n">from_arrays</span><span class="p">(</span><span class="n">y_extval_data</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">y_extval_surv</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>This is how the outcome column has to be formatted for survival models. In each array the first entry determines if there is any event or not and the second entry determines the last follow up time within a specific observation period. For example, when there is an event (e.g. daignosed disease) the first entry becomes True and the second entry show when it was recorded with respect to the baseline time (e.g. time of transplantation). If there was no event, then the last recorded sample of a patient is considered for the time and the event entry is False that clarifies that there was no event up to that time.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">survival_analysis</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;10 samples from the test set:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">y_train_surv_transformed</span><span class="p">[:</span><span class="mi">10</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<section id="training-and-evaluation-of-the-survival-models">
<h3>Training and evaluation of the survival models<a class="headerlink" href="#training-and-evaluation-of-the-survival-models" title="Link to this heading">#</a></h3>
<p>First we do corss validation using the traing set (development set) to assess the prediction performance of RSF and CPH models. The cross validation follows the same folding setting (i.e., number of folds) of the binary classification models (except for the survival models it is not stratified by the biary outcome variable). After we do the assessment of the models based on cross validation, we train the models on the whole trainig set and evaluate them on the test set. Two metrics are used to evaluate the models: (1) concordance index (CI), and (2) Integrated Brier Score (IBS). These scores are explained here: <a class="reference external" href="https://scikit-survival.readthedocs.io/en/v0.23.0/api/metrics.html">https://scikit-survival.readthedocs.io/en/v0.23.0/api/metrics.html</a>.</p>
<section id="concordance-index-ci-and-integrated-brier-score-ibs">
<h4>Concordance Index (CI) and Integrated Brier Score (IBS)<a class="headerlink" href="#concordance-index-ci-and-integrated-brier-score-ibs" title="Link to this heading">#</a></h4>
<section id="concordance-index-ci">
<h5>Concordance Index (CI)<a class="headerlink" href="#concordance-index-ci" title="Link to this heading">#</a></h5>
<p>The <strong>Concordance Index (CI)</strong> is a performance measure for survival models. It evaluates how well the model can correctly rank survival times. The CI measures the proportion of all usable pairs of individuals where the model correctly predicts the order of survival times. A CI of <code class="docutils literal notranslate"><span class="pre">1.0</span></code> indicates perfect predictions, while <code class="docutils literal notranslate"><span class="pre">0.5</span></code> represents random guessing.</p>
<ul class="simple">
<li><p><strong>Interpretation</strong>:</p>
<ul>
<li><p><strong>CI = 1</strong>: Perfect prediction, the model correctly ranks all pairs of individuals.</p></li>
<li><p><strong>CI = 0.5</strong>: Random prediction, no better than chance.</p></li>
<li><p><strong>CI &lt; 0.5</strong>: Worse than random, model is predicting the reverse order of survival times.</p></li>
</ul>
</li>
</ul>
<p>For more details: <a class="reference external" href="https://scikit-survival.readthedocs.io/en/v0.23.0/api/generated/sksurv.metrics.concordance_index_censored.html#sksurv.metrics.concordance_index_censored">Concordance Index in scikit-survival</a>.</p>
</section>
<section id="integrated-brier-score-ibs">
<h5>Integrated Brier Score (IBS)<a class="headerlink" href="#integrated-brier-score-ibs" title="Link to this heading">#</a></h5>
<p>The <strong>Integrated Brier Score (IBS)</strong> is a measure of the accuracy of predicted survival probabilities over time. It is the average Brier score, which measures the difference between the predicted survival probability and the actual outcome (whether the event occurred or not), across a range of time points. A lower IBS indicates better performance.</p>
<ul class="simple">
<li><p><strong>Interpretation</strong>:</p>
<ul>
<li><p><strong>IBS = 0</strong>: Perfect prediction, the model’s predicted probabilities match the true outcomes.</p></li>
<li><p><strong>Higher IBS values</strong>: Less accurate predictions.</p></li>
</ul>
</li>
</ul>
<p>For more details: <a class="reference external" href="https://scikit-survival.readthedocs.io/en/v0.23.0/api/generated/sksurv.metrics.integrated_brier_score.html#sksurv.metrics.integrated_brier_score">Integrated Brier Score in scikit-survival</a>.</p>
</section>
</section>
</section>
<section id="k-fold-cross-validation-of-survival-models">
<h3>K-fold cross validation of survival models<a class="headerlink" href="#k-fold-cross-validation-of-survival-models" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">survival_analysis</span><span class="p">:</span>
    <span class="n">n_rows</span> <span class="o">=</span> <span class="n">X_train_surv</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="c1">#########</span>
    <span class="k">def</span> <span class="nf">adjust_hyperparameters_surv_models</span><span class="p">(</span><span class="n">n_rows</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns a dictionary of hyperparameter distributions for various survival models.</span>

<span class="sd">        ## Parameters</span>
<span class="sd">            n_rows (int): The number of rows in the dataset.</span>

<span class="sd">        ## Returns</span>
<span class="sd">            dict: A dictionary containing the following keys:</span>
<span class="sd">                - &#39;RSF_param_dist&#39;: Hyperparameters for Random Forest Classifier.</span>
<span class="sd">                - &#39;CoxPH_param_dist&#39;: Hyperparameters for Cox Proportional Hazards Model.</span>
<span class="sd">                - &#39;Coxnet_param_dist&#39;: Hyperparameters for CoxnetSurvivalAnalysis.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">RSF_param_dist</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n_rows</span><span class="p">))),</span> <span class="n">num</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">),</span>  <span class="c1"># Number of trees in the forest</span>
            <span class="s1">&#39;min_samples_split&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">),</span>  <span class="c1"># Minimum number of samples required to split an internal node</span>
            <span class="s1">&#39;min_samples_leaf&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>  <span class="c1"># Minimum number of samples required to be at a leaf node</span>
        <span class="p">}</span>

        <span class="c1"># Define the parameter grid for CPH model</span>
        <span class="n">CoxPH_param_dist</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;alpha&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">1e-4</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span>  <span class="c1"># Regularization parameter for ridge regression penalty</span>
            <span class="s1">&#39;ties&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;breslow&#39;</span><span class="p">,</span> <span class="s1">&#39;efron&#39;</span><span class="p">],</span>  <span class="c1"># Method to handle tied event times</span>
            <span class="s1">&#39;n_iter&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n_rows</span><span class="p">))),</span> <span class="n">num</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">),</span>  <span class="c1"># Maximum number of iterations</span>
            <span class="s1">&#39;tol&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">1e-6</span><span class="p">,</span> <span class="mf">1e-7</span><span class="p">,</span> <span class="mf">1e-8</span><span class="p">],</span>  <span class="c1"># Convergence criteria</span>
            <span class="p">}</span>
        <span class="c1"># Define the parameter grid for CoxnetSurvivalAnalysis</span>
        <span class="n">Coxnet_param_dist</span> <span class="o">=</span> <span class="p">{</span>
            <span class="c1"># &#39;alphas&#39;: [0.001, 0.01, 0.1, 0.5],  # Range of alpha values for elastic net regularization</span>
            <span class="s1">&#39;l1_ratio&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">],</span>  <span class="c1"># Mix between L1 and L2 regularization</span>
            <span class="s1">&#39;max_iter&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n_rows</span><span class="p">))),</span> <span class="n">num</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">),</span>  <span class="c1"># Maximum number of iterations</span>
            <span class="s1">&#39;tol&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">1e-6</span><span class="p">,</span> <span class="mf">1e-7</span><span class="p">,</span> <span class="mf">1e-8</span><span class="p">],</span>  <span class="c1"># Convergence tolerance</span>
        <span class="p">}</span>

        <span class="k">return</span> <span class="n">RSF_param_dist</span><span class="p">,</span> <span class="n">CoxPH_param_dist</span><span class="p">,</span> <span class="n">Coxnet_param_dist</span>
    <span class="k">def</span> <span class="nf">set_params_surv_models</span><span class="p">(</span><span class="n">n_rows</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sets the parameters for different survival models based on the given dataset characteristics.</span>

<span class="sd">        Parameters:</span>
<span class="sd">            n_rows (int): The number of rows in the dataset.</span>

<span class="sd">        ## Returns</span>
<span class="sd">            A dictionary containing the parameters for each survival model, including:</span>
<span class="sd">                - Random Survival Forest (RSF)</span>
<span class="sd">                - Cox proportional hazards regression (CoxPH)</span>
<span class="sd">                - Cox proportional hazards regression with L1 regularization (Coxnet)</span>

<span class="sd">        Note that these functions assume hyperparameter tuning is not done and set default values based on common practices in survival analysis.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">RSF_params</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="nb">max</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n_rows</span><span class="p">))),</span>  <span class="c1"># Number of trees in the forest</span>
            <span class="s1">&#39;min_samples_split&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>  <span class="c1"># Minimum number of samples required to split an internal node</span>
            <span class="s1">&#39;min_samples_leaf&#39;</span><span class="p">:</span> <span class="mi">1</span>  <span class="c1"># Minimum number of samples required to be at a leaf node</span>
        <span class="p">}</span>
        <span class="n">CoxPH_param</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;alpha&#39;</span><span class="p">:</span> <span class="mf">1e-4</span><span class="p">,</span>  <span class="c1"># Regularization parameter for ridge regression penalty</span>
            <span class="s1">&#39;ties&#39;</span><span class="p">:</span> <span class="s1">&#39;efron&#39;</span><span class="p">,</span>  <span class="c1"># Method to handle tied event times</span>
            <span class="s1">&#39;n_iter&#39;</span><span class="p">:</span> <span class="nb">max</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n_rows</span><span class="p">))),</span>  <span class="c1"># Maximum number of iterations</span>
            <span class="s1">&#39;tol&#39;</span><span class="p">:</span> <span class="mf">1e-6</span><span class="p">,</span>  <span class="c1"># Convergence criteria</span>
            <span class="p">}</span>
        <span class="n">Coxnet_param</span> <span class="o">=</span> <span class="p">{</span>
            <span class="c1"># &#39;alphas&#39;: [0.01],  # Regularization parameter for elastic net (similar to Ridge regression)</span>
            <span class="s1">&#39;l1_ratio&#39;</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">,</span>  <span class="c1"># Mix between L1 and L2 regularization (0.5 means equal mix of L1 and L2)</span>
            <span class="s1">&#39;max_iter&#39;</span><span class="p">:</span> <span class="nb">max</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n_rows</span><span class="p">))),</span>  <span class="c1"># Maximum number of iterations</span>
            <span class="s1">&#39;tol&#39;</span><span class="p">:</span> <span class="mf">1e-6</span><span class="p">,</span>  <span class="c1"># Convergence tolerance</span>
            <span class="s2">&quot;fit_baseline_model&quot;</span><span class="p">:</span> <span class="kc">True</span>
        <span class="p">}</span>

        <span class="k">return</span> <span class="n">RSF_params</span><span class="p">,</span> <span class="n">CoxPH_param</span><span class="p">,</span> <span class="n">Coxnet_param</span>
    <span class="c1">#########</span>
    <span class="k">def</span> <span class="nf">calculate_surv_metrics</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">survival_train</span><span class="p">,</span> <span class="n">survival_test</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculate and compute key metrics for survival prediction models.</span>

<span class="sd">        This function takes in several inputs:</span>
<span class="sd">            - y_true: The true event labels (0 or 1) and corresponding times.</span>
<span class="sd">            - model: A trained survival prediction model.</span>
<span class="sd">            - X_test: Test feature data used to evaluate the model&#39;s performance.</span>
<span class="sd">            - survival_train: Training dataset containing event indicators, times, and predicted survival functions.</span>
<span class="sd">            - survival_test: Testing dataset containing event indicators, times, and predicted survival functions.</span>

<span class="sd">        The function computes the following metrics:</span>
<span class="sd">            - Concordance Index (CI): A measure of model accuracy that ranks predictions based on their performance.</span>
<span class="sd">            - Integrated Brier Score (IBS): An alternative measure of predictive performance that takes into account both false positives and false negatives.</span>

<span class="sd">        Parameters:</span>
<span class="sd">            y_true (pandas DataFrame): True event labels and corresponding times.</span>
<span class="sd">            model (scikit-learn estimator): Trained survival prediction model.</span>
<span class="sd">            X_test (numpy array or pandas DataFrame): Test feature data used to evaluate the model&#39;s performance.</span>
<span class="sd">            survival_train (pandas DataFrame): Training dataset containing event indicators, times, and predicted survival functions.</span>
<span class="sd">            survival_test (pandas DataFrame): Testing dataset containing event indicators, times, and predicted survival functions.</span>

<span class="sd">        ## Returns</span>
<span class="sd">            dict: A dictionary containing the Concordance Index (CI) and Integrated Brier Score (IBS).</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: If predictions array is empty or invalid.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">event_indicator</span> <span class="o">=</span> <span class="n">y_true</span><span class="p">[</span><span class="s1">&#39;event&#39;</span><span class="p">]</span>
        <span class="n">event_time</span> <span class="o">=</span> <span class="n">y_true</span><span class="p">[</span><span class="s1">&#39;time&#39;</span><span class="p">]</span>
        
        <span class="c1"># Get the concordance index (CI)</span>
        <span class="n">CI</span> <span class="o">=</span> <span class="n">concordance_index_censored</span><span class="p">(</span><span class="n">event_indicator</span><span class="p">,</span> <span class="n">event_time</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># Extract event times from survival_train and survival_test</span>
        <span class="n">train_times</span> <span class="o">=</span> <span class="n">survival_train</span><span class="p">[</span><span class="s1">&#39;time&#39;</span><span class="p">]</span>  <span class="c1"># Training event times</span>
        <span class="n">test_times</span> <span class="o">=</span> <span class="n">survival_test</span><span class="p">[</span><span class="s1">&#39;time&#39;</span><span class="p">]</span>    <span class="c1"># Test event times</span>
        
        <span class="c1"># Obtain predicted survival functions for each test instance</span>
        <span class="n">survival_preds</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_survival_function</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

        <span class="c1"># Get the follow-up time interval from both training and test datasets</span>
        <span class="n">min_followup_time</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">train_times</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">test_times</span><span class="o">.</span><span class="n">min</span><span class="p">())</span>  <span class="c1"># The later start</span>
        <span class="n">max_followup_time</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">train_times</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="n">test_times</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>  <span class="c1"># The earlier end</span>

        <span class="c1"># Define valid times based on the overlap of the follow-up times from both datasets</span>
        <span class="n">valid_times</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">min_followup_time</span><span class="p">,</span> <span class="n">max_followup_time</span><span class="p">)</span>

        <span class="c1"># Ensure valid_times does not include the maximum observed time</span>
        <span class="n">valid_times</span> <span class="o">=</span> <span class="n">valid_times</span><span class="p">[</span><span class="n">valid_times</span> <span class="o">&lt;</span> <span class="n">max_followup_time</span><span class="p">]</span>
        
        <span class="c1"># Generate predictions for each survival function at the valid time points</span>
        <span class="n">preds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([[</span><span class="n">fn</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">valid_times</span><span class="p">]</span> <span class="k">for</span> <span class="n">fn</span> <span class="ow">in</span> <span class="n">survival_preds</span><span class="p">])</span>

        <span class="c1"># Check for empty or invalid predictions before calculating IBS</span>
        <span class="k">if</span> <span class="n">preds</span><span class="o">.</span><span class="n">size</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Predictions array is empty. Check the time points and survival functions.&quot;</span><span class="p">)</span>

        <span class="c1"># Replace NaN and infinity values in preds with finite numbers</span>
        <span class="n">preds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan_to_num</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">nan</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">posinf</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span><span class="o">.</span><span class="n">max</span><span class="p">,</span> <span class="n">neginf</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span><span class="o">.</span><span class="n">min</span><span class="p">)</span>

        <span class="c1"># Calculate Integrated Brier Score (IBS) ensuring times are within the valid follow-up period</span>
        <span class="n">IBS</span> <span class="o">=</span> <span class="n">integrated_brier_score</span><span class="p">(</span><span class="n">survival_train</span><span class="o">=</span><span class="n">survival_train</span><span class="p">,</span> <span class="n">survival_test</span><span class="o">=</span><span class="n">survival_test</span><span class="p">,</span> <span class="n">estimate</span><span class="o">=</span><span class="n">preds</span><span class="p">,</span> <span class="n">times</span><span class="o">=</span><span class="n">valid_times</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;CI&#39;</span><span class="p">:</span> <span class="n">CI</span><span class="p">,</span> <span class="s1">&#39;IBS&#39;</span><span class="p">:</span> <span class="n">IBS</span><span class="p">}</span>


    <span class="c1">#########</span>
    <span class="c1"># Function to cross-validate the survival model</span>
    <span class="k">def</span> <span class="nf">cross_validate_surv_model</span><span class="p">(</span><span class="n">model_class</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">n_splits</span><span class="o">=</span><span class="n">cv_folds</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">,</span> <span class="n">measures</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">hp_tuning</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        This function performs cross-validation on a specified survival model class, evaluating its performance on a dataset. It allows users to tune hyperparameters using random search or grid search.</span>

<span class="sd">        ### Function Signature</span>

<span class="sd">        `cross_validate_surv_model(model_class: str, X: pd.DataFrame, y: np.ndarray, n_splits: int = cv_folds, random_state: int = SEED, measures: list[str] = [&#39;CI&#39;, &#39;IBS&#39;], hp_tuning: bool = False) -&gt; pd.DataFrame`</span>

<span class="sd">        ### Parameters</span>

<span class="sd">        - `model_class`: The class of the survival model to be used for cross-validation. Supported models include `RandomSurvivalForest`, `CoxPHSurvivalAnalysis`, and `CoxnetSurvivalAnalysis`.</span>
<span class="sd">        - `X`: The feature data.</span>
<span class="sd">        - `y`: The event data, where each row contains an &#39;event&#39; and a &#39;time&#39;.</span>
<span class="sd">        - `n_splits`: The number of folds for cross-validation. Defaults to `cv_folds` if not specified.</span>
<span class="sd">        - `random_state`: The random seed used for shuffling and splitting the data. Defaults to `SEED` if not specified.</span>
<span class="sd">        - `measures`: A list of metrics to be evaluated during cross-validation. Defaults to [&#39;CI&#39;, &#39;IBS&#39;] if not specified.</span>
<span class="sd">        - `hp_tuning`: Whether to perform hyperparameter tuning using random search or grid search.</span>

<span class="sd">        ### Function Behavior</span>

<span class="sd">        1. The function performs KFold cross-validation on the dataset, creating a new DataFrame for each fold to store the results of the model evaluation.</span>
<span class="sd">        2. For each fold, it converts the data back to its original structured format and prepares the survival data for calculating metrics.</span>
<span class="sd">        3. If hyperparameter tuning is enabled, it uses RandomizedSearchCV to perform random search or grid search on the specified model class and parameter distribution.</span>
<span class="sd">        4. It then fits the model with the trained parameters and predicts the event times for the test set.</span>
<span class="sd">        5. After obtaining the predicted event times, it calculates the evaluation metrics using `calculate_surv_metrics`.</span>
<span class="sd">        6. The function aggregates the results from each fold by calculating the mean and standard deviation of each metric.</span>
<span class="sd">        7. Finally, it displays the aggregated results in a table format.</span>

<span class="sd">        ### Returns</span>

<span class="sd">        The function returns a DataFrame containing the aggregated results of the model evaluations for each metric specified in the `measures` list.</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">if</span> <span class="n">measures</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">measures</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;CI&#39;</span><span class="p">,</span> <span class="s1">&#39;IBS&#39;</span><span class="p">]</span>
        
        <span class="n">fold_results</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
        
        <span class="c1"># Convert survival data to DataFrame for indexing purposes</span>
        <span class="n">y_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;event&#39;</span><span class="p">,</span> <span class="s1">&#39;time&#39;</span><span class="p">])</span>
        
        <span class="c1"># Use KFold instead of StratifiedKFold (since this is survival data, not classification)</span>
        <span class="n">kf</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="n">n_splits</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">fold</span><span class="p">,</span> <span class="p">(</span><span class="n">train_index</span><span class="p">,</span> <span class="n">test_index</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">kf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">X_train_fold</span><span class="p">,</span> <span class="n">X_test_fold</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
            <span class="n">y_train_fold_df</span><span class="p">,</span> <span class="n">y_test_fold_df</span> <span class="o">=</span> <span class="n">y_df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">y_df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
            
            <span class="c1"># Convert y_train_fold and y_test_fold back to original structured format</span>
            <span class="n">y_train_fold</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([(</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;event&#39;</span><span class="p">],</span> <span class="n">row</span><span class="p">[</span><span class="s1">&#39;time&#39;</span><span class="p">])</span> <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">y_train_fold_df</span><span class="o">.</span><span class="n">iterrows</span><span class="p">()],</span>
                                    <span class="n">dtype</span><span class="o">=</span><span class="p">[(</span><span class="s1">&#39;event&#39;</span><span class="p">,</span> <span class="s1">&#39;?&#39;</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;time&#39;</span><span class="p">,</span> <span class="s1">&#39;&lt;f8&#39;</span><span class="p">)])</span>
            <span class="n">y_test_fold</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([(</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;event&#39;</span><span class="p">],</span> <span class="n">row</span><span class="p">[</span><span class="s1">&#39;time&#39;</span><span class="p">])</span> <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">y_test_fold_df</span><span class="o">.</span><span class="n">iterrows</span><span class="p">()],</span>
                                <span class="n">dtype</span><span class="o">=</span><span class="p">[(</span><span class="s1">&#39;event&#39;</span><span class="p">,</span> <span class="s1">&#39;?&#39;</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;time&#39;</span><span class="p">,</span> <span class="s1">&#39;&lt;f8&#39;</span><span class="p">)])</span>
            
            <span class="n">n_rows</span> <span class="o">=</span> <span class="n">X_train_fold</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="c1"># Adjust hyperparameters based on the training data in this fold</span>
            <span class="n">RSF_param_dist</span><span class="p">,</span> <span class="n">CoxPH_param_dist</span><span class="p">,</span> <span class="n">Coxnet_param_dist</span> <span class="o">=</span> <span class="n">adjust_hyperparameters_surv_models</span><span class="p">(</span><span class="n">n_rows</span><span class="p">)</span>
            <span class="n">RSF_params</span><span class="p">,</span> <span class="n">CoxPH_params</span><span class="p">,</span> <span class="n">Coxnet_params</span> <span class="o">=</span> <span class="n">set_params_surv_models</span><span class="p">(</span><span class="n">n_rows</span><span class="p">)</span>
            <span class="c1"># Prepare survival data for calculating metrics</span>
            <span class="n">survival_train</span> <span class="o">=</span> <span class="n">Surv</span><span class="o">.</span><span class="n">from_dataframe</span><span class="p">(</span><span class="s1">&#39;event&#39;</span><span class="p">,</span> <span class="s1">&#39;time&#39;</span><span class="p">,</span> <span class="n">y_train_fold_df</span><span class="p">)</span>
            <span class="n">survival_test</span> <span class="o">=</span> <span class="n">Surv</span><span class="o">.</span><span class="n">from_dataframe</span><span class="p">(</span><span class="s1">&#39;event&#39;</span><span class="p">,</span> <span class="s1">&#39;time&#39;</span><span class="p">,</span> <span class="n">y_test_fold_df</span><span class="p">)</span>
            
            <span class="c1"># Initialize and fit the model</span>
            <span class="k">if</span> <span class="n">model_class</span> <span class="o">==</span> <span class="n">RandomSurvivalForest</span><span class="p">:</span>
                <span class="n">RSF_model</span> <span class="o">=</span> <span class="n">RandomSurvivalForest</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span> <span class="o">**</span><span class="n">RSF_params</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">hp_tuning</span><span class="p">:</span>
                    <span class="n">random_search</span> <span class="o">=</span> <span class="n">RandomizedSearchCV</span><span class="p">(</span>
                        <span class="n">estimator</span><span class="o">=</span><span class="n">RSF_model</span><span class="p">,</span> 
                        <span class="n">param_distributions</span><span class="o">=</span><span class="n">RSF_param_dist</span><span class="p">,</span> 
                        <span class="n">n_iter</span><span class="o">=</span><span class="n">n_iter_hptuning</span><span class="p">,</span> 
                        <span class="n">cv</span><span class="o">=</span><span class="n">cv_folds_hptuning</span><span class="p">,</span> 
                        <span class="n">refit</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
                        <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">)</span>
                    <span class="n">random_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_fold</span><span class="p">,</span> <span class="n">y_train_fold</span><span class="p">)</span>
                    <span class="c1"># RSF_model = random_search.best_estimator_</span>
                    <span class="n">RSF_model</span> <span class="o">=</span> <span class="n">RandomSurvivalForest</span><span class="p">(</span><span class="o">**</span><span class="n">random_search</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
                
                <span class="n">RSF_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_fold</span><span class="p">,</span> <span class="n">y_train_fold</span><span class="p">)</span>
                <span class="n">y_pred</span> <span class="o">=</span> <span class="n">RSF_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_fold</span><span class="p">)</span>
                
                <span class="c1"># Calculate evaluation metrics</span>
                <span class="n">metrics</span> <span class="o">=</span> <span class="n">calculate_surv_metrics</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_test_fold_df</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">RSF_model</span><span class="p">,</span> <span class="n">X_test</span><span class="o">=</span><span class="n">X_test_fold</span><span class="p">,</span> <span class="n">survival_train</span><span class="o">=</span><span class="n">survival_train</span><span class="p">,</span> <span class="n">survival_test</span><span class="o">=</span><span class="n">survival_test</span><span class="p">)</span>
                <span class="n">fold_results</span> <span class="o">=</span> <span class="n">fold_results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">metrics</span><span class="p">,</span> <span class="n">ignore_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                
            <span class="k">elif</span> <span class="n">model_class</span> <span class="o">==</span> <span class="n">CoxPHSurvivalAnalysis</span><span class="p">:</span>
                <span class="n">CPH_model</span> <span class="o">=</span> <span class="n">CoxPHSurvivalAnalysis</span><span class="p">(</span><span class="o">**</span><span class="n">CoxPH_params</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">hp_tuning</span><span class="p">:</span>
                    <span class="n">random_search</span> <span class="o">=</span> <span class="n">RandomizedSearchCV</span><span class="p">(</span>
                        <span class="n">estimator</span><span class="o">=</span><span class="n">CPH_model</span><span class="p">,</span> 
                        <span class="n">param_distributions</span><span class="o">=</span><span class="n">CoxPH_param_dist</span><span class="p">,</span> 
                        <span class="n">n_iter</span><span class="o">=</span><span class="n">n_iter_hptuning</span><span class="p">,</span> 
                        <span class="n">cv</span><span class="o">=</span><span class="n">cv_folds_hptuning</span><span class="p">,</span> 
                        <span class="n">refit</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
                        <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">)</span>
                    <span class="n">random_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_fold</span><span class="p">,</span> <span class="n">y_train_fold</span><span class="p">)</span>
                    <span class="c1"># CPH_model = random_search.best_estimator_</span>
                    <span class="n">CPH_model</span> <span class="o">=</span> <span class="n">CoxPHSurvivalAnalysis</span><span class="p">(</span><span class="o">**</span><span class="n">random_search</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
                    
                <span class="n">CPH_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_fold</span><span class="p">,</span> <span class="n">y_train_fold</span><span class="p">)</span>
                <span class="n">y_pred</span> <span class="o">=</span> <span class="n">CPH_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_fold</span><span class="p">)</span>
                <span class="c1"># Calculate evaluation metrics</span>
                <span class="n">metrics</span> <span class="o">=</span> <span class="n">calculate_surv_metrics</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_test_fold_df</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">CPH_model</span><span class="p">,</span> <span class="n">X_test</span><span class="o">=</span><span class="n">X_test_fold</span><span class="p">,</span> <span class="n">survival_train</span><span class="o">=</span><span class="n">survival_train</span><span class="p">,</span> <span class="n">survival_test</span><span class="o">=</span><span class="n">survival_test</span><span class="p">)</span>
                <span class="n">fold_results</span> <span class="o">=</span> <span class="n">fold_results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">metrics</span><span class="p">,</span> <span class="n">ignore_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">model_class</span> <span class="o">==</span> <span class="n">CoxnetSurvivalAnalysis</span><span class="p">:</span>
                <span class="n">Coxnet_model</span> <span class="o">=</span> <span class="n">CoxnetSurvivalAnalysis</span><span class="p">(</span><span class="o">**</span><span class="n">Coxnet_params</span><span class="p">)</span>
                
                <span class="k">if</span> <span class="n">hp_tuning</span><span class="p">:</span>
                    <span class="n">random_search</span> <span class="o">=</span> <span class="n">RandomizedSearchCV</span><span class="p">(</span>
                        <span class="n">estimator</span><span class="o">=</span><span class="n">Coxnet_model</span><span class="p">,</span> 
                        <span class="n">param_distributions</span><span class="o">=</span><span class="n">Coxnet_param_dist</span><span class="p">,</span> 
                        <span class="n">n_iter</span><span class="o">=</span><span class="n">n_iter_hptuning</span><span class="p">,</span> 
                        <span class="n">cv</span><span class="o">=</span><span class="n">cv_folds_hptuning</span><span class="p">,</span> 
                        <span class="n">refit</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
                        <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span>
                    <span class="p">)</span>
                    <span class="n">random_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_fold</span><span class="p">,</span> <span class="n">y_train_fold</span><span class="p">)</span>
                    <span class="c1"># Coxnet_model = random_search.best_estimator_</span>
                    <span class="n">Coxnet_model</span> <span class="o">=</span> <span class="n">CoxnetSurvivalAnalysis</span><span class="p">(</span><span class="n">fit_baseline_model</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">random_search</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
                
                <span class="n">Coxnet_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_fold</span><span class="p">,</span> <span class="n">y_train_fold</span><span class="p">)</span>
                <span class="n">y_pred</span> <span class="o">=</span> <span class="n">Coxnet_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_fold</span><span class="p">)</span>
                
                <span class="c1"># Calculate evaluation metrics</span>
                <span class="n">metrics</span> <span class="o">=</span> <span class="n">calculate_surv_metrics</span><span class="p">(</span>
                    <span class="n">y_true</span><span class="o">=</span><span class="n">y_test_fold_df</span><span class="p">,</span> 
                    <span class="n">model</span><span class="o">=</span><span class="n">Coxnet_model</span><span class="p">,</span> 
                    <span class="n">X_test</span><span class="o">=</span><span class="n">X_test_fold</span><span class="p">,</span> 
                    <span class="n">survival_train</span><span class="o">=</span><span class="n">survival_train</span><span class="p">,</span> 
                    <span class="n">survival_test</span><span class="o">=</span><span class="n">survival_test</span>
                <span class="p">)</span>
                <span class="n">fold_results</span> <span class="o">=</span> <span class="n">fold_results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">metrics</span><span class="p">,</span> <span class="n">ignore_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unsupported model class: </span><span class="si">{</span><span class="n">model_class</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            

        <span class="c1"># Aggregating the results</span>
        <span class="n">aggregated_results</span> <span class="o">=</span> <span class="p">{</span><span class="n">metric</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">nanmean</span><span class="p">(</span><span class="n">fold_results</span><span class="p">[</span><span class="n">metric</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="k">for</span> <span class="n">metric</span> <span class="ow">in</span> <span class="n">measures</span><span class="p">}</span>
        <span class="n">aggregated_results_sd</span> <span class="o">=</span> <span class="p">{</span><span class="n">metric</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">nanstd</span><span class="p">(</span><span class="n">fold_results</span><span class="p">[</span><span class="n">metric</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="k">for</span> <span class="n">metric</span> <span class="ow">in</span> <span class="n">measures</span><span class="p">}</span>
        
        <span class="c1"># Combine mean and standard deviation</span>
        <span class="n">combined_results</span> <span class="o">=</span> <span class="p">{</span><span class="n">metric</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">mean</span><span class="si">}</span><span class="s2"> ± </span><span class="si">{</span><span class="n">sd</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">metric</span><span class="p">,</span> <span class="n">mean</span> <span class="ow">in</span> <span class="n">aggregated_results</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">sd</span> <span class="ow">in</span> <span class="n">aggregated_results_sd</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">metric</span> <span class="o">==</span> <span class="n">_</span><span class="p">}</span>
        
        <span class="c1"># Create a DataFrame for displaying the results</span>
        <span class="n">results_table</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">combined_results</span><span class="o">.</span><span class="n">items</span><span class="p">()),</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Metric&#39;</span><span class="p">,</span> <span class="s1">&#39;Result&#39;</span><span class="p">])</span>
        
        
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Aggregated Results:&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">results_table</span><span class="o">.</span><span class="n">to_string</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
        
        <span class="k">return</span> <span class="n">results_table</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">integrated_brier_score</span><span class="p">(</span><span class="n">survival_train</span><span class="p">,</span> <span class="n">survival_test</span><span class="p">,</span> <span class="n">estimate</span><span class="p">,</span> <span class="n">times</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the Integrated Brier Score (IBS) using scikit-learn&#39;s Brier score loss.</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    survival_train : structured array</span>
<span class="sd">        Survival times for training data (event indicator, time).</span>
<span class="sd">    survival_test : structured array</span>
<span class="sd">        Survival times for test data (event indicator, time).</span>
<span class="sd">    estimate : array-like, shape = (n_samples, n_times)</span>
<span class="sd">        Estimated survival probabilities.</span>
<span class="sd">    times : array-like, shape = (n_times,)</span>
<span class="sd">        Time points for the calculation.</span>
<span class="sd">    </span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    ibs : float</span>
<span class="sd">        The Integrated Brier Score (IBS).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Initialize list to hold Brier scores at each time point</span>
    <span class="n">brier_scores</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="n">event_indicator</span> <span class="o">=</span> <span class="n">survival_test</span><span class="p">[</span><span class="s1">&#39;event&#39;</span><span class="p">]</span>
    <span class="n">time_of_event_or_censoring</span> <span class="o">=</span> <span class="n">survival_test</span><span class="p">[</span><span class="s1">&#39;time&#39;</span><span class="p">]</span>

    <span class="c1"># Iterate through all the times to calculate the Brier score at each time point</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">times</span><span class="p">):</span>
        <span class="c1"># Calculate the true survival status at time t</span>
        <span class="n">y_true</span> <span class="o">=</span> <span class="p">(</span><span class="n">time_of_event_or_censoring</span> <span class="o">&gt;</span> <span class="n">t</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
        
        <span class="c1"># Calculate the predicted survival probabilities at time t</span>
        <span class="n">pred_prob</span> <span class="o">=</span> <span class="n">estimate</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span>  <span class="c1"># Use the i-th column directly</span>
        
        <span class="c1"># Identify samples that are not censored before time t</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">time_of_event_or_censoring</span> <span class="o">&gt;=</span> <span class="n">t</span><span class="p">)</span> <span class="o">|</span> <span class="n">event_indicator</span>
        
        <span class="c1"># Brier score is calculated based on the true survival status and the predicted probability</span>
        <span class="n">brier_score</span> <span class="o">=</span> <span class="n">brier_score_loss</span><span class="p">(</span><span class="n">y_true</span><span class="p">[</span><span class="n">mask</span><span class="p">],</span> <span class="n">pred_prob</span><span class="p">[</span><span class="n">mask</span><span class="p">])</span>
        <span class="n">brier_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">brier_score</span><span class="p">)</span>

    <span class="c1"># Convert to numpy array for easier processing</span>
    <span class="n">brier_scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">brier_scores</span><span class="p">)</span>
    
    <span class="c1"># Compute the Integrated Brier Score using the trapezoidal rule</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">times</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;At least two time points must be provided&quot;</span><span class="p">)</span>

    <span class="c1"># Apply the trapezoidal rule to integrate the Brier scores</span>
    <span class="n">ibs_value</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">trapz</span><span class="p">(</span><span class="n">brier_scores</span><span class="p">,</span> <span class="n">times</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">times</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">times</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

    <span class="k">return</span> <span class="n">ibs_value</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">survival_analysis</span><span class="p">:</span>
    <span class="c1"># getting the cross validation results (performance) for RSF - mean and standard deviation of the metrics</span>
    <span class="n">results_table_RSF</span> <span class="o">=</span> <span class="n">cross_validate_surv_model</span><span class="p">(</span>
        <span class="n">model_class</span><span class="o">=</span><span class="n">RandomSurvivalForest</span><span class="p">,</span>
        <span class="n">X</span><span class="o">=</span><span class="n">X_train_surv</span><span class="p">,</span> 
        <span class="n">y</span><span class="o">=</span><span class="n">y_train_surv_transformed</span><span class="p">,</span>
        <span class="n">n_splits</span><span class="o">=</span><span class="n">cv_folds</span><span class="p">,</span>
        <span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span>
    <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sksurv.linear_model</span> <span class="kn">import</span> <span class="n">CoxnetSurvivalAnalysis</span>
<span class="k">if</span> <span class="n">survival_analysis</span><span class="p">:</span>
    <span class="c1"># getting the cross validation results (performance) for CPH - mean and standard deviation of the metrics</span>
    <span class="n">results_table_CPH</span> <span class="o">=</span> <span class="n">cross_validate_surv_model</span><span class="p">(</span>
        <span class="n">model_class</span><span class="o">=</span><span class="n">CoxnetSurvivalAnalysis</span><span class="p">,</span>
        <span class="n">X</span><span class="o">=</span><span class="n">X_train_surv</span><span class="p">,</span> 
        <span class="n">y</span><span class="o">=</span><span class="n">y_train_surv_transformed</span><span class="p">,</span>
        <span class="n">n_splits</span><span class="o">=</span><span class="n">cv_folds</span><span class="p">,</span>
        <span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span>
    <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># if survival_analysis:</span>
<span class="c1">#     # getting the cross validation results (performance) for CPH - mean and standard deviation of the metrics</span>
<span class="c1">#     results_table_CPH = cross_validate_surv_model(</span>
<span class="c1">#         model_class=CoxPHSurvivalAnalysis,</span>
<span class="c1">#         X=X_train_surv, </span>
<span class="c1">#         y=y_train_surv_transformed,</span>
<span class="c1">#         n_splits=cv_folds,</span>
<span class="c1">#         random_state=SEED</span>
<span class="c1">#     )</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">survival_analysis</span><span class="p">:</span>
    <span class="c1"># aggragation of the CV results for RSF and CPH models to make them into one table</span>

    <span class="n">results_table_RSF</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;Result&#39;</span><span class="p">:</span> <span class="s1">&#39;RSF&#39;</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">results_table_CPH</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;Result&#39;</span><span class="p">:</span> <span class="s1">&#39;CPH&#39;</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># Merging the two tables on the &#39;Metric&#39; column</span>
    <span class="n">merged_table</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">results_table_RSF</span><span class="p">,</span> <span class="n">results_table_CPH</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="s1">&#39;Metric&#39;</span><span class="p">)</span>

    <span class="c1"># Display the merged table</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">merged_table</span><span class="o">.</span><span class="n">to_string</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
    <span class="n">merged_table</span><span class="o">.</span><span class="n">to_excel</span><span class="p">(</span><span class="s1">&#39;CV_surv.xlsx&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># now we do the survival analysis using the whole trainig set for trainig the survival models and evaluating them on the test set</span>
<span class="k">if</span> <span class="n">survival_analysis</span><span class="p">:</span>
    <span class="c1"># Define the parameter grid for RSF model</span>
    <span class="n">n_rows</span> <span class="o">=</span> <span class="n">X_train_surv</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">RSF_param_dist</span><span class="p">,</span> <span class="n">CoxPH_param_dist</span><span class="p">,</span> <span class="n">Coxnet_param_dist</span> <span class="o">=</span> <span class="n">adjust_hyperparameters_surv_models</span><span class="p">(</span><span class="n">n_rows</span><span class="p">)</span>
    
    <span class="c1">############# RSF</span>
    <span class="c1"># RandomizedSearchCV for Random Survival Forest (RSF)</span>
    <span class="n">rsf</span> <span class="o">=</span> <span class="n">RandomSurvivalForest</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=</span><span class="n">n_cpu_model_training</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
    <span class="n">random_search</span> <span class="o">=</span> <span class="n">RandomizedSearchCV</span><span class="p">(</span><span class="n">rsf</span><span class="p">,</span> <span class="n">param_distributions</span><span class="o">=</span><span class="n">RSF_param_dist</span><span class="p">,</span> <span class="n">n_iter</span><span class="o">=</span><span class="n">n_iter_hptuning</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">cv_folds</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
    
    <span class="c1"># Fit RandomizedSearchCV on training data</span>
    <span class="n">random_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_surv</span><span class="p">,</span> <span class="n">y_train_surv_transformed</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best Parameters for RSF:&quot;</span><span class="p">,</span> <span class="n">random_search</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
    
    <span class="c1"># Train the RSF model with the best hyperparameters</span>
    <span class="n">rsf</span> <span class="o">=</span> <span class="n">RandomSurvivalForest</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=</span><span class="n">n_cpu_model_training</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">,</span> <span class="o">**</span><span class="n">random_search</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
    <span class="n">rsf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_surv</span><span class="p">,</span> <span class="n">y_train_surv_transformed</span><span class="p">)</span>
    
    <span class="c1"># Save the RSF model to disk</span>
    <span class="n">dump</span><span class="p">(</span><span class="n">rsf</span><span class="p">,</span> <span class="s1">&#39;RSF_model.pkl&#39;</span><span class="p">)</span>
    
    <span class="c1"># Predict survival function for test data</span>
    <span class="n">survival_preds_rsf</span> <span class="o">=</span> <span class="n">rsf</span><span class="o">.</span><span class="n">predict_survival_function</span><span class="p">(</span><span class="n">X_test_surv</span><span class="p">)</span>

    <span class="c1"># Extract event times from survival_train and survival_test</span>
    <span class="n">train_times</span> <span class="o">=</span> <span class="n">y_train_surv</span><span class="o">.</span><span class="n">values</span>  <span class="c1"># Training event times</span>
    <span class="n">test_times</span> <span class="o">=</span> <span class="n">y_test_surv</span><span class="o">.</span><span class="n">values</span>    <span class="c1"># Test event times</span>

    <span class="c1"># Get the follow-up time interval from both training and test datasets</span>
    <span class="n">min_followup_time</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">train_times</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">test_times</span><span class="o">.</span><span class="n">min</span><span class="p">())</span>  <span class="c1"># The later start</span>
    <span class="n">max_followup_time</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">train_times</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="n">test_times</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>  <span class="c1"># The earlier end</span>

    <span class="c1"># Define valid times based on the overlap of the follow-up times from both datasets</span>
    <span class="n">valid_times</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">min_followup_time</span><span class="p">,</span> <span class="n">max_followup_time</span><span class="p">)</span>

    <span class="c1"># Ensure valid_times does not include the maximum observed time</span>
    <span class="n">valid_times</span> <span class="o">=</span> <span class="n">valid_times</span><span class="p">[</span><span class="n">valid_times</span> <span class="o">&lt;</span> <span class="n">max_followup_time</span><span class="p">]</span>

    <span class="c1"># Generate predictions for each survival function at the valid time points</span>
    <span class="n">preds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([[</span><span class="n">fn</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">valid_times</span><span class="p">]</span> <span class="k">for</span> <span class="n">fn</span> <span class="ow">in</span> <span class="n">survival_preds_rsf</span><span class="p">])</span>

    <span class="c1"># Replace NaN and infinity values in preds with finite numbers</span>
    <span class="n">estimate_rsf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan_to_num</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">nan</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">posinf</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span><span class="o">.</span><span class="n">max</span><span class="p">,</span> <span class="n">neginf</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span><span class="o">.</span><span class="n">min</span><span class="p">)</span>

    <span class="c1"># Calculate IBS for RSF</span>
    <span class="n">IBS_rsf</span> <span class="o">=</span> <span class="n">integrated_brier_score</span><span class="p">(</span><span class="n">survival_train</span><span class="o">=</span><span class="n">y_train_surv_transformed</span><span class="p">,</span> <span class="n">survival_test</span><span class="o">=</span><span class="n">y_test_surv_transformed</span><span class="p">,</span> <span class="n">estimate</span><span class="o">=</span><span class="n">estimate_rsf</span><span class="p">,</span> <span class="n">times</span><span class="o">=</span><span class="n">valid_times</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Integrated Brier Score for RSF on the test set: </span><span class="si">{</span><span class="n">IBS_rsf</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    
    <span class="c1"># Get the concordance index (CI)</span>
    <span class="n">CI_rsf</span> <span class="o">=</span> <span class="n">concordance_index_censored</span><span class="p">(</span><span class="n">event_indicator</span><span class="o">=</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">event_time</span> <span class="o">=</span> <span class="n">y_test_surv</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">estimate</span> <span class="o">=</span> <span class="n">rsf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_surv</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;C-index for RSF on the test set: </span><span class="si">{</span><span class="n">CI_rsf</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    
    <span class="c1">############## CPH</span>
    <span class="c1"># RandomizedSearchCV for Cox Proportional Hazards (CPH)</span>
    <span class="c1"># coxph = CoxPHSurvivalAnalysis()</span>
    <span class="n">coxph</span> <span class="o">=</span> <span class="n">CoxnetSurvivalAnalysis</span><span class="p">(</span><span class="n">fit_baseline_model</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">random_search_coxph</span> <span class="o">=</span> <span class="n">RandomizedSearchCV</span><span class="p">(</span><span class="n">coxph</span><span class="p">,</span> <span class="n">param_distributions</span><span class="o">=</span><span class="n">Coxnet_param_dist</span><span class="p">,</span> <span class="n">n_iter</span><span class="o">=</span><span class="n">n_iter_hptuning</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">cv_folds</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>

    <span class="c1"># random_search_coxph = RandomizedSearchCV(coxph, param_distributions=CoxPH_param_dist, n_iter=n_iter_hptuning, cv=cv_folds, random_state=SEED)</span>
    
    <span class="c1"># Fit RandomizedSearchCV on training data</span>
    <span class="n">random_search_coxph</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_surv</span><span class="p">,</span> <span class="n">y_train_surv_transformed</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best Parameters for CPH:&quot;</span><span class="p">,</span> <span class="n">random_search_coxph</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>

    <span class="c1"># Train the CPH model with the best hyperparameters</span>
    <span class="n">coxph</span> <span class="o">=</span> <span class="n">CoxnetSurvivalAnalysis</span><span class="p">(</span><span class="n">fit_baseline_model</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">random_search_coxph</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
    <span class="c1"># coxph = CoxPHSurvivalAnalysis(**random_search_coxph.best_params_)</span>
    <span class="n">coxph</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_surv</span><span class="p">,</span> <span class="n">y_train_surv_transformed</span><span class="p">)</span>
    
    <span class="c1"># Save the CPH model to disk</span>
    <span class="n">dump</span><span class="p">(</span><span class="n">coxph</span><span class="p">,</span> <span class="s1">&#39;CPH_model.pkl&#39;</span><span class="p">)</span>

    <span class="c1"># Calculate Integrated Brier Score (IBS) for CPH</span>
    <span class="n">survival_preds_cph</span> <span class="o">=</span> <span class="n">coxph</span><span class="o">.</span><span class="n">predict_survival_function</span><span class="p">(</span><span class="n">X_test_surv</span><span class="p">)</span>
    
    <span class="c1"># Generate predictions for each survival function at the valid time points</span>
    <span class="n">preds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([[</span><span class="n">fn</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">valid_times</span><span class="p">]</span> <span class="k">for</span> <span class="n">fn</span> <span class="ow">in</span> <span class="n">survival_preds_cph</span><span class="p">])</span>

    <span class="c1"># Replace NaN and infinity values in preds with finite numbers</span>
    <span class="n">estimate_cph</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan_to_num</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">nan</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">posinf</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span><span class="o">.</span><span class="n">max</span><span class="p">,</span> <span class="n">neginf</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span><span class="o">.</span><span class="n">min</span><span class="p">)</span>

    <span class="c1"># Calculate IBS for CPH</span>
    <span class="n">IBS_cph</span> <span class="o">=</span> <span class="n">integrated_brier_score</span><span class="p">(</span><span class="n">survival_train</span><span class="o">=</span><span class="n">y_train_surv_transformed</span><span class="p">,</span> <span class="n">survival_test</span><span class="o">=</span><span class="n">y_test_surv_transformed</span><span class="p">,</span> <span class="n">estimate</span><span class="o">=</span><span class="n">estimate_cph</span><span class="p">,</span> <span class="n">times</span><span class="o">=</span><span class="n">valid_times</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Integrated Brier Score for CPH on the test set: </span><span class="si">{</span><span class="n">IBS_cph</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    
    <span class="c1"># Get the concordance index (CI)</span>
    <span class="n">CI_cph</span> <span class="o">=</span> <span class="n">concordance_index_censored</span><span class="p">(</span><span class="n">event_indicator</span><span class="o">=</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">event_time</span> <span class="o">=</span> <span class="n">y_test_surv</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">estimate</span> <span class="o">=</span> <span class="n">coxph</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_surv</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;C-index for CPH on the test set: </span><span class="si">{</span><span class="n">CI_cph</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">survival_analysis</span> <span class="ow">and</span> <span class="n">external_val</span><span class="p">:</span>
    <span class="c1"># RSF model evaluation on the external validation set</span>
    <span class="c1"># Predict survival function for test data</span>
    <span class="n">survival_preds_rsf</span> <span class="o">=</span> <span class="n">rsf</span><span class="o">.</span><span class="n">predict_survival_function</span><span class="p">(</span><span class="n">X_extval_surv</span><span class="p">)</span>

    <span class="c1"># Extract event times from survival_train and survival_test</span>
    <span class="n">train_times</span> <span class="o">=</span> <span class="n">y_train_surv</span><span class="o">.</span><span class="n">values</span>  <span class="c1"># Training event times</span>
    <span class="n">test_times</span> <span class="o">=</span> <span class="n">y_extval_surv</span><span class="o">.</span><span class="n">values</span>    <span class="c1"># Test event times</span>

    <span class="c1"># Get the follow-up time interval from both training and test datasets</span>
    <span class="n">min_followup_time</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">train_times</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">test_times</span><span class="o">.</span><span class="n">min</span><span class="p">())</span>  <span class="c1"># The later start</span>
    <span class="n">max_followup_time</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">train_times</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="n">test_times</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>  <span class="c1"># The earlier end</span>

    <span class="c1"># Define valid times based on the overlap of the follow-up times from both datasets</span>
    <span class="n">valid_times</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">min_followup_time</span><span class="p">,</span> <span class="n">max_followup_time</span><span class="p">)</span>

    <span class="c1"># Ensure valid_times does not include the maximum observed time</span>
    <span class="n">valid_times</span> <span class="o">=</span> <span class="n">valid_times</span><span class="p">[</span><span class="n">valid_times</span> <span class="o">&lt;</span> <span class="n">max_followup_time</span><span class="p">]</span>

    <span class="c1"># Generate predictions for each survival function at the valid time points</span>
    <span class="n">preds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([[</span><span class="n">fn</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">valid_times</span><span class="p">]</span> <span class="k">for</span> <span class="n">fn</span> <span class="ow">in</span> <span class="n">survival_preds_rsf</span><span class="p">])</span>

    <span class="c1"># Replace NaN and infinity values in preds with finite numbers</span>
    <span class="n">estimate_rsf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan_to_num</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">nan</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">posinf</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span><span class="o">.</span><span class="n">max</span><span class="p">,</span> <span class="n">neginf</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span><span class="o">.</span><span class="n">min</span><span class="p">)</span>
    <span class="c1"># # Define a time range for the Brier score calculation based on the test data</span>
    <span class="c1"># extval_times_rsf = y_extval_surv.values</span>
    <span class="c1"># valid_times_rsf = np.linspace(extval_times_rsf.min(), extval_times_rsf.max() - 1e-5, 100)</span>
    
    <span class="c1"># # Create an estimate array for the predicted survival probabilities at each valid time point</span>
    <span class="c1"># estimate_rsf = np.zeros((len(X_extval_surv), len(valid_times_rsf)))</span>
    <span class="c1"># for i, fn in enumerate(survival_preds_rsf):</span>
    <span class="c1">#     estimate_rsf[i, :] = fn(valid_times_rsf)</span>

    <span class="c1"># Calculate IBS for RSF</span>
    <span class="n">IBS_rsf</span> <span class="o">=</span> <span class="n">integrated_brier_score</span><span class="p">(</span><span class="n">survival_train</span><span class="o">=</span><span class="n">y_train_surv_transformed</span><span class="p">,</span> <span class="n">survival_test</span><span class="o">=</span><span class="n">y_extval_surv_transformed</span><span class="p">,</span> <span class="n">estimate</span><span class="o">=</span><span class="n">estimate_rsf</span><span class="p">,</span> <span class="n">times</span><span class="o">=</span><span class="n">valid_times</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Integrated Brier Score for RSF on the external validation set: </span><span class="si">{</span><span class="n">IBS_rsf</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    
    <span class="c1"># Get the concordance index (CI)</span>
    <span class="n">CI_rsf</span> <span class="o">=</span> <span class="n">concordance_index_censored</span><span class="p">(</span><span class="n">event_indicator</span><span class="o">=</span> <span class="n">y_extval_data</span><span class="p">,</span> <span class="n">event_time</span> <span class="o">=</span> <span class="n">y_extval_surv</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">estimate</span> <span class="o">=</span> <span class="n">rsf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_extval_surv</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;C-index for RSF on the external validation set: </span><span class="si">{</span><span class="n">CI_rsf</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="feature-importance-for-the-survival-model">
<h3>feature importance for the survival model<a class="headerlink" href="#feature-importance-for-the-survival-model" title="Link to this heading">#</a></h3>
<p>For each feature it shows if its relationship to survival time is removed (by random shuffling), the concordance index on the test data drops on average by mentioned values displayed on the table.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">survival_analysis</span><span class="p">:</span>
    <span class="c1"># RSF model</span>
    <span class="n">perm_result</span> <span class="o">=</span> <span class="n">permutation_importance</span><span class="p">(</span><span class="n">rsf</span><span class="p">,</span> <span class="n">X_test_surv</span><span class="p">,</span> <span class="n">y_test_surv_transformed</span><span class="p">,</span> <span class="n">n_repeats</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>

    <span class="n">RSF_perm_fi</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
        <span class="p">{</span>
            <span class="n">k</span><span class="p">:</span> <span class="n">perm_result</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="p">(</span>
                <span class="s2">&quot;importances_mean&quot;</span><span class="p">,</span>
                <span class="s2">&quot;importances_std&quot;</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">},</span>
        <span class="n">index</span><span class="o">=</span><span class="n">X_test_surv</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span>
    <span class="p">)</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s2">&quot;importances_mean&quot;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="n">RSF_perm_fi</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>One of the methods based on SHAP that is implemented for survival ML models like RSF is to use SurvSHAP(t). It provides time-dependent explanations for the survival machine learning models. The impact of a variable over the observation period may change and that is the information that SurvSHAP(t) can reveal. SurvSHAP(t) is explained in details in <a class="reference external" href="https://www.sciencedirect.com/science/article/pii/S0950705122013302?via%3Dihub">https://www.sciencedirect.com/science/article/pii/S0950705122013302?via%3Dihub</a> .</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># here we can see the impact of variables over time on the predictions of the survival model for one sample (patient)</span>
<span class="k">if</span> <span class="n">survival_analysis</span><span class="p">:</span>
    <span class="c1"># adopted from https://pypi.org/project/survshap/</span>

    <span class="c1"># create explainer(X_train_surv, y_train_surv_transformed)</span>
    <span class="n">rsf_exp</span> <span class="o">=</span> <span class="n">SurvivalModelExplainer</span><span class="p">(</span><span class="n">model</span> <span class="o">=</span> <span class="n">rsf</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">X_train_surv</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">y_train_surv_transformed</span><span class="p">)</span>

    <span class="c1"># compute SHAP values for a single instance</span>
    <span class="n">observation_A</span> <span class="o">=</span> <span class="n">X_train_surv</span><span class="o">.</span><span class="n">iloc</span><span class="p">[[</span><span class="mi">0</span><span class="p">]]</span>
    <span class="n">survshap_A</span> <span class="o">=</span> <span class="n">PredictSurvSHAP</span><span class="p">(</span>
        <span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">,</span>        <span class="c1"># Set the random seed for reproducibility</span>
        <span class="n">function_type</span> <span class="o">=</span> <span class="s2">&quot;chf&quot;</span><span class="p">,</span> <span class="c1"># Either &quot;sf&quot; representing survival function or &quot;chf&quot; representing cumulative hazard function (use chf if you want to see the direction of the feature impact aligned with binary classification models: positive SHAP equivalent to increase risk)</span>
        <span class="n">calculation_method</span><span class="o">=</span><span class="s2">&quot;sampling&quot;</span>  <span class="c1"># &quot;shap_kernel&quot; for shap.KernelExplainer, &quot;kernel&quot; for exact KernelSHAP, &quot;sampling&quot; for sampling method, or &quot;treeshap&quot; for shap.TreeExplainer</span>
    <span class="p">)</span>
    <span class="n">survshap_A</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">explainer</span> <span class="o">=</span> <span class="n">rsf_exp</span><span class="p">,</span> <span class="n">new_observation</span> <span class="o">=</span> <span class="n">observation_A</span><span class="p">)</span>

    <span class="n">survshap_A</span><span class="o">.</span><span class="n">result</span> 
    <span class="n">survshap_A</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># now we can get the survival SHAP values for a group of patients (samples) or all samples on the test set for example</span>
<span class="k">if</span> <span class="n">survival_analysis</span><span class="p">:</span>
    <span class="c1"># rsf_exp = SurvivalModelExplainer(rsf, X_train_surv, y_train_surv_transformed)</span>

    <span class="c1"># you can set this to smaller numbers for a subset of samples patients if it takes too long</span>
    <span class="n">n_samples</span> <span class="o">=</span> <span class="n">X_test_surv</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">parallel_compute_shap_surv</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">i</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the SHAP values for a single patient or sample using parallel computing.</span>
<span class="sd">        This function is used to compute the SHAP (SHapley Additive exPlanations) values for a single patient or sample in parallel, using the `parallel_compute_shap_surv` approach. It takes a pandas DataFrame `data` and an integer index `i` as input, and returns an object of type `PredictSurvSHAP`, which contains the computed SHAP values.</span>

<span class="sd">        The function uses the `Parallel` class from the `loky` library to run multiple iterations of the computation in parallel, taking advantage of multiple CPU cores for speedup. The number of CPU cores used is controlled by the `n_cpu_for_tuning` variable, which can be adjusted depending on the system&#39;s capabilities and the size of the dataset.</span>

<span class="sd">        The function is then applied to a range of indices using a list comprehension, and the resulting objects are collected into a list called `survshaps`. This approach allows for efficient computation of SHAP values for all samples in the test set.</span>

<span class="sd">        Parameters:</span>
<span class="sd">            data (pandas DataFrame): The input data.</span>
<span class="sd">            i (int): The index of the patient or sample to compute SHAP values for.</span>

<span class="sd">        ## Returns</span>
<span class="sd">            PredictSurvSHAP: An object containing the computed SHAP values.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">survshap</span> <span class="o">=</span> <span class="n">PredictSurvSHAP</span><span class="p">(</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">SEED</span><span class="p">,</span> <span class="n">function_type</span> <span class="o">=</span> <span class="s2">&quot;chf&quot;</span><span class="p">,</span> <span class="n">calculation_method</span><span class="o">=</span><span class="s2">&quot;sampling&quot;</span><span class="p">)</span>
        <span class="n">survshap</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">rsf_exp</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[[</span><span class="n">i</span><span class="p">]])</span>
        <span class="k">return</span> <span class="n">survshap</span>
    <span class="c1"># run it in parallel to speed up the processing</span>
    <span class="n">survshaps</span> <span class="o">=</span> <span class="n">Parallel</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=</span><span class="n">n_cpu_for_tuning</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="s1">&#39;loky&#39;</span><span class="p">)(</span><span class="n">delayed</span><span class="p">(</span><span class="n">parallel_compute_shap_surv</span><span class="p">)(</span><span class="n">X_test_surv</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_samples</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">external_val</span><span class="p">:</span>
        <span class="n">survshaps_extval</span> <span class="o">=</span> <span class="n">Parallel</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=</span><span class="n">n_cpu_for_tuning</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="s1">&#39;loky&#39;</span><span class="p">)(</span><span class="n">delayed</span><span class="p">(</span><span class="n">parallel_compute_shap_surv</span><span class="p">)(</span><span class="n">X_extval_surv</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_samples</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">survival_analysis</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">plot_survshap_detailed</span><span class="p">(</span><span class="n">shap_results</span><span class="p">,</span> <span class="n">top_n</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">sample_percentage</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Optimized function to plot SHAP values over time for the top N features on separate subplots,</span>
<span class="sd">        with an option to randomly sample a percentage of the data for each feature.</span>

<span class="sd">        Parameters:</span>
<span class="sd">        shap_results: List of SHAP results for each sample.</span>
<span class="sd">        top_n: The number of top features to plot based on mean of max absolute SHAP values.</span>
<span class="sd">        sample_percentage: Percentage of samples randomly selected to be displayed on the plots (0 &lt; sample_percentage &lt;= 100).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Combine results from all samples into one DataFrame</span>
        <span class="n">shap_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">shap</span><span class="o">.</span><span class="n">result</span> <span class="k">for</span> <span class="n">shap</span> <span class="ow">in</span> <span class="n">shap_results</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        
        <span class="c1"># Extract time columns (assuming they start with &#39;t = &#39;)</span>
        <span class="n">time_columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">col</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">shap_df</span><span class="o">.</span><span class="n">columns</span> <span class="k">if</span> <span class="n">col</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;t =&#39;</span><span class="p">)]</span>
        
        <span class="c1"># Get unique feature names</span>
        <span class="n">feature_names</span> <span class="o">=</span> <span class="n">shap_df</span><span class="p">[</span><span class="s1">&#39;variable_name&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span>

        <span class="c1"># Precompute mean of max absolute SHAP values for each feature</span>
        <span class="n">feature_data_dict</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">feature_name</span> <span class="ow">in</span> <span class="n">feature_names</span><span class="p">:</span>
            <span class="n">feature_data</span> <span class="o">=</span> <span class="n">shap_df</span><span class="p">[</span><span class="n">shap_df</span><span class="p">[</span><span class="s1">&#39;variable_name&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">feature_name</span><span class="p">]</span>
            <span class="n">shap_values</span> <span class="o">=</span> <span class="n">feature_data</span><span class="p">[</span><span class="n">time_columns</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>

            <span class="c1"># Calculate the max absolute SHAP value for each sample and then compute the mean across all samples</span>
            <span class="n">max_abs_shap_per_sample</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">shap_values</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">max_max_abs_shap</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">max_abs_shap_per_sample</span><span class="p">)</span>
            
            <span class="n">feature_data_dict</span><span class="p">[</span><span class="n">feature_name</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s1">&#39;data&#39;</span><span class="p">:</span> <span class="n">feature_data</span><span class="p">,</span>
                <span class="s1">&#39;shap_values&#39;</span><span class="p">:</span> <span class="n">shap_values</span><span class="p">,</span>
                <span class="s1">&#39;max_max_abs_shap&#39;</span><span class="p">:</span> <span class="n">max_max_abs_shap</span>
            <span class="p">}</span>

        <span class="c1"># Sort features by their max of max absolute SHAP value and take only the top N features</span>
        <span class="n">sorted_features</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">feature_data_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">feature_data_dict</span><span class="p">[</span><span class="n">x</span><span class="p">][</span><span class="s1">&#39;max_max_abs_shap&#39;</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)[:</span><span class="n">top_n</span><span class="p">]</span>
        
        <span class="c1"># Create subplots</span>
        <span class="n">num_features</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">sorted_features</span><span class="p">)</span>
        <span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">num_features</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">num_features</span><span class="p">),</span> <span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">constrained_layout</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">num_features</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">axes</span> <span class="o">=</span> <span class="p">[</span><span class="n">axes</span><span class="p">]</span>  <span class="c1"># Ensure axes is iterable if only one subplot</span>

        <span class="c1"># Colormap for feature values</span>
        <span class="n">cmap</span> <span class="o">=</span> <span class="n">cm</span><span class="o">.</span><span class="n">get_cmap</span><span class="p">(</span><span class="s1">&#39;coolwarm&#39;</span><span class="p">)</span>

        <span class="c1"># Process and plot each feature</span>
        <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="n">feature_name</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">axes</span><span class="p">,</span> <span class="n">sorted_features</span><span class="p">)):</span>
            <span class="c1"># Get data and SHAP values for the specific feature</span>
            <span class="n">feature_data</span> <span class="o">=</span> <span class="n">feature_data_dict</span><span class="p">[</span><span class="n">feature_name</span><span class="p">][</span><span class="s1">&#39;data&#39;</span><span class="p">]</span>
            <span class="n">shap_values</span> <span class="o">=</span> <span class="n">feature_data_dict</span><span class="p">[</span><span class="n">feature_name</span><span class="p">][</span><span class="s1">&#39;shap_values&#39;</span><span class="p">]</span>
            <span class="n">feature_values</span> <span class="o">=</span> <span class="n">feature_data</span><span class="p">[</span><span class="s1">&#39;variable_value&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
            
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">shap_values</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">continue</span>

            <span class="c1"># Randomly select a subset of samples if sample_percentage &lt; 100</span>
            <span class="k">if</span> <span class="n">sample_percentage</span> <span class="o">&lt;</span> <span class="mi">100</span><span class="p">:</span>
                <span class="n">num_samples</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">feature_data</span><span class="p">)</span>
                <span class="n">sample_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">num_samples</span> <span class="o">*</span> <span class="p">(</span><span class="n">sample_percentage</span> <span class="o">/</span> <span class="mi">100</span><span class="p">))</span>
                <span class="n">sampled_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">num_samples</span><span class="p">,</span> <span class="n">sample_size</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                <span class="n">shap_values</span> <span class="o">=</span> <span class="n">shap_values</span><span class="p">[</span><span class="n">sampled_indices</span><span class="p">]</span>
                <span class="n">feature_values</span> <span class="o">=</span> <span class="n">feature_values</span><span class="p">[</span><span class="n">sampled_indices</span><span class="p">]</span>

            <span class="c1"># feature value normalization</span>
            <span class="n">normalized_values</span> <span class="o">=</span> <span class="n">QuantileTransformer</span><span class="p">(</span><span class="n">output_distribution</span><span class="o">=</span><span class="s1">&#39;uniform&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">feature_values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
            
            <span class="c1"># Plot SHAP values for each sample</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">shap_values</span><span class="p">)):</span>
                <span class="n">color</span> <span class="o">=</span> <span class="n">cmap</span><span class="p">(</span><span class="n">normalized_values</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
                <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">time_columns</span><span class="p">,</span> <span class="n">shap_values</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            
            <span class="c1"># Title and Y-axis label</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">feature_name</span><span class="si">}</span><span class="s2"> (grand max |SHAP|: </span><span class="si">{</span><span class="n">feature_data_dict</span><span class="p">[</span><span class="n">feature_name</span><span class="p">][</span><span class="s1">&#39;max_max_abs_shap&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;SHAP value&quot;</span><span class="p">)</span>
            
            <span class="c1"># Horizontal line at y=0</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;grey&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;:&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        
        <span class="c1"># Simplify x-axis labels</span>
        <span class="n">xticks_interval</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">time_columns</span><span class="p">)</span> <span class="o">//</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># Ensure at least some ticks show up</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">time_columns</span><span class="p">[::</span><span class="n">xticks_interval</span><span class="p">],</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">)</span>

        <span class="c1"># Colorbar for all subplots</span>
        <span class="n">sm</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">ScalarMappable</span><span class="p">(</span><span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">)</span>
        <span class="n">sm</span><span class="o">.</span><span class="n">set_array</span><span class="p">([])</span>
        <span class="n">fig</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">sm</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">,</span> <span class="n">orientation</span><span class="o">=</span><span class="s1">&#39;vertical&#39;</span><span class="p">,</span> <span class="n">fraction</span><span class="o">=</span><span class="mf">0.02</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="mf">0.02</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Feature Value&#39;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">plt</span>

    <span class="n">survshaps_plt</span> <span class="o">=</span> <span class="n">plot_survshap_detailed</span><span class="p">(</span><span class="n">survshaps</span><span class="p">,</span> <span class="n">top_n</span><span class="o">=</span><span class="n">top_n_f</span><span class="p">,</span> <span class="n">sample_percentage</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span> <span class="c1"># plot top top_n_f features for 100% of samples from the test set</span>
    <span class="n">survshaps_plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;shap_surv_curves_testset.tif&#39;</span><span class="p">,</span> <span class="n">bbox_inches</span><span class="o">=</span><span class="s1">&#39;tight&#39;</span><span class="p">)</span>
    <span class="n">survshaps_plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">survival_analysis</span> <span class="ow">and</span> <span class="n">external_val</span><span class="p">:</span>
    <span class="n">survshaps_extval_plt</span> <span class="o">=</span> <span class="n">plot_survshap_detailed</span><span class="p">(</span><span class="n">survshaps_extval</span><span class="p">,</span> <span class="n">top_n</span><span class="o">=</span><span class="n">top_n_f</span><span class="p">,</span> <span class="n">sample_percentage</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span> <span class="c1"># plot top top_n_f features for 100% of samples from the test set</span>
    <span class="n">survshaps_extval_plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;shap_surv_curves_extval.tif&#39;</span><span class="p">,</span> <span class="n">bbox_inches</span><span class="o">=</span><span class="s1">&#39;tight&#39;</span><span class="p">)</span>
    <span class="n">survshaps_extval_plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># here we aggregate the shap values for each feature (variable) and display a SHAP summary plot based on the SHAP values calculated using survSHAP(t) for survival models</span>
<span class="c1"># What we see here is the feature values and their relationships with the SHAP values (that could not be shown on the previous plot with SHAP values over time)</span>
<span class="k">if</span> <span class="n">survival_analysis</span><span class="p">:</span>

    <span class="k">def</span> <span class="nf">aggregate_shap_values_with_base</span><span class="p">(</span><span class="n">survshaps</span><span class="p">,</span> <span class="n">X_test_surv</span><span class="p">,</span> <span class="n">aggregation</span><span class="o">=</span><span class="s1">&#39;mean_abs&#39;</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Aggregate SHAP values from a survival model.</span>

<span class="sd">        ## Parameters</span>
<span class="sd">            survshaps (list): A list of Shapely objects containing survival model results.</span>
<span class="sd">            X_test_surv (pd.DataFrame): The test set used for feature selection and model evaluation.</span>
<span class="sd">            aggregation (str, optional): The method to use for aggregating SHAP values. Can be &#39;mean_abs&#39;, &#39;sum&#39;, or &#39;mean&#39;. Defaults to &#39;mean_abs&#39;.</span>

<span class="sd">        ## Returns</span>
<span class="sd">            tuple: A tuple containing two arrays:</span>
<span class="sd">                - shap_values (np.ndarray): An array of shape (n_samples, n_features) where each row represents the aggregated SHAP value for a sample.</span>
<span class="sd">                - base_values (np.ndarray): An array of shape (n_samples,) where each element is the base value for a sample.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">n_features</span> <span class="o">=</span> <span class="n">X_test_surv</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># Number of features in the test set </span>
        <span class="n">n_samples</span> <span class="o">=</span> <span class="n">X_test_surv</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>   <span class="c1"># Number of samples</span>
        <span class="n">shap_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span><span class="p">))</span>  <span class="c1"># Initialize shap_values array</span>
        <span class="n">base_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span>   <span class="c1"># Initialize base_values array</span>

        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">survshap</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">survshaps</span><span class="p">):</span>
            <span class="n">shap_df</span> <span class="o">=</span> <span class="n">survshap</span><span class="o">.</span><span class="n">result</span>

            <span class="c1"># Extract columns corresponding to time points (these contain SHAP values)</span>
            <span class="n">time_point_columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">col</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">shap_df</span><span class="o">.</span><span class="n">columns</span> <span class="k">if</span> <span class="n">col</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;t =&#39;</span><span class="p">)]</span>
            <span class="n">shap_values_sample</span> <span class="o">=</span> <span class="n">shap_df</span><span class="p">[</span><span class="n">time_point_columns</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>  <span class="c1"># shape: (n_timepoints, n_features_per_timepoint)</span>
            
            <span class="c1"># Group SHAP values by feature</span>
            <span class="n">feature_groups</span> <span class="o">=</span> <span class="n">shap_df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;variable_name&#39;</span><span class="p">)</span>

            <span class="c1"># Initialize temporary array to store aggregated SHAP values per feature for this sample</span>
            <span class="n">shap_values_aggregated</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_features</span><span class="p">)</span>
            
            <span class="k">for</span> <span class="n">feature_name</span><span class="p">,</span> <span class="n">group</span> <span class="ow">in</span> <span class="n">feature_groups</span><span class="p">:</span>
                <span class="c1"># Aggregate SHAP values across time points for each feature</span>
                <span class="k">if</span> <span class="n">aggregation</span> <span class="o">==</span> <span class="s1">&#39;mean_abs&#39;</span><span class="p">:</span>
                    <span class="n">shap_agg</span> <span class="o">=</span> <span class="n">group</span><span class="p">[</span><span class="n">time_point_columns</span><span class="p">]</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Aggregating by absolute mean</span>
                <span class="k">elif</span> <span class="n">aggregation</span> <span class="o">==</span> <span class="s1">&#39;sum&#39;</span><span class="p">:</span>
                    <span class="n">shap_agg</span> <span class="o">=</span> <span class="n">group</span><span class="p">[</span><span class="n">time_point_columns</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Aggregating by sum</span>
                <span class="k">elif</span> <span class="n">aggregation</span> <span class="o">==</span> <span class="s1">&#39;mean&#39;</span><span class="p">:</span>
                    <span class="n">shap_agg</span> <span class="o">=</span> <span class="n">group</span><span class="p">[</span><span class="n">time_point_columns</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Aggregating by mean</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unknown aggregation method: </span><span class="si">{</span><span class="n">aggregation</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

                <span class="c1"># Map the aggregated SHAP values to the correct feature in shap_values_aggregated</span>
                <span class="n">feature_idx</span> <span class="o">=</span> <span class="n">X_test_surv</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">get_loc</span><span class="p">(</span><span class="n">feature_name</span><span class="p">)</span>  <span class="c1"># Get the index of the feature</span>
                <span class="n">shap_values_aggregated</span><span class="p">[</span><span class="n">feature_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">shap_agg</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>  <span class="c1"># Store the aggregated value for this feature</span>
            
            <span class="c1"># Store the aggregated SHAP values for this sample</span>
            <span class="n">shap_values</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">shap_values_aggregated</span>

            <span class="c1"># Extract base value if available</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">survshap</span><span class="p">,</span> <span class="s1">&#39;base_value&#39;</span><span class="p">):</span>
                <span class="n">base_values</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">survshap</span><span class="o">.</span><span class="n">base_value</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">base_values</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># Default or adjust as needed</span>
        
        <span class="k">return</span> <span class="n">shap_values</span><span class="p">,</span> <span class="n">base_values</span>

    <span class="c1"># getting the shap summary plot for the survival model (RSF) on the test set</span>
    <span class="n">shap_values</span><span class="p">,</span> <span class="n">base_values</span> <span class="o">=</span> <span class="n">aggregate_shap_values_with_base</span><span class="p">(</span><span class="n">survshaps</span><span class="p">,</span> <span class="n">X_test_surv</span><span class="p">,</span> <span class="n">aggregation</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span>

    <span class="c1"># Create the Explanation object with per-sample base_values</span>
    <span class="n">explainer_values</span> <span class="o">=</span> <span class="n">shap</span><span class="o">.</span><span class="n">Explanation</span><span class="p">(</span>
        <span class="n">values</span><span class="o">=</span><span class="n">shap_values</span><span class="p">,</span>
        <span class="n">base_values</span><span class="o">=</span><span class="n">base_values</span><span class="p">,</span>
        <span class="n">data</span><span class="o">=</span><span class="n">X_test_surv</span><span class="p">,</span>
        <span class="n">feature_names</span><span class="o">=</span><span class="n">X_test_surv</span><span class="o">.</span><span class="n">columns</span>
    <span class="p">)</span>

    <span class="n">shap</span><span class="o">.</span><span class="n">plots</span><span class="o">.</span><span class="n">beeswarm</span><span class="p">(</span><span class="n">explainer_values</span><span class="p">,</span> <span class="n">max_display</span><span class="o">=</span><span class="n">top_n_f</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s2">&quot;shap_beeswarm_testset.tif&quot;</span><span class="p">,</span> <span class="n">bbox_inches</span><span class="o">=</span><span class="s1">&#39;tight&#39;</span><span class="p">)</span>
    
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># getting the shap summary plot for the survival model (RSF) on the external validation set</span>
<span class="k">if</span> <span class="n">survival_analysis</span> <span class="ow">and</span> <span class="n">external_val</span><span class="p">:</span>
    <span class="n">shap_values_extval</span><span class="p">,</span> <span class="n">base_values_extval</span> <span class="o">=</span> <span class="n">aggregate_shap_values_with_base</span><span class="p">(</span><span class="n">survshaps_extval</span><span class="p">,</span> <span class="n">X_extval_surv</span><span class="p">,</span> <span class="n">aggregation</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span>

    <span class="c1"># Create the Explanation object with per-sample base_values</span>
    <span class="n">explainer_values_extval</span> <span class="o">=</span> <span class="n">shap</span><span class="o">.</span><span class="n">Explanation</span><span class="p">(</span>
        <span class="n">values</span><span class="o">=</span><span class="n">shap_values_extval</span><span class="p">,</span>
        <span class="n">base_values</span><span class="o">=</span><span class="n">base_values_extval</span><span class="p">,</span>
        <span class="n">data</span><span class="o">=</span><span class="n">X_extval_surv</span><span class="p">,</span>
        <span class="n">feature_names</span><span class="o">=</span><span class="n">X_extval_surv</span><span class="o">.</span><span class="n">columns</span>
    <span class="p">)</span>

    <span class="n">shap</span><span class="o">.</span><span class="n">plots</span><span class="o">.</span><span class="n">beeswarm</span><span class="p">(</span><span class="n">explainer_values_extval</span><span class="p">,</span> <span class="n">max_display</span><span class="o">=</span><span class="n">top_n_f</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s2">&quot;shap_beeswarm_extval.tif&quot;</span><span class="p">,</span> <span class="n">bbox_inches</span><span class="o">=</span><span class="s1">&#39;tight&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">f_imp_shapboxplot_surv</span><span class="p">(</span><span class="n">shap_values</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">num_features</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">num_subsamples</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">random_seed</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">apply_threshold</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The `f_imp_shapboxplot_surv` function generates an importance plot for SHAP (SHapley Additive exPlanations) values to identify the most influential features in a model. The function takes in SHAP value arrays, test data, and various parameters to customize the plot.</span>

<span class="sd">    Functionality:</span>

<span class="sd">    1. Compute median, lower quantile, and upper quantile of absolute SHAP values for all features.</span>
<span class="sd">    2. Sort features by median absolute SHAP value in descending order and select the top N most important features (default N=20).</span>
<span class="sd">    3. Perform an IQR crossing test with subsamples to determine feature significance.</span>
<span class="sd">    4. Mark significant features with an asterisk based on the IQR crossing test results.</span>
<span class="sd">    5. Plot a boxplot of the distribution of absolute SHAP values for the selected features, using different colors for significant and non-significant features.</span>

<span class="sd">    ## Parameters:</span>

<span class="sd">    `shap_values`: array of SHAP value arrays</span>
<span class="sd">    `X_test`: test data</span>
<span class="sd">    `num_features`: number of top features to select (default=20)</span>
<span class="sd">    `num_subsamples`: number of subsamples for the IQR crossing test (default=1000)</span>
<span class="sd">    `random_seed`: random seed for reproducibility (optional)</span>
<span class="sd">    `apply_threshold`: apply threshold to SHAP values (default=False)</span>

<span class="sd">    ## Returns</span>

<span class="sd">    A pandas DataFrame containing the top N most important features, including their median and quantile SHAP values, subsample proportion crossing zero, and significance status.</span>
<span class="sd">    A matplotlib plot of the boxplot showing the distribution of absolute SHAP values for the selected features.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Use absolute SHAP values for median and quantiles</span>
    <span class="n">abs_shap_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">shap_values</span><span class="p">)</span>
    <span class="n">median_abs_shap_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">abs_shap_values</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">lower_quantiles</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">abs_shap_values</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># 25th percentile of absolute values</span>
    <span class="n">upper_quantiles</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">abs_shap_values</span><span class="p">,</span> <span class="mi">75</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># 75th percentile of absolute values</span>

    <span class="n">feature_importance_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
        <span class="s1">&#39;Feature&#39;</span><span class="p">:</span> <span class="n">X_test</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span>
        <span class="s1">&#39;Median_SHAP&#39;</span><span class="p">:</span> <span class="n">median_abs_shap_values</span><span class="p">,</span>
        <span class="s1">&#39;Lower_Quantile&#39;</span><span class="p">:</span> <span class="n">lower_quantiles</span><span class="p">,</span>
        <span class="s1">&#39;Upper_Quantile&#39;</span><span class="p">:</span> <span class="n">upper_quantiles</span>
    <span class="p">})</span>

    <span class="c1"># Sort the features by median absolute SHAP values in descending order</span>
    <span class="n">feature_importance_df</span> <span class="o">=</span> <span class="n">feature_importance_df</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">&#39;Median_SHAP&#39;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">apply_threshold</span><span class="p">:</span>
        <span class="c1"># Compute the sum of SHAP values for instance</span>
        <span class="n">sum_shap_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">shap_values</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">sum_shap_values</span><span class="p">))</span>

        <span class="c1"># Define threshold as the 1st percentile of the sum of SHAP values</span>
        <span class="n">shap_threshold</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">sum_shap_values</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">shap_threshold</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">shap_threshold</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># Select the top N most important features</span>
    <span class="n">top_features</span> <span class="o">=</span> <span class="n">feature_importance_df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="n">num_features</span><span class="p">)</span>

    <span class="c1"># Initialize lists to store subsample results</span>
    <span class="n">subsample_results</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">is_significant</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">top_features</span><span class="o">.</span><span class="n">index</span><span class="p">:</span>
        <span class="n">feature_shap_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">shap_values</span><span class="p">[:,</span> <span class="n">i</span><span class="p">])</span>
        <span class="c1"># Perform the IQR crossing test with subsamples</span>
        <span class="n">proportion_crossing_zero</span> <span class="o">=</span> <span class="n">subsample_iqr_test</span><span class="p">(</span><span class="n">feature_shap_values</span><span class="p">,</span> <span class="n">num_subsamples</span><span class="o">=</span><span class="n">num_subsamples</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="n">shap_threshold</span><span class="p">,</span> <span class="n">random_seed</span><span class="o">=</span><span class="n">random_seed</span><span class="p">)</span>
        
        <span class="c1"># A feature is significant if less than (1 - confidence_level)% of the subsamples cross zero</span>
        <span class="n">significant</span> <span class="o">=</span> <span class="n">proportion_crossing_zero</span> <span class="o">&lt;=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="mf">0.95</span><span class="p">)</span>
        <span class="n">is_significant</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">significant</span><span class="p">)</span>
        
        <span class="n">subsample_results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">proportion_crossing_zero</span><span class="p">)</span>

    <span class="c1"># Add the subsample results and significance to the DataFrame</span>
    <span class="n">top_features</span><span class="p">[</span><span class="s1">&#39;Subsample_Proportion_Crossing_Zero&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">subsample_results</span>
    <span class="n">top_features</span><span class="p">[</span><span class="s1">&#39;Significant&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">is_significant</span>
    
    <span class="c1"># Mark significant features with an asterisk</span>
    <span class="n">top_features</span><span class="p">[</span><span class="s1">&#39;Feature&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">top_features</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">row</span><span class="p">:</span> <span class="n">row</span><span class="p">[</span><span class="s1">&#39;Feature&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="s1">&#39;*&#39;</span> <span class="k">if</span> <span class="n">row</span><span class="p">[</span><span class="s1">&#39;Significant&#39;</span><span class="p">]</span> <span class="k">else</span> <span class="s1">&#39;&#39;</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="c1"># Prepare colors based on significance: light green for significant, light red for non-significant</span>
    <span class="n">colors</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;lightgreen&#39;</span> <span class="k">if</span> <span class="n">sig</span> <span class="k">else</span> <span class="s1">&#39;lightcoral&#39;</span> <span class="k">for</span> <span class="n">sig</span> <span class="ow">in</span> <span class="n">top_features</span><span class="p">[</span><span class="s1">&#39;Significant&#39;</span><span class="p">]]</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="o">+</span><span class="nb">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">num_features</span><span class="p">)]))))</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">shap_values</span><span class="p">[:,</span> <span class="n">top_features</span><span class="o">.</span><span class="n">index</span><span class="p">[:</span><span class="n">num_features</span><span class="p">]]),</span> <span class="n">orient</span><span class="o">=</span><span class="s1">&#39;h&#39;</span><span class="p">,</span> <span class="n">whis</span><span class="o">=</span><span class="p">[</span><span class="mi">25</span><span class="p">,</span> <span class="mi">75</span><span class="p">],</span> 
                <span class="n">width</span><span class="o">=</span><span class="mf">.5</span><span class="p">,</span> <span class="n">flierprops</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;marker&quot;</span><span class="p">:</span> <span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="s2">&quot;alpha&quot;</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">},</span> <span class="n">palette</span><span class="o">=</span><span class="n">colors</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>

    <span class="c1"># Customize the plot</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">num_features</span><span class="p">),</span> <span class="n">top_features</span><span class="p">[</span><span class="s1">&#39;Feature&#39;</span><span class="p">],</span> <span class="n">size</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;:&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Absolute SHAP value&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Feature&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Distribution of absolute SHAP values for all available features&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">top_features</span><span class="p">,</span> <span class="n">plt</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">survival_analysis</span><span class="p">:</span>   
    <span class="n">f_imp_shap_table_testset_surv</span><span class="p">,</span> <span class="n">f_imp_shapboxplot_testset_surv</span> <span class="o">=</span> <span class="n">f_imp_shapboxplot_surv</span><span class="p">(</span><span class="n">shap_values</span><span class="p">,</span> <span class="n">X_test_surv</span><span class="p">,</span> <span class="n">num_features</span><span class="o">=</span><span class="n">X_test_surv</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">random_seed</span><span class="o">=</span> <span class="n">SEED</span><span class="p">,</span> <span class="n">apply_threshold</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">f_imp_shapboxplot_testset_surv</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">f_imp_shapboxplot_testset_surv</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s2">&quot;f_imp_shapboxplot_testset_surv.tif&quot;</span><span class="p">,</span> <span class="n">bbox_inches</span><span class="o">=</span><span class="s1">&#39;tight&#39;</span><span class="p">)</span> 
    <span class="n">f_imp_shapboxplot_testset_surv</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">f_imp_shap_table_testset_surv</span><span class="p">)</span>
    <span class="n">f_imp_shap_table_testset_surv</span><span class="o">.</span><span class="n">to_excel</span><span class="p">(</span><span class="s1">&#39;f_imp_shap_table_testset_surv.xlsx&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">survival_analysis</span> <span class="ow">and</span> <span class="n">external_val</span><span class="p">:</span>   

    <span class="n">f_imp_shap_table_extval_surv</span><span class="p">,</span> <span class="n">f_imp_shapboxplot_extval_surv</span> <span class="o">=</span> <span class="n">f_imp_shapboxplot_surv</span><span class="p">(</span><span class="n">shap_values_extval</span><span class="p">,</span> <span class="n">X_extval_surv</span><span class="p">,</span> <span class="n">num_features</span><span class="o">=</span><span class="n">X_extval_surv</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">random_seed</span><span class="o">=</span> <span class="n">SEED</span><span class="p">,</span> <span class="n">apply_threshold</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="n">f_imp_shapboxplot_extval_surv</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">f_imp_shapboxplot_extval_surv</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s2">&quot;f_imp_shapboxplot_extval_thr0_surv.tif&quot;</span><span class="p">,</span> <span class="n">bbox_inches</span><span class="o">=</span><span class="s1">&#39;tight&#39;</span><span class="p">)</span> 
    <span class="n">f_imp_shapboxplot_extval_surv</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">f_imp_shap_table_extval_surv</span><span class="p">)</span>
    <span class="n">f_imp_shap_table_extval_surv</span><span class="o">.</span><span class="n">to_excel</span><span class="p">(</span><span class="s1">&#39;f_imp_shap_table_extval_thr0_surv.xlsx&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">survival_analysis</span> <span class="ow">and</span> <span class="n">external_val</span><span class="p">:</span>   
    <span class="n">f_imp_shap_table_extval_surv</span><span class="p">,</span> <span class="n">f_imp_shapboxplot_extval_surv</span> <span class="o">=</span> <span class="n">f_imp_shapboxplot_surv</span><span class="p">(</span><span class="n">shap_values_extval</span><span class="p">,</span> <span class="n">X_extval_surv</span><span class="p">,</span> <span class="n">num_features</span><span class="o">=</span><span class="n">X_extval_surv</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">random_seed</span><span class="o">=</span> <span class="n">SEED</span><span class="p">,</span> <span class="n">apply_threshold</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">f_imp_shapboxplot_extval_surv</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">f_imp_shapboxplot_extval_surv</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s2">&quot;f_imp_shapboxplot_extval_surv.tif&quot;</span><span class="p">,</span> <span class="n">bbox_inches</span><span class="o">=</span><span class="s1">&#39;tight&#39;</span><span class="p">)</span> 
    <span class="n">f_imp_shapboxplot_extval_surv</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">f_imp_shap_table_extval_surv</span><span class="p">)</span>
    <span class="n">f_imp_shap_table_extval_surv</span><span class="o">.</span><span class="n">to_excel</span><span class="p">(</span><span class="s1">&#39;f_imp_shap_table_extval_surv.xlsx&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="predicted-survival-and-cumulative-hazard">
<h3>Predicted survival and cumulative hazard<a class="headerlink" href="#predicted-survival-and-cumulative-hazard" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">survival_analysis</span><span class="p">:</span>
    <span class="c1"># Predict cumulative hazard function for all training samples</span>
    <span class="c1"># The informaiton here will be used to translate the predicted hazard functions for each individuals in the test set (or external validation set) to binary classifcation</span>
    <span class="n">surv_train</span> <span class="o">=</span> <span class="n">rsf</span><span class="o">.</span><span class="n">predict_cumulative_hazard_function</span><span class="p">(</span><span class="n">X_train_surv</span><span class="p">,</span> <span class="n">return_array</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">class_0_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y_train</span><span class="o">.</span><span class="n">values</span> <span class="o">==</span> <span class="kc">False</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> 
    <span class="n">class_1_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y_train</span><span class="o">.</span><span class="n">values</span> <span class="o">==</span> <span class="kc">True</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> 

    <span class="c1"># Separate predictions into classes</span>
    <span class="n">surv_class_0</span> <span class="o">=</span> <span class="n">surv_train</span><span class="p">[</span><span class="n">class_0_indices</span><span class="p">]</span>
    <span class="n">surv_class_1</span> <span class="o">=</span> <span class="n">surv_train</span><span class="p">[</span><span class="n">class_1_indices</span><span class="p">]</span>

    <span class="c1"># Calculate median and interquartile range for both classes</span>
    <span class="n">median_hazard_class_0_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">surv_class_0</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">median_hazard_class_1_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">surv_class_1</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    
    <span class="n">rsf_riskscores_train</span> <span class="o">=</span> <span class="n">rsf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train_surv</span><span class="p">)</span>
    
    <span class="c1"># Calculate average risk scores for each class in the training set</span>
    <span class="n">predicted_risk_socres_class_0</span> <span class="o">=</span> <span class="n">rsf_riskscores_train</span><span class="p">[</span><span class="n">y_train</span><span class="p">]</span>
    <span class="n">predicted_risk_socres_class_1</span> <span class="o">=</span> <span class="n">rsf_riskscores_train</span><span class="p">[</span><span class="o">~</span><span class="n">y_train</span><span class="p">]</span>
    
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">survival_analysis</span><span class="p">:</span>
    
    <span class="c1"># Predict cumulative hazard function for all test samples</span>
    <span class="n">surv</span> <span class="o">=</span> <span class="n">rsf</span><span class="o">.</span><span class="n">predict_cumulative_hazard_function</span><span class="p">(</span><span class="n">X_test_surv</span><span class="p">,</span> <span class="n">return_array</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">class_0_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y_test</span><span class="o">.</span><span class="n">values</span> <span class="o">==</span> <span class="kc">False</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> 
    <span class="n">class_1_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y_test</span><span class="o">.</span><span class="n">values</span> <span class="o">==</span> <span class="kc">True</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>  

    <span class="c1"># Separate predictions into classes</span>
    <span class="n">surv_class_0</span> <span class="o">=</span> <span class="n">surv</span><span class="p">[</span><span class="n">class_0_indices</span><span class="p">]</span>
    <span class="n">surv_class_1</span> <span class="o">=</span> <span class="n">surv</span><span class="p">[</span><span class="n">class_1_indices</span><span class="p">]</span>

    <span class="c1"># Calculate median and interquartile range for both classes</span>
    <span class="n">median_hazard_class_0_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">surv_class_0</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">q1_hazard_class_0_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">surv_class_0</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">q3_hazard_class_0_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">surv_class_0</span><span class="p">,</span> <span class="mi">75</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">iqr_hazard_class_0_test</span> <span class="o">=</span> <span class="n">q3_hazard_class_0_test</span> <span class="o">-</span> <span class="n">q1_hazard_class_0_test</span>

    <span class="n">median_hazard_class_1_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">surv_class_1</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">q1_hazard_class_1_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">surv_class_1</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">q3_hazard_class_1_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">surv_class_1</span><span class="p">,</span> <span class="mi">75</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">iqr_hazard_class_1_test</span> <span class="o">=</span> <span class="n">q3_hazard_class_1_test</span> <span class="o">-</span> <span class="n">q1_hazard_class_1_test</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">survival_analysis</span><span class="p">:</span>

    <span class="c1"># Define a function to calculate the Euclidean distance</span>
    <span class="k">def</span> <span class="nf">euclidean_distance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculates the Euclidean distance between two vectors.</span>

<span class="sd">        The Euclidean distance is a measure of the straight-line distance between two points in n-dimensional space.</span>
<span class="sd">        It is defined as the square root of the sum of the squared differences between corresponding elements in the input vectors.</span>

<span class="sd">        ## Parameters</span>
<span class="sd">            x (numpy array): The first vector.</span>
<span class="sd">            y (numpy array): The second vector.</span>

<span class="sd">        ## Returns</span>
<span class="sd">            float: The Euclidean distance between the two input vectors.</span>

<span class="sd">        Note:</span>
<span class="sd">            This function assumes that the input vectors are of equal length. If they are not, an error will be raised.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">x</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">))</span>

    <span class="c1"># Predict cumulative hazard function for all test samples</span>
    <span class="n">surv</span> <span class="o">=</span> <span class="n">rsf</span><span class="o">.</span><span class="n">predict_cumulative_hazard_function</span><span class="p">(</span><span class="n">X_test_surv</span><span class="p">,</span> <span class="n">return_array</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># Calculate distances from median curves for each individual</span>
    <span class="n">distances_class_0</span> <span class="o">=</span> <span class="p">[</span><span class="n">euclidean_distance</span><span class="p">(</span><span class="n">curve</span><span class="p">,</span> <span class="n">median_hazard_class_0_train</span><span class="p">)</span> <span class="k">for</span> <span class="n">curve</span> <span class="ow">in</span> <span class="n">surv</span><span class="p">]</span>
    <span class="n">distances_class_1</span> <span class="o">=</span> <span class="p">[</span><span class="n">euclidean_distance</span><span class="p">(</span><span class="n">curve</span><span class="p">,</span> <span class="n">median_hazard_class_1_train</span><span class="p">)</span> <span class="k">for</span> <span class="n">curve</span> <span class="ow">in</span> <span class="n">surv</span><span class="p">]</span>

    <span class="c1"># Determine predicted class based on proximity to median curves</span>
    <span class="n">predicted_classes</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">dist_0</span><span class="p">,</span> <span class="n">dist_1</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">distances_class_0</span><span class="p">,</span> <span class="n">distances_class_1</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">dist_0</span> <span class="o">&lt;</span> <span class="n">dist_1</span><span class="p">:</span>
            <span class="n">predicted_classes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">predicted_classes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># Compute confusion matrix</span>
    <span class="n">conf_matrix</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">predicted_classes</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="kc">False</span><span class="p">,</span> <span class="kc">True</span><span class="p">])</span>

    <span class="c1"># Calculate metrics from confusion matrix</span>
    <span class="n">tn</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">fn</span><span class="p">,</span> <span class="n">tp</span> <span class="o">=</span> <span class="n">conf_matrix</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>

    <span class="n">sensitivity</span> <span class="o">=</span> <span class="n">tp</span> <span class="o">/</span> <span class="p">(</span><span class="n">tp</span> <span class="o">+</span> <span class="n">fn</span><span class="p">)</span>
    <span class="n">specificity</span> <span class="o">=</span> <span class="n">tn</span> <span class="o">/</span> <span class="p">(</span><span class="n">tn</span> <span class="o">+</span> <span class="n">fp</span><span class="p">)</span>
    <span class="n">ppv</span> <span class="o">=</span> <span class="n">tp</span> <span class="o">/</span> <span class="p">(</span><span class="n">tp</span> <span class="o">+</span> <span class="n">fp</span><span class="p">)</span>
    <span class="n">npv</span> <span class="o">=</span> <span class="n">tn</span> <span class="o">/</span> <span class="p">(</span><span class="n">tn</span> <span class="o">+</span> <span class="n">fn</span><span class="p">)</span>
    <span class="n">balanced_accuracy</span> <span class="o">=</span> <span class="p">(</span><span class="n">sensitivity</span> <span class="o">+</span> <span class="n">specificity</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>

    <span class="n">mcc</span> <span class="o">=</span> <span class="n">matthews_corrcoef</span><span class="p">(</span><span class="n">y_test</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">predicted_classes</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Confusion Matrix:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">conf_matrix</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Sensitivity:&quot;</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">sensitivity</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Specificity:&quot;</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">specificity</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Positive Predictive Value (PPV):&quot;</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">ppv</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Negative Predictive Value (NPV):&quot;</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">npv</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Balanced Accuracy:&quot;</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">balanced_accuracy</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Matthews Correlation Coefficient (MCC):&quot;</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">mcc</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>

    <span class="c1"># Plot confusion matrix with actual label names</span>
    <span class="c1"># class_labels_display = [class_0, class_1]</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>  
    <span class="n">myheatmap</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">conf_matrix</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s2">&quot;d&quot;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;Blues&quot;</span><span class="p">,</span> <span class="n">cbar</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">xticklabels</span><span class="o">=</span><span class="n">class_labels_display</span><span class="p">,</span> <span class="n">yticklabels</span><span class="o">=</span><span class="n">class_labels_display</span><span class="p">,</span> <span class="n">annot_kws</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;size&quot;</span><span class="p">:</span> <span class="mi">8</span><span class="p">})</span> 
    <span class="n">myheatmap</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Confusion Matrix for the test set&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>  
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Predicted Label&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>  
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;True Label&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>  
    <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>  
    <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>  
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">survival_analysis</span> <span class="ow">and</span> <span class="n">external_val</span><span class="p">:</span>

    <span class="c1"># Predict cumulative hazard function for all test samples</span>
    <span class="n">surv_extval</span> <span class="o">=</span> <span class="n">rsf</span><span class="o">.</span><span class="n">predict_cumulative_hazard_function</span><span class="p">(</span><span class="n">X_extval_surv</span><span class="p">,</span> <span class="n">return_array</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># Calculate distances from median curves for each individual</span>
    <span class="n">distances_class_0</span> <span class="o">=</span> <span class="p">[</span><span class="n">euclidean_distance</span><span class="p">(</span><span class="n">curve</span><span class="p">,</span> <span class="n">median_hazard_class_0_train</span><span class="p">)</span> <span class="k">for</span> <span class="n">curve</span> <span class="ow">in</span> <span class="n">surv_extval</span><span class="p">]</span>
    <span class="n">distances_class_1</span> <span class="o">=</span> <span class="p">[</span><span class="n">euclidean_distance</span><span class="p">(</span><span class="n">curve</span><span class="p">,</span> <span class="n">median_hazard_class_1_train</span><span class="p">)</span> <span class="k">for</span> <span class="n">curve</span> <span class="ow">in</span> <span class="n">surv_extval</span><span class="p">]</span>

    <span class="c1"># Determine predicted class based on proximity to median curves</span>
    <span class="n">predicted_classes</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">dist_0</span><span class="p">,</span> <span class="n">dist_1</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">distances_class_0</span><span class="p">,</span> <span class="n">distances_class_1</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">dist_0</span> <span class="o">&lt;</span> <span class="n">dist_1</span><span class="p">:</span>
            <span class="n">predicted_classes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">predicted_classes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># Compute confusion matrix</span>
    <span class="n">conf_matrix</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_extval_data</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">predicted_classes</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="kc">False</span><span class="p">,</span> <span class="kc">True</span><span class="p">])</span>

    <span class="c1"># Calculate metrics from confusion matrix</span>
    <span class="n">tn</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">fn</span><span class="p">,</span> <span class="n">tp</span> <span class="o">=</span> <span class="n">conf_matrix</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>

    <span class="n">sensitivity</span> <span class="o">=</span> <span class="n">tp</span> <span class="o">/</span> <span class="p">(</span><span class="n">tp</span> <span class="o">+</span> <span class="n">fn</span><span class="p">)</span>
    <span class="n">specificity</span> <span class="o">=</span> <span class="n">tn</span> <span class="o">/</span> <span class="p">(</span><span class="n">tn</span> <span class="o">+</span> <span class="n">fp</span><span class="p">)</span>
    <span class="n">ppv</span> <span class="o">=</span> <span class="n">tp</span> <span class="o">/</span> <span class="p">(</span><span class="n">tp</span> <span class="o">+</span> <span class="n">fp</span><span class="p">)</span>
    <span class="n">npv</span> <span class="o">=</span> <span class="n">tn</span> <span class="o">/</span> <span class="p">(</span><span class="n">tn</span> <span class="o">+</span> <span class="n">fn</span><span class="p">)</span>
    <span class="n">balanced_accuracy</span> <span class="o">=</span> <span class="p">(</span><span class="n">sensitivity</span> <span class="o">+</span> <span class="n">specificity</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>

    <span class="n">mcc</span> <span class="o">=</span> <span class="n">matthews_corrcoef</span><span class="p">(</span><span class="n">y_extval_data</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">predicted_classes</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Confusion Matrix:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">conf_matrix</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Sensitivity:&quot;</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">sensitivity</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Specificity:&quot;</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">specificity</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Positive Predictive Value (PPV):&quot;</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">ppv</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Negative Predictive Value (NPV):&quot;</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">npv</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Balanced Accuracy:&quot;</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">balanced_accuracy</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Matthews Correlation Coefficient (MCC):&quot;</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">mcc</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>

    <span class="c1"># Plot confusion matrix with actual label names</span>
    <span class="c1"># class_labels_display = [class_0, class_1]</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>  
    <span class="n">myheatmap</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">conf_matrix</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s2">&quot;d&quot;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;Blues&quot;</span><span class="p">,</span> <span class="n">cbar</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">xticklabels</span><span class="o">=</span><span class="n">class_labels_display</span><span class="p">,</span> <span class="n">yticklabels</span><span class="o">=</span><span class="n">class_labels_display</span><span class="p">,</span> <span class="n">annot_kws</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;size&quot;</span><span class="p">:</span> <span class="mi">8</span><span class="p">})</span> 
    <span class="n">myheatmap</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Confusion matrix for the external validation set&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>  
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Predicted label&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>  
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;True label&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>  
    <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>  
    <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>  
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">survival_analysis</span><span class="p">:</span>
    <span class="c1"># Predict cumulative hazard function for all test samples</span>
    <span class="n">surv_test</span> <span class="o">=</span> <span class="n">rsf</span><span class="o">.</span><span class="n">predict_cumulative_hazard_function</span><span class="p">(</span><span class="n">X_test_surv</span><span class="p">,</span> <span class="n">return_array</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">class_0_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y_test</span><span class="o">.</span><span class="n">values</span> <span class="o">==</span> <span class="kc">False</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> 
    <span class="n">class_1_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y_test</span><span class="o">.</span><span class="n">values</span> <span class="o">==</span> <span class="kc">True</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>  
    
  
    <span class="c1"># Separate predictions into classes</span>
    <span class="n">surv_class_0</span> <span class="o">=</span> <span class="n">surv_test</span><span class="p">[</span><span class="n">class_0_indices</span><span class="p">]</span>
    <span class="n">surv_class_1</span> <span class="o">=</span> <span class="n">surv_test</span><span class="p">[</span><span class="n">class_1_indices</span><span class="p">]</span>

    <span class="c1"># Calculate median and interquartile range for both classes</span>
    <span class="n">median_surv_class_0_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">surv_class_0</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">q1_surv_class_0_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">surv_class_0</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">q3_surv_class_0_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">surv_class_0</span><span class="p">,</span> <span class="mi">75</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">iqr_surv_class_0_test</span> <span class="o">=</span> <span class="n">q3_surv_class_0_test</span> <span class="o">-</span> <span class="n">q1_surv_class_0_test</span>

    <span class="n">median_surv_class_1_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">surv_class_1</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">q1_surv_class_1_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">surv_class_1</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">q3_surv_class_1_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">surv_class_1</span><span class="p">,</span> <span class="mi">75</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">iqr_surv_class_1_test</span> <span class="o">=</span> <span class="n">q3_surv_class_1_test</span> <span class="o">-</span> <span class="n">q1_surv_class_1_test</span>
    
   
    <span class="n">rsf_riskscores_test</span> <span class="o">=</span> <span class="n">rsf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_surv</span><span class="p">)</span>
    
    <span class="c1"># Calculate average risk scores for each class in the test set</span>
    <span class="n">predicted_risk_socres_class_0</span> <span class="o">=</span> <span class="n">rsf_riskscores_test</span><span class="p">[</span><span class="n">y_test</span><span class="p">]</span>
    <span class="n">predicted_risk_socres_class_1</span> <span class="o">=</span> <span class="n">rsf_riskscores_test</span><span class="p">[</span><span class="o">~</span><span class="n">y_test</span><span class="p">]</span>
    
    <span class="c1"># Perform Mann-Whitney U test to compare the medians of the two classes</span>
    <span class="n">statistic</span><span class="p">,</span> <span class="n">p_value</span> <span class="o">=</span> <span class="n">mannwhitneyu</span><span class="p">(</span><span class="n">predicted_risk_socres_class_0</span><span class="p">,</span> <span class="n">predicted_risk_socres_class_1</span><span class="p">)</span>
    <span class="c1"># Add annotation for statistical test</span>
    <span class="k">if</span> <span class="n">p_value</span> <span class="o">&lt;</span> <span class="mf">0.001</span><span class="p">:</span>
        <span class="n">p_value_text</span> <span class="o">=</span> <span class="s2">&quot;&lt;0.001&quot;</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">p_value_text</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;= </span><span class="si">{</span><span class="n">p_value</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span>
        
    <span class="c1"># Create subplots: one for the survival plot and one for the table</span>
    <span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">gridspec_kw</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;height_ratios&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">]},</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>

    <span class="c1"># Plot median and interquartile range for class 0 on the top plot</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">rsf</span><span class="o">.</span><span class="n">unique_times_</span><span class="p">,</span> <span class="n">median_surv_class_0_test</span><span class="p">,</span> <span class="n">where</span><span class="o">=</span><span class="s2">&quot;post&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;median of predicted cumulative hazard in samples from </span><span class="si">{</span><span class="n">class_labels_display</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2"> class&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;b&#39;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">rsf</span><span class="o">.</span><span class="n">unique_times_</span><span class="p">,</span> <span class="n">q1_surv_class_0_test</span><span class="p">,</span> <span class="n">q3_surv_class_0_test</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="s2">&quot;post&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;IQR&quot;</span><span class="p">)</span>

    <span class="c1"># Plot median and interquartile range for class 1</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">rsf</span><span class="o">.</span><span class="n">unique_times_</span><span class="p">,</span> <span class="n">median_surv_class_1_test</span><span class="p">,</span> <span class="n">where</span><span class="o">=</span><span class="s2">&quot;post&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;median of predicted cumulative hazard in samples from </span><span class="si">{</span><span class="n">class_labels_display</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2"> class&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">rsf</span><span class="o">.</span><span class="n">unique_times_</span><span class="p">,</span> <span class="n">q1_surv_class_1_test</span><span class="p">,</span> <span class="n">q3_surv_class_1_test</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="s2">&quot;post&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;IQR&quot;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Predicted cumulative hazard (test set)&quot;</span><span class="p">)</span> 
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Time in days&quot;</span><span class="p">)</span> <span class="c1"># Note: you should manually change it if for example the time is in months or years rather than in days</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    
    <span class="c1"># Divide time into 5 intervals</span>
    <span class="n">num_intervals</span> <span class="o">=</span> <span class="mi">5</span>
    <span class="n">time_intervals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">rsf</span><span class="o">.</span><span class="n">unique_times_</span><span class="p">),</span> <span class="nb">max</span><span class="p">(</span><span class="n">rsf</span><span class="o">.</span><span class="n">unique_times_</span><span class="p">),</span> <span class="n">num_intervals</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

    <span class="c1"># Initialize arrays to store at risk, events, and censored counts for each interval</span>
    <span class="n">at_risk_intervals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_intervals</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
    <span class="n">events_intervals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_intervals</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
    <span class="n">censored_intervals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_intervals</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
    
    <span class="c1"># Loop through each interval and calculate metrics</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_intervals</span><span class="p">):</span>
        <span class="n">start_time</span> <span class="o">=</span> <span class="n">time_intervals</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">end_time</span> <span class="o">=</span> <span class="n">time_intervals</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>
        
        <span class="c1"># Patients at risk at the start of the interval</span>
        <span class="n">at_risk_intervals</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y_test_surv</span> <span class="o">&gt;=</span> <span class="n">start_time</span><span class="p">)</span>
        
        <span class="c1"># Events within the interval</span>
        <span class="n">events_intervals</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">y_test_surv</span> <span class="o">&gt;</span> <span class="n">start_time</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">y_test_surv</span> <span class="o">&lt;=</span> <span class="n">end_time</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">y_test</span> <span class="o">==</span> <span class="kc">True</span><span class="p">))</span>
        
        <span class="c1"># Censored within the interval</span>
        <span class="n">censored_intervals</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">y_test_surv</span> <span class="o">&gt;</span> <span class="n">start_time</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">y_test_surv</span> <span class="o">&lt;</span> <span class="n">end_time</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">y_test</span> <span class="o">==</span> <span class="kc">False</span><span class="p">))</span>
        
    <span class="c1"># Create the table data with individual and cumulative counts</span>
    <span class="n">table_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
        <span class="p">[</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="n">time_intervals</span><span class="p">[</span><span class="n">i</span><span class="p">])</span><span class="si">}</span><span class="s1">-</span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="n">time_intervals</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">])</span><span class="si">}</span><span class="s1">&#39;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_intervals</span><span class="p">)],</span>
        <span class="p">[</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">at_risk_intervals</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s1">&#39;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_intervals</span><span class="p">)],</span>
        <span class="p">[</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">events_intervals</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s1">&#39;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_intervals</span><span class="p">)],</span>
        <span class="p">[</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">censored_intervals</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s1">&#39;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_intervals</span><span class="p">)]</span>
    <span class="p">])</span>

    <span class="c1"># Create the table in the second subplot</span>
    <span class="n">row_labels</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;time interval&quot;</span><span class="p">,</span><span class="s1">&#39;at risk&#39;</span><span class="p">,</span> <span class="s1">&#39;events&#39;</span><span class="p">,</span> <span class="s1">&#39;censored&#39;</span><span class="p">]</span>

    <span class="c1"># Hide the axis for the table</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;tight&#39;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>

    <span class="c1"># Add the table to the second subplot</span>
    <span class="n">table_display</span> <span class="o">=</span> <span class="n">table</span><span class="p">(</span><span class="n">ax2</span><span class="p">,</span> <span class="n">cellText</span><span class="o">=</span><span class="n">table_data</span><span class="p">,</span> <span class="n">rowLabels</span><span class="o">=</span><span class="n">row_labels</span><span class="p">,</span><span class="n">cellLoc</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>
    
    <span class="c1"># Add annotation for statistical test</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Mann-Whitney U test </span><span class="se">\n</span><span class="s1"> comparing the predicted risk scores </span><span class="se">\n</span><span class="s1">p </span><span class="si">{</span><span class="n">p_value_text</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">xy</span><span class="o">=</span><span class="p">(</span><span class="mf">0.15</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">),</span> <span class="n">xycoords</span><span class="o">=</span><span class="s1">&#39;axes fraction&#39;</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">fontsize</span> <span class="o">=</span> <span class="mi">10</span><span class="p">)</span>
    
    <span class="c1"># Adjust the layout to ensure the plots don&#39;t overlap</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">set_facecolor</span><span class="p">(</span><span class="s1">&#39;white&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">&#39;both&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;grey&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">&#39;minor&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">&#39;major&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s2">&quot;predicted_hazard_test.tif&quot;</span><span class="p">,</span> <span class="n">bbox_inches</span><span class="o">=</span><span class="s1">&#39;tight&#39;</span><span class="p">)</span>
    <span class="c1"># Show the final plot</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">survival_analysis</span><span class="p">:</span>
    <span class="c1"># conduct a statistical test to see if there is any significant difference between the groups in their survival data</span>
    <span class="c1"># This is what it does according to https://scikit-survival.readthedocs.io/en/v0.23.0/api/generated/sksurv.compare.compare_survival.html#sksurv.compare.compare_survival</span>
    <span class="c1"># K-sample log-rank hypothesis test of identical survival functions.</span>
    <span class="c1"># Compares the pooled hazard rate with each group-specific hazard rate. The alternative hypothesis is that the hazard rate of at least one group differs from the others at some time.</span>

    <span class="c1"># Run the survival comparison</span>
    <span class="n">chisq</span><span class="p">,</span> <span class="n">pvalue</span><span class="p">,</span> <span class="n">stats</span><span class="p">,</span> <span class="n">covariance</span> <span class="o">=</span> <span class="n">compare_survival</span><span class="p">(</span>
        <span class="n">y</span><span class="o">=</span><span class="n">y_test_surv_transformed</span><span class="p">,</span>
        <span class="n">group_indicator</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span>
        <span class="n">return_stats</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">)</span>

    <span class="c1"># Prepare the data to create a reportable DataFrame</span>
    <span class="n">comparison_data</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;Chi-Square&quot;</span><span class="p">:</span> <span class="n">chisq</span><span class="p">,</span>
        <span class="s2">&quot;p-value&quot;</span><span class="p">:</span> <span class="n">pvalue</span><span class="p">,</span>
        <span class="s2">&quot;Statistics&quot;</span><span class="p">:</span> <span class="n">stats</span><span class="p">,</span>
        <span class="s2">&quot;Covariance&quot;</span><span class="p">:</span> <span class="n">covariance</span>
    <span class="p">}</span>

    <span class="c1"># Convert the dictionary to a DataFrame for better readability</span>
    <span class="n">comparison_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">([</span><span class="n">comparison_data</span><span class="p">])</span>
    <span class="n">comparison_df</span><span class="o">.</span><span class="n">to_excel</span><span class="p">(</span><span class="s2">&quot;comparison_df_surv_testset.xlsx&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">survival_analysis</span> <span class="ow">and</span> <span class="n">external_val</span><span class="p">:</span>
    <span class="c1"># Predict cumulative hazard function for all external validation samples</span>
    <span class="n">surv_extval</span> <span class="o">=</span> <span class="n">rsf</span><span class="o">.</span><span class="n">predict_cumulative_hazard_function</span><span class="p">(</span><span class="n">X_extval_surv</span><span class="p">,</span> <span class="n">return_array</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">class_0_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y_extval_data</span><span class="o">.</span><span class="n">values</span> <span class="o">==</span> <span class="kc">False</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> 
    <span class="n">class_1_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y_extval_data</span><span class="o">.</span><span class="n">values</span> <span class="o">==</span> <span class="kc">True</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>  
    
  
    <span class="c1"># Separate predictions into classes</span>
    <span class="n">surv_class_0</span> <span class="o">=</span> <span class="n">surv_extval</span><span class="p">[</span><span class="n">class_0_indices</span><span class="p">]</span>
    <span class="n">surv_class_1</span> <span class="o">=</span> <span class="n">surv_extval</span><span class="p">[</span><span class="n">class_1_indices</span><span class="p">]</span>

    <span class="c1"># Calculate median and interquartile range for both classes</span>
    <span class="n">median_surv_class_0_extval</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">surv_class_0</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">q1_surv_class_0_extval</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">surv_class_0</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">q3_surv_class_0_extval</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">surv_class_0</span><span class="p">,</span> <span class="mi">75</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">iqr_surv_class_0_extval</span> <span class="o">=</span> <span class="n">q3_surv_class_0_extval</span> <span class="o">-</span> <span class="n">q1_surv_class_0_extval</span>

    <span class="n">median_surv_class_1_extval</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">surv_class_1</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">q1_surv_class_1_extval</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">surv_class_1</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">q3_surv_class_1_extval</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">surv_class_1</span><span class="p">,</span> <span class="mi">75</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">iqr_surv_class_1_extval</span> <span class="o">=</span> <span class="n">q3_surv_class_1_extval</span> <span class="o">-</span> <span class="n">q1_surv_class_1_extval</span>
    
   
    <span class="n">rsf_riskscores_extval</span> <span class="o">=</span> <span class="n">rsf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_extval_surv</span><span class="p">)</span>
    
    <span class="c1"># Calculate average risk scores for each class in the test set</span>
    <span class="n">predicted_risk_socres_class_0</span> <span class="o">=</span> <span class="n">rsf_riskscores_extval</span><span class="p">[</span><span class="n">y_extval_data</span><span class="p">]</span>
    <span class="n">predicted_risk_socres_class_1</span> <span class="o">=</span> <span class="n">rsf_riskscores_extval</span><span class="p">[</span><span class="o">~</span><span class="n">y_extval_data</span><span class="p">]</span>
    
    <span class="c1"># Perform Mann-Whitney U test to compare the medians of the two classes</span>
    <span class="n">statistic</span><span class="p">,</span> <span class="n">p_value</span> <span class="o">=</span> <span class="n">mannwhitneyu</span><span class="p">(</span><span class="n">predicted_risk_socres_class_0</span><span class="p">,</span> <span class="n">predicted_risk_socres_class_1</span><span class="p">)</span>
    <span class="c1"># Add annotation for statistical test</span>
    <span class="k">if</span> <span class="n">p_value</span> <span class="o">&lt;</span> <span class="mf">0.001</span><span class="p">:</span>
        <span class="n">p_value_text</span> <span class="o">=</span> <span class="s2">&quot;&lt;0.001&quot;</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">p_value_text</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;= </span><span class="si">{</span><span class="n">p_value</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span>
        
    <span class="c1"># Create subplots: one for the survival plot and one for the table</span>
    <span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">gridspec_kw</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;height_ratios&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">]},</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>

    <span class="c1"># Plot median and interquartile range for class 0 on the top plot</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">rsf</span><span class="o">.</span><span class="n">unique_times_</span><span class="p">,</span> <span class="n">median_surv_class_0_extval</span><span class="p">,</span> <span class="n">where</span><span class="o">=</span><span class="s2">&quot;post&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;median of predicted cumulative hazard in samples from </span><span class="si">{</span><span class="n">class_labels_display</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2"> class&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;b&#39;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">rsf</span><span class="o">.</span><span class="n">unique_times_</span><span class="p">,</span> <span class="n">q1_surv_class_0_test</span><span class="p">,</span> <span class="n">q3_surv_class_0_extval</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="s2">&quot;post&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;IQR&quot;</span><span class="p">)</span>

    <span class="c1"># Plot median and interquartile range for class 1</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">rsf</span><span class="o">.</span><span class="n">unique_times_</span><span class="p">,</span> <span class="n">median_surv_class_1_extval</span><span class="p">,</span> <span class="n">where</span><span class="o">=</span><span class="s2">&quot;post&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;median of predicted cumulative hazard in samples from </span><span class="si">{</span><span class="n">class_labels_display</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2"> class&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">rsf</span><span class="o">.</span><span class="n">unique_times_</span><span class="p">,</span> <span class="n">q1_surv_class_1_extval</span><span class="p">,</span> <span class="n">q3_surv_class_1_extval</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="s2">&quot;post&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;IQR&quot;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Predicted cumulative hazard (external validation set)&quot;</span><span class="p">)</span> 
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Time in days&quot;</span><span class="p">)</span> <span class="c1"># Note: you should manually change it if for example the time is in months or years rather than in days</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    
    <span class="c1"># Divide time into 5 intervals</span>
    <span class="n">num_intervals</span> <span class="o">=</span> <span class="mi">5</span>
    <span class="n">time_intervals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">rsf</span><span class="o">.</span><span class="n">unique_times_</span><span class="p">),</span> <span class="nb">max</span><span class="p">(</span><span class="n">rsf</span><span class="o">.</span><span class="n">unique_times_</span><span class="p">),</span> <span class="n">num_intervals</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

    <span class="c1"># Initialize arrays to store at risk, events, and censored counts for each interval</span>
    <span class="n">at_risk_intervals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_intervals</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
    <span class="n">events_intervals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_intervals</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
    <span class="n">censored_intervals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_intervals</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
    
    <span class="c1"># Loop through each interval and calculate metrics</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_intervals</span><span class="p">):</span>
        <span class="n">start_time</span> <span class="o">=</span> <span class="n">time_intervals</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">end_time</span> <span class="o">=</span> <span class="n">time_intervals</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>
        
        <span class="c1"># Patients at risk at the start of the interval</span>
        <span class="n">at_risk_intervals</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y_extval_surv</span> <span class="o">&gt;=</span> <span class="n">start_time</span><span class="p">)</span>
        
        <span class="c1"># Events within the interval</span>
        <span class="n">events_intervals</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">y_extval_surv</span> <span class="o">&gt;</span> <span class="n">start_time</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">y_extval_surv</span> <span class="o">&lt;=</span> <span class="n">end_time</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">y_extval_data</span> <span class="o">==</span> <span class="kc">True</span><span class="p">))</span>
        
        <span class="c1"># Censored within the interval</span>
        <span class="n">censored_intervals</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">y_extval_surv</span> <span class="o">&gt;</span> <span class="n">start_time</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">y_extval_surv</span> <span class="o">&lt;</span> <span class="n">end_time</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">y_extval_data</span> <span class="o">==</span> <span class="kc">False</span><span class="p">))</span>
        
    <span class="c1"># Create the table data with individual and cumulative counts</span>
    <span class="n">table_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
        <span class="p">[</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="n">time_intervals</span><span class="p">[</span><span class="n">i</span><span class="p">])</span><span class="si">}</span><span class="s1">-</span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="n">time_intervals</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">])</span><span class="si">}</span><span class="s1">&#39;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_intervals</span><span class="p">)],</span>
        <span class="p">[</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">at_risk_intervals</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s1">&#39;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_intervals</span><span class="p">)],</span>
        <span class="p">[</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">events_intervals</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s1">&#39;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_intervals</span><span class="p">)],</span>
        <span class="p">[</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">censored_intervals</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s1">&#39;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_intervals</span><span class="p">)]</span>
    <span class="p">])</span>

    <span class="c1"># Create the table in the second subplot</span>
    <span class="n">row_labels</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;time interval&quot;</span><span class="p">,</span><span class="s1">&#39;at risk&#39;</span><span class="p">,</span> <span class="s1">&#39;events&#39;</span><span class="p">,</span> <span class="s1">&#39;censored&#39;</span><span class="p">]</span>

    <span class="c1"># Hide the axis for the table</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;tight&#39;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>

    <span class="c1"># Add the table to the second subplot</span>
    <span class="n">table_display</span> <span class="o">=</span> <span class="n">table</span><span class="p">(</span><span class="n">ax2</span><span class="p">,</span> <span class="n">cellText</span><span class="o">=</span><span class="n">table_data</span><span class="p">,</span> <span class="n">rowLabels</span><span class="o">=</span><span class="n">row_labels</span><span class="p">,</span><span class="n">cellLoc</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>
    
    <span class="c1"># Add annotation for statistical test</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Mann-Whitney U test </span><span class="se">\n</span><span class="s1"> comparing the predicted risk scores </span><span class="se">\n</span><span class="s1">p </span><span class="si">{</span><span class="n">p_value_text</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">xy</span><span class="o">=</span><span class="p">(</span><span class="mf">0.15</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">),</span> <span class="n">xycoords</span><span class="o">=</span><span class="s1">&#39;axes fraction&#39;</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">fontsize</span> <span class="o">=</span> <span class="mi">10</span><span class="p">)</span>
    
    <span class="c1"># Adjust the layout to ensure the plots don&#39;t overlap</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">set_facecolor</span><span class="p">(</span><span class="s1">&#39;white&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">&#39;both&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;grey&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">&#39;minor&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">&#39;major&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s2">&quot;predicted_hazard_extval.tif&quot;</span><span class="p">,</span> <span class="n">bbox_inches</span><span class="o">=</span><span class="s1">&#39;tight&#39;</span><span class="p">)</span>
    <span class="c1"># Show the final plot</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">survival_analysis</span> <span class="ow">and</span> <span class="n">external_val</span><span class="p">:</span>
    <span class="c1"># Run the survival comparison</span>
    <span class="n">chisq</span><span class="p">,</span> <span class="n">pvalue</span><span class="p">,</span> <span class="n">stats</span><span class="p">,</span> <span class="n">covariance</span> <span class="o">=</span> <span class="n">compare_survival</span><span class="p">(</span>
        <span class="n">y</span><span class="o">=</span><span class="n">y_extval_surv_transformed</span><span class="p">,</span>
        <span class="n">group_indicator</span><span class="o">=</span><span class="n">y_extval_data</span><span class="p">,</span>
        <span class="n">return_stats</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">)</span>

    <span class="c1"># Prepare the data to create a reportable DataFrame</span>
    <span class="n">comparison_data</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;Chi-Square&quot;</span><span class="p">:</span> <span class="n">chisq</span><span class="p">,</span>
        <span class="s2">&quot;p-value&quot;</span><span class="p">:</span> <span class="n">pvalue</span><span class="p">,</span>
        <span class="s2">&quot;Statistics&quot;</span><span class="p">:</span> <span class="n">stats</span><span class="p">,</span>
        <span class="s2">&quot;Covariance&quot;</span><span class="p">:</span> <span class="n">covariance</span>
    <span class="p">}</span>

    <span class="c1"># Convert the dictionary to a DataFrame for better readability</span>
    <span class="n">comparison_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">([</span><span class="n">comparison_data</span><span class="p">])</span>
    <span class="n">comparison_df</span><span class="o">.</span><span class="n">to_excel</span><span class="p">(</span><span class="s2">&quot;comparison_df_surv_extval.xlsx&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">survival_analysis</span><span class="p">:</span>
    
    <span class="k">try</span><span class="p">:</span>

        <span class="c1"># Ensure test times are correctly extracted from the structured survival arrays</span>
        <span class="n">test_times_rsf</span> <span class="o">=</span> <span class="n">y_test_surv_transformed</span><span class="p">[</span><span class="s1">&#39;time&#39;</span><span class="p">]</span>  <span class="c1"># Extract the time from the structured array</span>
        <span class="n">valid_times_rsf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">test_times_rsf</span><span class="p">)</span>
        <span class="n">valid_times_rsf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">valid_times_rsf</span><span class="p">,</span> <span class="n">test_times_rsf</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">test_times_rsf</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">-</span> <span class="mf">1e-5</span><span class="p">)</span>

        <span class="c1"># Predict the risk scores using the Random Survival Forest model</span>
        <span class="n">rsf_risk_scores</span> <span class="o">=</span> <span class="n">rsf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_surv</span><span class="p">)</span>

        <span class="c1"># Calculate cumulative dynamic AUC</span>
        <span class="n">rsf_auc</span><span class="p">,</span> <span class="n">rsf_mean_auc</span> <span class="o">=</span> <span class="n">cumulative_dynamic_auc</span><span class="p">(</span>
            <span class="n">survival_train</span><span class="o">=</span><span class="n">y_train_surv_transformed</span><span class="p">,</span>
            <span class="n">survival_test</span><span class="o">=</span><span class="n">y_test_surv_transformed</span><span class="p">,</span>
            <span class="n">estimate</span><span class="o">=</span><span class="n">rsf_risk_scores</span><span class="p">,</span>
            <span class="n">times</span><span class="o">=</span><span class="n">valid_times_rsf</span>
        <span class="p">)</span>

        <span class="c1"># Plot the AUC over time</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">valid_times_rsf</span><span class="p">,</span> <span class="n">rsf_auc</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;RSF AUC (mean = </span><span class="si">{</span><span class="n">rsf_mean_auc</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;b&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Time&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;AUC (test set)&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;AUC over time for random survival forest&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>


    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;An error occurred: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">. Skipping to the next block.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">survival_analysis</span> <span class="ow">and</span> <span class="n">external_val</span><span class="p">:</span>
    
    <span class="k">try</span><span class="p">:</span>

        <span class="c1"># Ensure test times are correctly extracted from the structured survival arrays</span>
        <span class="n">test_times_rsf</span> <span class="o">=</span> <span class="n">y_extval_surv_transformed</span><span class="p">[</span><span class="s1">&#39;time&#39;</span><span class="p">]</span>  <span class="c1"># Extract the time from the structured array</span>
        <span class="n">valid_times_rsf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">test_times_rsf</span><span class="p">)</span>
        <span class="n">valid_times_rsf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">valid_times_rsf</span><span class="p">,</span> <span class="n">test_times_rsf</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">test_times_rsf</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">-</span> <span class="mf">1e-5</span><span class="p">)</span>

        <span class="c1"># Predict the risk scores using the Random Survival Forest model</span>
        <span class="n">rsf_risk_scores</span> <span class="o">=</span> <span class="n">rsf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_extval_surv</span><span class="p">)</span>

        <span class="c1"># Calculate cumulative dynamic AUC</span>
        <span class="n">rsf_auc</span><span class="p">,</span> <span class="n">rsf_mean_auc</span> <span class="o">=</span> <span class="n">cumulative_dynamic_auc</span><span class="p">(</span>
            <span class="n">survival_train</span><span class="o">=</span><span class="n">y_train_surv_transformed</span><span class="p">,</span>
            <span class="n">survival_test</span><span class="o">=</span><span class="n">y_extval_surv_transformed</span><span class="p">,</span>
            <span class="n">estimate</span><span class="o">=</span><span class="n">rsf_risk_scores</span><span class="p">,</span>
            <span class="n">times</span><span class="o">=</span><span class="n">valid_times_rsf</span>
        <span class="p">)</span>

        <span class="c1"># Plot the AUC over time</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">valid_times_rsf</span><span class="p">,</span> <span class="n">rsf_auc</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;RSF AUC (mean = </span><span class="si">{</span><span class="n">rsf_mean_auc</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;b&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Time&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;AUC (external validation set)&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;AUC over time for random survival forest&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>


    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;An error occurred: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">. Skipping to the next block.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="regression-models">
<h2>Regression models<a class="headerlink" href="#regression-models" title="Link to this heading">#</a></h2>
<p>Like survival analysis, if the data contains a column for continuous outcome variable then this analysis is relevant and can be conducted using the following code chunks. The continuous outcome is provided from a copy of the data that is saved in the beginning of the pipeline and it gets merged back to the train and test sets.</p>
<section id="interpreting-regression-model-performance-metrics">
<h3>Interpreting Regression Model Performance Metrics<a class="headerlink" href="#interpreting-regression-model-performance-metrics" title="Link to this heading">#</a></h3>
<ol class="arabic simple">
<li><p>Mean Squared Error (MSE)</p></li>
</ol>
<ul class="simple">
<li><p><strong>Formula:</strong> MSE = (1/n) * Σ(yᵢ - ŷᵢ)²</p></li>
<li><p><strong>Where:</strong></p>
<ul>
<li><p>( n ) is the number of observations</p></li>
<li><p>( yᵢ ) is the actual value</p></li>
<li><p>( ŷᵢ ) is the predicted value</p></li>
</ul>
</li>
<li><p><strong>Interpretation:</strong></p>
<ul>
<li><p>Measures the average squared difference between actual and predicted values.</p></li>
<li><p>Lower MSE indicates better fit.</p></li>
<li><p>Sensitive to outliers.</p></li>
</ul>
</li>
</ul>
<ol class="arabic simple" start="2">
<li><p>Mean Absolute Error (MAE)</p></li>
</ol>
<ul class="simple">
<li><p><strong>Formula:</strong> MAE = (1/n) * Σ|yᵢ - ŷᵢ|</p></li>
<li><p><strong>Where:</strong></p>
<ul>
<li><p>( n ) is the number of observations</p></li>
<li><p>( yᵢ ) is the actual value</p></li>
<li><p>( ŷᵢ ) is the predicted value</p></li>
</ul>
</li>
<li><p><strong>Interpretation:</strong></p>
<ul>
<li><p>Measures the average absolute difference between actual and predicted values.</p></li>
<li><p>Lower MAE indicates better fit.</p></li>
<li><p>Less sensitive to outliers than MSE.</p></li>
<li><p>Same units as the original data.</p></li>
</ul>
</li>
</ul>
<ol class="arabic simple" start="3">
<li><p>R-squared (R²)</p></li>
</ol>
<ul class="simple">
<li><p><strong>Formula:</strong> R² = 1 - (Σ(yᵢ - ŷᵢ)² / Σ(yᵢ - ȳ)²)</p></li>
<li><p><strong>Where:</strong></p>
<ul>
<li><p>( yᵢ ) is the actual value</p></li>
<li><p>( ŷᵢ ) is the predicted value</p></li>
<li><p>( ȳ ) is the mean of actual values</p></li>
</ul>
</li>
<li><p><strong>Interpretation:</strong></p>
<ul>
<li><p>Measures the proportion of variance in the dependent variable explained by the model.</p></li>
<li><p>Values range from -∞ to 1.</p></li>
<li><p>Higher values indicate better fit.</p></li>
<li><p>Negative values indicate the model performs worse than a horizontal line (mean of the target variable).</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">regression_analysis</span><span class="p">:</span>
    <span class="n">y_train_reg</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">mydata_copy_regression</span><span class="p">[</span><span class="n">regression_outcome</span><span class="p">],</span> <span class="n">left_index</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">right_index</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s1">&#39;left&#39;</span><span class="p">)</span>
    <span class="n">y_train_reg</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="n">outcome_var</span><span class="p">,</span><span class="n">inplace</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
    <span class="n">y_test_reg</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">mydata_copy_regression</span><span class="p">[</span><span class="n">regression_outcome</span><span class="p">],</span> <span class="n">left_index</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">right_index</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s1">&#39;left&#39;</span><span class="p">)</span>
    <span class="n">y_test_reg</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="n">outcome_var</span><span class="p">,</span><span class="n">inplace</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
    <span class="c1"># Create and fit the linear regression model</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_OHE_nocv</span><span class="p">,</span> <span class="n">y_train_reg</span><span class="p">)</span>

    <span class="c1"># Make predictions on the test set</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_OHE</span><span class="p">)</span>

    <span class="c1"># Calculate evaluation metrics</span>
    <span class="n">mse</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test_reg</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    <span class="n">mae</span> <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_test_reg</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    <span class="n">r2</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

    <span class="c1"># Print the evaluation metrics</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mean Squared Error (MSE): </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">mse</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mean Absolute Error (MAE): </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">mae</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;R-squared (R2): </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">r2</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">regression_analysis</span><span class="p">:</span>
    <span class="c1"># Define the parameter grid for the random search</span>
    <span class="n">rf_param_grid</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">500</span><span class="p">,</span> <span class="mi">1000</span><span class="p">],</span>  <span class="c1"># Number of trees in the forest</span>
        <span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">],</span>  <span class="c1"># Maximum depth of the trees</span>
        <span class="s1">&#39;min_samples_split&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span>  <span class="c1"># Minimum number of samples required to split a node</span>
        <span class="s1">&#39;min_samples_leaf&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>  <span class="c1"># Minimum number of samples required at each leaf node</span>
    <span class="p">}</span>

    <span class="c1"># Create Random Forest model</span>
    <span class="n">rf</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">()</span>

    <span class="c1"># Create RandomizedSearchCV</span>
    <span class="n">random_search</span> <span class="o">=</span> <span class="n">RandomizedSearchCV</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">rf</span><span class="p">,</span> <span class="n">param_distributions</span><span class="o">=</span><span class="n">rf_param_grid</span><span class="p">,</span> <span class="n">n_iter</span><span class="o">=</span><span class="n">n_iter_hptuning</span><span class="p">,</span>
                                       <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;neg_mean_squared_error&#39;</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">cv_folds_hptuning</span><span class="p">)</span>

    <span class="c1"># Perform random search to find the best hyperparameters</span>
    <span class="n">random_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_OHE_nocv</span><span class="p">,</span> <span class="n">y_train_reg</span><span class="p">)</span>

    <span class="c1"># Extract the best parameters</span>
    <span class="n">best_params</span> <span class="o">=</span> <span class="n">random_search</span><span class="o">.</span><span class="n">best_params_</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best parameters found: &quot;</span><span class="p">,</span> <span class="n">best_params</span><span class="p">)</span>

    <span class="c1"># Train the final model on the entire training set with the best hyperparameters</span>
    <span class="n">best_model</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="o">**</span><span class="n">best_params</span><span class="p">)</span>
    <span class="n">best_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_OHE_nocv</span><span class="p">,</span> <span class="n">y_train_reg</span><span class="p">)</span>

    <span class="c1"># Make predictions on the test set using the best model</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">best_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_OHE</span><span class="p">)</span>

    <span class="c1"># Calculate evaluation metrics</span>
    <span class="n">mse</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test_reg</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    <span class="n">mae</span> <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_test_reg</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    <span class="n">r2</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_test_reg</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

    <span class="c1"># Print the evaluation metrics</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mean Squared Error (MSE): </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">mse</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mean Absolute Error (MAE): </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">mae</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;R-squared (R2): </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">r2</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="model-interpretation">
<h3>Model interpretation<a class="headerlink" href="#model-interpretation" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">regression_analysis</span><span class="p">:</span>
    
    <span class="c1"># Initialize explainer with the best model</span>
    <span class="n">explainer</span> <span class="o">=</span> <span class="n">shap</span><span class="o">.</span><span class="n">TreeExplainer</span><span class="p">(</span><span class="n">best_model</span><span class="p">)</span>

    <span class="c1"># Calculate SHAP values for the test set</span>
    <span class="n">shap_values</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">shap_values</span><span class="p">(</span><span class="n">X_test_OHE</span><span class="p">)</span>

    <span class="c1"># Summary plot</span>
    <span class="n">shap</span><span class="o">.</span><span class="n">summary_plot</span><span class="p">(</span><span class="n">shap_values</span><span class="p">,</span> <span class="n">X_test_OHE</span><span class="p">,</span> <span class="n">feature_names</span><span class="o">=</span><span class="n">X_train_OHE_nocv</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
    
    <span class="c1"># save the model to disk</span>
    <span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">best_model</span><span class="p">,</span> <span class="s1">&#39;regression_model.pkl&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="report-the-environment">
<h2>Report the environment<a class="headerlink" href="#report-the-environment" title="Link to this heading">#</a></h2>
<p>Report Conda packages required to run the pipeline</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_conda_environment</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This function retrieves the list of packages currently installed in a conda environment. It runs the `conda list` command and returns the output as a string.</span>

<span class="sd">    ### Returns</span>

<span class="sd">    A string containing the list of packages installed in the conda environment.</span>

<span class="sd">    ### Notes</span>

<span class="sd">    *   This function assumes that the `conda` command is available on the system and that the user has permission to run it.</span>
<span class="sd">    *   The returned string may be truncated if it exceeds the maximum allowed size by the system.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">conda_list</span> <span class="o">=</span> <span class="n">subprocess</span><span class="o">.</span><span class="n">check_output</span><span class="p">([</span><span class="s1">&#39;conda&#39;</span><span class="p">,</span> <span class="s1">&#39;list&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">conda_list</span>

<span class="k">def</span> <span class="nf">get_python_info</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This function retrieves the version of Python currently installed on the system. It uses the `platform.python_version()` function to determine the version.</span>

<span class="sd">    ### Returns</span>

<span class="sd">    A string representing the version of Python.</span>

<span class="sd">    ### Notes</span>

<span class="sd">    *   This function may return a version in the format &#39;X.X.Y&#39; or &#39;X.X&#39;, depending on the version of the platform library being used.</span>
<span class="sd">    *   The returned version is specific to the Python interpreter being run, not necessarily the default Python interpreter for the system.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="n">python_version</span> <span class="o">=</span> <span class="n">platform</span><span class="o">.</span><span class="n">python_version</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">python_version</span>

<span class="k">def</span> <span class="nf">get_system_info</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This function retrieves information about the operating system and hardware configuration of the system. It uses various functions from the `platform` and `psutil` libraries to gather information about the OS, number of CPUs, and memory usage.</span>

<span class="sd">    ### Returns</span>

<span class="sd">    A dictionary containing three key-value pairs:</span>

<span class="sd">    *   `&#39;OS&#39;`: The name of the operating system (e.g., &#39;Windows&#39;, &#39;Linux&#39;, &#39;Darwin&#39;).</span>
<span class="sd">    *   `&#39;Number of CPUs&#39;`: The total number of CPU cores available on the system.</span>
<span class="sd">    *   `&#39;Memory&#39;`: A string representation of the current memory usage, including both physical and virtual memory.</span>

<span class="sd">    ### Notes</span>

<span class="sd">    *   This function assumes that the necessary permissions are available to access information about the system hardware.</span>
<span class="sd">    *   The returned dictionary is specific to the current Python interpreter being run, not necessarily the default Python interpreter for the system.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">system_info</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;OS&#39;</span><span class="p">:</span> <span class="n">platform</span><span class="o">.</span><span class="n">system</span><span class="p">(),</span>
        <span class="s1">&#39;Number of CPUs&#39;</span><span class="p">:</span> <span class="n">n_cpu_model_training</span><span class="p">,</span>
        <span class="s1">&#39;Memory&#39;</span><span class="p">:</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">psutil</span><span class="o">.</span><span class="n">virtual_memory</span><span class="p">()</span><span class="o">.</span><span class="n">total</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="p">(</span><span class="mi">1024</span><span class="w"> </span><span class="o">**</span><span class="w"> </span><span class="mi">3</span><span class="p">)</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1"> GB&#39;</span>
    <span class="p">}</span>
    <span class="k">return</span> <span class="n">system_info</span>

<span class="k">def</span> <span class="nf">get_gpu_info</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This function retrieves information about NVIDIA GPUs present on the system. If an NVIDIA GPU is detected, it runs the `nvidia-smi` command and returns its output as a string. Otherwise, it returns a message indicating that no NVIDIA GPU is available.</span>

<span class="sd">    ### Returns</span>

<span class="sd">    A string containing the output of the `nvidia-smi` command if an NVIDIA GPU is detected; otherwise, a message indicating that no NVIDIA GPU is available.</span>

<span class="sd">    ### Notes</span>

<span class="sd">    *   This function assumes that the `nvidia-smi` command is available on the system and that the user has permission to run it.</span>
<span class="sd">    *   The returned string may be truncated if it exceeds the maximum allowed size by the system.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">GPU_avail</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">gpu_info</span> <span class="o">=</span> <span class="n">subprocess</span><span class="o">.</span><span class="n">check_output</span><span class="p">([</span><span class="s1">&#39;nvidia-smi&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">gpu_info</span>
        <span class="k">except</span> <span class="n">subprocess</span><span class="o">.</span><span class="n">CalledProcessError</span><span class="p">:</span>
            <span class="k">return</span> <span class="s2">&quot;GPU information not available (nvidia-smi not installed or no NVIDIA GPU detected)&quot;</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="s2">&quot;GPU not used&quot;</span>
        
<span class="c1"># Record end time</span>
<span class="n">end_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

<span class="c1"># Calculate duration</span>
<span class="n">duration</span> <span class="o">=</span> <span class="n">end_time</span> <span class="o">-</span> <span class="n">start_time</span>

<span class="c1"># Define the filename for the report</span>
<span class="n">report_filename</span> <span class="o">=</span> <span class="s1">&#39;pipeline_report.txt&#39;</span>

<span class="c1"># Open the file for writing</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">report_filename</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="c1"># Write Conda environment to the file</span>
    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;Conda environment:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">get_conda_environment</span><span class="p">())</span>
    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2">&quot;</span><span class="p">)</span>
    
    <span class="c1"># Write Python version to the file</span>
    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;Python version:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">get_python_info</span><span class="p">())</span>
    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2">&quot;</span><span class="p">)</span>
    
    <span class="c1"># Write system information to the file</span>
    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;System information:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">system_info</span> <span class="o">=</span> <span class="n">get_system_info</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">system_info</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">value</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
    
    <span class="c1"># Write GPU information to the file</span>
    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;GPU information:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">get_gpu_info</span><span class="p">())</span>
    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
    
    <span class="c1"># Write duration to the file</span>
    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;Pipeline execution duration (seconds):</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">duration</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Report saved as </span><span class="si">{</span><span class="n">report_filename</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="save-the-pipeline-logs-in-html-format">
<h2>Save the pipeline logs in HTML format<a class="headerlink" href="#save-the-pipeline-logs-in-html-format" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">save_notebook</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This function saves the current state of a Jupyter Notebook to disk, effectively pausing the notebook&#39;s execution and preserving its environment, code, and data. The `IPython.notebook.save_checkpoint()` function is used internally by Jupyter to perform this task.</span>

<span class="sd">    ### Notes</span>

<span class="sd">    *   When this function is called, it will save the notebook&#39;s current state to a file in the format `.ipynb`, which can be loaded later into the same or another instance of Jupyter Notebook.</span>
<span class="sd">    *   This function does not execute any code; it simply saves the current state of the notebook and returns control to the caller.</span>

<span class="sd">    By calling this function, you can:</span>

<span class="sd">    *   Pause an ongoing computation and resume it later without losing its progress</span>
<span class="sd">    *   Save a snapshot of your work for reference or sharing with others</span>
<span class="sd">    *   Ensure that your changes are persisted even if the notebook is terminated unexpectedly</span>

<span class="sd">    However, note that saving a notebook will also save any unsaved changes to the cell contents, which may not be what you want in all cases. To avoid this, consider using the `save` method explicitly.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">display</span><span class="p">(</span><span class="n">Javascript</span><span class="p">(</span><span class="s1">&#39;IPython.notebook.save_checkpoint();&#39;</span><span class="p">))</span>

<span class="n">save_notebook</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># change directory to where the notebook file is located</span>
<span class="n">os</span><span class="o">.</span><span class="n">chdir</span><span class="p">(</span><span class="s2">&quot;..&quot;</span><span class="p">)</span>

<span class="c1"># Convert the notebook to HTML using nbconvert</span>
<span class="o">!</span>jupyter<span class="w"> </span>nbconvert<span class="w"> </span><span class="nv">$JupyterNotebook_filename</span><span class="w"> </span>--to<span class="w"> </span>html
</pre></div>
</div>
</div>
</div>
</section>
<section id="references">
<h2>References<a class="headerlink" href="#references" title="Link to this heading">#</a></h2>
<p>Information about all the packages (libraries) utilized in this pipeline is available in the exported report “pipeline_report.txt”.</p>
<p>More information about the methods used in this pipeline:</p>
<ul class="simple">
<li><p><strong>QLattice model</strong></p>
<ul>
<li><p>Broløs, K. R. et al. An Approach to Symbolic Regression Using Feyn. (2021)</p></li>
</ul>
</li>
<li><p><strong>Sci-kit learn</strong></p>
<ul>
<li><p>Pedregosa, F. et al. Scikit-learn: Machine learning in Python. J. Mach. Learn. Res. 12, 2825–2830 (2011)</p></li>
</ul>
</li>
<li><p><strong>CatBoost</strong></p>
<ul>
<li><p>Dorogush, A. V., Ershov, V. &amp; Gulin, A. CatBoost: gradient boosting with categorical features support. (2018)</p></li>
</ul>
</li>
<li><p><strong>LightGBM</strong></p>
<ul>
<li><p>Ke, G. et al. LightGBM: A highly efficient gradient boosting decision tree. in Advances in Neural Information Processing Systems (2017)</p></li>
</ul>
</li>
<li><p><strong>SHAP</strong></p>
<ul>
<li><p>Lundberg, S. M. &amp; Lee, S.-I. A unified approach to interpreting model predictions. in Advances in neural information processing systems 4765–4774 (2017)</p></li>
<li><p>Lundberg, S. M. et al. From local explanations to global understanding with explainable AI for trees. Nat. Mach. Intell. 2, 56–67 (2020)</p></li>
</ul>
</li>
<li><p><strong>SHAP clustering</strong></p>
<ul>
<li><p>Zargari Marandi, R. et al. Development of a machine learning model for early prediction of plasma leakage in suspected dengue patients. PLoS Negl. Trop. Dis. 17, e0010758 (2023)</p></li>
<li><p>Ramtin Zargari Marandi, ExplaineR: an R package to explain machine learning models, Bioinformatics Advances, Volume 4, Issue 1, 2024, vbae049, <a class="reference external" href="https://doi.org/10.1093/bioadv/vbae049">link</a></p></li>
</ul>
</li>
<li><p><strong>Survival SHAP</strong></p>
<ul>
<li><p>Krzyziński, Mateusz, et al. “SurvSHAP (t): time-dependent explanations of machine learning survival models.” Knowledge-Based Systems 262 (2023): 110234.</p></li>
<li><p><a class="github reference external" href="https://github.com/MI2DataLab/survshap">MI2DataLab/survshap</a></p></li>
</ul>
</li>
</ul>
<p>More information about for example data imputation and clustering methods, and other models can be found in <a class="reference external" href="https://scikit-learn.org/stable/">https://scikit-learn.org/stable/</a>.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="MAIT_Tutorial_BreastCancer_pub.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">MAIT 1.0.0 - Tutorial: Breast cancer prediction</p>
      </div>
    </a>
    <a class="right-next"
       href="MAIT_Tutorial_Azithromycin_pub.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">MAIT 1.0.0 - Tutorial: Azithromycin antibiotic resistance prediction based on unitigs representing DNA variation in bacteria</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dataset-summary">Dataset Summary</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#load-data-libraries-and-set-parameters">Load Data, Libraries, and Set Parameters.</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#most-important-settings">Most important settings</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#less-important-settings">Less important settings</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#data-preparation">Data preparation</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#specify-data-types-for-numerical-features-optional">Specify data types for numerical features (optional)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#defined-missingness">Defined missingness</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#rare-categories-in-categorical-variables-and-data-harmonization-for-missing-values">Rare categories in categorical variables and data harmonization for missing values</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#shorten-the-name-of-features-optional">Shorten the name of features (optional)</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-split-prediction-vs-discovery">Data split (prediction vs. discovery)</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#checking-the-availability-of-all-categories">Checking the availability of all categories</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#filter-highly-missing-data">Filter highly missing data</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#feature-selection-optional-but-recommended-if-the-dataset-is-high-dimensional-e-g-100-features">Feature selection (optional but recommended if the dataset is high dimensional, e.g &gt;100 features)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#cross-correlation-of-variables">Cross correlation of variables</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sample-size-assessment">Sample size assessment</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#statistical-comparision-of-the-training-and-test-sets">Statistical comparision of the training and test sets</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-overview">Data overview</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#display-the-type-of-the-variables-columns">Display the type of the variables (columns)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#check-missing-values">Check missing values</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-imputation">Data imputation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#correlation-analysis">Correlation analysis</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#checking-the-outcome-variable-and-its-categories-binary">Checking the outcome variable and its categories (binary)</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-visualization">Data visualization</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#function-to-evaluate-models-and-generate-roc-curve-pr-curve-and-confusion-matrix">Function to evaluate models and generate ROC curve, PR curve and confusion matrix</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#initiate-machine-learning-models">Initiate machine learning models</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#variable-type-encoding-for-qlattice-model-only-required-for-qlattice">Variable type encoding for QLattice model (only required for QLattice)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#set-model-weights-based-on-class-balance-from-the-training-development-set">Set model weights based on class balance from the training (development) set</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#define-the-parameter-grid-for-random-search">Define the parameter grid for random search</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#set-parameters-for-models-when-the-datset-is-small">Set parameters for models (when the datset is small)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#k-fold-stratified-cross-validation-of-binary-classification-models">K-fold stratified cross validation of binary classification models</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#shap-summary-plot-for-when-the-model-uses-categorical-features">SHAP summary plot for when the model uses categorical features</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#qlattice-model">QLattice model</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#gaussian-naive-bayes">Gaussian Naive Bayes</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#random-forest-classifier-rf">Random Forest Classifier (RF)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#histogram-based-gradient-boosting-classification-tree-hgbc">Histogram-based Gradient Boosting Classification Tree (HGBC)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#light-gradient-boosting-machine-lightgbm">Light gradient-boosting machine (LightGBM)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#categorical-boosting-catboost">Categorical boosting (CATBoost)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#summary-of-the-cross-validation-results">summary of the cross validation results</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#statistical-test-to-compare-the-performance-of-the-models-on-cross-validation">Statistical test to compare the performance of the models on cross validation</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#model-uncertainty-reduction-mur-optional">Model Uncertainty Reduction (MUR) - optional</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#stopping-if-there-is-no-data-split">Stopping if there is no data split</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#prediction-block-for-binary-classification-models">Prediction block for binary classification models</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">QLattice model</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#test-dummy-models">Test dummy models</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">Gaussian Naive Bayes</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#logistic-regression">Logistic Regression</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#histgbc">HistGBC</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#random-forest-rf">Random Forest (RF)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#lightgbm">LightGBM</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#catboost">CatBoost</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#model-interpretation-for-the-best-performing-model">Model interpretation for the best performing model</a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#shap-values-association-with-predicted-probabilities">SHAP values association with predicted probabilities</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#interpret-the-model-based-on-shap-analysis">Interpret the model based on SHAP analysis</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#shap-summary-plot">SHAP summary plot</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#significance-of-features">Significance of features</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#model-interpretation-only-based-on-correctly-classified-samples">Model interpretation only based on correctly classified samples</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#feature-interactions-based-on-shap-method">Feature interactions based on SHAP method</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#additional-analyses-on-model-interpretation-and-evaluation">Additional analyses on model interpretation and evaluation:</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#feature-interactions-based-on-feature-permutation-method-for-feature-pairs">Feature interactions based on feature permutation method for feature pairs</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#shap-decision-plot">SHAP decision plot</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#shap-dependence-plots">SHAP dependence plots</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#shap-clustering">SHAP clustering</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#shap-force-plot-for-individuals-e-g-one-patient">SHAP force plot for individuals (e.g., one patient)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#decision-curve-analysis">Decision curve analysis</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#cost-sensitive-model-evaluation">Cost-sensitive model evaluation</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#model-calibration-and-conformal-predictions-optional">Model calibration and conformal predictions (optional)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#export-the-selected-model-to-deploy">Export the selected model to deploy</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#survival-models">Survival models</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#training-and-evaluation-of-the-survival-models">Training and evaluation of the survival models</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#concordance-index-ci-and-integrated-brier-score-ibs">Concordance Index (CI) and Integrated Brier Score (IBS)</a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#concordance-index-ci">Concordance Index (CI)</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#integrated-brier-score-ibs">Integrated Brier Score (IBS)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#k-fold-cross-validation-of-survival-models">K-fold cross validation of survival models</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#feature-importance-for-the-survival-model">feature importance for the survival model</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#predicted-survival-and-cumulative-hazard">Predicted survival and cumulative hazard</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#regression-models">Regression models</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#interpreting-regression-model-performance-metrics">Interpreting Regression Model Performance Metrics</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#model-interpretation">Model interpretation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#report-the-environment">Report the environment</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#save-the-pipeline-logs-in-html-format">Save the pipeline logs in HTML format</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#references">References</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Ramtin Zargari Marandi
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549"></script>
<script defer src="_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>